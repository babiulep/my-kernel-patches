diff -rupN a/arch/Kconfig b/arch/Kconfig
--- a/arch/Kconfig	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/Kconfig	2025-06-01 20:34:16.722109146 +0200
@@ -1137,7 +1137,7 @@ config ARCH_MMAP_RND_BITS
 	int "Number of bits to use for ASLR of mmap base address" if EXPERT
 	range ARCH_MMAP_RND_BITS_MIN ARCH_MMAP_RND_BITS_MAX
 	default ARCH_MMAP_RND_BITS_DEFAULT if ARCH_MMAP_RND_BITS_DEFAULT
-	default ARCH_MMAP_RND_BITS_MIN
+	default ARCH_MMAP_RND_BITS_MAX
 	depends on HAVE_ARCH_MMAP_RND_BITS
 	help
 	  This value can be used to select the number of bits to use to
@@ -1171,7 +1171,7 @@ config ARCH_MMAP_RND_COMPAT_BITS
 	int "Number of bits to use for ASLR of mmap base address for compatible applications" if EXPERT
 	range ARCH_MMAP_RND_COMPAT_BITS_MIN ARCH_MMAP_RND_COMPAT_BITS_MAX
 	default ARCH_MMAP_RND_COMPAT_BITS_DEFAULT if ARCH_MMAP_RND_COMPAT_BITS_DEFAULT
-	default ARCH_MMAP_RND_COMPAT_BITS_MIN
+	default ARCH_MMAP_RND_COMPAT_BITS_MAX
 	depends on HAVE_ARCH_MMAP_RND_COMPAT_BITS
 	help
 	  This value can be used to select the number of bits to use to
diff -rupN a/arch/x86/include/asm/asm-prototypes.h b/arch/x86/include/asm/asm-prototypes.h
--- a/arch/x86/include/asm/asm-prototypes.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/include/asm/asm-prototypes.h	2025-06-01 20:34:16.722109146 +0200
@@ -16,10 +16,6 @@
 #include <asm/gsseg.h>
 #include <asm/nospec-branch.h>
 
-#ifndef CONFIG_X86_CX8
-extern void cmpxchg8b_emu(void);
-#endif
-
 #ifdef CONFIG_STACKPROTECTOR
 extern unsigned long __ref_stack_chk_guard;
 #endif
diff -rupN a/arch/x86/include/asm/atomic64_32.h b/arch/x86/include/asm/atomic64_32.h
--- a/arch/x86/include/asm/atomic64_32.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/include/asm/atomic64_32.h	2025-06-01 20:34:16.723109154 +0200
@@ -48,29 +48,14 @@ static __always_inline s64 arch_atomic64
 	ATOMIC64_EXPORT(atomic64_##sym)
 #endif
 
-#ifdef CONFIG_X86_CX8
 #define __alternative_atomic64(f, g, out, in, clobbers...)		\
 	asm volatile("call %c[func]"					\
-		     : ALT_OUTPUT_SP(out) \
+		     : ALT_OUTPUT_SP(out)				\
 		     : [func] "i" (atomic64_##g##_cx8)			\
 		       COMMA(in)					\
 		     : clobbers)
 
 #define ATOMIC64_DECL(sym) ATOMIC64_DECL_ONE(sym##_cx8)
-#else
-#define __alternative_atomic64(f, g, out, in, clobbers...)		\
-	alternative_call(atomic64_##f##_386, atomic64_##g##_cx8,	\
-			 X86_FEATURE_CX8, ASM_OUTPUT(out),		\
-			 ASM_INPUT(in), clobbers)
-
-#define ATOMIC64_DECL(sym) ATOMIC64_DECL_ONE(sym##_cx8); \
-	ATOMIC64_DECL_ONE(sym##_386)
-
-ATOMIC64_DECL_ONE(add_386);
-ATOMIC64_DECL_ONE(sub_386);
-ATOMIC64_DECL_ONE(inc_386);
-ATOMIC64_DECL_ONE(dec_386);
-#endif
 
 #define alternative_atomic64(f, out, in, clobbers...) \
 	__alternative_atomic64(f, f, ASM_OUTPUT(out), ASM_INPUT(in), clobbers)
diff -rupN a/arch/x86/include/asm/cmpxchg_32.h b/arch/x86/include/asm/cmpxchg_32.h
--- a/arch/x86/include/asm/cmpxchg_32.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/include/asm/cmpxchg_32.h	2025-06-01 20:34:16.723109154 +0200
@@ -69,89 +69,11 @@ static __always_inline bool __try_cmpxch
 	return __arch_try_cmpxchg64(ptr, oldp, new,);
 }
 
-#ifdef CONFIG_X86_CX8
+#define arch_cmpxchg64			__cmpxchg64
+#define arch_cmpxchg64_local		__cmpxchg64_local
+#define arch_try_cmpxchg64		__try_cmpxchg64
+#define arch_try_cmpxchg64_local	__try_cmpxchg64_local
 
-#define arch_cmpxchg64 __cmpxchg64
-
-#define arch_cmpxchg64_local __cmpxchg64_local
-
-#define arch_try_cmpxchg64 __try_cmpxchg64
-
-#define arch_try_cmpxchg64_local __try_cmpxchg64_local
-
-#else
-
-/*
- * Building a kernel capable running on 80386 and 80486. It may be necessary
- * to simulate the cmpxchg8b on the 80386 and 80486 CPU.
- */
-
-#define __arch_cmpxchg64_emu(_ptr, _old, _new, _lock_loc, _lock)	\
-({									\
-	union __u64_halves o = { .full = (_old), },			\
-			   n = { .full = (_new), };			\
-									\
-	asm_inline volatile(						\
-		ALTERNATIVE(_lock_loc					\
-			    "call cmpxchg8b_emu",			\
-			    _lock "cmpxchg8b %a[ptr]", X86_FEATURE_CX8)	\
-		: ALT_OUTPUT_SP("+a" (o.low), "+d" (o.high))		\
-		: "b" (n.low), "c" (n.high),				\
-		  [ptr] "S" (_ptr)					\
-		: "memory");						\
-									\
-	o.full;								\
-})
-
-static __always_inline u64 arch_cmpxchg64(volatile u64 *ptr, u64 old, u64 new)
-{
-	return __arch_cmpxchg64_emu(ptr, old, new, LOCK_PREFIX_HERE, "lock ");
-}
-#define arch_cmpxchg64 arch_cmpxchg64
-
-static __always_inline u64 arch_cmpxchg64_local(volatile u64 *ptr, u64 old, u64 new)
-{
-	return __arch_cmpxchg64_emu(ptr, old, new, ,);
-}
-#define arch_cmpxchg64_local arch_cmpxchg64_local
-
-#define __arch_try_cmpxchg64_emu(_ptr, _oldp, _new, _lock_loc, _lock)	\
-({									\
-	union __u64_halves o = { .full = *(_oldp), },			\
-			   n = { .full = (_new), };			\
-	bool ret;							\
-									\
-	asm_inline volatile(						\
-		ALTERNATIVE(_lock_loc					\
-			    "call cmpxchg8b_emu",			\
-			    _lock "cmpxchg8b %a[ptr]", X86_FEATURE_CX8) \
-		CC_SET(e)						\
-		: ALT_OUTPUT_SP(CC_OUT(e) (ret),			\
-				"+a" (o.low), "+d" (o.high))		\
-		: "b" (n.low), "c" (n.high),				\
-		  [ptr] "S" (_ptr)					\
-		: "memory");						\
-									\
-	if (unlikely(!ret))						\
-		*(_oldp) = o.full;					\
-									\
-	likely(ret);							\
-})
-
-static __always_inline bool arch_try_cmpxchg64(volatile u64 *ptr, u64 *oldp, u64 new)
-{
-	return __arch_try_cmpxchg64_emu(ptr, oldp, new, LOCK_PREFIX_HERE, "lock ");
-}
-#define arch_try_cmpxchg64 arch_try_cmpxchg64
-
-static __always_inline bool arch_try_cmpxchg64_local(volatile u64 *ptr, u64 *oldp, u64 new)
-{
-	return __arch_try_cmpxchg64_emu(ptr, oldp, new, ,);
-}
-#define arch_try_cmpxchg64_local arch_try_cmpxchg64_local
-
-#endif
-
-#define system_has_cmpxchg64()		boot_cpu_has(X86_FEATURE_CX8)
+#define system_has_cmpxchg64()		1
 
 #endif /* _ASM_X86_CMPXCHG_32_H */
diff -rupN a/arch/x86/include/asm/fpu/api.h b/arch/x86/include/asm/fpu/api.h
--- a/arch/x86/include/asm/fpu/api.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/include/asm/fpu/api.h	2025-06-01 20:34:16.723109154 +0200
@@ -119,12 +119,6 @@ extern void fpu__init_system(void);
 extern void fpu__init_check_bugs(void);
 extern void fpu__resume_cpu(void);
 
-#ifdef CONFIG_MATH_EMULATION
-extern void fpstate_init_soft(struct swregs_state *soft);
-#else
-static inline void fpstate_init_soft(struct swregs_state *soft) {}
-#endif
-
 /* State tracking */
 DECLARE_PER_CPU(bool, kernel_fpu_allowed);
 DECLARE_PER_CPU(struct fpu *, fpu_fpregs_owner_ctx);
diff -rupN a/arch/x86/include/asm/percpu.h b/arch/x86/include/asm/percpu.h
--- a/arch/x86/include/asm/percpu.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/include/asm/percpu.h	2025-06-01 20:34:16.724109163 +0200
@@ -335,13 +335,10 @@ do {									\
 	old__.var = _oval;						\
 	new__.var = _nval;						\
 									\
-	asm_inline qual (						\
-		ALTERNATIVE("call this_cpu_cmpxchg8b_emu",		\
-			    "cmpxchg8b " __percpu_arg([var]), X86_FEATURE_CX8) \
-		: ALT_OUTPUT_SP([var] "+m" (__my_cpu_var(_var)),	\
-				"+a" (old__.low), "+d" (old__.high))	\
-		: "b" (new__.low), "c" (new__.high),			\
-		  "S" (&(_var))						\
+	asm qual ("cmpxchg8b " __percpu_arg([var])			\
+		: "+m" (__my_cpu_var(_var)),				\
+		  "+a" (old__.low), "+d" (old__.high)			\
+		: "b" (new__.low), "c" (new__.high)			\
 		: "memory");						\
 									\
 	old__.var;							\
@@ -364,15 +361,12 @@ do {									\
 	old__.var = *_oval;						\
 	new__.var = _nval;						\
 									\
-	asm_inline qual (						\
-		ALTERNATIVE("call this_cpu_cmpxchg8b_emu",		\
-			    "cmpxchg8b " __percpu_arg([var]), X86_FEATURE_CX8) \
+	asm qual ("cmpxchg8b " __percpu_arg([var])			\
 		CC_SET(z)						\
-		: ALT_OUTPUT_SP(CC_OUT(z) (success),			\
-				[var] "+m" (__my_cpu_var(_var)),	\
-				"+a" (old__.low), "+d" (old__.high))	\
-		: "b" (new__.low), "c" (new__.high),			\
-		  "S" (&(_var))						\
+		: CC_OUT(z) (success),					\
+		  [var] "+m" (__my_cpu_var(_var)),			\
+		  "+a" (old__.low), "+d" (old__.high)			\
+		: "b" (new__.low), "c" (new__.high)			\
 		: "memory");						\
 	if (unlikely(!success))						\
 		*_oval = old__.var;					\
diff -rupN a/arch/x86/include/asm/timex.h b/arch/x86/include/asm/timex.h
--- a/arch/x86/include/asm/timex.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/include/asm/timex.h	2025-06-01 20:34:16.724109163 +0200
@@ -7,8 +7,7 @@
 
 static inline unsigned long random_get_entropy(void)
 {
-	if (!IS_ENABLED(CONFIG_X86_TSC) &&
-	    !cpu_feature_enabled(X86_FEATURE_TSC))
+	if (!cpu_feature_enabled(X86_FEATURE_TSC))
 		return random_get_entropy_fallback();
 	return rdtsc();
 }
diff -rupN a/arch/x86/include/asm/topology.h b/arch/x86/include/asm/topology.h
--- a/arch/x86/include/asm/topology.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/include/asm/topology.h	2025-06-01 20:34:16.725109171 +0200
@@ -255,6 +255,7 @@ extern bool __read_mostly sysctl_sched_i
 
 /* Interface to set priority of a cpu */
 void sched_set_itmt_core_prio(int prio, int core_cpu);
+void sched_set_itmt_power_ratio(int power_ratio, int core_cpu);
 
 /* Interface to notify scheduler that system supports ITMT */
 int sched_set_itmt_support(void);
diff -rupN a/arch/x86/include/asm/trace_clock.h b/arch/x86/include/asm/trace_clock.h
--- a/arch/x86/include/asm/trace_clock.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/include/asm/trace_clock.h	2025-06-01 20:34:16.725109171 +0200
@@ -5,17 +5,9 @@
 #include <linux/compiler.h>
 #include <linux/types.h>
 
-#ifdef CONFIG_X86_TSC
-
 extern u64 notrace trace_clock_x86_tsc(void);
 
 # define ARCH_TRACE_CLOCKS \
 	{ trace_clock_x86_tsc,	"x86-tsc",	.in_ns = 0 },
 
-#else /* !CONFIG_X86_TSC */
-
-#define ARCH_TRACE_CLOCKS
-
-#endif
-
 #endif  /* _ASM_X86_TRACE_CLOCK_H */
diff -rupN a/arch/x86/include/asm/tsc.h b/arch/x86/include/asm/tsc.h
--- a/arch/x86/include/asm/tsc.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/include/asm/tsc.h	2025-06-01 20:34:16.725109171 +0200
@@ -76,8 +76,7 @@ extern void disable_TSC(void);
 
 static inline cycles_t get_cycles(void)
 {
-	if (!IS_ENABLED(CONFIG_X86_TSC) &&
-	    !cpu_feature_enabled(X86_FEATURE_TSC))
+	if (!cpu_feature_enabled(X86_FEATURE_TSC))
 		return 0;
 	return rdtsc();
 }
@@ -94,25 +93,15 @@ extern unsigned long native_calibrate_ts
 extern unsigned long long native_sched_clock_from_tsc(u64 tsc);
 
 extern int tsc_clocksource_reliable;
-#ifdef CONFIG_X86_TSC
 extern bool tsc_async_resets;
-#else
-# define tsc_async_resets	false
-#endif
 
 /*
  * Boot-time check whether the TSCs are synchronized across
  * all CPUs/cores:
  */
-#ifdef CONFIG_X86_TSC
 extern bool tsc_store_and_check_tsc_adjust(bool bootcpu);
 extern void tsc_verify_tsc_adjust(bool resume);
 extern void check_tsc_sync_target(void);
-#else
-static inline bool tsc_store_and_check_tsc_adjust(bool bootcpu) { return false; }
-static inline void tsc_verify_tsc_adjust(bool resume) { }
-static inline void check_tsc_sync_target(void) { }
-#endif
 
 extern int notsc_setup(char *);
 extern void tsc_save_sched_clock_state(void);
diff -rupN a/arch/x86/include/asm/vermagic.h b/arch/x86/include/asm/vermagic.h
--- a/arch/x86/include/asm/vermagic.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/include/asm/vermagic.h	2025-06-01 20:34:16.726109179 +0200
@@ -5,12 +5,6 @@
 
 #ifdef CONFIG_X86_64
 /* X86_64 does not define MODULE_PROC_FAMILY */
-#elif defined CONFIG_M486SX
-#define MODULE_PROC_FAMILY "486SX "
-#elif defined CONFIG_M486
-#define MODULE_PROC_FAMILY "486 "
-#elif defined CONFIG_M586
-#define MODULE_PROC_FAMILY "586 "
 #elif defined CONFIG_M586TSC
 #define MODULE_PROC_FAMILY "586TSC "
 #elif defined CONFIG_M586MMX
@@ -31,16 +25,10 @@
 #define MODULE_PROC_FAMILY "K6 "
 #elif defined CONFIG_MK7
 #define MODULE_PROC_FAMILY "K7 "
-#elif defined CONFIG_MELAN
-#define MODULE_PROC_FAMILY "ELAN "
 #elif defined CONFIG_MCRUSOE
 #define MODULE_PROC_FAMILY "CRUSOE "
 #elif defined CONFIG_MEFFICEON
 #define MODULE_PROC_FAMILY "EFFICEON "
-#elif defined CONFIG_MWINCHIPC6
-#define MODULE_PROC_FAMILY "WINCHIPC6 "
-#elif defined CONFIG_MWINCHIP3D
-#define MODULE_PROC_FAMILY "WINCHIP3D "
 #elif defined CONFIG_MCYRIXIII
 #define MODULE_PROC_FAMILY "CYRIXIII "
 #elif defined CONFIG_MVIAC3_2
diff -rupN a/arch/x86/Kconfig b/arch/x86/Kconfig
--- a/arch/x86/Kconfig	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/Kconfig	2025-06-01 20:34:16.727109187 +0200
@@ -137,7 +137,7 @@ config X86
 	select ARCH_SUPPORTS_AUTOFDO_CLANG
 	select ARCH_SUPPORTS_PROPELLER_CLANG    if X86_64
 	select ARCH_USE_BUILTIN_BSWAP
-	select ARCH_USE_CMPXCHG_LOCKREF		if X86_CX8
+	select ARCH_USE_CMPXCHG_LOCKREF
 	select ARCH_USE_MEMTEST
 	select ARCH_USE_QUEUED_RWLOCKS
 	select ARCH_USE_QUEUED_SPINLOCKS
@@ -447,11 +447,6 @@ config SMP
 	  uniprocessor machines. On a uniprocessor machine, the kernel
 	  will run faster if you say N here.
 
-	  Note that if you say Y here and choose architecture "586" or
-	  "Pentium" under "Processor family", the kernel will not work on 486
-	  architectures. Similarly, multiprocessor kernels for the "PPro"
-	  architecture may not work on all Pentium based boards.
-
 	  People using multiprocessor machines who say Y here should also say
 	  Y to "Enhanced Real Time Clock Support", below. The "Advanced Power
 	  Management" code will be disabled if you say Y here.
@@ -662,7 +657,6 @@ config X86_INTEL_QUARK
 	depends on X86_32
 	depends on X86_EXTENDED_PLATFORM
 	depends on X86_PLATFORM_DEVICES
-	depends on X86_TSC
 	depends on PCI
 	depends on PCI_GOANY
 	depends on X86_IO_APIC
@@ -674,17 +668,6 @@ config X86_INTEL_QUARK
 	  Say Y here if you have a Quark based system such as the Arduino
 	  compatible Intel Galileo.
 
-config X86_RDC321X
-	bool "RDC R-321x SoC"
-	depends on X86_32
-	depends on X86_EXTENDED_PLATFORM
-	select M486
-	select X86_REBOOTFIXUPS
-	help
-	  This option is needed for RDC R-321x system-on-chip, also known
-	  as R-8610-(G).
-	  If you don't have one of these chips, you should say N here.
-
 config X86_INTEL_LPSS
 	bool "Intel Low Power Subsystem Support"
 	depends on X86 && ACPI && PCI
@@ -1629,33 +1612,6 @@ config X86_BOOTPARAM_MEMORY_CORRUPTION_C
 	  Set whether the default state of memory_corruption_check is
 	  on or off.
 
-config MATH_EMULATION
-	bool
-	depends on MODIFY_LDT_SYSCALL
-	prompt "Math emulation" if X86_32 && (M486SX || MELAN)
-	help
-	  Linux can emulate a math coprocessor (used for floating point
-	  operations) if you don't have one. 486DX and Pentium processors have
-	  a math coprocessor built in, 486SX and 386 do not, unless you added
-	  a 487DX or 387, respectively. (The messages during boot time can
-	  give you some hints here ["man dmesg"].) Everyone needs either a
-	  coprocessor or this emulation.
-
-	  If you don't have a math coprocessor, you need to say Y here; if you
-	  say Y here even though you have a coprocessor, the coprocessor will
-	  be used nevertheless. (This behavior can be changed with the kernel
-	  command line option "no387", which comes handy if your coprocessor
-	  is broken. Try "man bootparam" or see the documentation of your boot
-	  loader (lilo or loadlin) about how to pass options to the kernel at
-	  boot time.) This means that it is a good idea to say Y here if you
-	  intend to use this kernel on different machines.
-
-	  More information about the internals of the Linux math coprocessor
-	  emulation can be found in <file:arch/x86/math-emu/README>.
-
-	  If you are not sure, say Y; apart from resulting in a 66 KB bigger
-	  kernel, it won't hurt.
-
 config MTRR
 	def_bool y
 	prompt "MTRR (Memory Type Range Register) support" if EXPERT
@@ -1759,7 +1715,7 @@ config CC_HAS_IBT
 	# Clang/LLVM >= 14
 	# https://github.com/llvm/llvm-project/commit/e0b89df2e0f0130881bf6c39bf31d7f6aac00e0f
 	# https://github.com/llvm/llvm-project/commit/dfcf69770bc522b9e411c66454934a37c1f35332
-	def_bool ((CC_IS_GCC && $(cc-option, -fcf-protection=branch -mindirect-branch-register)) || \
+	def_bool ((CC_IS_GCC && $(cc-option, -fcf-protection=none -mindirect-branch-register)) || \
 		  (CC_IS_CLANG && CLANG_VERSION >= 140000)) && \
 		  $(as-instr,endbr64)
 
@@ -2379,7 +2335,7 @@ config USE_X86_SEG_SUPPORT
 	depends on CC_HAS_NAMED_AS_FIXED_SANITIZERS
 
 config CC_HAS_SLS
-	def_bool $(cc-option,-mharden-sls=all)
+	def_bool $(cc-option,-mharden-sls=none)
 
 config CC_HAS_RETURN_THUNK
 	def_bool $(cc-option,-mfunction-return=thunk-extern)
@@ -2741,11 +2697,6 @@ menuconfig APM
 	  manpage ("man 8 hdparm") for that), and it doesn't turn off
 	  VESA-compliant "green" monitors.
 
-	  This driver does not support the TI 4000M TravelMate and the ACER
-	  486/DX4/75 because they don't have compliant BIOSes. Many "green"
-	  desktop machines also don't have compliant BIOSes, and this driver
-	  may cause those machines to panic during the boot phase.
-
 	  Generally, if you don't have a battery in your machine, there isn't
 	  much point in using this driver and you should say N. If you get
 	  random kernel OOPSes or reboots that don't seem to be related to
@@ -2758,18 +2709,16 @@ menuconfig APM
 	  1) make sure that you have enough swap space and that it is
 	  enabled.
 	  2) pass the "idle=poll" option to the kernel
-	  3) switch on floating point emulation in the kernel and pass
-	  the "no387" option to the kernel
-	  4) pass the "floppy=nodma" option to the kernel
-	  5) pass the "mem=4M" option to the kernel (thereby disabling
+	  3) pass the "floppy=nodma" option to the kernel
+	  4) pass the "mem=4M" option to the kernel (thereby disabling
 	  all but the first 4 MB of RAM)
-	  6) make sure that the CPU is not over clocked.
-	  7) read the sig11 FAQ at <http://www.bitwizard.nl/sig11/>
-	  8) disable the cache from your BIOS settings
-	  9) install a fan for the video card or exchange video RAM
-	  10) install a better fan for the CPU
-	  11) exchange RAM chips
-	  12) exchange the motherboard.
+	  5) make sure that the CPU is not over clocked.
+	  6) read the sig11 FAQ at <http://www.bitwizard.nl/sig11/>
+	  7) disable the cache from your BIOS settings
+	  8) install a fan for the video card or exchange video RAM
+	  9) install a better fan for the CPU
+	  10) exchange RAM chips
+	  11) exchange the motherboard.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called apm.
diff -rupN a/arch/x86/Kconfig.cpu b/arch/x86/Kconfig.cpu
--- a/arch/x86/Kconfig.cpu	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/Kconfig.cpu	2025-06-01 20:34:16.728109195 +0200
@@ -8,19 +8,18 @@ choice
 	  This is the processor type of your CPU. This information is
 	  used for optimizing purposes. In order to compile a kernel
 	  that can run on all supported x86 CPU types (albeit not
-	  optimally fast), you can specify "486" here.
+	  optimally fast), you can specify "586" here.
 
-	  Note that the 386 is no longer supported, this includes
+	  Note that the 386 and 486 is no longer supported, this includes
 	  AMD/Cyrix/Intel 386DX/DXL/SL/SLC/SX, Cyrix/TI 486DLC/DLC2,
-	  UMC 486SX-S and the NexGen Nx586.
+	  UMC 486SX-S and the NexGen Nx586, AMD ELAN and all 486 based
+	  CPUs.
 
 	  The kernel will not necessarily run on earlier architectures than
 	  the one you have chosen, e.g. a Pentium optimized kernel will run on
 	  a PPro, but not necessarily on a i486.
 
 	  Here are the settings recommended for greatest speed:
-	  - "486" for the AMD/Cyrix/IBM/Intel 486DX/DX2/DX4 or
-	    SL/SLC/SLC2/SLC3/SX/SX2 and UMC U5D or U5S.
 	  - "586" for generic Pentium CPUs lacking the TSC
 	    (time stamp counter) register.
 	  - "Pentium-Classic" for the Intel Pentium.
@@ -33,8 +32,6 @@ choice
 	  - "Athlon" for the AMD K7 family (Athlon/Duron/Thunderbird).
 	  - "Crusoe" for the Transmeta Crusoe series.
 	  - "Efficeon" for the Transmeta Efficeon series.
-	  - "Winchip-C6" for original IDT Winchip.
-	  - "Winchip-2" for IDT Winchips with 3dNow! capabilities.
 	  - "AMD Elan" for the 32-bit AMD Elan embedded CPU.
 	  - "GeodeGX1" for Geode GX1 (Cyrix MediaGX).
 	  - "Geode GX/LX" For AMD Geode GX and LX processors.
@@ -46,28 +43,6 @@ choice
 	  See each option's help text for additional details. If you don't know
 	  what to do, choose "Pentium-Pro".
 
-config M486SX
-	bool "486SX"
-	depends on X86_32
-	help
-	  Select this for an 486-class CPU without an FPU such as
-	  AMD/Cyrix/IBM/Intel SL/SLC/SLC2/SLC3/SX/SX2 and UMC U5S.
-
-config M486
-	bool "486DX"
-	depends on X86_32
-	help
-	  Select this for an 486-class CPU such as AMD/Cyrix/IBM/Intel
-	  486DX/DX2/DX4 and UMC U5D.
-
-config M586
-	bool "586/K5/5x86/6x86/6x86MX"
-	depends on X86_32
-	help
-	  Select this for an 586 or 686 series processor such as the AMD K5,
-	  the Cyrix 5x86, 6x86 and 6x86MX.  This choice does not
-	  assume the RDTSC (Read Time Stamp Counter) instruction.
-
 config M586TSC
 	bool "Pentium-Classic"
 	depends on X86_32
@@ -170,32 +145,6 @@ config MEFFICEON
 	help
 	  Select this for a Transmeta Efficeon processor.
 
-config MWINCHIPC6
-	bool "Winchip-C6"
-	depends on X86_32
-	help
-	  Select this for an IDT Winchip C6 chip.  Linux and GCC
-	  treat this chip as a 586TSC with some extended instructions
-	  and alignment requirements.
-
-config MWINCHIP3D
-	bool "Winchip-2/Winchip-2A/Winchip-3"
-	depends on X86_32
-	help
-	  Select this for an IDT Winchip-2, 2A or 3.  Linux and GCC
-	  treat this chip as a 586TSC with some extended instructions
-	  and alignment requirements.  Also enable out of order memory
-	  stores for this CPU, which can increase performance of some
-	  operations.
-
-config MELAN
-	bool "AMD Elan"
-	depends on X86_32
-	help
-	  Select this for an AMD Elan processor.
-
-	  Do not use this option for K6/Athlon/Opteron processors!
-
 config MGEODEGX1
 	bool "GeodeGX1"
 	depends on X86_32
@@ -292,20 +241,16 @@ config X86_L1_CACHE_SHIFT
 	int
 	default "7" if MPENTIUM4
 	default "6" if MK7 || MPENTIUMM || MATOM || MVIAC7 || X86_GENERIC || X86_64
-	default "4" if MELAN || M486SX || M486 || MGEODEGX1
-	default "5" if MWINCHIP3D || MWINCHIPC6 || MCRUSOE || MEFFICEON || MCYRIXIII || MK6 || MPENTIUMIII || MPENTIUMII || M686 || M586MMX || M586TSC || M586 || MVIAC3_2 || MGEODE_LX
+	default "4" if MGEODEGX1
+	default "5" if MCRUSOE || MEFFICEON || MCYRIXIII || MK6 || MPENTIUMIII || MPENTIUMII || M686 || M586MMX || M586TSC || MVIAC3_2 || MGEODE_LX
 
 config X86_F00F_BUG
 	def_bool y
-	depends on M586MMX || M586TSC || M586 || M486SX || M486
-
-config X86_INVD_BUG
-	def_bool y
-	depends on M486SX || M486
+	depends on M586MMX || M586TSC || M586
 
 config X86_ALIGNMENT_16
 	def_bool y
-	depends on MWINCHIP3D || MWINCHIPC6 || MCYRIXIII || MELAN || MK6 || M586MMX || M586TSC || M586 || M486SX || M486 || MVIAC3_2 || MGEODEGX1
+	depends on MCYRIXIII || MK6 || M586MMX || M586TSC || M586 || MVIAC3_2 || MGEODEGX1
 
 config X86_INTEL_USERCOPY
 	def_bool y
@@ -313,11 +258,10 @@ config X86_INTEL_USERCOPY
 
 config X86_USE_PPRO_CHECKSUM
 	def_bool y
-	depends on MWINCHIP3D || MWINCHIPC6 || MCYRIXIII || MK7 || MK6 || MPENTIUM4 || MPENTIUMM || MPENTIUMIII || MPENTIUMII || M686 || MVIAC3_2 || MVIAC7 || MEFFICEON || MGEODE_LX || MATOM
+	depends on MCYRIXIII || MK7 || MK6 || MPENTIUM4 || MPENTIUMM || MPENTIUMIII || MPENTIUMII || M686 || MVIAC3_2 || MVIAC7 || MEFFICEON || MGEODE_LX || MATOM
 
 config X86_TSC
 	def_bool y
-	depends on (MWINCHIP3D || MCRUSOE || MEFFICEON || MCYRIXIII || MK7 || MK6 || MPENTIUM4 || MPENTIUMM || MPENTIUMIII || MPENTIUMII || M686 || M586MMX || M586TSC || MVIAC3_2 || MVIAC7 || MGEODEGX1 || MGEODE_LX || MATOM) || X86_64
 
 config X86_HAVE_PAE
 	def_bool y
@@ -325,7 +269,6 @@ config X86_HAVE_PAE
 
 config X86_CX8
 	def_bool y
-	depends on X86_HAVE_PAE || M586TSC || M586MMX || MK6 || MK7 || MGEODEGX1 || MGEODE_LX
 
 # this should be set for all -march=.. options where the compiler
 # generates cmov.
@@ -337,12 +280,11 @@ config X86_MINIMUM_CPU_FAMILY
 	int
 	default "64" if X86_64
 	default "6" if X86_32 && (MPENTIUM4 || MPENTIUMM || MPENTIUMIII || MPENTIUMII || M686 || MVIAC3_2 || MVIAC7 || MEFFICEON || MATOM || MK7)
-	default "5" if X86_32 && X86_CX8
-	default "4"
+	default "5" if X86_32
 
 config X86_DEBUGCTLMSR
 	def_bool y
-	depends on !(MK6 || MWINCHIPC6 || MWINCHIP3D || MCYRIXIII || M586MMX || M586TSC || M586 || M486SX || M486) && !UML
+	depends on !(MK6 || MCYRIXIII || M586MMX || M586TSC || M586) && !UML
 
 config IA32_FEAT_CTL
 	def_bool y
@@ -378,7 +320,7 @@ config CPU_SUP_INTEL
 config CPU_SUP_CYRIX_32
 	default y
 	bool "Support Cyrix processors" if PROCESSOR_SELECT
-	depends on M486SX || M486 || M586 || M586TSC || M586MMX || (EXPERT && !64BIT)
+	depends on M586 || M586TSC || M586MMX || (EXPERT && !64BIT)
 	help
 	  This enables detection, tunings and quirks for Cyrix processors
 
@@ -442,20 +384,6 @@ config CPU_SUP_TRANSMETA_32
 	  CPU might render the kernel unbootable.
 
 	  If unsure, say N.
-
-config CPU_SUP_UMC_32
-	default y
-	bool "Support UMC processors" if PROCESSOR_SELECT
-	depends on M486SX || M486 || (EXPERT && !64BIT)
-	help
-	  This enables detection, tunings and quirks for UMC processors
-
-	  You need this enabled if you want your kernel to run on a
-	  UMC CPU. Disabling this option on other types of CPUs
-	  makes the kernel a tiny bit smaller. Disabling it on a UMC
-	  CPU might render the kernel unbootable.
-
-	  If unsure, say N.
 
 config CPU_SUP_ZHAOXIN
 	default y
diff -rupN a/arch/x86/Kconfig.cpufeatures b/arch/x86/Kconfig.cpufeatures
--- a/arch/x86/Kconfig.cpufeatures	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/Kconfig.cpufeatures	2025-06-01 20:34:16.728109195 +0200
@@ -42,7 +42,6 @@ config X86_REQUIRED_FEATURE_NOPL
 
 config X86_REQUIRED_FEATURE_CX8
 	def_bool y
-	depends on X86_CX8
 
 # this should be set for all -march=.. options where the compiler
 # generates cmov.
@@ -66,7 +65,6 @@ config X86_REQUIRED_FEATURE_UP
 
 config X86_REQUIRED_FEATURE_FPU
 	def_bool y
-	depends on !MATH_EMULATION
 
 config X86_REQUIRED_FEATURE_PAE
 	def_bool y
diff -rupN a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c
--- a/arch/x86/kernel/cpu/common.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/kernel/cpu/common.c	2025-06-01 20:34:16.729109203 +0200
@@ -1655,13 +1655,6 @@ static void __init cpu_parse_early_param
 	int arglen;
 
 #ifdef CONFIG_X86_32
-	if (cmdline_find_option_bool(boot_command_line, "no387"))
-#ifdef CONFIG_MATH_EMULATION
-		setup_clear_cpu_cap(X86_FEATURE_FPU);
-#else
-		pr_err("Option 'no387' required CONFIG_MATH_EMULATION enabled.\n");
-#endif
-
 	if (cmdline_find_option_bool(boot_command_line, "nofxsr"))
 		setup_clear_cpu_cap(X86_FEATURE_FXSR);
 #endif
diff -rupN a/arch/x86/kernel/cpu/intel_epb.c b/arch/x86/kernel/cpu/intel_epb.c
--- a/arch/x86/kernel/cpu/intel_epb.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/kernel/cpu/intel_epb.c	2025-06-01 20:34:16.730109211 +0200
@@ -166,6 +166,10 @@ static ssize_t energy_perf_bias_store(st
 	if (ret < 0)
 		return ret;
 
+	/* update the ITMT scheduler logic to use the power policy data */
+	/* scale the val up by 2 so the range is 224 - 256 */
+	sched_set_itmt_power_ratio(256 - val * 2, cpu);
+
 	return count;
 }
 
diff -rupN a/arch/x86/kernel/cpu/umc.c b/arch/x86/kernel/cpu/umc.c
--- a/arch/x86/kernel/cpu/umc.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/kernel/cpu/umc.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,26 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-#include <linux/kernel.h>
-#include <asm/processor.h>
-#include "cpu.h"
-
-/*
- * UMC chips appear to be only either 386 or 486,
- * so no special init takes place.
- */
-
-static const struct cpu_dev umc_cpu_dev = {
-	.c_vendor	= "UMC",
-	.c_ident	= { "UMC UMC UMC" },
-	.legacy_models	= {
-		{ .family = 4, .model_names =
-		  {
-			  [1] = "U5D",
-			  [2] = "U5S",
-		  }
-		},
-	},
-	.c_x86_vendor	= X86_VENDOR_UMC,
-};
-
-cpu_dev_register(umc_cpu_dev);
-
diff -rupN a/arch/x86/kernel/fpu/core.c b/arch/x86/kernel/fpu/core.c
--- a/arch/x86/kernel/fpu/core.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/kernel/fpu/core.c	2025-06-01 20:34:16.731109219 +0200
@@ -528,11 +528,6 @@ static inline void fpstate_init_fstate(s
  */
 void fpstate_init_user(struct fpstate *fpstate)
 {
-	if (!cpu_feature_enabled(X86_FEATURE_FPU)) {
-		fpstate_init_soft(&fpstate->regs.soft);
-		return;
-	}
-
 	xstate_init_xcomp_bv(&fpstate->regs.xsave, fpstate->xfeatures);
 
 	if (cpu_feature_enabled(X86_FEATURE_FXSR))
diff -rupN a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
--- a/arch/x86/kernel/fpu/init.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/kernel/fpu/init.c	2025-06-01 20:34:16.731109219 +0200
@@ -36,12 +36,7 @@ static void fpu__init_cpu_generic(void)
 	write_cr0(cr0);
 
 	/* Flush out any pending x87 state: */
-#ifdef CONFIG_MATH_EMULATION
-	if (!boot_cpu_has(X86_FEATURE_FPU))
-		;
-	else
-#endif
-		asm volatile ("fninit");
+	asm volatile ("fninit");
 }
 
 /*
@@ -86,13 +81,11 @@ static void __init fpu__init_system_earl
 			setup_clear_cpu_cap(X86_FEATURE_FPU);
 	}
 
-#ifndef CONFIG_MATH_EMULATION
 	if (!test_cpu_cap(&boot_cpu_data, X86_FEATURE_FPU)) {
 		pr_emerg("x86/fpu: Giving up, no FPU found and no math emulation present\n");
 		for (;;)
 			asm volatile("hlt");
 	}
-#endif
 }
 
 /*
diff -rupN a/arch/x86/kernel/i8253.c b/arch/x86/kernel/i8253.c
--- a/arch/x86/kernel/i8253.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/kernel/i8253.c	2025-06-01 20:34:16.731109219 +0200
@@ -31,7 +31,7 @@ struct clock_event_device *global_clock_
  */
 static bool __init use_pit(void)
 {
-	if (!IS_ENABLED(CONFIG_X86_TSC) || !boot_cpu_has(X86_FEATURE_TSC))
+	if (!boot_cpu_has(X86_FEATURE_TSC))
 		return true;
 
 	/* This also returns true when APIC is disabled */
diff -rupN a/arch/x86/kernel/itmt.c b/arch/x86/kernel/itmt.c
--- a/arch/x86/kernel/itmt.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/kernel/itmt.c	2025-06-01 20:34:16.732109228 +0200
@@ -26,6 +26,7 @@
 
 static DEFINE_MUTEX(itmt_update_mutex);
 DEFINE_PER_CPU_READ_MOSTLY(int, sched_core_priority);
+DEFINE_PER_CPU_READ_MOSTLY(int, sched_power_ratio);
 
 /* Boolean to track if system has ITMT capabilities */
 static bool __read_mostly sched_itmt_capable;
@@ -144,7 +145,12 @@ void sched_clear_itmt_support(void)
 
 int arch_asym_cpu_priority(int cpu)
 {
-	return per_cpu(sched_core_priority, cpu);
+	int power_ratio = per_cpu(sched_power_ratio, cpu);
+
+	/* a power ratio of 0 (uninitialized) is assumed to be maximum */
+	if (power_ratio == 0)
+		power_ratio = 256 - 2 * 6;
+	return per_cpu(sched_core_priority, cpu) * power_ratio / 256;
 }
 
 /**
@@ -165,3 +171,24 @@ void sched_set_itmt_core_prio(int prio,
 {
 	per_cpu(sched_core_priority, cpu) = prio;
 }
+
+/**
+ * sched_set_itmt_power_ratio() - Set CPU priority based on ITMT
+ * @power_ratio:	The power scaling ratio [1..256] for the core
+ * @core_cpu:		The cpu number associated with the core
+ *
+ * Set a scaling to the cpu performance based on long term power
+ * settings (like EPB).
+ *
+ * Note this is for the policy not for the actual dynamic frequency;
+ * the frequency will increase itself as workloads run on a core.
+ */
+
+void sched_set_itmt_power_ratio(int power_ratio, int core_cpu)
+{
+	int cpu;
+
+	for_each_cpu(cpu, topology_sibling_cpumask(core_cpu)) {
+		per_cpu(sched_power_ratio, cpu) = power_ratio;
+	}
+}
diff -rupN a/arch/x86/kernel/Makefile b/arch/x86/kernel/Makefile
--- a/arch/x86/kernel/Makefile	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/kernel/Makefile	2025-06-01 20:34:16.732109228 +0200
@@ -94,7 +94,7 @@ apm-y				:= apm_32.o
 obj-$(CONFIG_APM)		+= apm.o
 obj-$(CONFIG_SMP)		+= smp.o
 obj-$(CONFIG_SMP)		+= smpboot.o
-obj-$(CONFIG_X86_TSC)		+= tsc_sync.o
+obj-y				+= tsc_sync.o
 obj-$(CONFIG_SMP)		+= setup_percpu.o
 obj-$(CONFIG_X86_MPPARSE)	+= mpparse.o
 obj-y				+= apic/
@@ -103,7 +103,7 @@ obj-$(CONFIG_DYNAMIC_FTRACE)	+= ftrace.o
 obj-$(CONFIG_FUNCTION_TRACER)	+= ftrace_$(BITS).o
 obj-$(CONFIG_FUNCTION_GRAPH_TRACER) += ftrace.o
 obj-$(CONFIG_FTRACE_SYSCALLS)	+= ftrace.o
-obj-$(CONFIG_X86_TSC)		+= trace_clock.o
+obj-y				+= trace_clock.o
 obj-$(CONFIG_TRACING)		+= trace.o
 obj-$(CONFIG_RETHOOK)		+= rethook.o
 obj-$(CONFIG_VMCORE_INFO)	+= vmcore_info_$(BITS).o
diff -rupN a/arch/x86/kernel/traps.c b/arch/x86/kernel/traps.c
--- a/arch/x86/kernel/traps.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/kernel/traps.c	2025-06-01 20:34:16.733109236 +0200
@@ -1346,13 +1346,6 @@ DEFINE_IDTENTRY(exc_coprocessor_error)
 
 DEFINE_IDTENTRY(exc_simd_coprocessor_error)
 {
-	if (IS_ENABLED(CONFIG_X86_INVD_BUG)) {
-		/* AMD 486 bug: INVD in CPL 0 raises #XF instead of #GP */
-		if (!static_cpu_has(X86_FEATURE_XMM)) {
-			__exc_general_protection(regs, 0);
-			return;
-		}
-	}
 	math_error(regs, X86_TRAP_XF);
 }
 
@@ -1421,20 +1414,6 @@ DEFINE_IDTENTRY(exc_device_not_available
 	if (handle_xfd_event(regs))
 		return;
 
-#ifdef CONFIG_MATH_EMULATION
-	if (!boot_cpu_has(X86_FEATURE_FPU) && (cr0 & X86_CR0_EM)) {
-		struct math_emu_info info = { };
-
-		cond_local_irq_enable(regs);
-
-		info.regs = regs;
-		math_emulate(&info);
-
-		cond_local_irq_disable(regs);
-		return;
-	}
-#endif
-
 	/* This should not happen. */
 	if (WARN(cr0 & X86_CR0_TS, "CR0.TS was set")) {
 		/* Try to fix it up and carry on. */
diff -rupN a/arch/x86/kernel/tsc.c b/arch/x86/kernel/tsc.c
--- a/arch/x86/kernel/tsc.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/kernel/tsc.c	2025-06-01 20:34:16.734109244 +0200
@@ -296,24 +296,11 @@ int check_tsc_unstable(void)
 }
 EXPORT_SYMBOL_GPL(check_tsc_unstable);
 
-#ifdef CONFIG_X86_TSC
 int __init notsc_setup(char *str)
 {
 	mark_tsc_unstable("boot parameter notsc");
 	return 1;
 }
-#else
-/*
- * disable flag for tsc. Takes effect by clearing the TSC cpu flag
- * in cpu/common.c
- */
-int __init notsc_setup(char *str)
-{
-	setup_clear_cpu_cap(X86_FEATURE_TSC);
-	return 1;
-}
-#endif
-
 __setup("notsc", notsc_setup);
 
 static int no_sched_irq_time;
@@ -1597,6 +1584,9 @@ unsigned long calibrate_delay_is_known(v
 	if (!constant_tsc || !mask)
 		return 0;
 
+	if (cpu != 0)
+		return cpu_data(0).loops_per_jiffy;
+
 	sibling = cpumask_any_but(mask, cpu);
 	if (sibling < nr_cpu_ids)
 		return cpu_data(sibling).loops_per_jiffy;
diff -rupN a/arch/x86/lib/atomic64_386_32.S b/arch/x86/lib/atomic64_386_32.S
--- a/arch/x86/lib/atomic64_386_32.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/lib/atomic64_386_32.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,195 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0-or-later */
-/*
- * atomic64_t for 386/486
- *
- * Copyright © 2010  Luca Barbieri
- */
-
-#include <linux/linkage.h>
-#include <asm/alternative.h>
-
-/* if you want SMP support, implement these with real spinlocks */
-.macro IRQ_SAVE reg
-	pushfl
-	cli
-.endm
-
-.macro IRQ_RESTORE reg
-	popfl
-.endm
-
-#define BEGIN_IRQ_SAVE(op) \
-.macro endp; \
-SYM_FUNC_END(atomic64_##op##_386); \
-.purgem endp; \
-.endm; \
-SYM_FUNC_START(atomic64_##op##_386); \
-	IRQ_SAVE v;
-
-#define ENDP endp
-
-#define RET_IRQ_RESTORE \
-	IRQ_RESTORE v; \
-	RET
-
-#define v %ecx
-BEGIN_IRQ_SAVE(read)
-	movl  (v), %eax
-	movl 4(v), %edx
-	RET_IRQ_RESTORE
-ENDP
-#undef v
-
-#define v %esi
-BEGIN_IRQ_SAVE(set)
-	movl %ebx,  (v)
-	movl %ecx, 4(v)
-	RET_IRQ_RESTORE
-ENDP
-#undef v
-
-#define v  %esi
-BEGIN_IRQ_SAVE(xchg)
-	movl  (v), %eax
-	movl 4(v), %edx
-	movl %ebx,  (v)
-	movl %ecx, 4(v)
-	RET_IRQ_RESTORE
-ENDP
-#undef v
-
-#define v %ecx
-BEGIN_IRQ_SAVE(add)
-	addl %eax,  (v)
-	adcl %edx, 4(v)
-	RET_IRQ_RESTORE
-ENDP
-#undef v
-
-#define v %ecx
-BEGIN_IRQ_SAVE(add_return)
-	addl  (v), %eax
-	adcl 4(v), %edx
-	movl %eax,  (v)
-	movl %edx, 4(v)
-	RET_IRQ_RESTORE
-ENDP
-#undef v
-
-#define v %ecx
-BEGIN_IRQ_SAVE(sub)
-	subl %eax,  (v)
-	sbbl %edx, 4(v)
-	RET_IRQ_RESTORE
-ENDP
-#undef v
-
-#define v %ecx
-BEGIN_IRQ_SAVE(sub_return)
-	negl %edx
-	negl %eax
-	sbbl $0, %edx
-	addl  (v), %eax
-	adcl 4(v), %edx
-	movl %eax,  (v)
-	movl %edx, 4(v)
-	RET_IRQ_RESTORE
-ENDP
-#undef v
-
-#define v %esi
-BEGIN_IRQ_SAVE(inc)
-	addl $1,  (v)
-	adcl $0, 4(v)
-	RET_IRQ_RESTORE
-ENDP
-#undef v
-
-#define v %esi
-BEGIN_IRQ_SAVE(inc_return)
-	movl  (v), %eax
-	movl 4(v), %edx
-	addl $1, %eax
-	adcl $0, %edx
-	movl %eax,  (v)
-	movl %edx, 4(v)
-	RET_IRQ_RESTORE
-ENDP
-#undef v
-
-#define v %esi
-BEGIN_IRQ_SAVE(dec)
-	subl $1,  (v)
-	sbbl $0, 4(v)
-	RET_IRQ_RESTORE
-ENDP
-#undef v
-
-#define v %esi
-BEGIN_IRQ_SAVE(dec_return)
-	movl  (v), %eax
-	movl 4(v), %edx
-	subl $1, %eax
-	sbbl $0, %edx
-	movl %eax,  (v)
-	movl %edx, 4(v)
-	RET_IRQ_RESTORE
-ENDP
-#undef v
-
-#define v %esi
-BEGIN_IRQ_SAVE(add_unless)
-	addl %eax, %ecx
-	adcl %edx, %edi
-	addl  (v), %eax
-	adcl 4(v), %edx
-	cmpl %eax, %ecx
-	je 3f
-1:
-	movl %eax,  (v)
-	movl %edx, 4(v)
-	movl $1, %eax
-2:
-	RET_IRQ_RESTORE
-3:
-	cmpl %edx, %edi
-	jne 1b
-	xorl %eax, %eax
-	jmp 2b
-ENDP
-#undef v
-
-#define v %esi
-BEGIN_IRQ_SAVE(inc_not_zero)
-	movl  (v), %eax
-	movl 4(v), %edx
-	testl %eax, %eax
-	je 3f
-1:
-	addl $1, %eax
-	adcl $0, %edx
-	movl %eax,  (v)
-	movl %edx, 4(v)
-	movl $1, %eax
-2:
-	RET_IRQ_RESTORE
-3:
-	testl %edx, %edx
-	jne 1b
-	jmp 2b
-ENDP
-#undef v
-
-#define v %esi
-BEGIN_IRQ_SAVE(dec_if_positive)
-	movl  (v), %eax
-	movl 4(v), %edx
-	subl $1, %eax
-	sbbl $0, %edx
-	js 1f
-	movl %eax,  (v)
-	movl %edx, 4(v)
-1:
-	RET_IRQ_RESTORE
-ENDP
-#undef v
diff -rupN a/arch/x86/lib/cmpxchg8b_emu.S b/arch/x86/lib/cmpxchg8b_emu.S
--- a/arch/x86/lib/cmpxchg8b_emu.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/lib/cmpxchg8b_emu.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,97 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0-only */
-
-#include <linux/export.h>
-#include <linux/linkage.h>
-#include <asm/percpu.h>
-#include <asm/processor-flags.h>
-
-.text
-
-#ifndef CONFIG_X86_CX8
-
-/*
- * Emulate 'cmpxchg8b (%esi)' on UP
- *
- * Inputs:
- * %esi : memory location to compare
- * %eax : low 32 bits of old value
- * %edx : high 32 bits of old value
- * %ebx : low 32 bits of new value
- * %ecx : high 32 bits of new value
- */
-SYM_FUNC_START(cmpxchg8b_emu)
-
-	pushfl
-	cli
-
-	cmpl	(%esi), %eax
-	jne	.Lnot_same
-	cmpl	4(%esi), %edx
-	jne	.Lnot_same
-
-	movl	%ebx, (%esi)
-	movl	%ecx, 4(%esi)
-
-	orl	$X86_EFLAGS_ZF, (%esp)
-
-	popfl
-	RET
-
-.Lnot_same:
-	movl	(%esi), %eax
-	movl	4(%esi), %edx
-
-	andl	$(~X86_EFLAGS_ZF), (%esp)
-
-	popfl
-	RET
-
-SYM_FUNC_END(cmpxchg8b_emu)
-EXPORT_SYMBOL(cmpxchg8b_emu)
-
-#endif
-
-#ifndef CONFIG_UML
-
-/*
- * Emulate 'cmpxchg8b %fs:(%rsi)'
- *
- * Inputs:
- * %esi : memory location to compare
- * %eax : low 32 bits of old value
- * %edx : high 32 bits of old value
- * %ebx : low 32 bits of new value
- * %ecx : high 32 bits of new value
- *
- * Notably this is not LOCK prefixed and is not safe against NMIs
- */
-SYM_FUNC_START(this_cpu_cmpxchg8b_emu)
-
-	pushfl
-	cli
-
-	cmpl	__percpu (%esi), %eax
-	jne	.Lnot_same2
-	cmpl	__percpu 4(%esi), %edx
-	jne	.Lnot_same2
-
-	movl	%ebx, __percpu (%esi)
-	movl	%ecx, __percpu 4(%esi)
-
-	orl	$X86_EFLAGS_ZF, (%esp)
-
-	popfl
-	RET
-
-.Lnot_same2:
-	movl	__percpu (%esi), %eax
-	movl	__percpu 4(%esi), %edx
-
-	andl	$(~X86_EFLAGS_ZF), (%esp)
-
-	popfl
-	RET
-
-SYM_FUNC_END(this_cpu_cmpxchg8b_emu)
-
-#endif
diff -rupN a/arch/x86/lib/Makefile b/arch/x86/lib/Makefile
--- a/arch/x86/lib/Makefile	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/lib/Makefile	2025-06-01 20:34:16.735109252 +0200
@@ -60,10 +60,6 @@ ifeq ($(CONFIG_X86_32),y)
         lib-y += strstr_32.o
         lib-y += string_32.o
         lib-y += memmove_32.o
-        lib-y += cmpxchg8b_emu.o
-ifneq ($(CONFIG_X86_CX8),y)
-        lib-y += atomic64_386_32.o
-endif
 else
 ifneq ($(CONFIG_GENERIC_CSUM),y)
         lib-y += csum-partial_64.o csum-copy_64.o csum-wrappers_64.o
diff -rupN a/arch/x86/Makefile b/arch/x86/Makefile
--- a/arch/x86/Makefile	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/Makefile	2025-06-01 20:34:16.735109252 +0200
@@ -74,7 +74,11 @@ export BITS
 #
 #    https://gcc.gnu.org/bugzilla/show_bug.cgi?id=53383
 #
-KBUILD_CFLAGS += -mno-sse -mno-mmx -mno-sse2 -mno-3dnow -mno-avx
+ifdef CONFIG_CC_IS_CLANG
+KBUILD_CFLAGS += -mno-sse -mno-mmx -mno-sse2 -mno-3dnow -mno-avx -mno-avx2 -O3 -fno-tree-vectorize -march=skylake -mpopcnt
+else
+KBUILD_CFLAGS += -mno-sse -mno-mmx -mno-sse2 -mno-3dnow -mno-avx -mno-avx2 -O3 -fno-tree-vectorize -march=skylake -mpopcnt -fivopts -fmodulo-sched
+endif
 KBUILD_RUSTFLAGS += --target=$(objtree)/scripts/target.json
 KBUILD_RUSTFLAGS += -Ctarget-feature=-sse,-sse2,-sse3,-ssse3,-sse4.1,-sse4.2,-avx,-avx2
 
@@ -235,7 +239,7 @@ ifdef CONFIG_MITIGATION_RETPOLINE
 endif
 
 ifdef CONFIG_MITIGATION_SLS
-  KBUILD_CFLAGS += -mharden-sls=all
+  KBUILD_CFLAGS += -mharden-sls=none
 endif
 
 ifdef CONFIG_CALL_PADDING
@@ -290,7 +294,6 @@ core-y  += arch/x86/boot/startup/
 libs-y  += arch/x86/lib/
 
 # drivers-y are linked after core-y
-drivers-$(CONFIG_MATH_EMULATION) += arch/x86/math-emu/
 drivers-$(CONFIG_PCI)            += arch/x86/pci/
 
 # suspend and hibernation support
diff -rupN a/arch/x86/Makefile_32.cpu b/arch/x86/Makefile_32.cpu
--- a/arch/x86/Makefile_32.cpu	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/Makefile_32.cpu	2025-06-01 20:34:16.736109260 +0200
@@ -10,9 +10,6 @@ else
 align		:= -falign-functions=0 -falign-jumps=0 -falign-loops=0
 endif
 
-cflags-$(CONFIG_M486SX)		+= -march=i486
-cflags-$(CONFIG_M486)		+= -march=i486
-cflags-$(CONFIG_M586)		+= -march=i586
 cflags-$(CONFIG_M586TSC)	+= -march=i586
 cflags-$(CONFIG_M586MMX)	+= -march=pentium-mmx
 cflags-$(CONFIG_M686)		+= -march=i686
@@ -26,16 +23,11 @@ cflags-$(CONFIG_MK6)		+= -march=k6
 cflags-$(CONFIG_MK7)		+= -march=athlon
 cflags-$(CONFIG_MCRUSOE)	+= -march=i686 $(align)
 cflags-$(CONFIG_MEFFICEON)	+= -march=i686 $(call tune,pentium3) $(align)
-cflags-$(CONFIG_MWINCHIPC6)	+= $(call cc-option,-march=winchip-c6,-march=i586)
-cflags-$(CONFIG_MWINCHIP3D)	+= $(call cc-option,-march=winchip2,-march=i586)
 cflags-$(CONFIG_MCYRIXIII)	+= $(call cc-option,-march=c3,-march=i486) $(align)
 cflags-$(CONFIG_MVIAC3_2)	+= $(call cc-option,-march=c3-2,-march=i686)
 cflags-$(CONFIG_MVIAC7)		+= -march=i686
 cflags-$(CONFIG_MATOM)		+= -march=atom
 
-# AMD Elan support
-cflags-$(CONFIG_MELAN)		+= -march=i486
-
 # Geode GX1 support
 cflags-$(CONFIG_MGEODEGX1)	+= -march=pentium-mmx
 cflags-$(CONFIG_MGEODE_LX)	+= $(call cc-option,-march=geode,-march=pentium-mmx)
diff -rupN a/arch/x86/math-emu/control_w.h b/arch/x86/math-emu/control_w.h
--- a/arch/x86/math-emu/control_w.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/control_w.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,46 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  control_w.h                                                              |
- |                                                                           |
- | Copyright (C) 1992,1993                                                   |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@vaxc.cc.monash.edu.au    |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#ifndef _CONTROLW_H_
-#define _CONTROLW_H_
-
-#ifdef __ASSEMBLER__
-#define	_Const_(x)	$##x
-#else
-#define	_Const_(x)	x
-#endif
-
-#define CW_RC		_Const_(0x0C00)	/* rounding control */
-#define CW_PC		_Const_(0x0300)	/* precision control */
-
-#define CW_Precision	Const_(0x0020)	/* loss of precision mask */
-#define CW_Underflow	Const_(0x0010)	/* underflow mask */
-#define CW_Overflow	Const_(0x0008)	/* overflow mask */
-#define CW_ZeroDiv	Const_(0x0004)	/* divide by zero mask */
-#define CW_Denormal	Const_(0x0002)	/* denormalized operand mask */
-#define CW_Invalid	Const_(0x0001)	/* invalid operation mask */
-
-#define CW_Exceptions  	_Const_(0x003f)	/* all masks */
-
-#define RC_RND		_Const_(0x0000)
-#define RC_DOWN		_Const_(0x0400)
-#define RC_UP		_Const_(0x0800)
-#define RC_CHOP		_Const_(0x0C00)
-
-/* p 15-5: Precision control bits affect only the following:
-   ADD, SUB(R), MUL, DIV(R), and SQRT */
-#define PR_24_BITS        _Const_(0x000)
-#define PR_53_BITS        _Const_(0x200)
-#define PR_64_BITS        _Const_(0x300)
-#define PR_RESERVED_BITS  _Const_(0x100)
-/* FULL_PRECISION simulates all exceptions masked */
-#define FULL_PRECISION  (PR_64_BITS | RC_RND | 0x3f)
-
-#endif /* _CONTROLW_H_ */
diff -rupN a/arch/x86/math-emu/div_small.S b/arch/x86/math-emu/div_small.S
--- a/arch/x86/math-emu/div_small.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/div_small.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,48 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-	.file	"div_small.S"
-/*---------------------------------------------------------------------------+
- |  div_small.S                                                              |
- |                                                                           |
- | Divide a 64 bit integer by a 32 bit integer & return remainder.           |
- |                                                                           |
- | Copyright (C) 1992,1995                                                   |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@jacobi.maths.monash.edu.au |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- |    unsigned long FPU_div_small(unsigned long long *x, unsigned long y)    |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_emu.h"
-
-.text
-SYM_FUNC_START(FPU_div_small)
-	pushl	%ebp
-	movl	%esp,%ebp
-
-	pushl	%esi
-
-	movl	PARAM1,%esi	/* pointer to num */
-	movl	PARAM2,%ecx	/* The denominator */
-
-	movl	4(%esi),%eax	/* Get the current num msw */
-	xorl	%edx,%edx
-	divl	%ecx
-
-	movl	%eax,4(%esi)
-
-	movl	(%esi),%eax	/* Get the num lsw */
-	divl	%ecx
-
-	movl	%eax,(%esi)
-
-	movl	%edx,%eax	/* Return the remainder in eax */
-
-	popl	%esi
-
-	leave
-	RET
-SYM_FUNC_END(FPU_div_small)
diff -rupN a/arch/x86/math-emu/div_Xsig.S b/arch/x86/math-emu/div_Xsig.S
--- a/arch/x86/math-emu/div_Xsig.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/div_Xsig.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,367 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-	.file	"div_Xsig.S"
-/*---------------------------------------------------------------------------+
- |  div_Xsig.S                                                               |
- |                                                                           |
- | Division subroutine for 96 bit quantities                                 |
- |                                                                           |
- | Copyright (C) 1994,1995                                                   |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@jacobi.maths.monash.edu.au |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | Divide the 96 bit quantity pointed to by a, by that pointed to by b, and  |
- | put the 96 bit result at the location d.                                  |
- |                                                                           |
- | The result may not be accurate to 96 bits. It is intended for use where   |
- | a result better than 64 bits is required. The result should usually be    |
- | good to at least 94 bits.                                                 |
- | The returned result is actually divided by one half. This is done to      |
- | prevent overflow.                                                         |
- |                                                                           |
- |  .aaaaaaaaaaaaaa / .bbbbbbbbbbbbb  ->  .dddddddddddd                      |
- |                                                                           |
- |  void div_Xsig(Xsig *a, Xsig *b, Xsig *dest)                              |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "fpu_emu.h"
-
-
-#define	XsigLL(x)	(x)
-#define	XsigL(x)	4(x)
-#define	XsigH(x)	8(x)
-
-
-#ifndef NON_REENTRANT_FPU
-/*
-	Local storage on the stack:
-	Accumulator:	FPU_accum_3:FPU_accum_2:FPU_accum_1:FPU_accum_0
- */
-#define FPU_accum_3	-4(%ebp)
-#define FPU_accum_2	-8(%ebp)
-#define FPU_accum_1	-12(%ebp)
-#define FPU_accum_0	-16(%ebp)
-#define FPU_result_3	-20(%ebp)
-#define FPU_result_2	-24(%ebp)
-#define FPU_result_1	-28(%ebp)
-
-#else
-.data
-/*
-	Local storage in a static area:
-	Accumulator:	FPU_accum_3:FPU_accum_2:FPU_accum_1:FPU_accum_0
- */
-	.align 4,0
-FPU_accum_3:
-	.long	0
-FPU_accum_2:
-	.long	0
-FPU_accum_1:
-	.long	0
-FPU_accum_0:
-	.long	0
-FPU_result_3:
-	.long	0
-FPU_result_2:
-	.long	0
-FPU_result_1:
-	.long	0
-#endif /* NON_REENTRANT_FPU */
-
-
-.text
-SYM_FUNC_START(div_Xsig)
-	pushl	%ebp
-	movl	%esp,%ebp
-#ifndef NON_REENTRANT_FPU
-	subl	$28,%esp
-#endif /* NON_REENTRANT_FPU */ 
-
-	pushl	%esi
-	pushl	%edi
-	pushl	%ebx
-
-	movl	PARAM1,%esi	/* pointer to num */
-	movl	PARAM2,%ebx	/* pointer to denom */
-
-#ifdef PARANOID
-	testl	$0x80000000, XsigH(%ebx)	/* Divisor */
-	je	L_bugged
-#endif /* PARANOID */
-
-
-/*---------------------------------------------------------------------------+
- |  Divide:   Return  arg1/arg2 to arg3.                                     |
- |                                                                           |
- |  The maximum returned value is (ignoring exponents)                       |
- |               .ffffffff ffffffff                                          |
- |               ------------------  =  1.ffffffff fffffffe                  |
- |               .80000000 00000000                                          |
- | and the minimum is                                                        |
- |               .80000000 00000000                                          |
- |               ------------------  =  .80000000 00000001   (rounded)       |
- |               .ffffffff ffffffff                                          |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-	/* Save extended dividend in local register */
-
-	/* Divide by 2 to prevent overflow */
-	clc
-	movl	XsigH(%esi),%eax
-	rcrl	%eax
-	movl	%eax,FPU_accum_3
-	movl	XsigL(%esi),%eax
-	rcrl	%eax
-	movl	%eax,FPU_accum_2
-	movl	XsigLL(%esi),%eax
-	rcrl	%eax
-	movl	%eax,FPU_accum_1
-	movl	$0,%eax
-	rcrl	%eax
-	movl	%eax,FPU_accum_0
-
-	movl	FPU_accum_2,%eax	/* Get the current num */
-	movl	FPU_accum_3,%edx
-
-/*----------------------------------------------------------------------*/
-/* Initialization done.
-   Do the first 32 bits. */
-
-	/* We will divide by a number which is too large */
-	movl	XsigH(%ebx),%ecx
-	addl	$1,%ecx
-	jnc	LFirst_div_not_1
-
-	/* here we need to divide by 100000000h,
-	   i.e., no division at all.. */
-	mov	%edx,%eax
-	jmp	LFirst_div_done
-
-LFirst_div_not_1:
-	divl	%ecx		/* Divide the numerator by the augmented
-				   denom ms dw */
-
-LFirst_div_done:
-	movl	%eax,FPU_result_3	/* Put the result in the answer */
-
-	mull	XsigH(%ebx)	/* mul by the ms dw of the denom */
-
-	subl	%eax,FPU_accum_2	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_3
-
-	movl	FPU_result_3,%eax	/* Get the result back */
-	mull	XsigL(%ebx)	/* now mul the ls dw of the denom */
-
-	subl	%eax,FPU_accum_1	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_2
-	sbbl	$0,FPU_accum_3
-	je	LDo_2nd_32_bits		/* Must check for non-zero result here */
-
-#ifdef PARANOID
-	jb	L_bugged_1
-#endif /* PARANOID */ 
-
-	/* need to subtract another once of the denom */
-	incl	FPU_result_3	/* Correct the answer */
-
-	movl	XsigL(%ebx),%eax
-	movl	XsigH(%ebx),%edx
-	subl	%eax,FPU_accum_1	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_2
-
-#ifdef PARANOID
-	sbbl	$0,FPU_accum_3
-	jne	L_bugged_1	/* Must check for non-zero result here */
-#endif /* PARANOID */ 
-
-/*----------------------------------------------------------------------*/
-/* Half of the main problem is done, there is just a reduced numerator
-   to handle now.
-   Work with the second 32 bits, FPU_accum_0 not used from now on */
-LDo_2nd_32_bits:
-	movl	FPU_accum_2,%edx	/* get the reduced num */
-	movl	FPU_accum_1,%eax
-
-	/* need to check for possible subsequent overflow */
-	cmpl	XsigH(%ebx),%edx
-	jb	LDo_2nd_div
-	ja	LPrevent_2nd_overflow
-
-	cmpl	XsigL(%ebx),%eax
-	jb	LDo_2nd_div
-
-LPrevent_2nd_overflow:
-/* The numerator is greater or equal, would cause overflow */
-	/* prevent overflow */
-	subl	XsigL(%ebx),%eax
-	sbbl	XsigH(%ebx),%edx
-	movl	%edx,FPU_accum_2
-	movl	%eax,FPU_accum_1
-
-	incl	FPU_result_3	/* Reflect the subtraction in the answer */
-
-#ifdef PARANOID
-	je	L_bugged_2	/* Can't bump the result to 1.0 */
-#endif /* PARANOID */ 
-
-LDo_2nd_div:
-	cmpl	$0,%ecx		/* augmented denom msw */
-	jnz	LSecond_div_not_1
-
-	/* %ecx == 0, we are dividing by 1.0 */
-	mov	%edx,%eax
-	jmp	LSecond_div_done
-
-LSecond_div_not_1:
-	divl	%ecx		/* Divide the numerator by the denom ms dw */
-
-LSecond_div_done:
-	movl	%eax,FPU_result_2	/* Put the result in the answer */
-
-	mull	XsigH(%ebx)	/* mul by the ms dw of the denom */
-
-	subl	%eax,FPU_accum_1	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_2
-
-#ifdef PARANOID
-	jc	L_bugged_2
-#endif /* PARANOID */
-
-	movl	FPU_result_2,%eax	/* Get the result back */
-	mull	XsigL(%ebx)	/* now mul the ls dw of the denom */
-
-	subl	%eax,FPU_accum_0	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_1	/* Subtract from the num local reg */
-	sbbl	$0,FPU_accum_2
-
-#ifdef PARANOID
-	jc	L_bugged_2
-#endif /* PARANOID */
-
-	jz	LDo_3rd_32_bits
-
-#ifdef PARANOID
-	cmpl	$1,FPU_accum_2
-	jne	L_bugged_2
-#endif /* PARANOID */ 
-
-	/* need to subtract another once of the denom */
-	movl	XsigL(%ebx),%eax
-	movl	XsigH(%ebx),%edx
-	subl	%eax,FPU_accum_0	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_1
-	sbbl	$0,FPU_accum_2
-
-#ifdef PARANOID
-	jc	L_bugged_2
-	jne	L_bugged_2
-#endif /* PARANOID */ 
-
-	addl	$1,FPU_result_2	/* Correct the answer */
-	adcl	$0,FPU_result_3
-
-#ifdef PARANOID
-	jc	L_bugged_2	/* Must check for non-zero result here */
-#endif /* PARANOID */ 
-
-/*----------------------------------------------------------------------*/
-/* The division is essentially finished here, we just need to perform
-   tidying operations.
-   Deal with the 3rd 32 bits */
-LDo_3rd_32_bits:
-	/* We use an approximation for the third 32 bits.
-	To take account of the 3rd 32 bits of the divisor
-	(call them del), we subtract  del * (a/b) */
-
-	movl	FPU_result_3,%eax	/* a/b */
-	mull	XsigLL(%ebx)		/* del */
-
-	subl	%edx,FPU_accum_1
-
-	/* A borrow indicates that the result is negative */
-	jnb	LTest_over
-
-	movl	XsigH(%ebx),%edx
-	addl	%edx,FPU_accum_1
-
-	subl	$1,FPU_result_2		/* Adjust the answer */
-	sbbl	$0,FPU_result_3
-
-	/* The above addition might not have been enough, check again. */
-	movl	FPU_accum_1,%edx	/* get the reduced num */
-	cmpl	XsigH(%ebx),%edx	/* denom */
-	jb	LDo_3rd_div
-
-	movl	XsigH(%ebx),%edx
-	addl	%edx,FPU_accum_1
-
-	subl	$1,FPU_result_2		/* Adjust the answer */
-	sbbl	$0,FPU_result_3
-	jmp	LDo_3rd_div
-
-LTest_over:
-	movl	FPU_accum_1,%edx	/* get the reduced num */
-
-	/* need to check for possible subsequent overflow */
-	cmpl	XsigH(%ebx),%edx	/* denom */
-	jb	LDo_3rd_div
-
-	/* prevent overflow */
-	subl	XsigH(%ebx),%edx
-	movl	%edx,FPU_accum_1
-
-	addl	$1,FPU_result_2	/* Reflect the subtraction in the answer */
-	adcl	$0,FPU_result_3
-
-LDo_3rd_div:
-	movl	FPU_accum_0,%eax
-	movl	FPU_accum_1,%edx
-	divl	XsigH(%ebx)
-
-	movl    %eax,FPU_result_1       /* Rough estimate of third word */
-
-	movl	PARAM3,%esi		/* pointer to answer */
-
-	movl	FPU_result_1,%eax
-	movl	%eax,XsigLL(%esi)
-	movl	FPU_result_2,%eax
-	movl	%eax,XsigL(%esi)
-	movl	FPU_result_3,%eax
-	movl	%eax,XsigH(%esi)
-
-L_exit:
-	popl	%ebx
-	popl	%edi
-	popl	%esi
-
-	leave
-	RET
-
-
-#ifdef PARANOID
-/* The logic is wrong if we got here */
-L_bugged:
-	pushl	EX_INTERNAL|0x240
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_exit
-
-L_bugged_1:
-	pushl	EX_INTERNAL|0x241
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_exit
-
-L_bugged_2:
-	pushl	EX_INTERNAL|0x242
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_exit
-#endif /* PARANOID */ 
-SYM_FUNC_END(div_Xsig)
diff -rupN a/arch/x86/math-emu/errors.c b/arch/x86/math-emu/errors.c
--- a/arch/x86/math-emu/errors.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/errors.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,686 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  errors.c                                                                 |
- |                                                                           |
- |  The error handling functions for wm-FPU-emu                              |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1996                                         |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@jacobi.maths.monash.edu.au                |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | Note:                                                                     |
- |    The file contains code which accesses user memory.                     |
- |    Emulator static data may change when user memory is accessed, due to   |
- |    other processes using the emulator while swapping is in progress.      |
- +---------------------------------------------------------------------------*/
-
-#include <linux/signal.h>
-
-#include <linux/uaccess.h>
-
-#include "fpu_emu.h"
-#include "fpu_system.h"
-#include "exception.h"
-#include "status_w.h"
-#include "control_w.h"
-#include "reg_constant.h"
-#include "version.h"
-
-/* */
-#undef PRINT_MESSAGES
-/* */
-
-#if 0
-void Un_impl(void)
-{
-	u_char byte1, FPU_modrm;
-	unsigned long address = FPU_ORIG_EIP;
-
-	RE_ENTRANT_CHECK_OFF;
-	/* No need to check access_ok(), we have previously fetched these bytes. */
-	printk("Unimplemented FPU Opcode at eip=%p : ", (void __user *)address);
-	if (FPU_CS == __USER_CS) {
-		while (1) {
-			FPU_get_user(byte1, (u_char __user *) address);
-			if ((byte1 & 0xf8) == 0xd8)
-				break;
-			printk("[%02x]", byte1);
-			address++;
-		}
-		printk("%02x ", byte1);
-		FPU_get_user(FPU_modrm, 1 + (u_char __user *) address);
-
-		if (FPU_modrm >= 0300)
-			printk("%02x (%02x+%d)\n", FPU_modrm, FPU_modrm & 0xf8,
-			       FPU_modrm & 7);
-		else
-			printk("/%d\n", (FPU_modrm >> 3) & 7);
-	} else {
-		printk("cs selector = %04x\n", FPU_CS);
-	}
-
-	RE_ENTRANT_CHECK_ON;
-
-	EXCEPTION(EX_Invalid);
-
-}
-#endif /*  0  */
-
-/*
-   Called for opcodes which are illegal and which are known to result in a
-   SIGILL with a real 80486.
-   */
-void FPU_illegal(void)
-{
-	math_abort(FPU_info, SIGILL);
-}
-
-void FPU_printall(void)
-{
-	int i;
-	static const char *tag_desc[] = { "Valid", "Zero", "ERROR", "Empty",
-		"DeNorm", "Inf", "NaN"
-	};
-	u_char byte1, FPU_modrm;
-	unsigned long address = FPU_ORIG_EIP;
-
-	RE_ENTRANT_CHECK_OFF;
-	/* No need to check access_ok(), we have previously fetched these bytes. */
-	printk("At %p:", (void *)address);
-	if (FPU_CS == __USER_CS) {
-#define MAX_PRINTED_BYTES 20
-		for (i = 0; i < MAX_PRINTED_BYTES; i++) {
-			FPU_get_user(byte1, (u_char __user *) address);
-			if ((byte1 & 0xf8) == 0xd8) {
-				printk(" %02x", byte1);
-				break;
-			}
-			printk(" [%02x]", byte1);
-			address++;
-		}
-		if (i == MAX_PRINTED_BYTES)
-			printk(" [more..]\n");
-		else {
-			FPU_get_user(FPU_modrm, 1 + (u_char __user *) address);
-
-			if (FPU_modrm >= 0300)
-				printk(" %02x (%02x+%d)\n", FPU_modrm,
-				       FPU_modrm & 0xf8, FPU_modrm & 7);
-			else
-				printk(" /%d, mod=%d rm=%d\n",
-				       (FPU_modrm >> 3) & 7,
-				       (FPU_modrm >> 6) & 3, FPU_modrm & 7);
-		}
-	} else {
-		printk("%04x\n", FPU_CS);
-	}
-
-	partial_status = status_word();
-
-#ifdef DEBUGGING
-	if (partial_status & SW_Backward)
-		printk("SW: backward compatibility\n");
-	if (partial_status & SW_C3)
-		printk("SW: condition bit 3\n");
-	if (partial_status & SW_C2)
-		printk("SW: condition bit 2\n");
-	if (partial_status & SW_C1)
-		printk("SW: condition bit 1\n");
-	if (partial_status & SW_C0)
-		printk("SW: condition bit 0\n");
-	if (partial_status & SW_Summary)
-		printk("SW: exception summary\n");
-	if (partial_status & SW_Stack_Fault)
-		printk("SW: stack fault\n");
-	if (partial_status & SW_Precision)
-		printk("SW: loss of precision\n");
-	if (partial_status & SW_Underflow)
-		printk("SW: underflow\n");
-	if (partial_status & SW_Overflow)
-		printk("SW: overflow\n");
-	if (partial_status & SW_Zero_Div)
-		printk("SW: divide by zero\n");
-	if (partial_status & SW_Denorm_Op)
-		printk("SW: denormalized operand\n");
-	if (partial_status & SW_Invalid)
-		printk("SW: invalid operation\n");
-#endif /* DEBUGGING */
-
-	printk(" SW: b=%d st=%d es=%d sf=%d cc=%d%d%d%d ef=%d%d%d%d%d%d\n", partial_status & 0x8000 ? 1 : 0,	/* busy */
-	       (partial_status & 0x3800) >> 11,	/* stack top pointer */
-	       partial_status & 0x80 ? 1 : 0,	/* Error summary status */
-	       partial_status & 0x40 ? 1 : 0,	/* Stack flag */
-	       partial_status & SW_C3 ? 1 : 0, partial_status & SW_C2 ? 1 : 0,	/* cc */
-	       partial_status & SW_C1 ? 1 : 0, partial_status & SW_C0 ? 1 : 0,	/* cc */
-	       partial_status & SW_Precision ? 1 : 0,
-	       partial_status & SW_Underflow ? 1 : 0,
-	       partial_status & SW_Overflow ? 1 : 0,
-	       partial_status & SW_Zero_Div ? 1 : 0,
-	       partial_status & SW_Denorm_Op ? 1 : 0,
-	       partial_status & SW_Invalid ? 1 : 0);
-
-	printk(" CW: ic=%d rc=%d%d pc=%d%d iem=%d     ef=%d%d%d%d%d%d\n",
-	       control_word & 0x1000 ? 1 : 0,
-	       (control_word & 0x800) >> 11, (control_word & 0x400) >> 10,
-	       (control_word & 0x200) >> 9, (control_word & 0x100) >> 8,
-	       control_word & 0x80 ? 1 : 0,
-	       control_word & SW_Precision ? 1 : 0,
-	       control_word & SW_Underflow ? 1 : 0,
-	       control_word & SW_Overflow ? 1 : 0,
-	       control_word & SW_Zero_Div ? 1 : 0,
-	       control_word & SW_Denorm_Op ? 1 : 0,
-	       control_word & SW_Invalid ? 1 : 0);
-
-	for (i = 0; i < 8; i++) {
-		FPU_REG *r = &st(i);
-		u_char tagi = FPU_gettagi(i);
-
-		switch (tagi) {
-		case TAG_Empty:
-			continue;
-		case TAG_Zero:
-		case TAG_Special:
-			/* Update tagi for the printk below */
-			tagi = FPU_Special(r);
-			fallthrough;
-		case TAG_Valid:
-			printk("st(%d)  %c .%04lx %04lx %04lx %04lx e%+-6d ", i,
-			       getsign(r) ? '-' : '+',
-			       (long)(r->sigh >> 16),
-			       (long)(r->sigh & 0xFFFF),
-			       (long)(r->sigl >> 16),
-			       (long)(r->sigl & 0xFFFF),
-			       exponent(r) - EXP_BIAS + 1);
-			break;
-		default:
-			printk("Whoops! Error in errors.c: tag%d is %d ", i,
-			       tagi);
-			continue;
-		}
-		printk("%s\n", tag_desc[(int)(unsigned)tagi]);
-	}
-
-	RE_ENTRANT_CHECK_ON;
-
-}
-
-static struct {
-	int type;
-	const char *name;
-} exception_names[] = {
-	{
-	EX_StackOver, "stack overflow"}, {
-	EX_StackUnder, "stack underflow"}, {
-	EX_Precision, "loss of precision"}, {
-	EX_Underflow, "underflow"}, {
-	EX_Overflow, "overflow"}, {
-	EX_ZeroDiv, "divide by zero"}, {
-	EX_Denormal, "denormalized operand"}, {
-	EX_Invalid, "invalid operation"}, {
-	EX_INTERNAL, "INTERNAL BUG in " FPU_VERSION}, {
-	0, NULL}
-};
-
-/*
- EX_INTERNAL is always given with a code which indicates where the
- error was detected.
-
- Internal error types:
-       0x14   in fpu_etc.c
-       0x1nn  in a *.c file:
-              0x101  in reg_add_sub.c
-              0x102  in reg_mul.c
-              0x104  in poly_atan.c
-              0x105  in reg_mul.c
-              0x107  in fpu_trig.c
-	      0x108  in reg_compare.c
-	      0x109  in reg_compare.c
-	      0x110  in reg_add_sub.c
-	      0x111  in fpe_entry.c
-	      0x112  in fpu_trig.c
-	      0x113  in errors.c
-	      0x115  in fpu_trig.c
-	      0x116  in fpu_trig.c
-	      0x117  in fpu_trig.c
-	      0x118  in fpu_trig.c
-	      0x119  in fpu_trig.c
-	      0x120  in poly_atan.c
-	      0x121  in reg_compare.c
-	      0x122  in reg_compare.c
-	      0x123  in reg_compare.c
-	      0x125  in fpu_trig.c
-	      0x126  in fpu_entry.c
-	      0x127  in poly_2xm1.c
-	      0x128  in fpu_entry.c
-	      0x129  in fpu_entry.c
-	      0x130  in get_address.c
-	      0x131  in get_address.c
-	      0x132  in get_address.c
-	      0x133  in get_address.c
-	      0x140  in load_store.c
-	      0x141  in load_store.c
-              0x150  in poly_sin.c
-              0x151  in poly_sin.c
-	      0x160  in reg_ld_str.c
-	      0x161  in reg_ld_str.c
-	      0x162  in reg_ld_str.c
-	      0x163  in reg_ld_str.c
-	      0x164  in reg_ld_str.c
-	      0x170  in fpu_tags.c
-	      0x171  in fpu_tags.c
-	      0x172  in fpu_tags.c
-	      0x180  in reg_convert.c
-       0x2nn  in an *.S file:
-              0x201  in reg_u_add.S
-              0x202  in reg_u_div.S
-              0x203  in reg_u_div.S
-              0x204  in reg_u_div.S
-              0x205  in reg_u_mul.S
-              0x206  in reg_u_sub.S
-              0x207  in wm_sqrt.S
-	      0x208  in reg_div.S
-              0x209  in reg_u_sub.S
-              0x210  in reg_u_sub.S
-              0x211  in reg_u_sub.S
-              0x212  in reg_u_sub.S
-	      0x213  in wm_sqrt.S
-	      0x214  in wm_sqrt.S
-	      0x215  in wm_sqrt.S
-	      0x220  in reg_norm.S
-	      0x221  in reg_norm.S
-	      0x230  in reg_round.S
-	      0x231  in reg_round.S
-	      0x232  in reg_round.S
-	      0x233  in reg_round.S
-	      0x234  in reg_round.S
-	      0x235  in reg_round.S
-	      0x236  in reg_round.S
-	      0x240  in div_Xsig.S
-	      0x241  in div_Xsig.S
-	      0x242  in div_Xsig.S
- */
-
-asmlinkage __visible void FPU_exception(int n)
-{
-	int i, int_type;
-
-	int_type = 0;		/* Needed only to stop compiler warnings */
-	if (n & EX_INTERNAL) {
-		int_type = n - EX_INTERNAL;
-		n = EX_INTERNAL;
-		/* Set lots of exception bits! */
-		partial_status |= (SW_Exc_Mask | SW_Summary | SW_Backward);
-	} else {
-		/* Extract only the bits which we use to set the status word */
-		n &= (SW_Exc_Mask);
-		/* Set the corresponding exception bit */
-		partial_status |= n;
-		/* Set summary bits iff exception isn't masked */
-		if (partial_status & ~control_word & CW_Exceptions)
-			partial_status |= (SW_Summary | SW_Backward);
-		if (n & (SW_Stack_Fault | EX_Precision)) {
-			if (!(n & SW_C1))
-				/* This bit distinguishes over- from underflow for a stack fault,
-				   and roundup from round-down for precision loss. */
-				partial_status &= ~SW_C1;
-		}
-	}
-
-	RE_ENTRANT_CHECK_OFF;
-	if ((~control_word & n & CW_Exceptions) || (n == EX_INTERNAL)) {
-		/* Get a name string for error reporting */
-		for (i = 0; exception_names[i].type; i++)
-			if ((exception_names[i].type & n) ==
-			    exception_names[i].type)
-				break;
-
-		if (exception_names[i].type) {
-#ifdef PRINT_MESSAGES
-			printk("FP Exception: %s!\n", exception_names[i].name);
-#endif /* PRINT_MESSAGES */
-		} else
-			printk("FPU emulator: Unknown Exception: 0x%04x!\n", n);
-
-		if (n == EX_INTERNAL) {
-			printk("FPU emulator: Internal error type 0x%04x\n",
-			       int_type);
-			FPU_printall();
-		}
-#ifdef PRINT_MESSAGES
-		else
-			FPU_printall();
-#endif /* PRINT_MESSAGES */
-
-		/*
-		 * The 80486 generates an interrupt on the next non-control FPU
-		 * instruction. So we need some means of flagging it.
-		 * We use the ES (Error Summary) bit for this.
-		 */
-	}
-	RE_ENTRANT_CHECK_ON;
-
-#ifdef __DEBUG__
-	math_abort(FPU_info, SIGFPE);
-#endif /* __DEBUG__ */
-
-}
-
-/* Real operation attempted on a NaN. */
-/* Returns < 0 if the exception is unmasked */
-int real_1op_NaN(FPU_REG *a)
-{
-	int signalling, isNaN;
-
-	isNaN = (exponent(a) == EXP_OVER) && (a->sigh & 0x80000000);
-
-	/* The default result for the case of two "equal" NaNs (signs may
-	   differ) is chosen to reproduce 80486 behaviour */
-	signalling = isNaN && !(a->sigh & 0x40000000);
-
-	if (!signalling) {
-		if (!isNaN) {	/* pseudo-NaN, or other unsupported? */
-			if (control_word & CW_Invalid) {
-				/* Masked response */
-				reg_copy(&CONST_QNaN, a);
-			}
-			EXCEPTION(EX_Invalid);
-			return (!(control_word & CW_Invalid) ? FPU_Exception :
-				0) | TAG_Special;
-		}
-		return TAG_Special;
-	}
-
-	if (control_word & CW_Invalid) {
-		/* The masked response */
-		if (!(a->sigh & 0x80000000)) {	/* pseudo-NaN ? */
-			reg_copy(&CONST_QNaN, a);
-		}
-		/* ensure a Quiet NaN */
-		a->sigh |= 0x40000000;
-	}
-
-	EXCEPTION(EX_Invalid);
-
-	return (!(control_word & CW_Invalid) ? FPU_Exception : 0) | TAG_Special;
-}
-
-/* Real operation attempted on two operands, one a NaN. */
-/* Returns < 0 if the exception is unmasked */
-int real_2op_NaN(FPU_REG const *b, u_char tagb,
-		 int deststnr, FPU_REG const *defaultNaN)
-{
-	FPU_REG *dest = &st(deststnr);
-	FPU_REG const *a = dest;
-	u_char taga = FPU_gettagi(deststnr);
-	FPU_REG const *x;
-	int signalling, unsupported;
-
-	if (taga == TAG_Special)
-		taga = FPU_Special(a);
-	if (tagb == TAG_Special)
-		tagb = FPU_Special(b);
-
-	/* TW_NaN is also used for unsupported data types. */
-	unsupported = ((taga == TW_NaN)
-		       && !((exponent(a) == EXP_OVER)
-			    && (a->sigh & 0x80000000)))
-	    || ((tagb == TW_NaN)
-		&& !((exponent(b) == EXP_OVER) && (b->sigh & 0x80000000)));
-	if (unsupported) {
-		if (control_word & CW_Invalid) {
-			/* Masked response */
-			FPU_copy_to_regi(&CONST_QNaN, TAG_Special, deststnr);
-		}
-		EXCEPTION(EX_Invalid);
-		return (!(control_word & CW_Invalid) ? FPU_Exception : 0) |
-		    TAG_Special;
-	}
-
-	if (taga == TW_NaN) {
-		x = a;
-		if (tagb == TW_NaN) {
-			signalling = !(a->sigh & b->sigh & 0x40000000);
-			if (significand(b) > significand(a))
-				x = b;
-			else if (significand(b) == significand(a)) {
-				/* The default result for the case of two "equal" NaNs (signs may
-				   differ) is chosen to reproduce 80486 behaviour */
-				x = defaultNaN;
-			}
-		} else {
-			/* return the quiet version of the NaN in a */
-			signalling = !(a->sigh & 0x40000000);
-		}
-	} else
-#ifdef PARANOID
-	if (tagb == TW_NaN)
-#endif /* PARANOID */
-	{
-		signalling = !(b->sigh & 0x40000000);
-		x = b;
-	}
-#ifdef PARANOID
-	else {
-		signalling = 0;
-		EXCEPTION(EX_INTERNAL | 0x113);
-		x = &CONST_QNaN;
-	}
-#endif /* PARANOID */
-
-	if ((!signalling) || (control_word & CW_Invalid)) {
-		if (!x)
-			x = b;
-
-		if (!(x->sigh & 0x80000000))	/* pseudo-NaN ? */
-			x = &CONST_QNaN;
-
-		FPU_copy_to_regi(x, TAG_Special, deststnr);
-
-		if (!signalling)
-			return TAG_Special;
-
-		/* ensure a Quiet NaN */
-		dest->sigh |= 0x40000000;
-	}
-
-	EXCEPTION(EX_Invalid);
-
-	return (!(control_word & CW_Invalid) ? FPU_Exception : 0) | TAG_Special;
-}
-
-/* Invalid arith operation on Valid registers */
-/* Returns < 0 if the exception is unmasked */
-asmlinkage __visible int arith_invalid(int deststnr)
-{
-
-	EXCEPTION(EX_Invalid);
-
-	if (control_word & CW_Invalid) {
-		/* The masked response */
-		FPU_copy_to_regi(&CONST_QNaN, TAG_Special, deststnr);
-	}
-
-	return (!(control_word & CW_Invalid) ? FPU_Exception : 0) | TAG_Valid;
-
-}
-
-/* Divide a finite number by zero */
-asmlinkage __visible int FPU_divide_by_zero(int deststnr, u_char sign)
-{
-	FPU_REG *dest = &st(deststnr);
-	int tag = TAG_Valid;
-
-	if (control_word & CW_ZeroDiv) {
-		/* The masked response */
-		FPU_copy_to_regi(&CONST_INF, TAG_Special, deststnr);
-		setsign(dest, sign);
-		tag = TAG_Special;
-	}
-
-	EXCEPTION(EX_ZeroDiv);
-
-	return (!(control_word & CW_ZeroDiv) ? FPU_Exception : 0) | tag;
-
-}
-
-/* This may be called often, so keep it lean */
-int set_precision_flag(int flags)
-{
-	if (control_word & CW_Precision) {
-		partial_status &= ~(SW_C1 & flags);
-		partial_status |= flags;	/* The masked response */
-		return 0;
-	} else {
-		EXCEPTION(flags);
-		return 1;
-	}
-}
-
-/* This may be called often, so keep it lean */
-asmlinkage __visible void set_precision_flag_up(void)
-{
-	if (control_word & CW_Precision)
-		partial_status |= (SW_Precision | SW_C1);	/* The masked response */
-	else
-		EXCEPTION(EX_Precision | SW_C1);
-}
-
-/* This may be called often, so keep it lean */
-asmlinkage __visible void set_precision_flag_down(void)
-{
-	if (control_word & CW_Precision) {	/* The masked response */
-		partial_status &= ~SW_C1;
-		partial_status |= SW_Precision;
-	} else
-		EXCEPTION(EX_Precision);
-}
-
-asmlinkage __visible int denormal_operand(void)
-{
-	if (control_word & CW_Denormal) {	/* The masked response */
-		partial_status |= SW_Denorm_Op;
-		return TAG_Special;
-	} else {
-		EXCEPTION(EX_Denormal);
-		return TAG_Special | FPU_Exception;
-	}
-}
-
-asmlinkage __visible int arith_overflow(FPU_REG *dest)
-{
-	int tag = TAG_Valid;
-
-	if (control_word & CW_Overflow) {
-		/* The masked response */
-/* ###### The response here depends upon the rounding mode */
-		reg_copy(&CONST_INF, dest);
-		tag = TAG_Special;
-	} else {
-		/* Subtract the magic number from the exponent */
-		addexponent(dest, (-3 * (1 << 13)));
-	}
-
-	EXCEPTION(EX_Overflow);
-	if (control_word & CW_Overflow) {
-		/* The overflow exception is masked. */
-		/* By definition, precision is lost.
-		   The roundup bit (C1) is also set because we have
-		   "rounded" upwards to Infinity. */
-		EXCEPTION(EX_Precision | SW_C1);
-		return tag;
-	}
-
-	return tag;
-
-}
-
-asmlinkage __visible int arith_underflow(FPU_REG *dest)
-{
-	int tag = TAG_Valid;
-
-	if (control_word & CW_Underflow) {
-		/* The masked response */
-		if (exponent16(dest) <= EXP_UNDER - 63) {
-			reg_copy(&CONST_Z, dest);
-			partial_status &= ~SW_C1;	/* Round down. */
-			tag = TAG_Zero;
-		} else {
-			stdexp(dest);
-		}
-	} else {
-		/* Add the magic number to the exponent. */
-		addexponent(dest, (3 * (1 << 13)) + EXTENDED_Ebias);
-	}
-
-	EXCEPTION(EX_Underflow);
-	if (control_word & CW_Underflow) {
-		/* The underflow exception is masked. */
-		EXCEPTION(EX_Precision);
-		return tag;
-	}
-
-	return tag;
-
-}
-
-void FPU_stack_overflow(void)
-{
-
-	if (control_word & CW_Invalid) {
-		/* The masked response */
-		top--;
-		FPU_copy_to_reg0(&CONST_QNaN, TAG_Special);
-	}
-
-	EXCEPTION(EX_StackOver);
-
-	return;
-
-}
-
-void FPU_stack_underflow(void)
-{
-
-	if (control_word & CW_Invalid) {
-		/* The masked response */
-		FPU_copy_to_reg0(&CONST_QNaN, TAG_Special);
-	}
-
-	EXCEPTION(EX_StackUnder);
-
-	return;
-
-}
-
-void FPU_stack_underflow_i(int i)
-{
-
-	if (control_word & CW_Invalid) {
-		/* The masked response */
-		FPU_copy_to_regi(&CONST_QNaN, TAG_Special, i);
-	}
-
-	EXCEPTION(EX_StackUnder);
-
-	return;
-
-}
-
-void FPU_stack_underflow_pop(int i)
-{
-
-	if (control_word & CW_Invalid) {
-		/* The masked response */
-		FPU_copy_to_regi(&CONST_QNaN, TAG_Special, i);
-		FPU_pop();
-	}
-
-	EXCEPTION(EX_StackUnder);
-
-	return;
-
-}
diff -rupN a/arch/x86/math-emu/exception.h b/arch/x86/math-emu/exception.h
--- a/arch/x86/math-emu/exception.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/exception.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,51 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  exception.h                                                              |
- |                                                                           |
- | Copyright (C) 1992    W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@vaxc.cc.monash.edu.au    |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#ifndef _EXCEPTION_H_
-#define _EXCEPTION_H_
-
-#ifdef __ASSEMBLER__
-#define	Const_(x)	$##x
-#else
-#define	Const_(x)	x
-#endif
-
-#ifndef SW_C1
-#include "fpu_emu.h"
-#endif /* SW_C1 */
-
-#define FPU_BUSY        Const_(0x8000)	/* FPU busy bit (8087 compatibility) */
-#define EX_ErrorSummary Const_(0x0080)	/* Error summary status */
-/* Special exceptions: */
-#define	EX_INTERNAL	Const_(0x8000)	/* Internal error in wm-FPU-emu */
-#define EX_StackOver	Const_(0x0041|SW_C1)	/* stack overflow */
-#define EX_StackUnder	Const_(0x0041)	/* stack underflow */
-/* Exception flags: */
-#define EX_Precision	Const_(0x0020)	/* loss of precision */
-#define EX_Underflow	Const_(0x0010)	/* underflow */
-#define EX_Overflow	Const_(0x0008)	/* overflow */
-#define EX_ZeroDiv	Const_(0x0004)	/* divide by zero */
-#define EX_Denormal	Const_(0x0002)	/* denormalized operand */
-#define EX_Invalid	Const_(0x0001)	/* invalid operation */
-
-#define PRECISION_LOST_UP    Const_((EX_Precision | SW_C1))
-#define PRECISION_LOST_DOWN  Const_(EX_Precision)
-
-#ifndef __ASSEMBLER__
-
-#ifdef DEBUG
-#define	EXCEPTION(x)	{ printk("exception in %s at line %d\n", \
-	__FILE__, __LINE__); FPU_exception(x); }
-#else
-#define	EXCEPTION(x)	FPU_exception(x)
-#endif
-
-#endif /* __ASSEMBLER__ */
-
-#endif /* _EXCEPTION_H_ */
diff -rupN a/arch/x86/math-emu/fpu_arith.c b/arch/x86/math-emu/fpu_arith.c
--- a/arch/x86/math-emu/fpu_arith.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/fpu_arith.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,153 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  fpu_arith.c                                                              |
- |                                                                           |
- | Code to implement the FPU register/register arithmetic instructions       |
- |                                                                           |
- | Copyright (C) 1992,1993,1997                                              |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_system.h"
-#include "fpu_emu.h"
-#include "control_w.h"
-#include "status_w.h"
-
-void fadd__(void)
-{
-	/* fadd st,st(i) */
-	int i = FPU_rm;
-	clear_C1();
-	FPU_add(&st(i), FPU_gettagi(i), 0, control_word);
-}
-
-void fmul__(void)
-{
-	/* fmul st,st(i) */
-	int i = FPU_rm;
-	clear_C1();
-	FPU_mul(&st(i), FPU_gettagi(i), 0, control_word);
-}
-
-void fsub__(void)
-{
-	/* fsub st,st(i) */
-	clear_C1();
-	FPU_sub(0, FPU_rm, control_word);
-}
-
-void fsubr_(void)
-{
-	/* fsubr st,st(i) */
-	clear_C1();
-	FPU_sub(REV, FPU_rm, control_word);
-}
-
-void fdiv__(void)
-{
-	/* fdiv st,st(i) */
-	clear_C1();
-	FPU_div(0, FPU_rm, control_word);
-}
-
-void fdivr_(void)
-{
-	/* fdivr st,st(i) */
-	clear_C1();
-	FPU_div(REV, FPU_rm, control_word);
-}
-
-void fadd_i(void)
-{
-	/* fadd st(i),st */
-	int i = FPU_rm;
-	clear_C1();
-	FPU_add(&st(i), FPU_gettagi(i), i, control_word);
-}
-
-void fmul_i(void)
-{
-	/* fmul st(i),st */
-	clear_C1();
-	FPU_mul(&st(0), FPU_gettag0(), FPU_rm, control_word);
-}
-
-void fsubri(void)
-{
-	/* fsubr st(i),st */
-	clear_C1();
-	FPU_sub(DEST_RM, FPU_rm, control_word);
-}
-
-void fsub_i(void)
-{
-	/* fsub st(i),st */
-	clear_C1();
-	FPU_sub(REV | DEST_RM, FPU_rm, control_word);
-}
-
-void fdivri(void)
-{
-	/* fdivr st(i),st */
-	clear_C1();
-	FPU_div(DEST_RM, FPU_rm, control_word);
-}
-
-void fdiv_i(void)
-{
-	/* fdiv st(i),st */
-	clear_C1();
-	FPU_div(REV | DEST_RM, FPU_rm, control_word);
-}
-
-void faddp_(void)
-{
-	/* faddp st(i),st */
-	int i = FPU_rm;
-	clear_C1();
-	if (FPU_add(&st(i), FPU_gettagi(i), i, control_word) >= 0)
-		FPU_pop();
-}
-
-void fmulp_(void)
-{
-	/* fmulp st(i),st */
-	clear_C1();
-	if (FPU_mul(&st(0), FPU_gettag0(), FPU_rm, control_word) >= 0)
-		FPU_pop();
-}
-
-void fsubrp(void)
-{
-	/* fsubrp st(i),st */
-	clear_C1();
-	if (FPU_sub(DEST_RM, FPU_rm, control_word) >= 0)
-		FPU_pop();
-}
-
-void fsubp_(void)
-{
-	/* fsubp st(i),st */
-	clear_C1();
-	if (FPU_sub(REV | DEST_RM, FPU_rm, control_word) >= 0)
-		FPU_pop();
-}
-
-void fdivrp(void)
-{
-	/* fdivrp st(i),st */
-	clear_C1();
-	if (FPU_div(DEST_RM, FPU_rm, control_word) >= 0)
-		FPU_pop();
-}
-
-void fdivp_(void)
-{
-	/* fdivp st(i),st */
-	clear_C1();
-	if (FPU_div(REV | DEST_RM, FPU_rm, control_word) >= 0)
-		FPU_pop();
-}
diff -rupN a/arch/x86/math-emu/fpu_asm.h b/arch/x86/math-emu/fpu_asm.h
--- a/arch/x86/math-emu/fpu_asm.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/fpu_asm.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,32 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  fpu_asm.h                                                                |
- |                                                                           |
- | Copyright (C) 1992,1995,1997                                              |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@suburbia.net               |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#ifndef _FPU_ASM_H_
-#define _FPU_ASM_H_
-
-#include <linux/linkage.h>
-
-#define	EXCEPTION	FPU_exception
-
-#define PARAM1	8(%ebp)
-#define	PARAM2	12(%ebp)
-#define	PARAM3	16(%ebp)
-#define	PARAM4	20(%ebp)
-#define	PARAM5	24(%ebp)
-#define	PARAM6	28(%ebp)
-#define	PARAM7	32(%ebp)
-
-#define SIGL_OFFSET 0
-#define	EXP(x)	8(x)
-#define SIG(x)	SIGL_OFFSET##(x)
-#define	SIGL(x)	SIGL_OFFSET##(x)
-#define	SIGH(x)	4(x)
-
-#endif /* _FPU_ASM_H_ */
diff -rupN a/arch/x86/math-emu/fpu_aux.c b/arch/x86/math-emu/fpu_aux.c
--- a/arch/x86/math-emu/fpu_aux.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/fpu_aux.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,267 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  fpu_aux.c                                                                |
- |                                                                           |
- | Code to implement some of the FPU auxiliary instructions.                 |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997                                         |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_system.h"
-#include "exception.h"
-#include "fpu_emu.h"
-#include "status_w.h"
-#include "control_w.h"
-
-static void fnop(void)
-{
-}
-
-static void fclex(void)
-{
-	partial_status &=
-	    ~(SW_Backward | SW_Summary | SW_Stack_Fault | SW_Precision |
-	      SW_Underflow | SW_Overflow | SW_Zero_Div | SW_Denorm_Op |
-	      SW_Invalid);
-	no_ip_update = 1;
-}
-
-/* Needs to be externally visible */
-void fpstate_init_soft(struct swregs_state *soft)
-{
-	struct address *oaddr, *iaddr;
-	memset(soft, 0, sizeof(*soft));
-	soft->cwd = 0x037f;
-	soft->swd = 0;
-	soft->ftop = 0;	/* We don't keep top in the status word internally. */
-	soft->twd = 0xffff;
-	/* The behaviour is different from that detailed in
-	   Section 15.1.6 of the Intel manual */
-	oaddr = (struct address *)&soft->foo;
-	oaddr->offset = 0;
-	oaddr->selector = 0;
-	iaddr = (struct address *)&soft->fip;
-	iaddr->offset = 0;
-	iaddr->selector = 0;
-	iaddr->opcode = 0;
-	soft->no_update = 1;
-}
-
-void finit(void)
-{
-	fpstate_init_soft(&x86_task_fpu(current)->fpstate->regs.soft);
-}
-
-/*
- * These are nops on the i387..
- */
-#define feni fnop
-#define fdisi fnop
-#define fsetpm fnop
-
-static FUNC const finit_table[] = {
-	feni, fdisi, fclex, finit,
-	fsetpm, FPU_illegal, FPU_illegal, FPU_illegal
-};
-
-void finit_(void)
-{
-	(finit_table[FPU_rm]) ();
-}
-
-static void fstsw_ax(void)
-{
-	*(short *)&FPU_EAX = status_word();
-	no_ip_update = 1;
-}
-
-static FUNC const fstsw_table[] = {
-	fstsw_ax, FPU_illegal, FPU_illegal, FPU_illegal,
-	FPU_illegal, FPU_illegal, FPU_illegal, FPU_illegal
-};
-
-void fstsw_(void)
-{
-	(fstsw_table[FPU_rm]) ();
-}
-
-static FUNC const fp_nop_table[] = {
-	fnop, FPU_illegal, FPU_illegal, FPU_illegal,
-	FPU_illegal, FPU_illegal, FPU_illegal, FPU_illegal
-};
-
-void fp_nop(void)
-{
-	(fp_nop_table[FPU_rm]) ();
-}
-
-void fld_i_(void)
-{
-	FPU_REG *st_new_ptr;
-	int i;
-	u_char tag;
-
-	if (STACK_OVERFLOW) {
-		FPU_stack_overflow();
-		return;
-	}
-
-	/* fld st(i) */
-	i = FPU_rm;
-	if (NOT_EMPTY(i)) {
-		reg_copy(&st(i), st_new_ptr);
-		tag = FPU_gettagi(i);
-		push();
-		FPU_settag0(tag);
-	} else {
-		if (control_word & CW_Invalid) {
-			/* The masked response */
-			FPU_stack_underflow();
-		} else
-			EXCEPTION(EX_StackUnder);
-	}
-
-}
-
-void fxch_i(void)
-{
-	/* fxch st(i) */
-	FPU_REG t;
-	int i = FPU_rm;
-	FPU_REG *st0_ptr = &st(0), *sti_ptr = &st(i);
-	long tag_word = fpu_tag_word;
-	int regnr = top & 7, regnri = ((regnr + i) & 7);
-	u_char st0_tag = (tag_word >> (regnr * 2)) & 3;
-	u_char sti_tag = (tag_word >> (regnri * 2)) & 3;
-
-	if (st0_tag == TAG_Empty) {
-		if (sti_tag == TAG_Empty) {
-			FPU_stack_underflow();
-			FPU_stack_underflow_i(i);
-			return;
-		}
-		if (control_word & CW_Invalid) {
-			/* Masked response */
-			FPU_copy_to_reg0(sti_ptr, sti_tag);
-		}
-		FPU_stack_underflow_i(i);
-		return;
-	}
-	if (sti_tag == TAG_Empty) {
-		if (control_word & CW_Invalid) {
-			/* Masked response */
-			FPU_copy_to_regi(st0_ptr, st0_tag, i);
-		}
-		FPU_stack_underflow();
-		return;
-	}
-	clear_C1();
-
-	reg_copy(st0_ptr, &t);
-	reg_copy(sti_ptr, st0_ptr);
-	reg_copy(&t, sti_ptr);
-
-	tag_word &= ~(3 << (regnr * 2)) & ~(3 << (regnri * 2));
-	tag_word |= (sti_tag << (regnr * 2)) | (st0_tag << (regnri * 2));
-	fpu_tag_word = tag_word;
-}
-
-static void fcmovCC(void)
-{
-	/* fcmovCC st(i) */
-	int i = FPU_rm;
-	FPU_REG *st0_ptr = &st(0);
-	FPU_REG *sti_ptr = &st(i);
-	long tag_word = fpu_tag_word;
-	int regnr = top & 7;
-	int regnri = (top + i) & 7;
-	u_char sti_tag = (tag_word >> (regnri * 2)) & 3;
-
-	if (sti_tag == TAG_Empty) {
-		FPU_stack_underflow();
-		clear_C1();
-		return;
-	}
-	reg_copy(sti_ptr, st0_ptr);
-	tag_word &= ~(3 << (regnr * 2));
-	tag_word |= (sti_tag << (regnr * 2));
-	fpu_tag_word = tag_word;
-}
-
-void fcmovb(void)
-{
-	if (FPU_EFLAGS & X86_EFLAGS_CF)
-		fcmovCC();
-}
-
-void fcmove(void)
-{
-	if (FPU_EFLAGS & X86_EFLAGS_ZF)
-		fcmovCC();
-}
-
-void fcmovbe(void)
-{
-	if (FPU_EFLAGS & (X86_EFLAGS_CF|X86_EFLAGS_ZF))
-		fcmovCC();
-}
-
-void fcmovu(void)
-{
-	if (FPU_EFLAGS & X86_EFLAGS_PF)
-		fcmovCC();
-}
-
-void fcmovnb(void)
-{
-	if (!(FPU_EFLAGS & X86_EFLAGS_CF))
-		fcmovCC();
-}
-
-void fcmovne(void)
-{
-	if (!(FPU_EFLAGS & X86_EFLAGS_ZF))
-		fcmovCC();
-}
-
-void fcmovnbe(void)
-{
-	if (!(FPU_EFLAGS & (X86_EFLAGS_CF|X86_EFLAGS_ZF)))
-		fcmovCC();
-}
-
-void fcmovnu(void)
-{
-	if (!(FPU_EFLAGS & X86_EFLAGS_PF))
-		fcmovCC();
-}
-
-void ffree_(void)
-{
-	/* ffree st(i) */
-	FPU_settagi(FPU_rm, TAG_Empty);
-}
-
-void ffreep(void)
-{
-	/* ffree st(i) + pop - unofficial code */
-	FPU_settagi(FPU_rm, TAG_Empty);
-	FPU_pop();
-}
-
-void fst_i_(void)
-{
-	/* fst st(i) */
-	FPU_copy_to_regi(&st(0), FPU_gettag0(), FPU_rm);
-}
-
-void fstp_i(void)
-{
-	/* fstp st(i) */
-	FPU_copy_to_regi(&st(0), FPU_gettag0(), FPU_rm);
-	FPU_pop();
-}
diff -rupN a/arch/x86/math-emu/fpu_emu.h b/arch/x86/math-emu/fpu_emu.h
--- a/arch/x86/math-emu/fpu_emu.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/fpu_emu.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,218 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  fpu_emu.h                                                                |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997                                         |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@suburbia.net             |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#ifndef _FPU_EMU_H_
-#define _FPU_EMU_H_
-
-/*
- * Define PECULIAR_486 to get a closer approximation to 80486 behaviour,
- * rather than behaviour which appears to be cleaner.
- * This is a matter of opinion: for all I know, the 80486 may simply
- * be complying with the IEEE spec. Maybe one day I'll get to see the
- * spec...
- */
-#define PECULIAR_486
-
-#ifdef __ASSEMBLER__
-#include "fpu_asm.h"
-#define	Const(x)	$##x
-#else
-#define	Const(x)	x
-#endif
-
-#define EXP_BIAS	Const(0)
-#define EXP_OVER	Const(0x4000)	/* smallest invalid large exponent */
-#define	EXP_UNDER	Const(-0x3fff)	/* largest invalid small exponent */
-#define EXP_WAY_UNDER   Const(-0x6000)	/* Below the smallest denormal, but
-					   still a 16 bit nr. */
-#define EXP_Infinity    EXP_OVER
-#define EXP_NaN         EXP_OVER
-
-#define EXTENDED_Ebias Const(0x3fff)
-#define EXTENDED_Emin (-0x3ffe)	/* smallest valid exponent */
-
-#define SIGN_POS	Const(0)
-#define SIGN_NEG	Const(0x80)
-
-#define SIGN_Positive	Const(0)
-#define SIGN_Negative	Const(0x8000)
-
-/* Keep the order TAG_Valid, TAG_Zero, TW_Denormal */
-/* The following fold to 2 (Special) in the Tag Word */
-#define TW_Denormal     Const(4)	/* De-normal */
-#define TW_Infinity	Const(5)	/* + or - infinity */
-#define	TW_NaN		Const(6)	/* Not a Number */
-#define	TW_Unsupported	Const(7)	/* Not supported by an 80486 */
-
-#define TAG_Valid	Const(0)	/* valid */
-#define TAG_Zero	Const(1)	/* zero */
-#define TAG_Special	Const(2)	/* De-normal, + or - infinity,
-					   or Not a Number */
-#define TAG_Empty	Const(3)	/* empty */
-#define TAG_Error	Const(0x80)	/* probably need to abort */
-
-#define LOADED_DATA	Const(10101)	/* Special st() number to identify
-					   loaded data (not on stack). */
-
-/* A few flags (must be >= 0x10). */
-#define REV             0x10
-#define DEST_RM         0x20
-#define LOADED          0x40
-
-#define FPU_Exception   Const(0x80000000)	/* Added to tag returns. */
-
-#ifndef __ASSEMBLER__
-
-#include "fpu_system.h"
-
-#include <uapi/asm/sigcontext.h>	/* for struct _fpstate */
-#include <asm/math_emu.h>
-#include <linux/linkage.h>
-
-/*
-#define RE_ENTRANT_CHECKING
- */
-
-#ifdef RE_ENTRANT_CHECKING
-extern u_char emulating;
-#  define RE_ENTRANT_CHECK_OFF emulating = 0
-#  define RE_ENTRANT_CHECK_ON emulating = 1
-#else
-#  define RE_ENTRANT_CHECK_OFF
-#  define RE_ENTRANT_CHECK_ON
-#endif /* RE_ENTRANT_CHECKING */
-
-#define FWAIT_OPCODE 0x9b
-#define OP_SIZE_PREFIX 0x66
-#define ADDR_SIZE_PREFIX 0x67
-#define PREFIX_CS 0x2e
-#define PREFIX_DS 0x3e
-#define PREFIX_ES 0x26
-#define PREFIX_SS 0x36
-#define PREFIX_FS 0x64
-#define PREFIX_GS 0x65
-#define PREFIX_REPE 0xf3
-#define PREFIX_REPNE 0xf2
-#define PREFIX_LOCK 0xf0
-#define PREFIX_CS_ 1
-#define PREFIX_DS_ 2
-#define PREFIX_ES_ 3
-#define PREFIX_FS_ 4
-#define PREFIX_GS_ 5
-#define PREFIX_SS_ 6
-#define PREFIX_DEFAULT 7
-
-struct address {
-	unsigned int offset;
-	unsigned int selector:16;
-	unsigned int opcode:11;
-	unsigned int empty:5;
-};
-struct fpu__reg {
-	unsigned sigl;
-	unsigned sigh;
-	short exp;
-};
-
-typedef void (*FUNC) (void);
-typedef struct fpu__reg FPU_REG;
-typedef void (*FUNC_ST0) (FPU_REG *st0_ptr, u_char st0_tag);
-typedef struct {
-	u_char address_size, operand_size, segment;
-} overrides;
-/* This structure is 32 bits: */
-typedef struct {
-	overrides override;
-	u_char default_mode;
-} fpu_addr_modes;
-/* PROTECTED has a restricted meaning in the emulator; it is used
-   to signal that the emulator needs to do special things to ensure
-   that protection is respected in a segmented model. */
-#define PROTECTED 4
-#define SIXTEEN   1		/* We rely upon this being 1 (true) */
-#define VM86      SIXTEEN
-#define PM16      (SIXTEEN | PROTECTED)
-#define SEG32     PROTECTED
-extern u_char const data_sizes_16[32];
-
-#define register_base ((u_char *) registers )
-#define fpu_register(x)  ( * ((FPU_REG *)( register_base + 10 * (x & 7) )) )
-#define	st(x)      ( * ((FPU_REG *)( register_base + 10 * ((top+x) & 7) )) )
-
-#define	STACK_OVERFLOW	(FPU_stackoverflow(&st_new_ptr))
-#define	NOT_EMPTY(i)	(!FPU_empty_i(i))
-
-#define	NOT_EMPTY_ST0	(st0_tag ^ TAG_Empty)
-
-#define poppop() { FPU_pop(); FPU_pop(); }
-
-/* push() does not affect the tags */
-#define push()	{ top--; }
-
-#define signbyte(a) (((u_char *)(a))[9])
-#define getsign(a) (signbyte(a) & 0x80)
-#define setsign(a,b) { if ((b) != 0) signbyte(a) |= 0x80; else signbyte(a) &= 0x7f; }
-#define copysign(a,b) { if (getsign(a)) signbyte(b) |= 0x80; \
-                        else signbyte(b) &= 0x7f; }
-#define changesign(a) { signbyte(a) ^= 0x80; }
-#define setpositive(a) { signbyte(a) &= 0x7f; }
-#define setnegative(a) { signbyte(a) |= 0x80; }
-#define signpositive(a) ( (signbyte(a) & 0x80) == 0 )
-#define signnegative(a) (signbyte(a) & 0x80)
-
-static inline void reg_copy(FPU_REG const *x, FPU_REG *y)
-{
-	*(short *)&(y->exp) = *(const short *)&(x->exp);
-	*(long long *)&(y->sigl) = *(const long long *)&(x->sigl);
-}
-
-#define exponent(x)  (((*(short *)&((x)->exp)) & 0x7fff) - EXTENDED_Ebias)
-#define setexponentpos(x,y) { (*(short *)&((x)->exp)) = \
-  ((y) + EXTENDED_Ebias) & 0x7fff; }
-#define exponent16(x)         (*(short *)&((x)->exp))
-#define setexponent16(x,y)  { (*(short *)&((x)->exp)) = (u16)(y); }
-#define addexponent(x,y)    { (*(short *)&((x)->exp)) += (y); }
-#define stdexp(x)           { (*(short *)&((x)->exp)) += EXTENDED_Ebias; }
-
-#define isdenormal(ptr)   (exponent(ptr) == EXP_BIAS+EXP_UNDER)
-
-#define significand(x) ( ((unsigned long long *)&((x)->sigl))[0] )
-
-/*----- Prototypes for functions written in assembler -----*/
-/* extern void reg_move(FPU_REG *a, FPU_REG *b); */
-
-asmlinkage int FPU_normalize(FPU_REG *x);
-asmlinkage int FPU_normalize_nuo(FPU_REG *x);
-asmlinkage int FPU_u_sub(FPU_REG const *arg1, FPU_REG const *arg2,
-			 FPU_REG * answ, unsigned int control_w, u_char sign,
-			 int expa, int expb);
-asmlinkage int FPU_u_mul(FPU_REG const *arg1, FPU_REG const *arg2,
-			 FPU_REG * answ, unsigned int control_w, u_char sign,
-			 int expon);
-asmlinkage int FPU_u_div(FPU_REG const *arg1, FPU_REG const *arg2,
-			 FPU_REG * answ, unsigned int control_w, u_char sign);
-asmlinkage int FPU_u_add(FPU_REG const *arg1, FPU_REG const *arg2,
-			 FPU_REG * answ, unsigned int control_w, u_char sign,
-			 int expa, int expb);
-asmlinkage int wm_sqrt(FPU_REG *n, int dummy1, int dummy2,
-		       unsigned int control_w, u_char sign);
-asmlinkage unsigned FPU_shrx(void *l, unsigned x);
-asmlinkage unsigned FPU_shrxs(void *v, unsigned x);
-asmlinkage unsigned long FPU_div_small(unsigned long long *x, unsigned long y);
-asmlinkage int FPU_round(FPU_REG *arg, unsigned int extent, int dummy,
-			 unsigned int control_w, u_char sign);
-
-#ifndef MAKING_PROTO
-#include "fpu_proto.h"
-#endif
-
-#endif /* __ASSEMBLER__ */
-
-#endif /* _FPU_EMU_H_ */
diff -rupN a/arch/x86/math-emu/fpu_entry.c b/arch/x86/math-emu/fpu_entry.c
--- a/arch/x86/math-emu/fpu_entry.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/fpu_entry.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,718 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  fpu_entry.c                                                              |
- |                                                                           |
- | The entry functions for wm-FPU-emu                                        |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1996,1997                                    |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- | See the files "README" and "COPYING" for further copyright and warranty   |
- | information.                                                              |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | Note:                                                                     |
- |    The file contains code which accesses user memory.                     |
- |    Emulator static data may change when user memory is accessed, due to   |
- |    other processes using the emulator while swapping is in progress.      |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | math_emulate(), restore_i387_soft() and save_i387_soft() are the only     |
- | entry points for wm-FPU-emu.                                              |
- +---------------------------------------------------------------------------*/
-
-#include <linux/signal.h>
-#include <linux/regset.h>
-
-#include <linux/uaccess.h>
-#include <asm/traps.h>
-#include <asm/user.h>
-#include <asm/fpu/api.h>
-#include <asm/fpu/regset.h>
-
-#include "fpu_system.h"
-#include "fpu_emu.h"
-#include "exception.h"
-#include "control_w.h"
-#include "status_w.h"
-
-#define __BAD__ FPU_illegal	/* Illegal on an 80486, causes SIGILL */
-
-/* fcmovCC and f(u)comi(p) are enabled if CPUID(1).EDX(15) "cmov" is set */
-
-/* WARNING: "u" entries are not documented by Intel in their 80486 manual
-   and may not work on FPU clones or later Intel FPUs.
-   Changes to support them provided by Linus Torvalds. */
-
-static FUNC const st_instr_table[64] = {
-/* Opcode:	d8		d9		da		db */
-/*		dc		dd		de		df */
-/* c0..7 */	fadd__,		fld_i_,		fcmovb,		fcmovnb,
-/* c0..7 */	fadd_i,		ffree_,		faddp_,		ffreep,/*u*/
-/* c8..f */	fmul__,		fxch_i,		fcmove,		fcmovne,
-/* c8..f */	fmul_i,		fxch_i,/*u*/	fmulp_,		fxch_i,/*u*/
-/* d0..7 */	fcom_st,	fp_nop,		fcmovbe,	fcmovnbe,
-/* d0..7 */	fcom_st,/*u*/	fst_i_,		fcompst,/*u*/	fstp_i,/*u*/
-/* d8..f */	fcompst,	fstp_i,/*u*/	fcmovu,		fcmovnu,
-/* d8..f */	fcompst,/*u*/	fstp_i,		fcompp,		fstp_i,/*u*/
-/* e0..7 */	fsub__,		FPU_etc,	__BAD__,	finit_,
-/* e0..7 */	fsubri,		fucom_,		fsubrp,		fstsw_,
-/* e8..f */	fsubr_,		fconst,		fucompp,	fucomi_,
-/* e8..f */	fsub_i,		fucomp,		fsubp_,		fucomip,
-/* f0..7 */	fdiv__,		FPU_triga,	__BAD__,	fcomi_,
-/* f0..7 */	fdivri,		__BAD__,	fdivrp,		fcomip,
-/* f8..f */	fdivr_,		FPU_trigb,	__BAD__,	__BAD__,
-/* f8..f */	fdiv_i,		__BAD__,	fdivp_,		__BAD__,
-};
-
-#define _NONE_ 0		/* Take no special action */
-#define _REG0_ 1		/* Need to check for not empty st(0) */
-#define _REGI_ 2		/* Need to check for not empty st(0) and st(rm) */
-#define _REGi_ 0		/* Uses st(rm) */
-#define _PUSH_ 3		/* Need to check for space to push onto stack */
-#define _null_ 4		/* Function illegal or not implemented */
-#define _REGIi 5		/* Uses st(0) and st(rm), result to st(rm) */
-#define _REGIp 6		/* Uses st(0) and st(rm), result to st(rm) then pop */
-#define _REGIc 0		/* Compare st(0) and st(rm) */
-#define _REGIn 0		/* Uses st(0) and st(rm), but handle checks later */
-
-static u_char const type_table[64] = {
-/* Opcode:	d8	d9	da	db	dc	dd	de	df */
-/* c0..7 */	_REGI_, _NONE_, _REGIn, _REGIn, _REGIi, _REGi_, _REGIp, _REGi_,
-/* c8..f */	_REGI_, _REGIn, _REGIn, _REGIn, _REGIi, _REGI_, _REGIp, _REGI_,
-/* d0..7 */	_REGIc, _NONE_, _REGIn, _REGIn, _REGIc, _REG0_, _REGIc, _REG0_,
-/* d8..f */	_REGIc, _REG0_, _REGIn, _REGIn, _REGIc, _REG0_, _REGIc, _REG0_,
-/* e0..7 */	_REGI_, _NONE_, _null_, _NONE_, _REGIi, _REGIc, _REGIp, _NONE_,
-/* e8..f */	_REGI_, _NONE_, _REGIc, _REGIc, _REGIi, _REGIc, _REGIp, _REGIc,
-/* f0..7 */	_REGI_, _NONE_, _null_, _REGIc, _REGIi, _null_, _REGIp, _REGIc,
-/* f8..f */	_REGI_, _NONE_, _null_, _null_, _REGIi, _null_, _REGIp, _null_,
-};
-
-#ifdef RE_ENTRANT_CHECKING
-u_char emulating = 0;
-#endif /* RE_ENTRANT_CHECKING */
-
-static int valid_prefix(u_char *Byte, u_char __user ** fpu_eip,
-			overrides * override);
-
-void math_emulate(struct math_emu_info *info)
-{
-	u_char FPU_modrm, byte1;
-	unsigned short code;
-	fpu_addr_modes addr_modes;
-	int unmasked;
-	FPU_REG loaded_data;
-	FPU_REG *st0_ptr;
-	u_char loaded_tag, st0_tag;
-	void __user *data_address;
-	struct address data_sel_off;
-	struct address entry_sel_off;
-	unsigned long code_base = 0;
-	unsigned long code_limit = 0;	/* Initialized to stop compiler warnings */
-	struct desc_struct code_descriptor;
-
-#ifdef RE_ENTRANT_CHECKING
-	if (emulating) {
-		printk("ERROR: wm-FPU-emu is not RE-ENTRANT!\n");
-	}
-	RE_ENTRANT_CHECK_ON;
-#endif /* RE_ENTRANT_CHECKING */
-
-	FPU_info = info;
-
-	FPU_ORIG_EIP = FPU_EIP;
-
-	if ((FPU_EFLAGS & 0x00020000) != 0) {
-		/* Virtual 8086 mode */
-		addr_modes.default_mode = VM86;
-		FPU_EIP += code_base = FPU_CS << 4;
-		code_limit = code_base + 0xffff;	/* Assumes code_base <= 0xffff0000 */
-	} else if (FPU_CS == __USER_CS && FPU_DS == __USER_DS) {
-		addr_modes.default_mode = 0;
-	} else if (FPU_CS == __KERNEL_CS) {
-		printk("math_emulate: %04x:%08lx\n", FPU_CS, FPU_EIP);
-		panic("Math emulation needed in kernel");
-	} else {
-
-		if ((FPU_CS & 4) != 4) {	/* Must be in the LDT */
-			/* Can only handle segmented addressing via the LDT
-			   for now, and it must be 16 bit */
-			printk("FPU emulator: Unsupported addressing mode\n");
-			math_abort(FPU_info, SIGILL);
-		}
-
-		code_descriptor = FPU_get_ldt_descriptor(FPU_CS);
-		if (code_descriptor.d) {
-			/* The above test may be wrong, the book is not clear */
-			/* Segmented 32 bit protected mode */
-			addr_modes.default_mode = SEG32;
-		} else {
-			/* 16 bit protected mode */
-			addr_modes.default_mode = PM16;
-		}
-		FPU_EIP += code_base = seg_get_base(&code_descriptor);
-		code_limit = seg_get_limit(&code_descriptor) + 1;
-		code_limit *= seg_get_granularity(&code_descriptor);
-		code_limit += code_base - 1;
-		if (code_limit < code_base)
-			code_limit = 0xffffffff;
-	}
-
-	FPU_lookahead = !(FPU_EFLAGS & X86_EFLAGS_TF);
-
-	if (!valid_prefix(&byte1, (u_char __user **) & FPU_EIP,
-			  &addr_modes.override)) {
-		RE_ENTRANT_CHECK_OFF;
-		printk
-		    ("FPU emulator: Unknown prefix byte 0x%02x, probably due to\n"
-		     "FPU emulator: self-modifying code! (emulation impossible)\n",
-		     byte1);
-		RE_ENTRANT_CHECK_ON;
-		EXCEPTION(EX_INTERNAL | 0x126);
-		math_abort(FPU_info, SIGILL);
-	}
-
-      do_another_FPU_instruction:
-
-	no_ip_update = 0;
-
-	FPU_EIP++;		/* We have fetched the prefix and first code bytes. */
-
-	if (addr_modes.default_mode) {
-		/* This checks for the minimum instruction bytes.
-		   We also need to check any extra (address mode) code access. */
-		if (FPU_EIP > code_limit)
-			math_abort(FPU_info, SIGSEGV);
-	}
-
-	if ((byte1 & 0xf8) != 0xd8) {
-		if (byte1 == FWAIT_OPCODE) {
-			if (partial_status & SW_Summary)
-				goto do_the_FPU_interrupt;
-			else
-				goto FPU_fwait_done;
-		}
-#ifdef PARANOID
-		EXCEPTION(EX_INTERNAL | 0x128);
-		math_abort(FPU_info, SIGILL);
-#endif /* PARANOID */
-	}
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_code_access_ok(1);
-	FPU_get_user(FPU_modrm, (u_char __user *) FPU_EIP);
-	RE_ENTRANT_CHECK_ON;
-	FPU_EIP++;
-
-	if (partial_status & SW_Summary) {
-		/* Ignore the error for now if the current instruction is a no-wait
-		   control instruction */
-		/* The 80486 manual contradicts itself on this topic,
-		   but a real 80486 uses the following instructions:
-		   fninit, fnstenv, fnsave, fnstsw, fnstenv, fnclex.
-		 */
-		code = (FPU_modrm << 8) | byte1;
-		if (!((((code & 0xf803) == 0xe003) ||	/* fnclex, fninit, fnstsw */
-		       (((code & 0x3003) == 0x3001) &&	/* fnsave, fnstcw, fnstenv,
-							   fnstsw */
-			((code & 0xc000) != 0xc000))))) {
-			/*
-			 *  We need to simulate the action of the kernel to FPU
-			 *  interrupts here.
-			 */
-		      do_the_FPU_interrupt:
-
-			FPU_EIP = FPU_ORIG_EIP;	/* Point to current FPU instruction. */
-
-			RE_ENTRANT_CHECK_OFF;
-			current->thread.trap_nr = X86_TRAP_MF;
-			current->thread.error_code = 0;
-			send_sig(SIGFPE, current, 1);
-			return;
-		}
-	}
-
-	entry_sel_off.offset = FPU_ORIG_EIP;
-	entry_sel_off.selector = FPU_CS;
-	entry_sel_off.opcode = (byte1 << 8) | FPU_modrm;
-	entry_sel_off.empty = 0;
-
-	FPU_rm = FPU_modrm & 7;
-
-	if (FPU_modrm < 0300) {
-		/* All of these instructions use the mod/rm byte to get a data address */
-
-		if ((addr_modes.default_mode & SIXTEEN)
-		    ^ (addr_modes.override.address_size == ADDR_SIZE_PREFIX))
-			data_address =
-			    FPU_get_address_16(FPU_modrm, &FPU_EIP,
-					       &data_sel_off, addr_modes);
-		else
-			data_address =
-			    FPU_get_address(FPU_modrm, &FPU_EIP, &data_sel_off,
-					    addr_modes);
-
-		if (addr_modes.default_mode) {
-			if (FPU_EIP - 1 > code_limit)
-				math_abort(FPU_info, SIGSEGV);
-		}
-
-		if (!(byte1 & 1)) {
-			unsigned short status1 = partial_status;
-
-			st0_ptr = &st(0);
-			st0_tag = FPU_gettag0();
-
-			/* Stack underflow has priority */
-			if (NOT_EMPTY_ST0) {
-				if (addr_modes.default_mode & PROTECTED) {
-					/* This table works for 16 and 32 bit protected mode */
-					if (access_limit <
-					    data_sizes_16[(byte1 >> 1) & 3])
-						math_abort(FPU_info, SIGSEGV);
-				}
-
-				unmasked = 0;	/* Do this here to stop compiler warnings. */
-				switch ((byte1 >> 1) & 3) {
-				case 0:
-					unmasked =
-					    FPU_load_single((float __user *)
-							    data_address,
-							    &loaded_data);
-					loaded_tag = unmasked & 0xff;
-					unmasked &= ~0xff;
-					break;
-				case 1:
-					loaded_tag =
-					    FPU_load_int32((long __user *)
-							   data_address,
-							   &loaded_data);
-					break;
-				case 2:
-					unmasked =
-					    FPU_load_double((double __user *)
-							    data_address,
-							    &loaded_data);
-					loaded_tag = unmasked & 0xff;
-					unmasked &= ~0xff;
-					break;
-				case 3:
-				default:	/* Used here to suppress gcc warnings. */
-					loaded_tag =
-					    FPU_load_int16((short __user *)
-							   data_address,
-							   &loaded_data);
-					break;
-				}
-
-				/* No more access to user memory, it is safe
-				   to use static data now */
-
-				/* NaN operands have the next priority. */
-				/* We have to delay looking at st(0) until after
-				   loading the data, because that data might contain an SNaN */
-				if (((st0_tag == TAG_Special) && isNaN(st0_ptr))
-				    || ((loaded_tag == TAG_Special)
-					&& isNaN(&loaded_data))) {
-					/* Restore the status word; we might have loaded a
-					   denormal. */
-					partial_status = status1;
-					if ((FPU_modrm & 0x30) == 0x10) {
-						/* fcom or fcomp */
-						EXCEPTION(EX_Invalid);
-						setcc(SW_C3 | SW_C2 | SW_C0);
-						if ((FPU_modrm & 0x08)
-						    && (control_word &
-							CW_Invalid))
-							FPU_pop();	/* fcomp, masked, so we pop. */
-					} else {
-						if (loaded_tag == TAG_Special)
-							loaded_tag =
-							    FPU_Special
-							    (&loaded_data);
-#ifdef PECULIAR_486
-						/* This is not really needed, but gives behaviour
-						   identical to an 80486 */
-						if ((FPU_modrm & 0x28) == 0x20)
-							/* fdiv or fsub */
-							real_2op_NaN
-							    (&loaded_data,
-							     loaded_tag, 0,
-							     &loaded_data);
-						else
-#endif /* PECULIAR_486 */
-							/* fadd, fdivr, fmul, or fsubr */
-							real_2op_NaN
-							    (&loaded_data,
-							     loaded_tag, 0,
-							     st0_ptr);
-					}
-					goto reg_mem_instr_done;
-				}
-
-				if (unmasked && !((FPU_modrm & 0x30) == 0x10)) {
-					/* Is not a comparison instruction. */
-					if ((FPU_modrm & 0x38) == 0x38) {
-						/* fdivr */
-						if ((st0_tag == TAG_Zero) &&
-						    ((loaded_tag == TAG_Valid)
-						     || (loaded_tag ==
-							 TAG_Special
-							 &&
-							 isdenormal
-							 (&loaded_data)))) {
-							if (FPU_divide_by_zero
-							    (0,
-							     getsign
-							     (&loaded_data))
-							    < 0) {
-								/* We use the fact here that the unmasked
-								   exception in the loaded data was for a
-								   denormal operand */
-								/* Restore the state of the denormal op bit */
-								partial_status
-								    &=
-								    ~SW_Denorm_Op;
-								partial_status
-								    |=
-								    status1 &
-								    SW_Denorm_Op;
-							} else
-								setsign(st0_ptr,
-									getsign
-									(&loaded_data));
-						}
-					}
-					goto reg_mem_instr_done;
-				}
-
-				switch ((FPU_modrm >> 3) & 7) {
-				case 0:	/* fadd */
-					clear_C1();
-					FPU_add(&loaded_data, loaded_tag, 0,
-						control_word);
-					break;
-				case 1:	/* fmul */
-					clear_C1();
-					FPU_mul(&loaded_data, loaded_tag, 0,
-						control_word);
-					break;
-				case 2:	/* fcom */
-					FPU_compare_st_data(&loaded_data,
-							    loaded_tag);
-					break;
-				case 3:	/* fcomp */
-					if (!FPU_compare_st_data
-					    (&loaded_data, loaded_tag)
-					    && !unmasked)
-						FPU_pop();
-					break;
-				case 4:	/* fsub */
-					clear_C1();
-					FPU_sub(LOADED | loaded_tag,
-						(int)&loaded_data,
-						control_word);
-					break;
-				case 5:	/* fsubr */
-					clear_C1();
-					FPU_sub(REV | LOADED | loaded_tag,
-						(int)&loaded_data,
-						control_word);
-					break;
-				case 6:	/* fdiv */
-					clear_C1();
-					FPU_div(LOADED | loaded_tag,
-						(int)&loaded_data,
-						control_word);
-					break;
-				case 7:	/* fdivr */
-					clear_C1();
-					if (st0_tag == TAG_Zero)
-						partial_status = status1;	/* Undo any denorm tag,
-										   zero-divide has priority. */
-					FPU_div(REV | LOADED | loaded_tag,
-						(int)&loaded_data,
-						control_word);
-					break;
-				}
-			} else {
-				if ((FPU_modrm & 0x30) == 0x10) {
-					/* The instruction is fcom or fcomp */
-					EXCEPTION(EX_StackUnder);
-					setcc(SW_C3 | SW_C2 | SW_C0);
-					if ((FPU_modrm & 0x08)
-					    && (control_word & CW_Invalid))
-						FPU_pop();	/* fcomp */
-				} else
-					FPU_stack_underflow();
-			}
-		      reg_mem_instr_done:
-			operand_address = data_sel_off;
-		} else {
-			if (!(no_ip_update =
-			      FPU_load_store(((FPU_modrm & 0x38) | (byte1 & 6))
-					     >> 1, addr_modes, data_address))) {
-				operand_address = data_sel_off;
-			}
-		}
-
-	} else {
-		/* None of these instructions access user memory */
-		u_char instr_index = (FPU_modrm & 0x38) | (byte1 & 7);
-
-#ifdef PECULIAR_486
-		/* This is supposed to be undefined, but a real 80486 seems
-		   to do this: */
-		operand_address.offset = 0;
-		operand_address.selector = FPU_DS;
-#endif /* PECULIAR_486 */
-
-		st0_ptr = &st(0);
-		st0_tag = FPU_gettag0();
-		switch (type_table[(int)instr_index]) {
-		case _NONE_:	/* also _REGIc: _REGIn */
-			break;
-		case _REG0_:
-			if (!NOT_EMPTY_ST0) {
-				FPU_stack_underflow();
-				goto FPU_instruction_done;
-			}
-			break;
-		case _REGIi:
-			if (!NOT_EMPTY_ST0 || !NOT_EMPTY(FPU_rm)) {
-				FPU_stack_underflow_i(FPU_rm);
-				goto FPU_instruction_done;
-			}
-			break;
-		case _REGIp:
-			if (!NOT_EMPTY_ST0 || !NOT_EMPTY(FPU_rm)) {
-				FPU_stack_underflow_pop(FPU_rm);
-				goto FPU_instruction_done;
-			}
-			break;
-		case _REGI_:
-			if (!NOT_EMPTY_ST0 || !NOT_EMPTY(FPU_rm)) {
-				FPU_stack_underflow();
-				goto FPU_instruction_done;
-			}
-			break;
-		case _PUSH_:	/* Only used by the fld st(i) instruction */
-			break;
-		case _null_:
-			FPU_illegal();
-			goto FPU_instruction_done;
-		default:
-			EXCEPTION(EX_INTERNAL | 0x111);
-			goto FPU_instruction_done;
-		}
-		(*st_instr_table[(int)instr_index]) ();
-
-	      FPU_instruction_done:
-		;
-	}
-
-	if (!no_ip_update)
-		instruction_address = entry_sel_off;
-
-      FPU_fwait_done:
-
-#ifdef DEBUG
-	RE_ENTRANT_CHECK_OFF;
-	FPU_printall();
-	RE_ENTRANT_CHECK_ON;
-#endif /* DEBUG */
-
-	if (FPU_lookahead && !need_resched()) {
-		FPU_ORIG_EIP = FPU_EIP - code_base;
-		if (valid_prefix(&byte1, (u_char __user **) & FPU_EIP,
-				 &addr_modes.override))
-			goto do_another_FPU_instruction;
-	}
-
-	if (addr_modes.default_mode)
-		FPU_EIP -= code_base;
-
-	RE_ENTRANT_CHECK_OFF;
-}
-
-/* Support for prefix bytes is not yet complete. To properly handle
-   all prefix bytes, further changes are needed in the emulator code
-   which accesses user address space. Access to separate segments is
-   important for msdos emulation. */
-static int valid_prefix(u_char *Byte, u_char __user **fpu_eip,
-			overrides * override)
-{
-	u_char byte;
-	u_char __user *ip = *fpu_eip;
-
-	*override = (overrides) {
-	0, 0, PREFIX_DEFAULT};	/* defaults */
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_code_access_ok(1);
-	FPU_get_user(byte, ip);
-	RE_ENTRANT_CHECK_ON;
-
-	while (1) {
-		switch (byte) {
-		case ADDR_SIZE_PREFIX:
-			override->address_size = ADDR_SIZE_PREFIX;
-			goto do_next_byte;
-
-		case OP_SIZE_PREFIX:
-			override->operand_size = OP_SIZE_PREFIX;
-			goto do_next_byte;
-
-		case PREFIX_CS:
-			override->segment = PREFIX_CS_;
-			goto do_next_byte;
-		case PREFIX_ES:
-			override->segment = PREFIX_ES_;
-			goto do_next_byte;
-		case PREFIX_SS:
-			override->segment = PREFIX_SS_;
-			goto do_next_byte;
-		case PREFIX_FS:
-			override->segment = PREFIX_FS_;
-			goto do_next_byte;
-		case PREFIX_GS:
-			override->segment = PREFIX_GS_;
-			goto do_next_byte;
-		case PREFIX_DS:
-			override->segment = PREFIX_DS_;
-			goto do_next_byte;
-
-/* lock is not a valid prefix for FPU instructions,
-   let the cpu handle it to generate a SIGILL. */
-/*	case PREFIX_LOCK: */
-
-			/* rep.. prefixes have no meaning for FPU instructions */
-		case PREFIX_REPE:
-		case PREFIX_REPNE:
-
-		      do_next_byte:
-			ip++;
-			RE_ENTRANT_CHECK_OFF;
-			FPU_code_access_ok(1);
-			FPU_get_user(byte, ip);
-			RE_ENTRANT_CHECK_ON;
-			break;
-		case FWAIT_OPCODE:
-			*Byte = byte;
-			return 1;
-		default:
-			if ((byte & 0xf8) == 0xd8) {
-				*Byte = byte;
-				*fpu_eip = ip;
-				return 1;
-			} else {
-				/* Not a valid sequence of prefix bytes followed by
-				   an FPU instruction. */
-				*Byte = byte;	/* Needed for error message. */
-				return 0;
-			}
-		}
-	}
-}
-
-void math_abort(struct math_emu_info *info, unsigned int signal)
-{
-	FPU_EIP = FPU_ORIG_EIP;
-	current->thread.trap_nr = X86_TRAP_MF;
-	current->thread.error_code = 0;
-	send_sig(signal, current, 1);
-	RE_ENTRANT_CHECK_OFF;
-      __asm__("movl %0,%%esp ; ret": :"g"(((long)info) - 4));
-#ifdef PARANOID
-	printk("ERROR: wm-FPU-emu math_abort failed!\n");
-#endif /* PARANOID */
-}
-
-#define S387 ((struct swregs_state *)s387)
-#define sstatus_word() \
-  ((S387->swd & ~SW_Top & 0xffff) | ((S387->ftop << SW_Top_Shift) & SW_Top))
-
-int fpregs_soft_set(struct task_struct *target,
-		    const struct user_regset *regset,
-		    unsigned int pos, unsigned int count,
-		    const void *kbuf, const void __user *ubuf)
-{
-	struct swregs_state *s387 = &x86_task_fpu(target)->fpstate->regs.soft;
-	void *space = s387->st_space;
-	int ret;
-	int offset, other, i, tags, regnr, tag, newtop;
-
-	RE_ENTRANT_CHECK_OFF;
-	ret = user_regset_copyin(&pos, &count, &kbuf, &ubuf, s387, 0,
-				 offsetof(struct swregs_state, st_space));
-	RE_ENTRANT_CHECK_ON;
-
-	if (ret)
-		return ret;
-
-	S387->ftop = (S387->swd >> SW_Top_Shift) & 7;
-	offset = (S387->ftop & 7) * 10;
-	other = 80 - offset;
-
-	RE_ENTRANT_CHECK_OFF;
-
-	/* Copy all registers in stack order. */
-	ret = user_regset_copyin(&pos, &count, &kbuf, &ubuf,
-				 space + offset, 0, other);
-	if (!ret && offset)
-		ret = user_regset_copyin(&pos, &count, &kbuf, &ubuf,
-					 space, 0, offset);
-
-	RE_ENTRANT_CHECK_ON;
-
-	/* The tags may need to be corrected now. */
-	tags = S387->twd;
-	newtop = S387->ftop;
-	for (i = 0; i < 8; i++) {
-		regnr = (i + newtop) & 7;
-		if (((tags >> ((regnr & 7) * 2)) & 3) != TAG_Empty) {
-			/* The loaded data over-rides all other cases. */
-			tag =
-			    FPU_tagof((FPU_REG *) ((u_char *) S387->st_space +
-						   10 * regnr));
-			tags &= ~(3 << (regnr * 2));
-			tags |= (tag & 3) << (regnr * 2);
-		}
-	}
-	S387->twd = tags;
-
-	return ret;
-}
-
-int fpregs_soft_get(struct task_struct *target,
-		    const struct user_regset *regset,
-		    struct membuf to)
-{
-	struct swregs_state *s387 = &x86_task_fpu(target)->fpstate->regs.soft;
-	const void *space = s387->st_space;
-	int offset = (S387->ftop & 7) * 10, other = 80 - offset;
-
-	RE_ENTRANT_CHECK_OFF;
-
-#ifdef PECULIAR_486
-	S387->cwd &= ~0xe080;
-	/* An 80486 sets nearly all of the reserved bits to 1. */
-	S387->cwd |= 0xffff0040;
-	S387->swd = sstatus_word() | 0xffff0000;
-	S387->twd |= 0xffff0000;
-	S387->fcs &= ~0xf8000000;
-	S387->fos |= 0xffff0000;
-#endif /* PECULIAR_486 */
-
-	membuf_write(&to, s387, offsetof(struct swregs_state, st_space));
-	membuf_write(&to, space + offset, other);
-	membuf_write(&to, space, offset);
-
-	RE_ENTRANT_CHECK_ON;
-
-	return 0;
-}
diff -rupN a/arch/x86/math-emu/fpu_etc.c b/arch/x86/math-emu/fpu_etc.c
--- a/arch/x86/math-emu/fpu_etc.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/fpu_etc.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,136 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  fpu_etc.c                                                                |
- |                                                                           |
- | Implement a few FPU instructions.                                         |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997                                         |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@suburbia.net             |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_system.h"
-#include "exception.h"
-#include "fpu_emu.h"
-#include "status_w.h"
-#include "reg_constant.h"
-
-static void fchs(FPU_REG *st0_ptr, u_char st0tag)
-{
-	if (st0tag ^ TAG_Empty) {
-		signbyte(st0_ptr) ^= SIGN_NEG;
-		clear_C1();
-	} else
-		FPU_stack_underflow();
-}
-
-static void fabs(FPU_REG *st0_ptr, u_char st0tag)
-{
-	if (st0tag ^ TAG_Empty) {
-		setpositive(st0_ptr);
-		clear_C1();
-	} else
-		FPU_stack_underflow();
-}
-
-static void ftst_(FPU_REG *st0_ptr, u_char st0tag)
-{
-	switch (st0tag) {
-	case TAG_Zero:
-		setcc(SW_C3);
-		break;
-	case TAG_Valid:
-		if (getsign(st0_ptr) == SIGN_POS)
-			setcc(0);
-		else
-			setcc(SW_C0);
-		break;
-	case TAG_Special:
-		switch (FPU_Special(st0_ptr)) {
-		case TW_Denormal:
-			if (getsign(st0_ptr) == SIGN_POS)
-				setcc(0);
-			else
-				setcc(SW_C0);
-			if (denormal_operand() < 0) {
-#ifdef PECULIAR_486
-				/* This is weird! */
-				if (getsign(st0_ptr) == SIGN_POS)
-					setcc(SW_C3);
-#endif /* PECULIAR_486 */
-				return;
-			}
-			break;
-		case TW_NaN:
-			setcc(SW_C0 | SW_C2 | SW_C3);	/* Operand is not comparable */
-			EXCEPTION(EX_Invalid);
-			break;
-		case TW_Infinity:
-			if (getsign(st0_ptr) == SIGN_POS)
-				setcc(0);
-			else
-				setcc(SW_C0);
-			break;
-		default:
-			setcc(SW_C0 | SW_C2 | SW_C3);	/* Operand is not comparable */
-			EXCEPTION(EX_INTERNAL | 0x14);
-			break;
-		}
-		break;
-	case TAG_Empty:
-		setcc(SW_C0 | SW_C2 | SW_C3);
-		EXCEPTION(EX_StackUnder);
-		break;
-	}
-}
-
-static void fxam(FPU_REG *st0_ptr, u_char st0tag)
-{
-	int c = 0;
-	switch (st0tag) {
-	case TAG_Empty:
-		c = SW_C3 | SW_C0;
-		break;
-	case TAG_Zero:
-		c = SW_C3;
-		break;
-	case TAG_Valid:
-		c = SW_C2;
-		break;
-	case TAG_Special:
-		switch (FPU_Special(st0_ptr)) {
-		case TW_Denormal:
-			c = SW_C2 | SW_C3;	/* Denormal */
-			break;
-		case TW_NaN:
-			/* We also use NaN for unsupported types. */
-			if ((st0_ptr->sigh & 0x80000000)
-			    && (exponent(st0_ptr) == EXP_OVER))
-				c = SW_C0;
-			break;
-		case TW_Infinity:
-			c = SW_C2 | SW_C0;
-			break;
-		}
-	}
-	if (getsign(st0_ptr) == SIGN_NEG)
-		c |= SW_C1;
-	setcc(c);
-}
-
-static void FPU_ST0_illegal(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	FPU_illegal();
-}
-
-static FUNC_ST0 const fp_etc_table[] = {
-	fchs, fabs, FPU_ST0_illegal, FPU_ST0_illegal,
-	ftst_, fxam, FPU_ST0_illegal, FPU_ST0_illegal,
-};
-
-void FPU_etc(void)
-{
-	(fp_etc_table[FPU_rm]) (&st(0), FPU_gettag0());
-}
diff -rupN a/arch/x86/math-emu/fpu_proto.h b/arch/x86/math-emu/fpu_proto.h
--- a/arch/x86/math-emu/fpu_proto.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/fpu_proto.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,157 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-#ifndef _FPU_PROTO_H
-#define _FPU_PROTO_H
-
-/* errors.c */
-extern void FPU_illegal(void);
-extern void FPU_printall(void);
-asmlinkage void FPU_exception(int n);
-extern int real_1op_NaN(FPU_REG *a);
-extern int real_2op_NaN(FPU_REG const *b, u_char tagb, int deststnr,
-			FPU_REG const *defaultNaN);
-asmlinkage int arith_invalid(int deststnr);
-asmlinkage int FPU_divide_by_zero(int deststnr, u_char sign);
-extern int set_precision_flag(int flags);
-asmlinkage void set_precision_flag_up(void);
-asmlinkage void set_precision_flag_down(void);
-asmlinkage int denormal_operand(void);
-asmlinkage int arith_overflow(FPU_REG *dest);
-asmlinkage int arith_underflow(FPU_REG *dest);
-extern void FPU_stack_overflow(void);
-extern void FPU_stack_underflow(void);
-extern void FPU_stack_underflow_i(int i);
-extern void FPU_stack_underflow_pop(int i);
-/* fpu_arith.c */
-extern void fadd__(void);
-extern void fmul__(void);
-extern void fsub__(void);
-extern void fsubr_(void);
-extern void fdiv__(void);
-extern void fdivr_(void);
-extern void fadd_i(void);
-extern void fmul_i(void);
-extern void fsubri(void);
-extern void fsub_i(void);
-extern void fdivri(void);
-extern void fdiv_i(void);
-extern void faddp_(void);
-extern void fmulp_(void);
-extern void fsubrp(void);
-extern void fsubp_(void);
-extern void fdivrp(void);
-extern void fdivp_(void);
-/* fpu_aux.c */
-extern void finit(void);
-extern void finit_(void);
-extern void fstsw_(void);
-extern void fp_nop(void);
-extern void fld_i_(void);
-extern void fxch_i(void);
-extern void fcmovb(void);
-extern void fcmove(void);
-extern void fcmovbe(void);
-extern void fcmovu(void);
-extern void fcmovnb(void);
-extern void fcmovne(void);
-extern void fcmovnbe(void);
-extern void fcmovnu(void);
-extern void ffree_(void);
-extern void ffreep(void);
-extern void fst_i_(void);
-extern void fstp_i(void);
-/* fpu_entry.c */
-extern void math_emulate(struct math_emu_info *info);
-extern void math_abort(struct math_emu_info *info, unsigned int signal);
-/* fpu_etc.c */
-extern void FPU_etc(void);
-/* fpu_tags.c */
-extern int FPU_gettag0(void);
-extern int FPU_gettagi(int stnr);
-extern int FPU_gettag(int regnr);
-extern void FPU_settag0(int tag);
-extern void FPU_settagi(int stnr, int tag);
-extern void FPU_settag(int regnr, int tag);
-extern int FPU_Special(FPU_REG const *ptr);
-extern int isNaN(FPU_REG const *ptr);
-extern void FPU_pop(void);
-extern int FPU_empty_i(int stnr);
-extern int FPU_stackoverflow(FPU_REG ** st_new_ptr);
-extern void FPU_copy_to_regi(FPU_REG const *r, u_char tag, int stnr);
-extern void FPU_copy_to_reg1(FPU_REG const *r, u_char tag);
-extern void FPU_copy_to_reg0(FPU_REG const *r, u_char tag);
-/* fpu_trig.c */
-extern void FPU_triga(void);
-extern void FPU_trigb(void);
-/* get_address.c */
-extern void __user *FPU_get_address(u_char FPU_modrm, unsigned long *fpu_eip,
-				    struct address *addr,
-				    fpu_addr_modes addr_modes);
-extern void __user *FPU_get_address_16(u_char FPU_modrm, unsigned long *fpu_eip,
-				       struct address *addr,
-				       fpu_addr_modes addr_modes);
-/* load_store.c */
-extern int FPU_load_store(u_char type, fpu_addr_modes addr_modes,
-			  void __user * data_address);
-/* poly_2xm1.c */
-extern int poly_2xm1(u_char sign, FPU_REG * arg, FPU_REG *result);
-/* poly_atan.c */
-extern void poly_atan(FPU_REG * st0_ptr, u_char st0_tag, FPU_REG *st1_ptr,
-		      u_char st1_tag);
-/* poly_l2.c */
-extern void poly_l2(FPU_REG *st0_ptr, FPU_REG *st1_ptr, u_char st1_sign);
-extern int poly_l2p1(u_char s0, u_char s1, FPU_REG *r0, FPU_REG *r1,
-		     FPU_REG * d);
-/* poly_sin.c */
-extern void poly_sine(FPU_REG *st0_ptr);
-extern void poly_cos(FPU_REG *st0_ptr);
-/* poly_tan.c */
-extern void poly_tan(FPU_REG *st0_ptr);
-/* reg_add_sub.c */
-extern int FPU_add(FPU_REG const *b, u_char tagb, int destrnr, int control_w);
-extern int FPU_sub(int flags, int rm, int control_w);
-/* reg_compare.c */
-extern int FPU_compare_st_data(FPU_REG const *loaded_data, u_char loaded_tag);
-extern void fcom_st(void);
-extern void fcompst(void);
-extern void fcompp(void);
-extern void fucom_(void);
-extern void fucomp(void);
-extern void fucompp(void);
-extern void fcomi_(void);
-extern void fcomip(void);
-extern void fucomi_(void);
-extern void fucomip(void);
-/* reg_constant.c */
-extern void fconst(void);
-/* reg_ld_str.c */
-extern int FPU_load_extended(long double __user *s, int stnr);
-extern int FPU_load_double(double __user *dfloat, FPU_REG *loaded_data);
-extern int FPU_load_single(float __user *single, FPU_REG *loaded_data);
-extern int FPU_load_int64(long long __user *_s);
-extern int FPU_load_int32(long __user *_s, FPU_REG *loaded_data);
-extern int FPU_load_int16(short __user *_s, FPU_REG *loaded_data);
-extern int FPU_load_bcd(u_char __user *s);
-extern int FPU_store_extended(FPU_REG *st0_ptr, u_char st0_tag,
-			      long double __user * d);
-extern int FPU_store_double(FPU_REG *st0_ptr, u_char st0_tag,
-			    double __user * dfloat);
-extern int FPU_store_single(FPU_REG *st0_ptr, u_char st0_tag,
-			    float __user * single);
-extern int FPU_store_int64(FPU_REG *st0_ptr, u_char st0_tag,
-			   long long __user * d);
-extern int FPU_store_int32(FPU_REG *st0_ptr, u_char st0_tag, long __user *d);
-extern int FPU_store_int16(FPU_REG *st0_ptr, u_char st0_tag, short __user *d);
-extern int FPU_store_bcd(FPU_REG *st0_ptr, u_char st0_tag, u_char __user *d);
-extern int FPU_round_to_int(FPU_REG *r, u_char tag);
-extern u_char __user *fldenv(fpu_addr_modes addr_modes, u_char __user *s);
-extern void FPU_frstor(fpu_addr_modes addr_modes, u_char __user *data_address);
-extern u_char __user *fstenv(fpu_addr_modes addr_modes, u_char __user *d);
-extern void fsave(fpu_addr_modes addr_modes, u_char __user *data_address);
-extern int FPU_tagof(FPU_REG *ptr);
-/* reg_mul.c */
-extern int FPU_mul(FPU_REG const *b, u_char tagb, int deststnr, int control_w);
-
-extern int FPU_div(int flags, int regrm, int control_w);
-/* reg_convert.c */
-extern int FPU_to_exp16(FPU_REG const *a, FPU_REG *x);
-#endif /* _FPU_PROTO_H */
diff -rupN a/arch/x86/math-emu/fpu_system.h b/arch/x86/math-emu/fpu_system.h
--- a/arch/x86/math-emu/fpu_system.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/fpu_system.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,130 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  fpu_system.h                                                             |
- |                                                                           |
- | Copyright (C) 1992,1994,1997                                              |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@suburbia.net             |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#ifndef _FPU_SYSTEM_H
-#define _FPU_SYSTEM_H
-
-/* system dependent definitions */
-
-#include <linux/sched.h>
-#include <linux/kernel.h>
-#include <linux/mm.h>
-
-#include <asm/desc.h>
-#include <asm/mmu_context.h>
-
-static inline struct desc_struct FPU_get_ldt_descriptor(unsigned seg)
-{
-	static struct desc_struct zero_desc;
-	struct desc_struct ret = zero_desc;
-
-#ifdef CONFIG_MODIFY_LDT_SYSCALL
-	seg >>= 3;
-	mutex_lock(&current->mm->context.lock);
-	if (current->mm->context.ldt && seg < current->mm->context.ldt->nr_entries)
-		ret = current->mm->context.ldt->entries[seg];
-	mutex_unlock(&current->mm->context.lock);
-#endif
-	return ret;
-}
-
-#define SEG_TYPE_WRITABLE	(1U << 1)
-#define SEG_TYPE_EXPANDS_DOWN	(1U << 2)
-#define SEG_TYPE_EXECUTE	(1U << 3)
-#define SEG_TYPE_EXPAND_MASK	(SEG_TYPE_EXPANDS_DOWN | SEG_TYPE_EXECUTE)
-#define SEG_TYPE_EXECUTE_MASK	(SEG_TYPE_WRITABLE | SEG_TYPE_EXECUTE)
-
-static inline unsigned long seg_get_base(struct desc_struct *d)
-{
-	unsigned long base = (unsigned long)d->base2 << 24;
-
-	return base | ((unsigned long)d->base1 << 16) | d->base0;
-}
-
-static inline unsigned long seg_get_limit(struct desc_struct *d)
-{
-	return ((unsigned long)d->limit1 << 16) | d->limit0;
-}
-
-static inline unsigned long seg_get_granularity(struct desc_struct *d)
-{
-	return d->g ? 4096 : 1;
-}
-
-static inline bool seg_expands_down(struct desc_struct *d)
-{
-	return (d->type & SEG_TYPE_EXPAND_MASK) == SEG_TYPE_EXPANDS_DOWN;
-}
-
-static inline bool seg_execute_only(struct desc_struct *d)
-{
-	return (d->type & SEG_TYPE_EXECUTE_MASK) == SEG_TYPE_EXECUTE;
-}
-
-static inline bool seg_writable(struct desc_struct *d)
-{
-	return (d->type & SEG_TYPE_EXECUTE_MASK) == SEG_TYPE_WRITABLE;
-}
-
-#define I387			(&x86_task_fpu(current)->fpstate->regs)
-#define FPU_info		(I387->soft.info)
-
-#define FPU_CS			(*(unsigned short *) &(FPU_info->regs->cs))
-#define FPU_SS			(*(unsigned short *) &(FPU_info->regs->ss))
-#define FPU_DS			(*(unsigned short *) &(FPU_info->regs->ds))
-#define FPU_EAX			(FPU_info->regs->ax)
-#define FPU_EFLAGS		(FPU_info->regs->flags)
-#define FPU_EIP			(FPU_info->regs->ip)
-#define FPU_ORIG_EIP		(FPU_info->___orig_eip)
-
-#define FPU_lookahead           (I387->soft.lookahead)
-
-/* nz if ip_offset and cs_selector are not to be set for the current
-   instruction. */
-#define no_ip_update		(*(u_char *)&(I387->soft.no_update))
-#define FPU_rm			(*(u_char *)&(I387->soft.rm))
-
-/* Number of bytes of data which can be legally accessed by the current
-   instruction. This only needs to hold a number <= 108, so a byte will do. */
-#define access_limit		(*(u_char *)&(I387->soft.alimit))
-
-#define partial_status		(I387->soft.swd)
-#define control_word		(I387->soft.cwd)
-#define fpu_tag_word		(I387->soft.twd)
-#define registers		(I387->soft.st_space)
-#define top			(I387->soft.ftop)
-
-#define instruction_address	(*(struct address *)&I387->soft.fip)
-#define operand_address		(*(struct address *)&I387->soft.foo)
-
-#define FPU_access_ok(y,z)	if ( !access_ok(y,z) ) \
-				math_abort(FPU_info,SIGSEGV)
-#define FPU_abort		math_abort(FPU_info, SIGSEGV)
-#define FPU_copy_from_user(to, from, n)	\
-		do { if (copy_from_user(to, from, n)) FPU_abort; } while (0)
-
-#undef FPU_IGNORE_CODE_SEGV
-#ifdef FPU_IGNORE_CODE_SEGV
-/* access_ok() is very expensive, and causes the emulator to run
-   about 20% slower if applied to the code. Anyway, errors due to bad
-   code addresses should be much rarer than errors due to bad data
-   addresses. */
-#define	FPU_code_access_ok(z)
-#else
-/* A simpler test than access_ok() can probably be done for
-   FPU_code_access_ok() because the only possible error is to step
-   past the upper boundary of a legal code area. */
-#define	FPU_code_access_ok(z) FPU_access_ok((void __user *)FPU_EIP,z)
-#endif
-
-#define FPU_get_user(x,y) do { if (get_user((x),(y))) FPU_abort; } while (0)
-#define FPU_put_user(x,y) do { if (put_user((x),(y))) FPU_abort; } while (0)
-
-#endif
diff -rupN a/arch/x86/math-emu/fpu_tags.c b/arch/x86/math-emu/fpu_tags.c
--- a/arch/x86/math-emu/fpu_tags.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/fpu_tags.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,116 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  fpu_tags.c                                                               |
- |                                                                           |
- |  Set FPU register tags.                                                   |
- |                                                                           |
- | Copyright (C) 1997                                                        |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@jacobi.maths.monash.edu.au                |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_emu.h"
-#include "fpu_system.h"
-#include "exception.h"
-
-void FPU_pop(void)
-{
-	fpu_tag_word |= 3 << ((top & 7) * 2);
-	top++;
-}
-
-int FPU_gettag0(void)
-{
-	return (fpu_tag_word >> ((top & 7) * 2)) & 3;
-}
-
-int FPU_gettagi(int stnr)
-{
-	return (fpu_tag_word >> (((top + stnr) & 7) * 2)) & 3;
-}
-
-int FPU_gettag(int regnr)
-{
-	return (fpu_tag_word >> ((regnr & 7) * 2)) & 3;
-}
-
-void FPU_settag0(int tag)
-{
-	int regnr = top;
-	regnr &= 7;
-	fpu_tag_word &= ~(3 << (regnr * 2));
-	fpu_tag_word |= (tag & 3) << (regnr * 2);
-}
-
-void FPU_settagi(int stnr, int tag)
-{
-	int regnr = stnr + top;
-	regnr &= 7;
-	fpu_tag_word &= ~(3 << (regnr * 2));
-	fpu_tag_word |= (tag & 3) << (regnr * 2);
-}
-
-void FPU_settag(int regnr, int tag)
-{
-	regnr &= 7;
-	fpu_tag_word &= ~(3 << (regnr * 2));
-	fpu_tag_word |= (tag & 3) << (regnr * 2);
-}
-
-int FPU_Special(FPU_REG const *ptr)
-{
-	int exp = exponent(ptr);
-
-	if (exp == EXP_BIAS + EXP_UNDER)
-		return TW_Denormal;
-	else if (exp != EXP_BIAS + EXP_OVER)
-		return TW_NaN;
-	else if ((ptr->sigh == 0x80000000) && (ptr->sigl == 0))
-		return TW_Infinity;
-	return TW_NaN;
-}
-
-int isNaN(FPU_REG const *ptr)
-{
-	return ((exponent(ptr) == EXP_BIAS + EXP_OVER)
-		&& !((ptr->sigh == 0x80000000) && (ptr->sigl == 0)));
-}
-
-int FPU_empty_i(int stnr)
-{
-	int regnr = (top + stnr) & 7;
-
-	return ((fpu_tag_word >> (regnr * 2)) & 3) == TAG_Empty;
-}
-
-int FPU_stackoverflow(FPU_REG ** st_new_ptr)
-{
-	*st_new_ptr = &st(-1);
-
-	return ((fpu_tag_word >> (((top - 1) & 7) * 2)) & 3) != TAG_Empty;
-}
-
-void FPU_copy_to_regi(FPU_REG const *r, u_char tag, int stnr)
-{
-	reg_copy(r, &st(stnr));
-	FPU_settagi(stnr, tag);
-}
-
-void FPU_copy_to_reg1(FPU_REG const *r, u_char tag)
-{
-	reg_copy(r, &st(1));
-	FPU_settagi(1, tag);
-}
-
-void FPU_copy_to_reg0(FPU_REG const *r, u_char tag)
-{
-	int regnr = top;
-	regnr &= 7;
-
-	reg_copy(r, &st(0));
-
-	fpu_tag_word &= ~(3 << (regnr * 2));
-	fpu_tag_word |= (tag & 3) << (regnr * 2);
-}
diff -rupN a/arch/x86/math-emu/fpu_trig.c b/arch/x86/math-emu/fpu_trig.c
--- a/arch/x86/math-emu/fpu_trig.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/fpu_trig.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,1649 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  fpu_trig.c                                                               |
- |                                                                           |
- | Implementation of the FPU "transcendental" functions.                     |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997,1999                                    |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@melbpc.org.au            |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_system.h"
-#include "exception.h"
-#include "fpu_emu.h"
-#include "status_w.h"
-#include "control_w.h"
-#include "reg_constant.h"
-
-static void rem_kernel(unsigned long long st0, unsigned long long *y,
-		       unsigned long long st1, unsigned long long q, int n);
-
-#define BETTER_THAN_486
-
-#define FCOS  4
-
-/* Used only by fptan, fsin, fcos, and fsincos. */
-/* This routine produces very accurate results, similar to
-   using a value of pi with more than 128 bits precision. */
-/* Limited measurements show no results worse than 64 bit precision
-   except for the results for arguments close to 2^63, where the
-   precision of the result sometimes degrades to about 63.9 bits */
-static int trig_arg(FPU_REG *st0_ptr, int even)
-{
-	FPU_REG tmp;
-	u_char tmptag;
-	unsigned long long q;
-	int old_cw = control_word, saved_status = partial_status;
-	int tag, st0_tag = TAG_Valid;
-
-	if (exponent(st0_ptr) >= 63) {
-		partial_status |= SW_C2;	/* Reduction incomplete. */
-		return -1;
-	}
-
-	control_word &= ~CW_RC;
-	control_word |= RC_CHOP;
-
-	setpositive(st0_ptr);
-	tag = FPU_u_div(st0_ptr, &CONST_PI2, &tmp, PR_64_BITS | RC_CHOP | 0x3f,
-			SIGN_POS);
-
-	FPU_round_to_int(&tmp, tag);	/* Fortunately, this can't overflow
-					   to 2^64 */
-	q = significand(&tmp);
-	if (q) {
-		rem_kernel(significand(st0_ptr),
-			   &significand(&tmp),
-			   significand(&CONST_PI2),
-			   q, exponent(st0_ptr) - exponent(&CONST_PI2));
-		setexponent16(&tmp, exponent(&CONST_PI2));
-		st0_tag = FPU_normalize(&tmp);
-		FPU_copy_to_reg0(&tmp, st0_tag);
-	}
-
-	if ((even && !(q & 1)) || (!even && (q & 1))) {
-		st0_tag =
-		    FPU_sub(REV | LOADED | TAG_Valid, (int)&CONST_PI2,
-			    FULL_PRECISION);
-
-#ifdef BETTER_THAN_486
-		/* So far, the results are exact but based upon a 64 bit
-		   precision approximation to pi/2. The technique used
-		   now is equivalent to using an approximation to pi/2 which
-		   is accurate to about 128 bits. */
-		if ((exponent(st0_ptr) <= exponent(&CONST_PI2extra) + 64)
-		    || (q > 1)) {
-			/* This code gives the effect of having pi/2 to better than
-			   128 bits precision. */
-
-			significand(&tmp) = q + 1;
-			setexponent16(&tmp, 63);
-			FPU_normalize(&tmp);
-			tmptag =
-			    FPU_u_mul(&CONST_PI2extra, &tmp, &tmp,
-				      FULL_PRECISION, SIGN_POS,
-				      exponent(&CONST_PI2extra) +
-				      exponent(&tmp));
-			setsign(&tmp, getsign(&CONST_PI2extra));
-			st0_tag = FPU_add(&tmp, tmptag, 0, FULL_PRECISION);
-			if (signnegative(st0_ptr)) {
-				/* CONST_PI2extra is negative, so the result of the addition
-				   can be negative. This means that the argument is actually
-				   in a different quadrant. The correction is always < pi/2,
-				   so it can't overflow into yet another quadrant. */
-				setpositive(st0_ptr);
-				q++;
-			}
-		}
-#endif /* BETTER_THAN_486 */
-	}
-#ifdef BETTER_THAN_486
-	else {
-		/* So far, the results are exact but based upon a 64 bit
-		   precision approximation to pi/2. The technique used
-		   now is equivalent to using an approximation to pi/2 which
-		   is accurate to about 128 bits. */
-		if (((q > 0)
-		     && (exponent(st0_ptr) <= exponent(&CONST_PI2extra) + 64))
-		    || (q > 1)) {
-			/* This code gives the effect of having p/2 to better than
-			   128 bits precision. */
-
-			significand(&tmp) = q;
-			setexponent16(&tmp, 63);
-			FPU_normalize(&tmp);	/* This must return TAG_Valid */
-			tmptag =
-			    FPU_u_mul(&CONST_PI2extra, &tmp, &tmp,
-				      FULL_PRECISION, SIGN_POS,
-				      exponent(&CONST_PI2extra) +
-				      exponent(&tmp));
-			setsign(&tmp, getsign(&CONST_PI2extra));
-			st0_tag = FPU_sub(LOADED | (tmptag & 0x0f), (int)&tmp,
-					  FULL_PRECISION);
-			if ((exponent(st0_ptr) == exponent(&CONST_PI2)) &&
-			    ((st0_ptr->sigh > CONST_PI2.sigh)
-			     || ((st0_ptr->sigh == CONST_PI2.sigh)
-				 && (st0_ptr->sigl > CONST_PI2.sigl)))) {
-				/* CONST_PI2extra is negative, so the result of the
-				   subtraction can be larger than pi/2. This means
-				   that the argument is actually in a different quadrant.
-				   The correction is always < pi/2, so it can't overflow
-				   into yet another quadrant. */
-				st0_tag =
-				    FPU_sub(REV | LOADED | TAG_Valid,
-					    (int)&CONST_PI2, FULL_PRECISION);
-				q++;
-			}
-		}
-	}
-#endif /* BETTER_THAN_486 */
-
-	FPU_settag0(st0_tag);
-	control_word = old_cw;
-	partial_status = saved_status & ~SW_C2;	/* Reduction complete. */
-
-	return (q & 3) | even;
-}
-
-/* Convert a long to register */
-static void convert_l2reg(long const *arg, int deststnr)
-{
-	int tag;
-	long num = *arg;
-	u_char sign;
-	FPU_REG *dest = &st(deststnr);
-
-	if (num == 0) {
-		FPU_copy_to_regi(&CONST_Z, TAG_Zero, deststnr);
-		return;
-	}
-
-	if (num > 0) {
-		sign = SIGN_POS;
-	} else {
-		num = -num;
-		sign = SIGN_NEG;
-	}
-
-	dest->sigh = num;
-	dest->sigl = 0;
-	setexponent16(dest, 31);
-	tag = FPU_normalize(dest);
-	FPU_settagi(deststnr, tag);
-	setsign(dest, sign);
-	return;
-}
-
-static void single_arg_error(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	if (st0_tag == TAG_Empty)
-		FPU_stack_underflow();	/* Puts a QNaN in st(0) */
-	else if (st0_tag == TW_NaN)
-		real_1op_NaN(st0_ptr);	/* return with a NaN in st(0) */
-#ifdef PARANOID
-	else
-		EXCEPTION(EX_INTERNAL | 0x0112);
-#endif /* PARANOID */
-}
-
-static void single_arg_2_error(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	int isNaN;
-
-	switch (st0_tag) {
-	case TW_NaN:
-		isNaN = (exponent(st0_ptr) == EXP_OVER)
-		    && (st0_ptr->sigh & 0x80000000);
-		if (isNaN && !(st0_ptr->sigh & 0x40000000)) {	/* Signaling ? */
-			EXCEPTION(EX_Invalid);
-			if (control_word & CW_Invalid) {
-				/* The masked response */
-				/* Convert to a QNaN */
-				st0_ptr->sigh |= 0x40000000;
-				push();
-				FPU_copy_to_reg0(st0_ptr, TAG_Special);
-			}
-		} else if (isNaN) {
-			/* A QNaN */
-			push();
-			FPU_copy_to_reg0(st0_ptr, TAG_Special);
-		} else {
-			/* pseudoNaN or other unsupported */
-			EXCEPTION(EX_Invalid);
-			if (control_word & CW_Invalid) {
-				/* The masked response */
-				FPU_copy_to_reg0(&CONST_QNaN, TAG_Special);
-				push();
-				FPU_copy_to_reg0(&CONST_QNaN, TAG_Special);
-			}
-		}
-		break;		/* return with a NaN in st(0) */
-#ifdef PARANOID
-	default:
-		EXCEPTION(EX_INTERNAL | 0x0112);
-#endif /* PARANOID */
-	}
-}
-
-/*---------------------------------------------------------------------------*/
-
-static void f2xm1(FPU_REG *st0_ptr, u_char tag)
-{
-	FPU_REG a;
-
-	clear_C1();
-
-	if (tag == TAG_Valid) {
-		/* For an 80486 FPU, the result is undefined if the arg is >= 1.0 */
-		if (exponent(st0_ptr) < 0) {
-		      denormal_arg:
-
-			FPU_to_exp16(st0_ptr, &a);
-
-			/* poly_2xm1(x) requires 0 < st(0) < 1. */
-			poly_2xm1(getsign(st0_ptr), &a, st0_ptr);
-		}
-		set_precision_flag_up();	/* 80486 appears to always do this */
-		return;
-	}
-
-	if (tag == TAG_Zero)
-		return;
-
-	if (tag == TAG_Special)
-		tag = FPU_Special(st0_ptr);
-
-	switch (tag) {
-	case TW_Denormal:
-		if (denormal_operand() < 0)
-			return;
-		goto denormal_arg;
-	case TW_Infinity:
-		if (signnegative(st0_ptr)) {
-			/* -infinity gives -1 (p16-10) */
-			FPU_copy_to_reg0(&CONST_1, TAG_Valid);
-			setnegative(st0_ptr);
-		}
-		return;
-	default:
-		single_arg_error(st0_ptr, tag);
-	}
-}
-
-static void fptan(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	FPU_REG *st_new_ptr;
-	int q;
-	u_char arg_sign = getsign(st0_ptr);
-
-	/* Stack underflow has higher priority */
-	if (st0_tag == TAG_Empty) {
-		FPU_stack_underflow();	/* Puts a QNaN in st(0) */
-		if (control_word & CW_Invalid) {
-			st_new_ptr = &st(-1);
-			push();
-			FPU_stack_underflow();	/* Puts a QNaN in the new st(0) */
-		}
-		return;
-	}
-
-	if (STACK_OVERFLOW) {
-		FPU_stack_overflow();
-		return;
-	}
-
-	if (st0_tag == TAG_Valid) {
-		if (exponent(st0_ptr) > -40) {
-			if ((q = trig_arg(st0_ptr, 0)) == -1) {
-				/* Operand is out of range */
-				return;
-			}
-
-			poly_tan(st0_ptr);
-			setsign(st0_ptr, (q & 1) ^ (arg_sign != 0));
-			set_precision_flag_up();	/* We do not really know if up or down */
-		} else {
-			/* For a small arg, the result == the argument */
-			/* Underflow may happen */
-
-		      denormal_arg:
-
-			FPU_to_exp16(st0_ptr, st0_ptr);
-
-			st0_tag =
-			    FPU_round(st0_ptr, 1, 0, FULL_PRECISION, arg_sign);
-			FPU_settag0(st0_tag);
-		}
-		push();
-		FPU_copy_to_reg0(&CONST_1, TAG_Valid);
-		return;
-	}
-
-	if (st0_tag == TAG_Zero) {
-		push();
-		FPU_copy_to_reg0(&CONST_1, TAG_Valid);
-		setcc(0);
-		return;
-	}
-
-	if (st0_tag == TAG_Special)
-		st0_tag = FPU_Special(st0_ptr);
-
-	if (st0_tag == TW_Denormal) {
-		if (denormal_operand() < 0)
-			return;
-
-		goto denormal_arg;
-	}
-
-	if (st0_tag == TW_Infinity) {
-		/* The 80486 treats infinity as an invalid operand */
-		if (arith_invalid(0) >= 0) {
-			st_new_ptr = &st(-1);
-			push();
-			arith_invalid(0);
-		}
-		return;
-	}
-
-	single_arg_2_error(st0_ptr, st0_tag);
-}
-
-static void fxtract(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	FPU_REG *st_new_ptr;
-	u_char sign;
-	register FPU_REG *st1_ptr = st0_ptr;	/* anticipate */
-
-	if (STACK_OVERFLOW) {
-		FPU_stack_overflow();
-		return;
-	}
-
-	clear_C1();
-
-	if (st0_tag == TAG_Valid) {
-		long e;
-
-		push();
-		sign = getsign(st1_ptr);
-		reg_copy(st1_ptr, st_new_ptr);
-		setexponent16(st_new_ptr, exponent(st_new_ptr));
-
-	      denormal_arg:
-
-		e = exponent16(st_new_ptr);
-		convert_l2reg(&e, 1);
-		setexponentpos(st_new_ptr, 0);
-		setsign(st_new_ptr, sign);
-		FPU_settag0(TAG_Valid);	/* Needed if arg was a denormal */
-		return;
-	} else if (st0_tag == TAG_Zero) {
-		sign = getsign(st0_ptr);
-
-		if (FPU_divide_by_zero(0, SIGN_NEG) < 0)
-			return;
-
-		push();
-		FPU_copy_to_reg0(&CONST_Z, TAG_Zero);
-		setsign(st_new_ptr, sign);
-		return;
-	}
-
-	if (st0_tag == TAG_Special)
-		st0_tag = FPU_Special(st0_ptr);
-
-	if (st0_tag == TW_Denormal) {
-		if (denormal_operand() < 0)
-			return;
-
-		push();
-		sign = getsign(st1_ptr);
-		FPU_to_exp16(st1_ptr, st_new_ptr);
-		goto denormal_arg;
-	} else if (st0_tag == TW_Infinity) {
-		sign = getsign(st0_ptr);
-		setpositive(st0_ptr);
-		push();
-		FPU_copy_to_reg0(&CONST_INF, TAG_Special);
-		setsign(st_new_ptr, sign);
-		return;
-	} else if (st0_tag == TW_NaN) {
-		if (real_1op_NaN(st0_ptr) < 0)
-			return;
-
-		push();
-		FPU_copy_to_reg0(st0_ptr, TAG_Special);
-		return;
-	} else if (st0_tag == TAG_Empty) {
-		/* Is this the correct behaviour? */
-		if (control_word & EX_Invalid) {
-			FPU_stack_underflow();
-			push();
-			FPU_stack_underflow();
-		} else
-			EXCEPTION(EX_StackUnder);
-	}
-#ifdef PARANOID
-	else
-		EXCEPTION(EX_INTERNAL | 0x119);
-#endif /* PARANOID */
-}
-
-static void fdecstp(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	clear_C1();
-	top--;
-}
-
-static void fincstp(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	clear_C1();
-	top++;
-}
-
-static void fsqrt_(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	int expon;
-
-	clear_C1();
-
-	if (st0_tag == TAG_Valid) {
-		u_char tag;
-
-		if (signnegative(st0_ptr)) {
-			arith_invalid(0);	/* sqrt(negative) is invalid */
-			return;
-		}
-
-		/* make st(0) in  [1.0 .. 4.0) */
-		expon = exponent(st0_ptr);
-
-	      denormal_arg:
-
-		setexponent16(st0_ptr, (expon & 1));
-
-		/* Do the computation, the sign of the result will be positive. */
-		tag = wm_sqrt(st0_ptr, 0, 0, control_word, SIGN_POS);
-		addexponent(st0_ptr, expon >> 1);
-		FPU_settag0(tag);
-		return;
-	}
-
-	if (st0_tag == TAG_Zero)
-		return;
-
-	if (st0_tag == TAG_Special)
-		st0_tag = FPU_Special(st0_ptr);
-
-	if (st0_tag == TW_Infinity) {
-		if (signnegative(st0_ptr))
-			arith_invalid(0);	/* sqrt(-Infinity) is invalid */
-		return;
-	} else if (st0_tag == TW_Denormal) {
-		if (signnegative(st0_ptr)) {
-			arith_invalid(0);	/* sqrt(negative) is invalid */
-			return;
-		}
-
-		if (denormal_operand() < 0)
-			return;
-
-		FPU_to_exp16(st0_ptr, st0_ptr);
-
-		expon = exponent16(st0_ptr);
-
-		goto denormal_arg;
-	}
-
-	single_arg_error(st0_ptr, st0_tag);
-
-}
-
-static void frndint_(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	int flags, tag;
-
-	if (st0_tag == TAG_Valid) {
-		u_char sign;
-
-	      denormal_arg:
-
-		sign = getsign(st0_ptr);
-
-		if (exponent(st0_ptr) > 63)
-			return;
-
-		if (st0_tag == TW_Denormal) {
-			if (denormal_operand() < 0)
-				return;
-		}
-
-		/* Fortunately, this can't overflow to 2^64 */
-		if ((flags = FPU_round_to_int(st0_ptr, st0_tag)))
-			set_precision_flag(flags);
-
-		setexponent16(st0_ptr, 63);
-		tag = FPU_normalize(st0_ptr);
-		setsign(st0_ptr, sign);
-		FPU_settag0(tag);
-		return;
-	}
-
-	if (st0_tag == TAG_Zero)
-		return;
-
-	if (st0_tag == TAG_Special)
-		st0_tag = FPU_Special(st0_ptr);
-
-	if (st0_tag == TW_Denormal)
-		goto denormal_arg;
-	else if (st0_tag == TW_Infinity)
-		return;
-	else
-		single_arg_error(st0_ptr, st0_tag);
-}
-
-static int f_sin(FPU_REG *st0_ptr, u_char tag)
-{
-	u_char arg_sign = getsign(st0_ptr);
-
-	if (tag == TAG_Valid) {
-		int q;
-
-		if (exponent(st0_ptr) > -40) {
-			if ((q = trig_arg(st0_ptr, 0)) == -1) {
-				/* Operand is out of range */
-				return 1;
-			}
-
-			poly_sine(st0_ptr);
-
-			if (q & 2)
-				changesign(st0_ptr);
-
-			setsign(st0_ptr, getsign(st0_ptr) ^ arg_sign);
-
-			/* We do not really know if up or down */
-			set_precision_flag_up();
-			return 0;
-		} else {
-			/* For a small arg, the result == the argument */
-			set_precision_flag_up();	/* Must be up. */
-			return 0;
-		}
-	}
-
-	if (tag == TAG_Zero) {
-		setcc(0);
-		return 0;
-	}
-
-	if (tag == TAG_Special)
-		tag = FPU_Special(st0_ptr);
-
-	if (tag == TW_Denormal) {
-		if (denormal_operand() < 0)
-			return 1;
-
-		/* For a small arg, the result == the argument */
-		/* Underflow may happen */
-		FPU_to_exp16(st0_ptr, st0_ptr);
-
-		tag = FPU_round(st0_ptr, 1, 0, FULL_PRECISION, arg_sign);
-
-		FPU_settag0(tag);
-
-		return 0;
-	} else if (tag == TW_Infinity) {
-		/* The 80486 treats infinity as an invalid operand */
-		arith_invalid(0);
-		return 1;
-	} else {
-		single_arg_error(st0_ptr, tag);
-		return 1;
-	}
-}
-
-static void fsin(FPU_REG *st0_ptr, u_char tag)
-{
-	f_sin(st0_ptr, tag);
-}
-
-static int f_cos(FPU_REG *st0_ptr, u_char tag)
-{
-	u_char st0_sign;
-
-	st0_sign = getsign(st0_ptr);
-
-	if (tag == TAG_Valid) {
-		int q;
-
-		if (exponent(st0_ptr) > -40) {
-			if ((exponent(st0_ptr) < 0)
-			    || ((exponent(st0_ptr) == 0)
-				&& (significand(st0_ptr) <=
-				    0xc90fdaa22168c234LL))) {
-				poly_cos(st0_ptr);
-
-				/* We do not really know if up or down */
-				set_precision_flag_down();
-
-				return 0;
-			} else if ((q = trig_arg(st0_ptr, FCOS)) != -1) {
-				poly_sine(st0_ptr);
-
-				if ((q + 1) & 2)
-					changesign(st0_ptr);
-
-				/* We do not really know if up or down */
-				set_precision_flag_down();
-
-				return 0;
-			} else {
-				/* Operand is out of range */
-				return 1;
-			}
-		} else {
-		      denormal_arg:
-
-			setcc(0);
-			FPU_copy_to_reg0(&CONST_1, TAG_Valid);
-#ifdef PECULIAR_486
-			set_precision_flag_down();	/* 80486 appears to do this. */
-#else
-			set_precision_flag_up();	/* Must be up. */
-#endif /* PECULIAR_486 */
-			return 0;
-		}
-	} else if (tag == TAG_Zero) {
-		FPU_copy_to_reg0(&CONST_1, TAG_Valid);
-		setcc(0);
-		return 0;
-	}
-
-	if (tag == TAG_Special)
-		tag = FPU_Special(st0_ptr);
-
-	if (tag == TW_Denormal) {
-		if (denormal_operand() < 0)
-			return 1;
-
-		goto denormal_arg;
-	} else if (tag == TW_Infinity) {
-		/* The 80486 treats infinity as an invalid operand */
-		arith_invalid(0);
-		return 1;
-	} else {
-		single_arg_error(st0_ptr, tag);	/* requires st0_ptr == &st(0) */
-		return 1;
-	}
-}
-
-static void fcos(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	f_cos(st0_ptr, st0_tag);
-}
-
-static void fsincos(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	FPU_REG *st_new_ptr;
-	FPU_REG arg;
-	u_char tag;
-
-	/* Stack underflow has higher priority */
-	if (st0_tag == TAG_Empty) {
-		FPU_stack_underflow();	/* Puts a QNaN in st(0) */
-		if (control_word & CW_Invalid) {
-			st_new_ptr = &st(-1);
-			push();
-			FPU_stack_underflow();	/* Puts a QNaN in the new st(0) */
-		}
-		return;
-	}
-
-	if (STACK_OVERFLOW) {
-		FPU_stack_overflow();
-		return;
-	}
-
-	if (st0_tag == TAG_Special)
-		tag = FPU_Special(st0_ptr);
-	else
-		tag = st0_tag;
-
-	if (tag == TW_NaN) {
-		single_arg_2_error(st0_ptr, TW_NaN);
-		return;
-	} else if (tag == TW_Infinity) {
-		/* The 80486 treats infinity as an invalid operand */
-		if (arith_invalid(0) >= 0) {
-			/* Masked response */
-			push();
-			arith_invalid(0);
-		}
-		return;
-	}
-
-	reg_copy(st0_ptr, &arg);
-	if (!f_sin(st0_ptr, st0_tag)) {
-		push();
-		FPU_copy_to_reg0(&arg, st0_tag);
-		f_cos(&st(0), st0_tag);
-	} else {
-		/* An error, so restore st(0) */
-		FPU_copy_to_reg0(&arg, st0_tag);
-	}
-}
-
-/*---------------------------------------------------------------------------*/
-/* The following all require two arguments: st(0) and st(1) */
-
-/* A lean, mean kernel for the fprem instructions. This relies upon
-   the division and rounding to an integer in do_fprem giving an
-   exact result. Because of this, rem_kernel() needs to deal only with
-   the least significant 64 bits, the more significant bits of the
-   result must be zero.
- */
-static void rem_kernel(unsigned long long st0, unsigned long long *y,
-		       unsigned long long st1, unsigned long long q, int n)
-{
-	int dummy;
-	unsigned long long x;
-
-	x = st0 << n;
-
-	/* Do the required multiplication and subtraction in the one operation */
-
-	/* lsw x -= lsw st1 * lsw q */
-	asm volatile ("mull %4; subl %%eax,%0; sbbl %%edx,%1":"=m"
-		      (((unsigned *)&x)[0]), "=m"(((unsigned *)&x)[1]),
-		      "=a"(dummy)
-		      :"2"(((unsigned *)&st1)[0]), "m"(((unsigned *)&q)[0])
-		      :"%dx");
-	/* msw x -= msw st1 * lsw q */
-	asm volatile ("mull %3; subl %%eax,%0":"=m" (((unsigned *)&x)[1]),
-		      "=a"(dummy)
-		      :"1"(((unsigned *)&st1)[1]), "m"(((unsigned *)&q)[0])
-		      :"%dx");
-	/* msw x -= lsw st1 * msw q */
-	asm volatile ("mull %3; subl %%eax,%0":"=m" (((unsigned *)&x)[1]),
-		      "=a"(dummy)
-		      :"1"(((unsigned *)&st1)[0]), "m"(((unsigned *)&q)[1])
-		      :"%dx");
-
-	*y = x;
-}
-
-/* Remainder of st(0) / st(1) */
-/* This routine produces exact results, i.e. there is never any
-   rounding or truncation, etc of the result. */
-static void do_fprem(FPU_REG *st0_ptr, u_char st0_tag, int round)
-{
-	FPU_REG *st1_ptr = &st(1);
-	u_char st1_tag = FPU_gettagi(1);
-
-	if (!((st0_tag ^ TAG_Valid) | (st1_tag ^ TAG_Valid))) {
-		FPU_REG tmp, st0, st1;
-		u_char st0_sign, st1_sign;
-		u_char tmptag;
-		int tag;
-		int old_cw;
-		int expdif;
-		long long q;
-		unsigned short saved_status;
-		int cc;
-
-	      fprem_valid:
-		/* Convert registers for internal use. */
-		st0_sign = FPU_to_exp16(st0_ptr, &st0);
-		st1_sign = FPU_to_exp16(st1_ptr, &st1);
-		expdif = exponent16(&st0) - exponent16(&st1);
-
-		old_cw = control_word;
-		cc = 0;
-
-		/* We want the status following the denorm tests, but don't want
-		   the status changed by the arithmetic operations. */
-		saved_status = partial_status;
-		control_word &= ~CW_RC;
-		control_word |= RC_CHOP;
-
-		if (expdif < 64) {
-			/* This should be the most common case */
-
-			if (expdif > -2) {
-				u_char sign = st0_sign ^ st1_sign;
-				tag = FPU_u_div(&st0, &st1, &tmp,
-						PR_64_BITS | RC_CHOP | 0x3f,
-						sign);
-				setsign(&tmp, sign);
-
-				if (exponent(&tmp) >= 0) {
-					FPU_round_to_int(&tmp, tag);	/* Fortunately, this can't
-									   overflow to 2^64 */
-					q = significand(&tmp);
-
-					rem_kernel(significand(&st0),
-						   &significand(&tmp),
-						   significand(&st1),
-						   q, expdif);
-
-					setexponent16(&tmp, exponent16(&st1));
-				} else {
-					reg_copy(&st0, &tmp);
-					q = 0;
-				}
-
-				if ((round == RC_RND)
-				    && (tmp.sigh & 0xc0000000)) {
-					/* We may need to subtract st(1) once more,
-					   to get a result <= 1/2 of st(1). */
-					unsigned long long x;
-					expdif =
-					    exponent16(&st1) - exponent16(&tmp);
-					if (expdif <= 1) {
-						if (expdif == 0)
-							x = significand(&st1) -
-							    significand(&tmp);
-						else	/* expdif is 1 */
-							x = (significand(&st1)
-							     << 1) -
-							    significand(&tmp);
-						if ((x < significand(&tmp)) ||
-						    /* or equi-distant (from 0 & st(1)) and q is odd */
-						    ((x == significand(&tmp))
-						     && (q & 1))) {
-							st0_sign = !st0_sign;
-							significand(&tmp) = x;
-							q++;
-						}
-					}
-				}
-
-				if (q & 4)
-					cc |= SW_C0;
-				if (q & 2)
-					cc |= SW_C3;
-				if (q & 1)
-					cc |= SW_C1;
-			} else {
-				control_word = old_cw;
-				setcc(0);
-				return;
-			}
-		} else {
-			/* There is a large exponent difference ( >= 64 ) */
-			/* To make much sense, the code in this section should
-			   be done at high precision. */
-			int exp_1, N;
-			u_char sign;
-
-			/* prevent overflow here */
-			/* N is 'a number between 32 and 63' (p26-113) */
-			reg_copy(&st0, &tmp);
-			tmptag = st0_tag;
-			N = (expdif & 0x0000001f) + 32;	/* This choice gives results
-							   identical to an AMD 486 */
-			setexponent16(&tmp, N);
-			exp_1 = exponent16(&st1);
-			setexponent16(&st1, 0);
-			expdif -= N;
-
-			sign = getsign(&tmp) ^ st1_sign;
-			tag =
-			    FPU_u_div(&tmp, &st1, &tmp,
-				      PR_64_BITS | RC_CHOP | 0x3f, sign);
-			setsign(&tmp, sign);
-
-			FPU_round_to_int(&tmp, tag);	/* Fortunately, this can't
-							   overflow to 2^64 */
-
-			rem_kernel(significand(&st0),
-				   &significand(&tmp),
-				   significand(&st1),
-				   significand(&tmp), exponent(&tmp)
-			    );
-			setexponent16(&tmp, exp_1 + expdif);
-
-			/* It is possible for the operation to be complete here.
-			   What does the IEEE standard say? The Intel 80486 manual
-			   implies that the operation will never be completed at this
-			   point, and the behaviour of a real 80486 confirms this.
-			 */
-			if (!(tmp.sigh | tmp.sigl)) {
-				/* The result is zero */
-				control_word = old_cw;
-				partial_status = saved_status;
-				FPU_copy_to_reg0(&CONST_Z, TAG_Zero);
-				setsign(&st0, st0_sign);
-#ifdef PECULIAR_486
-				setcc(SW_C2);
-#else
-				setcc(0);
-#endif /* PECULIAR_486 */
-				return;
-			}
-			cc = SW_C2;
-		}
-
-		control_word = old_cw;
-		partial_status = saved_status;
-		tag = FPU_normalize_nuo(&tmp);
-		reg_copy(&tmp, st0_ptr);
-
-		/* The only condition to be looked for is underflow,
-		   and it can occur here only if underflow is unmasked. */
-		if ((exponent16(&tmp) <= EXP_UNDER) && (tag != TAG_Zero)
-		    && !(control_word & CW_Underflow)) {
-			setcc(cc);
-			tag = arith_underflow(st0_ptr);
-			setsign(st0_ptr, st0_sign);
-			FPU_settag0(tag);
-			return;
-		} else if ((exponent16(&tmp) > EXP_UNDER) || (tag == TAG_Zero)) {
-			stdexp(st0_ptr);
-			setsign(st0_ptr, st0_sign);
-		} else {
-			tag =
-			    FPU_round(st0_ptr, 0, 0, FULL_PRECISION, st0_sign);
-		}
-		FPU_settag0(tag);
-		setcc(cc);
-
-		return;
-	}
-
-	if (st0_tag == TAG_Special)
-		st0_tag = FPU_Special(st0_ptr);
-	if (st1_tag == TAG_Special)
-		st1_tag = FPU_Special(st1_ptr);
-
-	if (((st0_tag == TAG_Valid) && (st1_tag == TW_Denormal))
-	    || ((st0_tag == TW_Denormal) && (st1_tag == TAG_Valid))
-	    || ((st0_tag == TW_Denormal) && (st1_tag == TW_Denormal))) {
-		if (denormal_operand() < 0)
-			return;
-		goto fprem_valid;
-	} else if ((st0_tag == TAG_Empty) || (st1_tag == TAG_Empty)) {
-		FPU_stack_underflow();
-		return;
-	} else if (st0_tag == TAG_Zero) {
-		if (st1_tag == TAG_Valid) {
-			setcc(0);
-			return;
-		} else if (st1_tag == TW_Denormal) {
-			if (denormal_operand() < 0)
-				return;
-			setcc(0);
-			return;
-		} else if (st1_tag == TAG_Zero) {
-			arith_invalid(0);
-			return;
-		} /* fprem(?,0) always invalid */
-		else if (st1_tag == TW_Infinity) {
-			setcc(0);
-			return;
-		}
-	} else if ((st0_tag == TAG_Valid) || (st0_tag == TW_Denormal)) {
-		if (st1_tag == TAG_Zero) {
-			arith_invalid(0);	/* fprem(Valid,Zero) is invalid */
-			return;
-		} else if (st1_tag != TW_NaN) {
-			if (((st0_tag == TW_Denormal)
-			     || (st1_tag == TW_Denormal))
-			    && (denormal_operand() < 0))
-				return;
-
-			if (st1_tag == TW_Infinity) {
-				/* fprem(Valid,Infinity) is o.k. */
-				setcc(0);
-				return;
-			}
-		}
-	} else if (st0_tag == TW_Infinity) {
-		if (st1_tag != TW_NaN) {
-			arith_invalid(0);	/* fprem(Infinity,?) is invalid */
-			return;
-		}
-	}
-
-	/* One of the registers must contain a NaN if we got here. */
-
-#ifdef PARANOID
-	if ((st0_tag != TW_NaN) && (st1_tag != TW_NaN))
-		EXCEPTION(EX_INTERNAL | 0x118);
-#endif /* PARANOID */
-
-	real_2op_NaN(st1_ptr, st1_tag, 0, st1_ptr);
-
-}
-
-/* ST(1) <- ST(1) * log ST;  pop ST */
-static void fyl2x(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	FPU_REG *st1_ptr = &st(1), exponent;
-	u_char st1_tag = FPU_gettagi(1);
-	u_char sign;
-	int e, tag;
-
-	clear_C1();
-
-	if ((st0_tag == TAG_Valid) && (st1_tag == TAG_Valid)) {
-	      both_valid:
-		/* Both regs are Valid or Denormal */
-		if (signpositive(st0_ptr)) {
-			if (st0_tag == TW_Denormal)
-				FPU_to_exp16(st0_ptr, st0_ptr);
-			else
-				/* Convert st(0) for internal use. */
-				setexponent16(st0_ptr, exponent(st0_ptr));
-
-			if ((st0_ptr->sigh == 0x80000000)
-			    && (st0_ptr->sigl == 0)) {
-				/* Special case. The result can be precise. */
-				u_char esign;
-				e = exponent16(st0_ptr);
-				if (e >= 0) {
-					exponent.sigh = e;
-					esign = SIGN_POS;
-				} else {
-					exponent.sigh = -e;
-					esign = SIGN_NEG;
-				}
-				exponent.sigl = 0;
-				setexponent16(&exponent, 31);
-				tag = FPU_normalize_nuo(&exponent);
-				stdexp(&exponent);
-				setsign(&exponent, esign);
-				tag =
-				    FPU_mul(&exponent, tag, 1, FULL_PRECISION);
-				if (tag >= 0)
-					FPU_settagi(1, tag);
-			} else {
-				/* The usual case */
-				sign = getsign(st1_ptr);
-				if (st1_tag == TW_Denormal)
-					FPU_to_exp16(st1_ptr, st1_ptr);
-				else
-					/* Convert st(1) for internal use. */
-					setexponent16(st1_ptr,
-						      exponent(st1_ptr));
-				poly_l2(st0_ptr, st1_ptr, sign);
-			}
-		} else {
-			/* negative */
-			if (arith_invalid(1) < 0)
-				return;
-		}
-
-		FPU_pop();
-
-		return;
-	}
-
-	if (st0_tag == TAG_Special)
-		st0_tag = FPU_Special(st0_ptr);
-	if (st1_tag == TAG_Special)
-		st1_tag = FPU_Special(st1_ptr);
-
-	if ((st0_tag == TAG_Empty) || (st1_tag == TAG_Empty)) {
-		FPU_stack_underflow_pop(1);
-		return;
-	} else if ((st0_tag <= TW_Denormal) && (st1_tag <= TW_Denormal)) {
-		if (st0_tag == TAG_Zero) {
-			if (st1_tag == TAG_Zero) {
-				/* Both args zero is invalid */
-				if (arith_invalid(1) < 0)
-					return;
-			} else {
-				u_char sign;
-				sign = getsign(st1_ptr) ^ SIGN_NEG;
-				if (FPU_divide_by_zero(1, sign) < 0)
-					return;
-
-				setsign(st1_ptr, sign);
-			}
-		} else if (st1_tag == TAG_Zero) {
-			/* st(1) contains zero, st(0) valid <> 0 */
-			/* Zero is the valid answer */
-			sign = getsign(st1_ptr);
-
-			if (signnegative(st0_ptr)) {
-				/* log(negative) */
-				if (arith_invalid(1) < 0)
-					return;
-			} else if ((st0_tag == TW_Denormal)
-				   && (denormal_operand() < 0))
-				return;
-			else {
-				if (exponent(st0_ptr) < 0)
-					sign ^= SIGN_NEG;
-
-				FPU_copy_to_reg1(&CONST_Z, TAG_Zero);
-				setsign(st1_ptr, sign);
-			}
-		} else {
-			/* One or both operands are denormals. */
-			if (denormal_operand() < 0)
-				return;
-			goto both_valid;
-		}
-	} else if ((st0_tag == TW_NaN) || (st1_tag == TW_NaN)) {
-		if (real_2op_NaN(st0_ptr, st0_tag, 1, st0_ptr) < 0)
-			return;
-	}
-	/* One or both arg must be an infinity */
-	else if (st0_tag == TW_Infinity) {
-		if ((signnegative(st0_ptr)) || (st1_tag == TAG_Zero)) {
-			/* log(-infinity) or 0*log(infinity) */
-			if (arith_invalid(1) < 0)
-				return;
-		} else {
-			u_char sign = getsign(st1_ptr);
-
-			if ((st1_tag == TW_Denormal)
-			    && (denormal_operand() < 0))
-				return;
-
-			FPU_copy_to_reg1(&CONST_INF, TAG_Special);
-			setsign(st1_ptr, sign);
-		}
-	}
-	/* st(1) must be infinity here */
-	else if (((st0_tag == TAG_Valid) || (st0_tag == TW_Denormal))
-		 && (signpositive(st0_ptr))) {
-		if (exponent(st0_ptr) >= 0) {
-			if ((exponent(st0_ptr) == 0) &&
-			    (st0_ptr->sigh == 0x80000000) &&
-			    (st0_ptr->sigl == 0)) {
-				/* st(0) holds 1.0 */
-				/* infinity*log(1) */
-				if (arith_invalid(1) < 0)
-					return;
-			}
-			/* else st(0) is positive and > 1.0 */
-		} else {
-			/* st(0) is positive and < 1.0 */
-
-			if ((st0_tag == TW_Denormal)
-			    && (denormal_operand() < 0))
-				return;
-
-			changesign(st1_ptr);
-		}
-	} else {
-		/* st(0) must be zero or negative */
-		if (st0_tag == TAG_Zero) {
-			/* This should be invalid, but a real 80486 is happy with it. */
-
-#ifndef PECULIAR_486
-			sign = getsign(st1_ptr);
-			if (FPU_divide_by_zero(1, sign) < 0)
-				return;
-#endif /* PECULIAR_486 */
-
-			changesign(st1_ptr);
-		} else if (arith_invalid(1) < 0)	/* log(negative) */
-			return;
-	}
-
-	FPU_pop();
-}
-
-static void fpatan(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	FPU_REG *st1_ptr = &st(1);
-	u_char st1_tag = FPU_gettagi(1);
-	int tag;
-
-	clear_C1();
-	if (!((st0_tag ^ TAG_Valid) | (st1_tag ^ TAG_Valid))) {
-	      valid_atan:
-
-		poly_atan(st0_ptr, st0_tag, st1_ptr, st1_tag);
-
-		FPU_pop();
-
-		return;
-	}
-
-	if (st0_tag == TAG_Special)
-		st0_tag = FPU_Special(st0_ptr);
-	if (st1_tag == TAG_Special)
-		st1_tag = FPU_Special(st1_ptr);
-
-	if (((st0_tag == TAG_Valid) && (st1_tag == TW_Denormal))
-	    || ((st0_tag == TW_Denormal) && (st1_tag == TAG_Valid))
-	    || ((st0_tag == TW_Denormal) && (st1_tag == TW_Denormal))) {
-		if (denormal_operand() < 0)
-			return;
-
-		goto valid_atan;
-	} else if ((st0_tag == TAG_Empty) || (st1_tag == TAG_Empty)) {
-		FPU_stack_underflow_pop(1);
-		return;
-	} else if ((st0_tag == TW_NaN) || (st1_tag == TW_NaN)) {
-		if (real_2op_NaN(st0_ptr, st0_tag, 1, st0_ptr) >= 0)
-			FPU_pop();
-		return;
-	} else if ((st0_tag == TW_Infinity) || (st1_tag == TW_Infinity)) {
-		u_char sign = getsign(st1_ptr);
-		if (st0_tag == TW_Infinity) {
-			if (st1_tag == TW_Infinity) {
-				if (signpositive(st0_ptr)) {
-					FPU_copy_to_reg1(&CONST_PI4, TAG_Valid);
-				} else {
-					setpositive(st1_ptr);
-					tag =
-					    FPU_u_add(&CONST_PI4, &CONST_PI2,
-						      st1_ptr, FULL_PRECISION,
-						      SIGN_POS,
-						      exponent(&CONST_PI4),
-						      exponent(&CONST_PI2));
-					if (tag >= 0)
-						FPU_settagi(1, tag);
-				}
-			} else {
-				if ((st1_tag == TW_Denormal)
-				    && (denormal_operand() < 0))
-					return;
-
-				if (signpositive(st0_ptr)) {
-					FPU_copy_to_reg1(&CONST_Z, TAG_Zero);
-					setsign(st1_ptr, sign);	/* An 80486 preserves the sign */
-					FPU_pop();
-					return;
-				} else {
-					FPU_copy_to_reg1(&CONST_PI, TAG_Valid);
-				}
-			}
-		} else {
-			/* st(1) is infinity, st(0) not infinity */
-			if ((st0_tag == TW_Denormal)
-			    && (denormal_operand() < 0))
-				return;
-
-			FPU_copy_to_reg1(&CONST_PI2, TAG_Valid);
-		}
-		setsign(st1_ptr, sign);
-	} else if (st1_tag == TAG_Zero) {
-		/* st(0) must be valid or zero */
-		u_char sign = getsign(st1_ptr);
-
-		if ((st0_tag == TW_Denormal) && (denormal_operand() < 0))
-			return;
-
-		if (signpositive(st0_ptr)) {
-			/* An 80486 preserves the sign */
-			FPU_pop();
-			return;
-		}
-
-		FPU_copy_to_reg1(&CONST_PI, TAG_Valid);
-		setsign(st1_ptr, sign);
-	} else if (st0_tag == TAG_Zero) {
-		/* st(1) must be TAG_Valid here */
-		u_char sign = getsign(st1_ptr);
-
-		if ((st1_tag == TW_Denormal) && (denormal_operand() < 0))
-			return;
-
-		FPU_copy_to_reg1(&CONST_PI2, TAG_Valid);
-		setsign(st1_ptr, sign);
-	}
-#ifdef PARANOID
-	else
-		EXCEPTION(EX_INTERNAL | 0x125);
-#endif /* PARANOID */
-
-	FPU_pop();
-	set_precision_flag_up();	/* We do not really know if up or down */
-}
-
-static void fprem(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	do_fprem(st0_ptr, st0_tag, RC_CHOP);
-}
-
-static void fprem1(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	do_fprem(st0_ptr, st0_tag, RC_RND);
-}
-
-static void fyl2xp1(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	u_char sign, sign1;
-	FPU_REG *st1_ptr = &st(1), a, b;
-	u_char st1_tag = FPU_gettagi(1);
-
-	clear_C1();
-	if (!((st0_tag ^ TAG_Valid) | (st1_tag ^ TAG_Valid))) {
-	      valid_yl2xp1:
-
-		sign = getsign(st0_ptr);
-		sign1 = getsign(st1_ptr);
-
-		FPU_to_exp16(st0_ptr, &a);
-		FPU_to_exp16(st1_ptr, &b);
-
-		if (poly_l2p1(sign, sign1, &a, &b, st1_ptr))
-			return;
-
-		FPU_pop();
-		return;
-	}
-
-	if (st0_tag == TAG_Special)
-		st0_tag = FPU_Special(st0_ptr);
-	if (st1_tag == TAG_Special)
-		st1_tag = FPU_Special(st1_ptr);
-
-	if (((st0_tag == TAG_Valid) && (st1_tag == TW_Denormal))
-	    || ((st0_tag == TW_Denormal) && (st1_tag == TAG_Valid))
-	    || ((st0_tag == TW_Denormal) && (st1_tag == TW_Denormal))) {
-		if (denormal_operand() < 0)
-			return;
-
-		goto valid_yl2xp1;
-	} else if ((st0_tag == TAG_Empty) | (st1_tag == TAG_Empty)) {
-		FPU_stack_underflow_pop(1);
-		return;
-	} else if (st0_tag == TAG_Zero) {
-		switch (st1_tag) {
-		case TW_Denormal:
-			if (denormal_operand() < 0)
-				return;
-			fallthrough;
-		case TAG_Zero:
-		case TAG_Valid:
-			setsign(st0_ptr, getsign(st0_ptr) ^ getsign(st1_ptr));
-			FPU_copy_to_reg1(st0_ptr, st0_tag);
-			break;
-
-		case TW_Infinity:
-			/* Infinity*log(1) */
-			if (arith_invalid(1) < 0)
-				return;
-			break;
-
-		case TW_NaN:
-			if (real_2op_NaN(st0_ptr, st0_tag, 1, st0_ptr) < 0)
-				return;
-			break;
-
-		default:
-#ifdef PARANOID
-			EXCEPTION(EX_INTERNAL | 0x116);
-			return;
-#endif /* PARANOID */
-			break;
-		}
-	} else if ((st0_tag == TAG_Valid) || (st0_tag == TW_Denormal)) {
-		switch (st1_tag) {
-		case TAG_Zero:
-			if (signnegative(st0_ptr)) {
-				if (exponent(st0_ptr) >= 0) {
-					/* st(0) holds <= -1.0 */
-#ifdef PECULIAR_486		/* Stupid 80486 doesn't worry about log(negative). */
-					changesign(st1_ptr);
-#else
-					if (arith_invalid(1) < 0)
-						return;
-#endif /* PECULIAR_486 */
-				} else if ((st0_tag == TW_Denormal)
-					   && (denormal_operand() < 0))
-					return;
-				else
-					changesign(st1_ptr);
-			} else if ((st0_tag == TW_Denormal)
-				   && (denormal_operand() < 0))
-				return;
-			break;
-
-		case TW_Infinity:
-			if (signnegative(st0_ptr)) {
-				if ((exponent(st0_ptr) >= 0) &&
-				    !((st0_ptr->sigh == 0x80000000) &&
-				      (st0_ptr->sigl == 0))) {
-					/* st(0) holds < -1.0 */
-#ifdef PECULIAR_486		/* Stupid 80486 doesn't worry about log(negative). */
-					changesign(st1_ptr);
-#else
-					if (arith_invalid(1) < 0)
-						return;
-#endif /* PECULIAR_486 */
-				} else if ((st0_tag == TW_Denormal)
-					   && (denormal_operand() < 0))
-					return;
-				else
-					changesign(st1_ptr);
-			} else if ((st0_tag == TW_Denormal)
-				   && (denormal_operand() < 0))
-				return;
-			break;
-
-		case TW_NaN:
-			if (real_2op_NaN(st0_ptr, st0_tag, 1, st0_ptr) < 0)
-				return;
-		}
-
-	} else if (st0_tag == TW_NaN) {
-		if (real_2op_NaN(st0_ptr, st0_tag, 1, st0_ptr) < 0)
-			return;
-	} else if (st0_tag == TW_Infinity) {
-		if (st1_tag == TW_NaN) {
-			if (real_2op_NaN(st0_ptr, st0_tag, 1, st0_ptr) < 0)
-				return;
-		} else if (signnegative(st0_ptr)) {
-#ifndef PECULIAR_486
-			/* This should have higher priority than denormals, but... */
-			if (arith_invalid(1) < 0)	/* log(-infinity) */
-				return;
-#endif /* PECULIAR_486 */
-			if ((st1_tag == TW_Denormal)
-			    && (denormal_operand() < 0))
-				return;
-#ifdef PECULIAR_486
-			/* Denormal operands actually get higher priority */
-			if (arith_invalid(1) < 0)	/* log(-infinity) */
-				return;
-#endif /* PECULIAR_486 */
-		} else if (st1_tag == TAG_Zero) {
-			/* log(infinity) */
-			if (arith_invalid(1) < 0)
-				return;
-		}
-
-		/* st(1) must be valid here. */
-
-		else if ((st1_tag == TW_Denormal) && (denormal_operand() < 0))
-			return;
-
-		/* The Manual says that log(Infinity) is invalid, but a real
-		   80486 sensibly says that it is o.k. */
-		else {
-			u_char sign = getsign(st1_ptr);
-			FPU_copy_to_reg1(&CONST_INF, TAG_Special);
-			setsign(st1_ptr, sign);
-		}
-	}
-#ifdef PARANOID
-	else {
-		EXCEPTION(EX_INTERNAL | 0x117);
-		return;
-	}
-#endif /* PARANOID */
-
-	FPU_pop();
-	return;
-
-}
-
-static void fscale(FPU_REG *st0_ptr, u_char st0_tag)
-{
-	FPU_REG *st1_ptr = &st(1);
-	u_char st1_tag = FPU_gettagi(1);
-	int old_cw = control_word;
-	u_char sign = getsign(st0_ptr);
-
-	clear_C1();
-	if (!((st0_tag ^ TAG_Valid) | (st1_tag ^ TAG_Valid))) {
-		long scale;
-		FPU_REG tmp;
-
-		/* Convert register for internal use. */
-		setexponent16(st0_ptr, exponent(st0_ptr));
-
-	      valid_scale:
-
-		if (exponent(st1_ptr) > 30) {
-			/* 2^31 is far too large, would require 2^(2^30) or 2^(-2^30) */
-
-			if (signpositive(st1_ptr)) {
-				EXCEPTION(EX_Overflow);
-				FPU_copy_to_reg0(&CONST_INF, TAG_Special);
-			} else {
-				EXCEPTION(EX_Underflow);
-				FPU_copy_to_reg0(&CONST_Z, TAG_Zero);
-			}
-			setsign(st0_ptr, sign);
-			return;
-		}
-
-		control_word &= ~CW_RC;
-		control_word |= RC_CHOP;
-		reg_copy(st1_ptr, &tmp);
-		FPU_round_to_int(&tmp, st1_tag);	/* This can never overflow here */
-		control_word = old_cw;
-		scale = signnegative(st1_ptr) ? -tmp.sigl : tmp.sigl;
-		scale += exponent16(st0_ptr);
-
-		setexponent16(st0_ptr, scale);
-
-		/* Use FPU_round() to properly detect under/overflow etc */
-		FPU_round(st0_ptr, 0, 0, control_word, sign);
-
-		return;
-	}
-
-	if (st0_tag == TAG_Special)
-		st0_tag = FPU_Special(st0_ptr);
-	if (st1_tag == TAG_Special)
-		st1_tag = FPU_Special(st1_ptr);
-
-	if ((st0_tag == TAG_Valid) || (st0_tag == TW_Denormal)) {
-		switch (st1_tag) {
-		case TAG_Valid:
-			/* st(0) must be a denormal */
-			if ((st0_tag == TW_Denormal)
-			    && (denormal_operand() < 0))
-				return;
-
-			FPU_to_exp16(st0_ptr, st0_ptr);	/* Will not be left on stack */
-			goto valid_scale;
-
-		case TAG_Zero:
-			if (st0_tag == TW_Denormal)
-				denormal_operand();
-			return;
-
-		case TW_Denormal:
-			denormal_operand();
-			return;
-
-		case TW_Infinity:
-			if ((st0_tag == TW_Denormal)
-			    && (denormal_operand() < 0))
-				return;
-
-			if (signpositive(st1_ptr))
-				FPU_copy_to_reg0(&CONST_INF, TAG_Special);
-			else
-				FPU_copy_to_reg0(&CONST_Z, TAG_Zero);
-			setsign(st0_ptr, sign);
-			return;
-
-		case TW_NaN:
-			real_2op_NaN(st1_ptr, st1_tag, 0, st0_ptr);
-			return;
-		}
-	} else if (st0_tag == TAG_Zero) {
-		switch (st1_tag) {
-		case TAG_Valid:
-		case TAG_Zero:
-			return;
-
-		case TW_Denormal:
-			denormal_operand();
-			return;
-
-		case TW_Infinity:
-			if (signpositive(st1_ptr))
-				arith_invalid(0);	/* Zero scaled by +Infinity */
-			return;
-
-		case TW_NaN:
-			real_2op_NaN(st1_ptr, st1_tag, 0, st0_ptr);
-			return;
-		}
-	} else if (st0_tag == TW_Infinity) {
-		switch (st1_tag) {
-		case TAG_Valid:
-		case TAG_Zero:
-			return;
-
-		case TW_Denormal:
-			denormal_operand();
-			return;
-
-		case TW_Infinity:
-			if (signnegative(st1_ptr))
-				arith_invalid(0);	/* Infinity scaled by -Infinity */
-			return;
-
-		case TW_NaN:
-			real_2op_NaN(st1_ptr, st1_tag, 0, st0_ptr);
-			return;
-		}
-	} else if (st0_tag == TW_NaN) {
-		if (st1_tag != TAG_Empty) {
-			real_2op_NaN(st1_ptr, st1_tag, 0, st0_ptr);
-			return;
-		}
-	}
-#ifdef PARANOID
-	if (!((st0_tag == TAG_Empty) || (st1_tag == TAG_Empty))) {
-		EXCEPTION(EX_INTERNAL | 0x115);
-		return;
-	}
-#endif
-
-	/* At least one of st(0), st(1) must be empty */
-	FPU_stack_underflow();
-
-}
-
-/*---------------------------------------------------------------------------*/
-
-static FUNC_ST0 const trig_table_a[] = {
-	f2xm1, fyl2x, fptan, fpatan,
-	fxtract, fprem1, fdecstp, fincstp,
-};
-
-void FPU_triga(void)
-{
-	(trig_table_a[FPU_rm]) (&st(0), FPU_gettag0());
-}
-
-static FUNC_ST0 const trig_table_b[] = {
-	fprem, fyl2xp1, fsqrt_, fsincos, frndint_, fscale, fsin, fcos
-};
-
-void FPU_trigb(void)
-{
-	(trig_table_b[FPU_rm]) (&st(0), FPU_gettag0());
-}
diff -rupN a/arch/x86/math-emu/get_address.c b/arch/x86/math-emu/get_address.c
--- a/arch/x86/math-emu/get_address.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/get_address.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,401 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  get_address.c                                                            |
- |                                                                           |
- | Get the effective address from an FPU instruction.                        |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997                                         |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@suburbia.net             |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | Note:                                                                     |
- |    The file contains code which accesses user memory.                     |
- |    Emulator static data may change when user memory is accessed, due to   |
- |    other processes using the emulator while swapping is in progress.      |
- +---------------------------------------------------------------------------*/
-
-#include <linux/stddef.h>
-
-#include <linux/uaccess.h>
-#include <asm/vm86.h>
-
-#include "fpu_system.h"
-#include "exception.h"
-#include "fpu_emu.h"
-
-#define FPU_WRITE_BIT 0x10
-
-static int reg_offset[] = {
-	offsetof(struct pt_regs, ax),
-	offsetof(struct pt_regs, cx),
-	offsetof(struct pt_regs, dx),
-	offsetof(struct pt_regs, bx),
-	offsetof(struct pt_regs, sp),
-	offsetof(struct pt_regs, bp),
-	offsetof(struct pt_regs, si),
-	offsetof(struct pt_regs, di)
-};
-
-#define REG_(x) (*(long *)(reg_offset[(x)] + (u_char *)FPU_info->regs))
-
-static int reg_offset_vm86[] = {
-	offsetof(struct pt_regs, cs),
-	offsetof(struct kernel_vm86_regs, ds),
-	offsetof(struct kernel_vm86_regs, es),
-	offsetof(struct kernel_vm86_regs, fs),
-	offsetof(struct kernel_vm86_regs, gs),
-	offsetof(struct pt_regs, ss),
-	offsetof(struct kernel_vm86_regs, ds)
-};
-
-#define VM86_REG_(x) (*(unsigned short *) \
-		(reg_offset_vm86[((unsigned)x)] + (u_char *)FPU_info->regs))
-
-static int reg_offset_pm[] = {
-	offsetof(struct pt_regs, cs),
-	offsetof(struct pt_regs, ds),
-	offsetof(struct pt_regs, es),
-	offsetof(struct pt_regs, fs),
-	offsetof(struct pt_regs, ds),	/* dummy, not saved on stack */
-	offsetof(struct pt_regs, ss),
-	offsetof(struct pt_regs, ds)
-};
-
-#define PM_REG_(x) (*(unsigned short *) \
-		(reg_offset_pm[((unsigned)x)] + (u_char *)FPU_info->regs))
-
-/* Decode the SIB byte. This function assumes mod != 0 */
-static int sib(int mod, unsigned long *fpu_eip)
-{
-	u_char ss, index, base;
-	long offset;
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_code_access_ok(1);
-	FPU_get_user(base, (u_char __user *) (*fpu_eip));	/* The SIB byte */
-	RE_ENTRANT_CHECK_ON;
-	(*fpu_eip)++;
-	ss = base >> 6;
-	index = (base >> 3) & 7;
-	base &= 7;
-
-	if ((mod == 0) && (base == 5))
-		offset = 0;	/* No base register */
-	else
-		offset = REG_(base);
-
-	if (index == 4) {
-		/* No index register */
-		/* A non-zero ss is illegal */
-		if (ss)
-			EXCEPTION(EX_Invalid);
-	} else {
-		offset += (REG_(index)) << ss;
-	}
-
-	if (mod == 1) {
-		/* 8 bit signed displacement */
-		long displacement;
-		RE_ENTRANT_CHECK_OFF;
-		FPU_code_access_ok(1);
-		FPU_get_user(displacement, (signed char __user *)(*fpu_eip));
-		offset += displacement;
-		RE_ENTRANT_CHECK_ON;
-		(*fpu_eip)++;
-	} else if (mod == 2 || base == 5) {	/* The second condition also has mod==0 */
-		/* 32 bit displacement */
-		long displacement;
-		RE_ENTRANT_CHECK_OFF;
-		FPU_code_access_ok(4);
-		FPU_get_user(displacement, (long __user *)(*fpu_eip));
-		offset += displacement;
-		RE_ENTRANT_CHECK_ON;
-		(*fpu_eip) += 4;
-	}
-
-	return offset;
-}
-
-static unsigned long vm86_segment(u_char segment, struct address *addr)
-{
-	segment--;
-#ifdef PARANOID
-	if (segment > PREFIX_SS_) {
-		EXCEPTION(EX_INTERNAL | 0x130);
-		math_abort(FPU_info, SIGSEGV);
-	}
-#endif /* PARANOID */
-	addr->selector = VM86_REG_(segment);
-	return (unsigned long)VM86_REG_(segment) << 4;
-}
-
-/* This should work for 16 and 32 bit protected mode. */
-static long pm_address(u_char FPU_modrm, u_char segment,
-		       struct address *addr, long offset)
-{
-	struct desc_struct descriptor;
-	unsigned long base_address, limit, address, seg_top;
-
-	segment--;
-
-#ifdef PARANOID
-	/* segment is unsigned, so this also detects if segment was 0: */
-	if (segment > PREFIX_SS_) {
-		EXCEPTION(EX_INTERNAL | 0x132);
-		math_abort(FPU_info, SIGSEGV);
-	}
-#endif /* PARANOID */
-
-	switch (segment) {
-	case PREFIX_GS_ - 1:
-		/* user gs handling can be lazy, use special accessors */
-		savesegment(gs, addr->selector);
-		break;
-	default:
-		addr->selector = PM_REG_(segment);
-	}
-
-	descriptor = FPU_get_ldt_descriptor(addr->selector);
-	base_address = seg_get_base(&descriptor);
-	address = base_address + offset;
-	limit = seg_get_limit(&descriptor) + 1;
-	limit *= seg_get_granularity(&descriptor);
-	limit += base_address - 1;
-	if (limit < base_address)
-		limit = 0xffffffff;
-
-	if (seg_expands_down(&descriptor)) {
-		if (descriptor.g) {
-			seg_top = 0xffffffff;
-		} else {
-			seg_top = base_address + (1 << 20);
-			if (seg_top < base_address)
-				seg_top = 0xffffffff;
-		}
-		access_limit =
-		    (address <= limit) || (address >= seg_top) ? 0 :
-		    ((seg_top - address) >= 255 ? 255 : seg_top - address);
-	} else {
-		access_limit =
-		    (address > limit) || (address < base_address) ? 0 :
-		    ((limit - address) >= 254 ? 255 : limit - address + 1);
-	}
-	if (seg_execute_only(&descriptor) ||
-	    (!seg_writable(&descriptor) && (FPU_modrm & FPU_WRITE_BIT))) {
-		access_limit = 0;
-	}
-	return address;
-}
-
-/*
-       MOD R/M byte:  MOD == 3 has a special use for the FPU
-                      SIB byte used iff R/M = 100b
-
-       7   6   5   4   3   2   1   0
-       .....   .........   .........
-        MOD    OPCODE(2)     R/M
-
-       SIB byte
-
-       7   6   5   4   3   2   1   0
-       .....   .........   .........
-        SS      INDEX        BASE
-
-*/
-
-void __user *FPU_get_address(u_char FPU_modrm, unsigned long *fpu_eip,
-			     struct address *addr, fpu_addr_modes addr_modes)
-{
-	u_char mod;
-	unsigned rm = FPU_modrm & 7;
-	long *cpu_reg_ptr;
-	int address = 0;	/* Initialized just to stop compiler warnings. */
-
-	/* Memory accessed via the cs selector is write protected
-	   in `non-segmented' 32 bit protected mode. */
-	if (!addr_modes.default_mode && (FPU_modrm & FPU_WRITE_BIT)
-	    && (addr_modes.override.segment == PREFIX_CS_)) {
-		math_abort(FPU_info, SIGSEGV);
-	}
-
-	addr->selector = FPU_DS;	/* Default, for 32 bit non-segmented mode. */
-
-	mod = (FPU_modrm >> 6) & 3;
-
-	if (rm == 4 && mod != 3) {
-		address = sib(mod, fpu_eip);
-	} else {
-		cpu_reg_ptr = &REG_(rm);
-		switch (mod) {
-		case 0:
-			if (rm == 5) {
-				/* Special case: disp32 */
-				RE_ENTRANT_CHECK_OFF;
-				FPU_code_access_ok(4);
-				FPU_get_user(address,
-					     (unsigned long __user
-					      *)(*fpu_eip));
-				(*fpu_eip) += 4;
-				RE_ENTRANT_CHECK_ON;
-				addr->offset = address;
-				return (void __user *)address;
-			} else {
-				address = *cpu_reg_ptr;	/* Just return the contents
-							   of the cpu register */
-				addr->offset = address;
-				return (void __user *)address;
-			}
-		case 1:
-			/* 8 bit signed displacement */
-			RE_ENTRANT_CHECK_OFF;
-			FPU_code_access_ok(1);
-			FPU_get_user(address, (signed char __user *)(*fpu_eip));
-			RE_ENTRANT_CHECK_ON;
-			(*fpu_eip)++;
-			break;
-		case 2:
-			/* 32 bit displacement */
-			RE_ENTRANT_CHECK_OFF;
-			FPU_code_access_ok(4);
-			FPU_get_user(address, (long __user *)(*fpu_eip));
-			(*fpu_eip) += 4;
-			RE_ENTRANT_CHECK_ON;
-			break;
-		case 3:
-			/* Not legal for the FPU */
-			EXCEPTION(EX_Invalid);
-		}
-		address += *cpu_reg_ptr;
-	}
-
-	addr->offset = address;
-
-	switch (addr_modes.default_mode) {
-	case 0:
-		break;
-	case VM86:
-		address += vm86_segment(addr_modes.override.segment, addr);
-		break;
-	case PM16:
-	case SEG32:
-		address = pm_address(FPU_modrm, addr_modes.override.segment,
-				     addr, address);
-		break;
-	default:
-		EXCEPTION(EX_INTERNAL | 0x133);
-	}
-
-	return (void __user *)address;
-}
-
-void __user *FPU_get_address_16(u_char FPU_modrm, unsigned long *fpu_eip,
-				struct address *addr, fpu_addr_modes addr_modes)
-{
-	u_char mod;
-	unsigned rm = FPU_modrm & 7;
-	int address = 0;	/* Default used for mod == 0 */
-
-	/* Memory accessed via the cs selector is write protected
-	   in `non-segmented' 32 bit protected mode. */
-	if (!addr_modes.default_mode && (FPU_modrm & FPU_WRITE_BIT)
-	    && (addr_modes.override.segment == PREFIX_CS_)) {
-		math_abort(FPU_info, SIGSEGV);
-	}
-
-	addr->selector = FPU_DS;	/* Default, for 32 bit non-segmented mode. */
-
-	mod = (FPU_modrm >> 6) & 3;
-
-	switch (mod) {
-	case 0:
-		if (rm == 6) {
-			/* Special case: disp16 */
-			RE_ENTRANT_CHECK_OFF;
-			FPU_code_access_ok(2);
-			FPU_get_user(address,
-				     (unsigned short __user *)(*fpu_eip));
-			(*fpu_eip) += 2;
-			RE_ENTRANT_CHECK_ON;
-			goto add_segment;
-		}
-		break;
-	case 1:
-		/* 8 bit signed displacement */
-		RE_ENTRANT_CHECK_OFF;
-		FPU_code_access_ok(1);
-		FPU_get_user(address, (signed char __user *)(*fpu_eip));
-		RE_ENTRANT_CHECK_ON;
-		(*fpu_eip)++;
-		break;
-	case 2:
-		/* 16 bit displacement */
-		RE_ENTRANT_CHECK_OFF;
-		FPU_code_access_ok(2);
-		FPU_get_user(address, (unsigned short __user *)(*fpu_eip));
-		(*fpu_eip) += 2;
-		RE_ENTRANT_CHECK_ON;
-		break;
-	case 3:
-		/* Not legal for the FPU */
-		EXCEPTION(EX_Invalid);
-		break;
-	}
-	switch (rm) {
-	case 0:
-		address += FPU_info->regs->bx + FPU_info->regs->si;
-		break;
-	case 1:
-		address += FPU_info->regs->bx + FPU_info->regs->di;
-		break;
-	case 2:
-		address += FPU_info->regs->bp + FPU_info->regs->si;
-		if (addr_modes.override.segment == PREFIX_DEFAULT)
-			addr_modes.override.segment = PREFIX_SS_;
-		break;
-	case 3:
-		address += FPU_info->regs->bp + FPU_info->regs->di;
-		if (addr_modes.override.segment == PREFIX_DEFAULT)
-			addr_modes.override.segment = PREFIX_SS_;
-		break;
-	case 4:
-		address += FPU_info->regs->si;
-		break;
-	case 5:
-		address += FPU_info->regs->di;
-		break;
-	case 6:
-		address += FPU_info->regs->bp;
-		if (addr_modes.override.segment == PREFIX_DEFAULT)
-			addr_modes.override.segment = PREFIX_SS_;
-		break;
-	case 7:
-		address += FPU_info->regs->bx;
-		break;
-	}
-
-      add_segment:
-	address &= 0xffff;
-
-	addr->offset = address;
-
-	switch (addr_modes.default_mode) {
-	case 0:
-		break;
-	case VM86:
-		address += vm86_segment(addr_modes.override.segment, addr);
-		break;
-	case PM16:
-	case SEG32:
-		address = pm_address(FPU_modrm, addr_modes.override.segment,
-				     addr, address);
-		break;
-	default:
-		EXCEPTION(EX_INTERNAL | 0x131);
-	}
-
-	return (void __user *)address;
-}
diff -rupN a/arch/x86/math-emu/load_store.c b/arch/x86/math-emu/load_store.c
--- a/arch/x86/math-emu/load_store.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/load_store.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,322 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  load_store.c                                                             |
- |                                                                           |
- | This file contains most of the code to interpret the FPU instructions     |
- | which load and store from user memory.                                    |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997                                         |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@suburbia.net             |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | Note:                                                                     |
- |    The file contains code which accesses user memory.                     |
- |    Emulator static data may change when user memory is accessed, due to   |
- |    other processes using the emulator while swapping is in progress.      |
- +---------------------------------------------------------------------------*/
-
-#include <linux/uaccess.h>
-
-#include "fpu_system.h"
-#include "exception.h"
-#include "fpu_emu.h"
-#include "status_w.h"
-#include "control_w.h"
-
-#define _NONE_ 0		/* st0_ptr etc not needed */
-#define _REG0_ 1		/* Will be storing st(0) */
-#define _PUSH_ 3		/* Need to check for space to push onto stack */
-#define _null_ 4		/* Function illegal or not implemented */
-
-#define pop_0()	{ FPU_settag0(TAG_Empty); top++; }
-
-/* index is a 5-bit value: (3-bit FPU_modrm.reg field | opcode[2,1]) */
-static u_char const type_table[32] = {
-	_PUSH_, _PUSH_, _PUSH_, _PUSH_, /* /0: d9:fld f32,  db:fild m32,  dd:fld f64,  df:fild m16 */
-	_null_, _REG0_, _REG0_, _REG0_, /* /1: d9:undef,    db,dd,df:fisttp m32/64/16 */
-	_REG0_, _REG0_, _REG0_, _REG0_, /* /2: d9:fst f32,  db:fist m32,  dd:fst f64,  df:fist m16 */
-	_REG0_, _REG0_, _REG0_, _REG0_, /* /3: d9:fstp f32, db:fistp m32, dd:fstp f64, df:fistp m16 */
-	_NONE_, _null_, _NONE_, _PUSH_,
-	_NONE_, _PUSH_, _null_, _PUSH_,
-	_NONE_, _null_, _NONE_, _REG0_,
-	_NONE_, _REG0_, _NONE_, _REG0_
-};
-
-u_char const data_sizes_16[32] = {
-	4, 4, 8, 2,
-	0, 4, 8, 2, /* /1: d9:undef, db,dd,df:fisttp */
-	4, 4, 8, 2,
-	4, 4, 8, 2,
-	14, 0, 94, 10, 2, 10, 0, 8,
-	14, 0, 94, 10, 2, 10, 2, 8
-};
-
-static u_char const data_sizes_32[32] = {
-	4, 4, 8, 2,
-	0, 4, 8, 2, /* /1: d9:undef, db,dd,df:fisttp */
-	4, 4, 8, 2,
-	4, 4, 8, 2,
-	28, 0, 108, 10, 2, 10, 0, 8,
-	28, 0, 108, 10, 2, 10, 2, 8
-};
-
-int FPU_load_store(u_char type, fpu_addr_modes addr_modes,
-		   void __user * data_address)
-{
-	FPU_REG loaded_data;
-	FPU_REG *st0_ptr;
-	u_char st0_tag = TAG_Empty;	/* This is just to stop a gcc warning. */
-	u_char loaded_tag;
-	int sv_cw;
-
-	st0_ptr = NULL;		/* Initialized just to stop compiler warnings. */
-
-	if (addr_modes.default_mode & PROTECTED) {
-		if (addr_modes.default_mode == SEG32) {
-			if (access_limit < data_sizes_32[type])
-				math_abort(FPU_info, SIGSEGV);
-		} else if (addr_modes.default_mode == PM16) {
-			if (access_limit < data_sizes_16[type])
-				math_abort(FPU_info, SIGSEGV);
-		}
-#ifdef PARANOID
-		else
-			EXCEPTION(EX_INTERNAL | 0x140);
-#endif /* PARANOID */
-	}
-
-	switch (type_table[type]) {
-	case _NONE_:
-		break;
-	case _REG0_:
-		st0_ptr = &st(0);	/* Some of these instructions pop after
-					   storing */
-		st0_tag = FPU_gettag0();
-		break;
-	case _PUSH_:
-		{
-			if (FPU_gettagi(-1) != TAG_Empty) {
-				FPU_stack_overflow();
-				return 0;
-			}
-			top--;
-			st0_ptr = &st(0);
-		}
-		break;
-	case _null_:
-		FPU_illegal();
-		return 0;
-#ifdef PARANOID
-	default:
-		EXCEPTION(EX_INTERNAL | 0x141);
-		return 0;
-#endif /* PARANOID */
-	}
-
-	switch (type) {
-	/* type is a 5-bit value: (3-bit FPU_modrm.reg field | opcode[2,1]) */
-	case 000:		/* fld m32real (d9 /0) */
-		clear_C1();
-		loaded_tag =
-		    FPU_load_single((float __user *)data_address, &loaded_data);
-		if ((loaded_tag == TAG_Special)
-		    && isNaN(&loaded_data)
-		    && (real_1op_NaN(&loaded_data) < 0)) {
-			top++;
-			break;
-		}
-		FPU_copy_to_reg0(&loaded_data, loaded_tag);
-		break;
-	case 001:		/* fild m32int (db /0) */
-		clear_C1();
-		loaded_tag =
-		    FPU_load_int32((long __user *)data_address, &loaded_data);
-		FPU_copy_to_reg0(&loaded_data, loaded_tag);
-		break;
-	case 002:		/* fld m64real (dd /0) */
-		clear_C1();
-		loaded_tag =
-		    FPU_load_double((double __user *)data_address,
-				    &loaded_data);
-		if ((loaded_tag == TAG_Special)
-		    && isNaN(&loaded_data)
-		    && (real_1op_NaN(&loaded_data) < 0)) {
-			top++;
-			break;
-		}
-		FPU_copy_to_reg0(&loaded_data, loaded_tag);
-		break;
-	case 003:		/* fild m16int (df /0) */
-		clear_C1();
-		loaded_tag =
-		    FPU_load_int16((short __user *)data_address, &loaded_data);
-		FPU_copy_to_reg0(&loaded_data, loaded_tag);
-		break;
-	/* case 004: undefined (d9 /1) */
-	/* fisttp are enabled if CPUID(1).ECX(0) "sse3" is set */
-	case 005:		/* fisttp m32int (db /1) */
-		clear_C1();
-		sv_cw = control_word;
-		control_word |= RC_CHOP;
-		if (FPU_store_int32
-		    (st0_ptr, st0_tag, (long __user *)data_address))
-			pop_0();	/* pop only if the number was actually stored
-					   (see the 80486 manual p16-28) */
-		control_word = sv_cw;
-		break;
-	case 006:		/* fisttp m64int (dd /1) */
-		clear_C1();
-		sv_cw = control_word;
-		control_word |= RC_CHOP;
-		if (FPU_store_int64
-		    (st0_ptr, st0_tag, (long long __user *)data_address))
-			pop_0();	/* pop only if the number was actually stored
-					   (see the 80486 manual p16-28) */
-		control_word = sv_cw;
-		break;
-	case 007:		/* fisttp m16int (df /1) */
-		clear_C1();
-		sv_cw = control_word;
-		control_word |= RC_CHOP;
-		if (FPU_store_int16
-		    (st0_ptr, st0_tag, (short __user *)data_address))
-			pop_0();	/* pop only if the number was actually stored
-					   (see the 80486 manual p16-28) */
-		control_word = sv_cw;
-		break;
-	case 010:		/* fst m32real */
-		clear_C1();
-		FPU_store_single(st0_ptr, st0_tag,
-				 (float __user *)data_address);
-		break;
-	case 011:		/* fist m32int */
-		clear_C1();
-		FPU_store_int32(st0_ptr, st0_tag, (long __user *)data_address);
-		break;
-	case 012:		/* fst m64real */
-		clear_C1();
-		FPU_store_double(st0_ptr, st0_tag,
-				 (double __user *)data_address);
-		break;
-	case 013:		/* fist m16int */
-		clear_C1();
-		FPU_store_int16(st0_ptr, st0_tag, (short __user *)data_address);
-		break;
-	case 014:		/* fstp m32real */
-		clear_C1();
-		if (FPU_store_single
-		    (st0_ptr, st0_tag, (float __user *)data_address))
-			pop_0();	/* pop only if the number was actually stored
-					   (see the 80486 manual p16-28) */
-		break;
-	case 015:		/* fistp m32int */
-		clear_C1();
-		if (FPU_store_int32
-		    (st0_ptr, st0_tag, (long __user *)data_address))
-			pop_0();	/* pop only if the number was actually stored
-					   (see the 80486 manual p16-28) */
-		break;
-	case 016:		/* fstp m64real */
-		clear_C1();
-		if (FPU_store_double
-		    (st0_ptr, st0_tag, (double __user *)data_address))
-			pop_0();	/* pop only if the number was actually stored
-					   (see the 80486 manual p16-28) */
-		break;
-	case 017:		/* fistp m16int */
-		clear_C1();
-		if (FPU_store_int16
-		    (st0_ptr, st0_tag, (short __user *)data_address))
-			pop_0();	/* pop only if the number was actually stored
-					   (see the 80486 manual p16-28) */
-		break;
-	case 020:		/* fldenv  m14/28byte */
-		fldenv(addr_modes, (u_char __user *) data_address);
-		/* Ensure that the values just loaded are not changed by
-		   fix-up operations. */
-		return 1;
-	case 022:		/* frstor m94/108byte */
-		FPU_frstor(addr_modes, (u_char __user *) data_address);
-		/* Ensure that the values just loaded are not changed by
-		   fix-up operations. */
-		return 1;
-	case 023:		/* fbld m80dec */
-		clear_C1();
-		loaded_tag = FPU_load_bcd((u_char __user *) data_address);
-		FPU_settag0(loaded_tag);
-		break;
-	case 024:		/* fldcw */
-		RE_ENTRANT_CHECK_OFF;
-		FPU_access_ok(data_address, 2);
-		FPU_get_user(control_word,
-			     (unsigned short __user *)data_address);
-		RE_ENTRANT_CHECK_ON;
-		if (partial_status & ~control_word & CW_Exceptions)
-			partial_status |= (SW_Summary | SW_Backward);
-		else
-			partial_status &= ~(SW_Summary | SW_Backward);
-#ifdef PECULIAR_486
-		control_word |= 0x40;	/* An 80486 appears to always set this bit */
-#endif /* PECULIAR_486 */
-		return 1;
-	case 025:		/* fld m80real */
-		clear_C1();
-		loaded_tag =
-		    FPU_load_extended((long double __user *)data_address, 0);
-		FPU_settag0(loaded_tag);
-		break;
-	case 027:		/* fild m64int */
-		clear_C1();
-		loaded_tag = FPU_load_int64((long long __user *)data_address);
-		if (loaded_tag == TAG_Error)
-			return 0;
-		FPU_settag0(loaded_tag);
-		break;
-	case 030:		/* fstenv  m14/28byte */
-		fstenv(addr_modes, (u_char __user *) data_address);
-		return 1;
-	case 032:		/* fsave */
-		fsave(addr_modes, (u_char __user *) data_address);
-		return 1;
-	case 033:		/* fbstp m80dec */
-		clear_C1();
-		if (FPU_store_bcd
-		    (st0_ptr, st0_tag, (u_char __user *) data_address))
-			pop_0();	/* pop only if the number was actually stored
-					   (see the 80486 manual p16-28) */
-		break;
-	case 034:		/* fstcw m16int */
-		RE_ENTRANT_CHECK_OFF;
-		FPU_access_ok(data_address, 2);
-		FPU_put_user(control_word,
-			     (unsigned short __user *)data_address);
-		RE_ENTRANT_CHECK_ON;
-		return 1;
-	case 035:		/* fstp m80real */
-		clear_C1();
-		if (FPU_store_extended
-		    (st0_ptr, st0_tag, (long double __user *)data_address))
-			pop_0();	/* pop only if the number was actually stored
-					   (see the 80486 manual p16-28) */
-		break;
-	case 036:		/* fstsw m2byte */
-		RE_ENTRANT_CHECK_OFF;
-		FPU_access_ok(data_address, 2);
-		FPU_put_user(status_word(),
-			     (unsigned short __user *)data_address);
-		RE_ENTRANT_CHECK_ON;
-		return 1;
-	case 037:		/* fistp m64int */
-		clear_C1();
-		if (FPU_store_int64
-		    (st0_ptr, st0_tag, (long long __user *)data_address))
-			pop_0();	/* pop only if the number was actually stored
-					   (see the 80486 manual p16-28) */
-		break;
-	}
-	return 0;
-}
diff -rupN a/arch/x86/math-emu/Makefile b/arch/x86/math-emu/Makefile
--- a/arch/x86/math-emu/Makefile	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/Makefile	1970-01-01 01:00:00.000000000 +0100
@@ -1,30 +0,0 @@
-# SPDX-License-Identifier: GPL-2.0
-#
-#               Makefile for wm-FPU-emu
-#
-
-#DEBUG	= -DDEBUGGING
-DEBUG	=
-PARANOID = -DPARANOID
-ccflags-y += $(PARANOID) $(DEBUG) -fno-builtin $(MATH_EMULATION)
-asflags-y += $(PARANOID)
-
-# From 'C' language sources:
-C_OBJS =fpu_entry.o errors.o \
-	fpu_arith.o fpu_aux.o fpu_etc.o fpu_tags.o fpu_trig.o \
-	load_store.o get_address.o \
-	poly_atan.o poly_l2.o poly_2xm1.o poly_sin.o poly_tan.o \
-	reg_add_sub.o reg_compare.o reg_constant.o reg_convert.o \
-	reg_ld_str.o reg_divide.o reg_mul.o
-
-# From 80x86 assembler sources:
-A_OBJS =reg_u_add.o reg_u_div.o reg_u_mul.o reg_u_sub.o \
-	div_small.o reg_norm.o reg_round.o \
-	wm_shrx.o wm_sqrt.o \
-	div_Xsig.o polynom_Xsig.o round_Xsig.o \
-	shr_Xsig.o mul_Xsig.o
-
-obj-y =$(C_OBJS) $(A_OBJS)
-
-proto:
-	cproto -e -DMAKING_PROTO *.c >fpu_proto.h
diff -rupN a/arch/x86/math-emu/mul_Xsig.S b/arch/x86/math-emu/mul_Xsig.S
--- a/arch/x86/math-emu/mul_Xsig.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/mul_Xsig.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,179 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  mul_Xsig.S                                                               |
- |                                                                           |
- | Multiply a 12 byte fixed point number by another fixed point number.      |
- |                                                                           |
- | Copyright (C) 1992,1994,1995                                              |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@jacobi.maths.monash.edu.au |
- |                                                                           |
- | Call from C as:                                                           |
- |   void mul32_Xsig(Xsig *x, unsigned b)                                    |
- |                                                                           |
- |   void mul64_Xsig(Xsig *x, unsigned long long *b)                         |
- |                                                                           |
- |   void mul_Xsig_Xsig(Xsig *x, unsigned *b)                                |
- |                                                                           |
- | The result is neither rounded nor normalized, and the ls bit or so may    |
- | be wrong.                                                                 |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-	.file	"mul_Xsig.S"
-
-
-#include "fpu_emu.h"
-
-.text
-SYM_FUNC_START(mul32_Xsig)
-	pushl %ebp
-	movl %esp,%ebp
-	subl $16,%esp
-	pushl %esi
-
-	movl PARAM1,%esi
-	movl PARAM2,%ecx
-
-	xor %eax,%eax
-	movl %eax,-4(%ebp)
-	movl %eax,-8(%ebp)
-
-	movl (%esi),%eax        /* lsl of Xsig */
-	mull %ecx		/* msl of b */
-	movl %edx,-12(%ebp)
-
-	movl 4(%esi),%eax	/* midl of Xsig */
-	mull %ecx		/* msl of b */
-	addl %eax,-12(%ebp)
-	adcl %edx,-8(%ebp)
-	adcl $0,-4(%ebp)
-
-	movl 8(%esi),%eax	/* msl of Xsig */
-	mull %ecx		/* msl of b */
-	addl %eax,-8(%ebp)
-	adcl %edx,-4(%ebp)
-
-	movl -12(%ebp),%eax
-	movl %eax,(%esi)
-	movl -8(%ebp),%eax
-	movl %eax,4(%esi)
-	movl -4(%ebp),%eax
-	movl %eax,8(%esi)
-
-	popl %esi
-	leave
-	RET
-SYM_FUNC_END(mul32_Xsig)
-
-
-SYM_FUNC_START(mul64_Xsig)
-	pushl %ebp
-	movl %esp,%ebp
-	subl $16,%esp
-	pushl %esi
-
-	movl PARAM1,%esi
-	movl PARAM2,%ecx
-
-	xor %eax,%eax
-	movl %eax,-4(%ebp)
-	movl %eax,-8(%ebp)
-
-	movl (%esi),%eax        /* lsl of Xsig */
-	mull 4(%ecx)		/* msl of b */
-	movl %edx,-12(%ebp)
-
-	movl 4(%esi),%eax	/* midl of Xsig */
-	mull (%ecx)		/* lsl of b */
-	addl %edx,-12(%ebp)
-	adcl $0,-8(%ebp)
-	adcl $0,-4(%ebp)
-
-	movl 4(%esi),%eax	/* midl of Xsig */
-	mull 4(%ecx)		/* msl of b */
-	addl %eax,-12(%ebp)
-	adcl %edx,-8(%ebp)
-	adcl $0,-4(%ebp)
-
-	movl 8(%esi),%eax	/* msl of Xsig */
-	mull (%ecx)		/* lsl of b */
-	addl %eax,-12(%ebp)
-	adcl %edx,-8(%ebp)
-	adcl $0,-4(%ebp)
-
-	movl 8(%esi),%eax	/* msl of Xsig */
-	mull 4(%ecx)		/* msl of b */
-	addl %eax,-8(%ebp)
-	adcl %edx,-4(%ebp)
-
-	movl -12(%ebp),%eax
-	movl %eax,(%esi)
-	movl -8(%ebp),%eax
-	movl %eax,4(%esi)
-	movl -4(%ebp),%eax
-	movl %eax,8(%esi)
-
-	popl %esi
-	leave
-	RET
-SYM_FUNC_END(mul64_Xsig)
-
-
-
-SYM_FUNC_START(mul_Xsig_Xsig)
-	pushl %ebp
-	movl %esp,%ebp
-	subl $16,%esp
-	pushl %esi
-
-	movl PARAM1,%esi
-	movl PARAM2,%ecx
-
-	xor %eax,%eax
-	movl %eax,-4(%ebp)
-	movl %eax,-8(%ebp)
-
-	movl (%esi),%eax        /* lsl of Xsig */
-	mull 8(%ecx)		/* msl of b */
-	movl %edx,-12(%ebp)
-
-	movl 4(%esi),%eax	/* midl of Xsig */
-	mull 4(%ecx)		/* midl of b */
-	addl %edx,-12(%ebp)
-	adcl $0,-8(%ebp)
-	adcl $0,-4(%ebp)
-
-	movl 8(%esi),%eax	/* msl of Xsig */
-	mull (%ecx)		/* lsl of b */
-	addl %edx,-12(%ebp)
-	adcl $0,-8(%ebp)
-	adcl $0,-4(%ebp)
-
-	movl 4(%esi),%eax	/* midl of Xsig */
-	mull 8(%ecx)		/* msl of b */
-	addl %eax,-12(%ebp)
-	adcl %edx,-8(%ebp)
-	adcl $0,-4(%ebp)
-
-	movl 8(%esi),%eax	/* msl of Xsig */
-	mull 4(%ecx)		/* midl of b */
-	addl %eax,-12(%ebp)
-	adcl %edx,-8(%ebp)
-	adcl $0,-4(%ebp)
-
-	movl 8(%esi),%eax	/* msl of Xsig */
-	mull 8(%ecx)		/* msl of b */
-	addl %eax,-8(%ebp)
-	adcl %edx,-4(%ebp)
-
-	movl -12(%ebp),%edx
-	movl %edx,(%esi)
-	movl -8(%ebp),%edx
-	movl %edx,4(%esi)
-	movl -4(%ebp),%edx
-	movl %edx,8(%esi)
-
-	popl %esi
-	leave
-	RET
-SYM_FUNC_END(mul_Xsig_Xsig)
diff -rupN a/arch/x86/math-emu/poly_2xm1.c b/arch/x86/math-emu/poly_2xm1.c
--- a/arch/x86/math-emu/poly_2xm1.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/poly_2xm1.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,146 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  poly_2xm1.c                                                              |
- |                                                                           |
- | Function to compute 2^x-1 by a polynomial approximation.                  |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997                                         |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "reg_constant.h"
-#include "fpu_emu.h"
-#include "fpu_system.h"
-#include "control_w.h"
-#include "poly.h"
-
-#define	HIPOWER	11
-static const unsigned long long lterms[HIPOWER] = {
-	0x0000000000000000LL,	/* This term done separately as 12 bytes */
-	0xf5fdeffc162c7543LL,
-	0x1c6b08d704a0bfa6LL,
-	0x0276556df749cc21LL,
-	0x002bb0ffcf14f6b8LL,
-	0x0002861225ef751cLL,
-	0x00001ffcbfcd5422LL,
-	0x00000162c005d5f1LL,
-	0x0000000da96ccb1bLL,
-	0x0000000078d1b897LL,
-	0x000000000422b029LL
-};
-
-static const Xsig hiterm = MK_XSIG(0xb17217f7, 0xd1cf79ab, 0xc8a39194);
-
-/* Four slices: 0.0 : 0.25 : 0.50 : 0.75 : 1.0,
-   These numbers are 2^(1/4), 2^(1/2), and 2^(3/4)
- */
-static const Xsig shiftterm0 = MK_XSIG(0, 0, 0);
-static const Xsig shiftterm1 = MK_XSIG(0x9837f051, 0x8db8a96f, 0x46ad2318);
-static const Xsig shiftterm2 = MK_XSIG(0xb504f333, 0xf9de6484, 0x597d89b3);
-static const Xsig shiftterm3 = MK_XSIG(0xd744fcca, 0xd69d6af4, 0x39a68bb9);
-
-static const Xsig *shiftterm[] = { &shiftterm0, &shiftterm1,
-	&shiftterm2, &shiftterm3
-};
-
-/*--- poly_2xm1() -----------------------------------------------------------+
- | Requires st(0) which is TAG_Valid and < 1.                                |
- +---------------------------------------------------------------------------*/
-int poly_2xm1(u_char sign, FPU_REG *arg, FPU_REG *result)
-{
-	long int exponent, shift;
-	unsigned long long Xll;
-	Xsig accumulator, Denom, argSignif;
-	u_char tag;
-
-	exponent = exponent16(arg);
-
-#ifdef PARANOID
-	if (exponent >= 0) {	/* Don't want a |number| >= 1.0 */
-		/* Number negative, too large, or not Valid. */
-		EXCEPTION(EX_INTERNAL | 0x127);
-		return 1;
-	}
-#endif /* PARANOID */
-
-	argSignif.lsw = 0;
-	XSIG_LL(argSignif) = Xll = significand(arg);
-
-	if (exponent == -1) {
-		shift = (argSignif.msw & 0x40000000) ? 3 : 2;
-		/* subtract 0.5 or 0.75 */
-		exponent -= 2;
-		XSIG_LL(argSignif) <<= 2;
-		Xll <<= 2;
-	} else if (exponent == -2) {
-		shift = 1;
-		/* subtract 0.25 */
-		exponent--;
-		XSIG_LL(argSignif) <<= 1;
-		Xll <<= 1;
-	} else
-		shift = 0;
-
-	if (exponent < -2) {
-		/* Shift the argument right by the required places. */
-		if (FPU_shrx(&Xll, -2 - exponent) >= 0x80000000U)
-			Xll++;	/* round up */
-	}
-
-	accumulator.lsw = accumulator.midw = accumulator.msw = 0;
-	polynomial_Xsig(&accumulator, &Xll, lterms, HIPOWER - 1);
-	mul_Xsig_Xsig(&accumulator, &argSignif);
-	shr_Xsig(&accumulator, 3);
-
-	mul_Xsig_Xsig(&argSignif, &hiterm);	/* The leading term */
-	add_two_Xsig(&accumulator, &argSignif, &exponent);
-
-	if (shift) {
-		/* The argument is large, use the identity:
-		   f(x+a) = f(a) * (f(x) + 1) - 1;
-		 */
-		shr_Xsig(&accumulator, -exponent);
-		accumulator.msw |= 0x80000000;	/* add 1.0 */
-		mul_Xsig_Xsig(&accumulator, shiftterm[shift]);
-		accumulator.msw &= 0x3fffffff;	/* subtract 1.0 */
-		exponent = 1;
-	}
-
-	if (sign != SIGN_POS) {
-		/* The argument is negative, use the identity:
-		   f(-x) = -f(x) / (1 + f(x))
-		 */
-		Denom.lsw = accumulator.lsw;
-		XSIG_LL(Denom) = XSIG_LL(accumulator);
-		if (exponent < 0)
-			shr_Xsig(&Denom, -exponent);
-		else if (exponent > 0) {
-			/* exponent must be 1 here */
-			XSIG_LL(Denom) <<= 1;
-			if (Denom.lsw & 0x80000000)
-				XSIG_LL(Denom) |= 1;
-			(Denom.lsw) <<= 1;
-		}
-		Denom.msw |= 0x80000000;	/* add 1.0 */
-		div_Xsig(&accumulator, &Denom, &accumulator);
-	}
-
-	/* Convert to 64 bit signed-compatible */
-	exponent += round_Xsig(&accumulator);
-
-	result = &st(0);
-	significand(result) = XSIG_LL(accumulator);
-	setexponent16(result, exponent);
-
-	tag = FPU_round(result, 1, 0, FULL_PRECISION, sign);
-
-	setsign(result, sign);
-	FPU_settag0(tag);
-
-	return 0;
-
-}
diff -rupN a/arch/x86/math-emu/poly_atan.c b/arch/x86/math-emu/poly_atan.c
--- a/arch/x86/math-emu/poly_atan.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/poly_atan.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,209 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  poly_atan.c                                                              |
- |                                                                           |
- | Compute the arctan of a FPU_REG, using a polynomial approximation.        |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997                                         |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "reg_constant.h"
-#include "fpu_emu.h"
-#include "fpu_system.h"
-#include "status_w.h"
-#include "control_w.h"
-#include "poly.h"
-
-#define	HIPOWERon	6	/* odd poly, negative terms */
-static const unsigned long long oddnegterms[HIPOWERon] = {
-	0x0000000000000000LL,	/* Dummy (not for - 1.0) */
-	0x015328437f756467LL,
-	0x0005dda27b73dec6LL,
-	0x0000226bf2bfb91aLL,
-	0x000000ccc439c5f7LL,
-	0x0000000355438407LL
-};
-
-#define	HIPOWERop	6	/* odd poly, positive terms */
-static const unsigned long long oddplterms[HIPOWERop] = {
-/*  0xaaaaaaaaaaaaaaabLL,  transferred to fixedpterm[] */
-	0x0db55a71875c9ac2LL,
-	0x0029fce2d67880b0LL,
-	0x0000dfd3908b4596LL,
-	0x00000550fd61dab4LL,
-	0x0000001c9422b3f9LL,
-	0x000000003e3301e1LL
-};
-
-static const unsigned long long denomterm = 0xebd9b842c5c53a0eLL;
-
-static const Xsig fixedpterm = MK_XSIG(0xaaaaaaaa, 0xaaaaaaaa, 0xaaaaaaaa);
-
-static const Xsig pi_signif = MK_XSIG(0xc90fdaa2, 0x2168c234, 0xc4c6628b);
-
-/*--- poly_atan() -----------------------------------------------------------+
- |                                                                           |
- +---------------------------------------------------------------------------*/
-void poly_atan(FPU_REG *st0_ptr, u_char st0_tag,
-	       FPU_REG *st1_ptr, u_char st1_tag)
-{
-	u_char transformed, inverted, sign1, sign2;
-	int exponent;
-	long int dummy_exp;
-	Xsig accumulator, Numer, Denom, accumulatore, argSignif, argSq, argSqSq;
-	u_char tag;
-
-	sign1 = getsign(st0_ptr);
-	sign2 = getsign(st1_ptr);
-	if (st0_tag == TAG_Valid) {
-		exponent = exponent(st0_ptr);
-	} else {
-		/* This gives non-compatible stack contents... */
-		FPU_to_exp16(st0_ptr, st0_ptr);
-		exponent = exponent16(st0_ptr);
-	}
-	if (st1_tag == TAG_Valid) {
-		exponent -= exponent(st1_ptr);
-	} else {
-		/* This gives non-compatible stack contents... */
-		FPU_to_exp16(st1_ptr, st1_ptr);
-		exponent -= exponent16(st1_ptr);
-	}
-
-	if ((exponent < 0) || ((exponent == 0) &&
-			       ((st0_ptr->sigh < st1_ptr->sigh) ||
-				((st0_ptr->sigh == st1_ptr->sigh) &&
-				 (st0_ptr->sigl < st1_ptr->sigl))))) {
-		inverted = 1;
-		Numer.lsw = Denom.lsw = 0;
-		XSIG_LL(Numer) = significand(st0_ptr);
-		XSIG_LL(Denom) = significand(st1_ptr);
-	} else {
-		inverted = 0;
-		exponent = -exponent;
-		Numer.lsw = Denom.lsw = 0;
-		XSIG_LL(Numer) = significand(st1_ptr);
-		XSIG_LL(Denom) = significand(st0_ptr);
-	}
-	div_Xsig(&Numer, &Denom, &argSignif);
-	exponent += norm_Xsig(&argSignif);
-
-	if ((exponent >= -1)
-	    || ((exponent == -2) && (argSignif.msw > 0xd413ccd0))) {
-		/* The argument is greater than sqrt(2)-1 (=0.414213562...) */
-		/* Convert the argument by an identity for atan */
-		transformed = 1;
-
-		if (exponent >= 0) {
-#ifdef PARANOID
-			if (!((exponent == 0) &&
-			      (argSignif.lsw == 0) && (argSignif.midw == 0) &&
-			      (argSignif.msw == 0x80000000))) {
-				EXCEPTION(EX_INTERNAL | 0x104);	/* There must be a logic error */
-				return;
-			}
-#endif /* PARANOID */
-			argSignif.msw = 0;	/* Make the transformed arg -> 0.0 */
-		} else {
-			Numer.lsw = Denom.lsw = argSignif.lsw;
-			XSIG_LL(Numer) = XSIG_LL(Denom) = XSIG_LL(argSignif);
-
-			if (exponent < -1)
-				shr_Xsig(&Numer, -1 - exponent);
-			negate_Xsig(&Numer);
-
-			shr_Xsig(&Denom, -exponent);
-			Denom.msw |= 0x80000000;
-
-			div_Xsig(&Numer, &Denom, &argSignif);
-
-			exponent = -1 + norm_Xsig(&argSignif);
-		}
-	} else {
-		transformed = 0;
-	}
-
-	argSq.lsw = argSignif.lsw;
-	argSq.midw = argSignif.midw;
-	argSq.msw = argSignif.msw;
-	mul_Xsig_Xsig(&argSq, &argSq);
-
-	argSqSq.lsw = argSq.lsw;
-	argSqSq.midw = argSq.midw;
-	argSqSq.msw = argSq.msw;
-	mul_Xsig_Xsig(&argSqSq, &argSqSq);
-
-	accumulatore.lsw = argSq.lsw;
-	XSIG_LL(accumulatore) = XSIG_LL(argSq);
-
-	shr_Xsig(&argSq, 2 * (-1 - exponent - 1));
-	shr_Xsig(&argSqSq, 4 * (-1 - exponent - 1));
-
-	/* Now have argSq etc with binary point at the left
-	   .1xxxxxxxx */
-
-	/* Do the basic fixed point polynomial evaluation */
-	accumulator.msw = accumulator.midw = accumulator.lsw = 0;
-	polynomial_Xsig(&accumulator, &XSIG_LL(argSqSq),
-			oddplterms, HIPOWERop - 1);
-	mul64_Xsig(&accumulator, &XSIG_LL(argSq));
-	negate_Xsig(&accumulator);
-	polynomial_Xsig(&accumulator, &XSIG_LL(argSqSq), oddnegterms,
-			HIPOWERon - 1);
-	negate_Xsig(&accumulator);
-	add_two_Xsig(&accumulator, &fixedpterm, &dummy_exp);
-
-	mul64_Xsig(&accumulatore, &denomterm);
-	shr_Xsig(&accumulatore, 1 + 2 * (-1 - exponent));
-	accumulatore.msw |= 0x80000000;
-
-	div_Xsig(&accumulator, &accumulatore, &accumulator);
-
-	mul_Xsig_Xsig(&accumulator, &argSignif);
-	mul_Xsig_Xsig(&accumulator, &argSq);
-
-	shr_Xsig(&accumulator, 3);
-	negate_Xsig(&accumulator);
-	add_Xsig_Xsig(&accumulator, &argSignif);
-
-	if (transformed) {
-		/* compute pi/4 - accumulator */
-		shr_Xsig(&accumulator, -1 - exponent);
-		negate_Xsig(&accumulator);
-		add_Xsig_Xsig(&accumulator, &pi_signif);
-		exponent = -1;
-	}
-
-	if (inverted) {
-		/* compute pi/2 - accumulator */
-		shr_Xsig(&accumulator, -exponent);
-		negate_Xsig(&accumulator);
-		add_Xsig_Xsig(&accumulator, &pi_signif);
-		exponent = 0;
-	}
-
-	if (sign1) {
-		/* compute pi - accumulator */
-		shr_Xsig(&accumulator, 1 - exponent);
-		negate_Xsig(&accumulator);
-		add_Xsig_Xsig(&accumulator, &pi_signif);
-		exponent = 1;
-	}
-
-	exponent += round_Xsig(&accumulator);
-
-	significand(st1_ptr) = XSIG_LL(accumulator);
-	setexponent16(st1_ptr, exponent);
-
-	tag = FPU_round(st1_ptr, 1, 0, FULL_PRECISION, sign2);
-	FPU_settagi(1, tag);
-
-	set_precision_flag_up();	/* We do not really know if up or down,
-					   use this as the default. */
-
-}
diff -rupN a/arch/x86/math-emu/poly.h b/arch/x86/math-emu/poly.h
--- a/arch/x86/math-emu/poly.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/poly.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,115 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  poly.h                                                                   |
- |                                                                           |
- |  Header file for the FPU-emu poly*.c source files.                        |
- |                                                                           |
- | Copyright (C) 1994,1999                                                   |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@melbpc.org.au            |
- |                                                                           |
- | Declarations and definitions for functions operating on Xsig (12-byte     |
- | extended-significand) quantities.                                         |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#ifndef _POLY_H
-#define _POLY_H
-
-/* This 12-byte structure is used to improve the accuracy of computation
-   of transcendental functions.
-   Intended to be used to get results better than 8-byte computation
-   allows. 9-byte would probably be sufficient.
-   */
-typedef struct {
-	unsigned long lsw;
-	unsigned long midw;
-	unsigned long msw;
-} Xsig;
-
-asmlinkage void mul64(unsigned long long const *a, unsigned long long const *b,
-		      unsigned long long *result);
-asmlinkage void polynomial_Xsig(Xsig *, const unsigned long long *x,
-				const unsigned long long terms[], const int n);
-
-asmlinkage void mul32_Xsig(Xsig *, const unsigned long mult);
-asmlinkage void mul64_Xsig(Xsig *, const unsigned long long *mult);
-asmlinkage void mul_Xsig_Xsig(Xsig *dest, const Xsig *mult);
-
-asmlinkage void shr_Xsig(Xsig *, const int n);
-asmlinkage int round_Xsig(Xsig *);
-asmlinkage int norm_Xsig(Xsig *);
-asmlinkage void div_Xsig(Xsig *x1, const Xsig *x2, const Xsig *dest);
-
-/* Macro to extract the most significant 32 bits from a long long */
-#define LL_MSW(x)     (((unsigned long *)&x)[1])
-
-/* Macro to initialize an Xsig struct */
-#define MK_XSIG(a,b,c)     { c, b, a }
-
-/* Macro to access the 8 ms bytes of an Xsig as a long long */
-#define XSIG_LL(x)         (*(unsigned long long *)&x.midw)
-
-/*
-   Need to run gcc with optimizations on to get these to
-   actually be in-line.
-   */
-
-/* Multiply two fixed-point 32 bit numbers, producing a 32 bit result.
-   The answer is the ms word of the product. */
-/* Some versions of gcc make it difficult to stop eax from being clobbered.
-   Merely specifying that it is used doesn't work...
- */
-static inline unsigned long mul_32_32(const unsigned long arg1,
-				      const unsigned long arg2)
-{
-	int retval;
-	asm volatile ("mull %2; movl %%edx,%%eax":"=a" (retval)
-		      :"0"(arg1), "g"(arg2)
-		      :"dx");
-	return retval;
-}
-
-/* Add the 12 byte Xsig x2 to Xsig dest, with no checks for overflow. */
-static inline void add_Xsig_Xsig(Xsig *dest, const Xsig *x2)
-{
-	asm volatile ("movl %1,%%edi; movl %2,%%esi;\n"
-		      "movl (%%esi),%%eax; addl %%eax,(%%edi);\n"
-		      "movl 4(%%esi),%%eax; adcl %%eax,4(%%edi);\n"
-		      "movl 8(%%esi),%%eax; adcl %%eax,8(%%edi);\n":"=g"
-		      (*dest):"g"(dest), "g"(x2)
-		      :"ax", "si", "di");
-}
-
-/* Add the 12 byte Xsig x2 to Xsig dest, adjust exp if overflow occurs. */
-/* Note: the constraints in the asm statement didn't always work properly
-   with gcc 2.5.8.  Changing from using edi to using ecx got around the
-   problem, but keep fingers crossed! */
-static inline void add_two_Xsig(Xsig *dest, const Xsig *x2, long int *exp)
-{
-	asm volatile ("movl %2,%%ecx; movl %3,%%esi;\n"
-		      "movl (%%esi),%%eax; addl %%eax,(%%ecx);\n"
-		      "movl 4(%%esi),%%eax; adcl %%eax,4(%%ecx);\n"
-		      "movl 8(%%esi),%%eax; adcl %%eax,8(%%ecx);\n"
-		      "jnc 0f;\n"
-		      "rcrl 8(%%ecx); rcrl 4(%%ecx); rcrl (%%ecx)\n"
-		      "movl %4,%%ecx; incl (%%ecx)\n"
-		      "movl $1,%%eax; jmp 1f;\n"
-		      "0: xorl %%eax,%%eax;\n" "1:\n":"=g" (*exp), "=g"(*dest)
-		      :"g"(dest), "g"(x2), "g"(exp)
-		      :"cx", "si", "ax");
-}
-
-/* Negate (subtract from 1.0) the 12 byte Xsig */
-/* This is faster in a loop on my 386 than using the "neg" instruction. */
-static inline void negate_Xsig(Xsig *x)
-{
-	asm volatile ("movl %1,%%esi;\n"
-		      "xorl %%ecx,%%ecx;\n"
-		      "movl %%ecx,%%eax; subl (%%esi),%%eax; movl %%eax,(%%esi);\n"
-		      "movl %%ecx,%%eax; sbbl 4(%%esi),%%eax; movl %%eax,4(%%esi);\n"
-		      "movl %%ecx,%%eax; sbbl 8(%%esi),%%eax; movl %%eax,8(%%esi);\n":"=g"
-		      (*x):"g"(x):"si", "ax", "cx");
-}
-
-#endif /* _POLY_H */
diff -rupN a/arch/x86/math-emu/poly_l2.c b/arch/x86/math-emu/poly_l2.c
--- a/arch/x86/math-emu/poly_l2.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/poly_l2.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,245 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  poly_l2.c                                                                |
- |                                                                           |
- | Compute the base 2 log of a FPU_REG, using a polynomial approximation.    |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997                                         |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "reg_constant.h"
-#include "fpu_emu.h"
-#include "fpu_system.h"
-#include "control_w.h"
-#include "poly.h"
-
-static void log2_kernel(FPU_REG const *arg, u_char argsign,
-			Xsig * accum_result, long int *expon);
-
-/*--- poly_l2() -------------------------------------------------------------+
- |   Base 2 logarithm by a polynomial approximation.                         |
- +---------------------------------------------------------------------------*/
-void poly_l2(FPU_REG *st0_ptr, FPU_REG *st1_ptr, u_char st1_sign)
-{
-	long int exponent, expon, expon_expon;
-	Xsig accumulator, expon_accum, yaccum;
-	u_char sign, argsign;
-	FPU_REG x;
-	int tag;
-
-	exponent = exponent16(st0_ptr);
-
-	/* From st0_ptr, make a number > sqrt(2)/2 and < sqrt(2) */
-	if (st0_ptr->sigh > (unsigned)0xb504f334) {
-		/* Treat as  sqrt(2)/2 < st0_ptr < 1 */
-		significand(&x) = -significand(st0_ptr);
-		setexponent16(&x, -1);
-		exponent++;
-		argsign = SIGN_NEG;
-	} else {
-		/* Treat as  1 <= st0_ptr < sqrt(2) */
-		x.sigh = st0_ptr->sigh - 0x80000000;
-		x.sigl = st0_ptr->sigl;
-		setexponent16(&x, 0);
-		argsign = SIGN_POS;
-	}
-	tag = FPU_normalize_nuo(&x);
-
-	if (tag == TAG_Zero) {
-		expon = 0;
-		accumulator.msw = accumulator.midw = accumulator.lsw = 0;
-	} else {
-		log2_kernel(&x, argsign, &accumulator, &expon);
-	}
-
-	if (exponent < 0) {
-		sign = SIGN_NEG;
-		exponent = -exponent;
-	} else
-		sign = SIGN_POS;
-	expon_accum.msw = exponent;
-	expon_accum.midw = expon_accum.lsw = 0;
-	if (exponent) {
-		expon_expon = 31 + norm_Xsig(&expon_accum);
-		shr_Xsig(&accumulator, expon_expon - expon);
-
-		if (sign ^ argsign)
-			negate_Xsig(&accumulator);
-		add_Xsig_Xsig(&accumulator, &expon_accum);
-	} else {
-		expon_expon = expon;
-		sign = argsign;
-	}
-
-	yaccum.lsw = 0;
-	XSIG_LL(yaccum) = significand(st1_ptr);
-	mul_Xsig_Xsig(&accumulator, &yaccum);
-
-	expon_expon += round_Xsig(&accumulator);
-
-	if (accumulator.msw == 0) {
-		FPU_copy_to_reg1(&CONST_Z, TAG_Zero);
-		return;
-	}
-
-	significand(st1_ptr) = XSIG_LL(accumulator);
-	setexponent16(st1_ptr, expon_expon + exponent16(st1_ptr) + 1);
-
-	tag = FPU_round(st1_ptr, 1, 0, FULL_PRECISION, sign ^ st1_sign);
-	FPU_settagi(1, tag);
-
-	set_precision_flag_up();	/* 80486 appears to always do this */
-
-	return;
-
-}
-
-/*--- poly_l2p1() -----------------------------------------------------------+
- |   Base 2 logarithm by a polynomial approximation.                         |
- |   log2(x+1)                                                               |
- +---------------------------------------------------------------------------*/
-int poly_l2p1(u_char sign0, u_char sign1,
-	      FPU_REG * st0_ptr, FPU_REG * st1_ptr, FPU_REG * dest)
-{
-	u_char tag;
-	long int exponent;
-	Xsig accumulator, yaccum;
-
-	if (exponent16(st0_ptr) < 0) {
-		log2_kernel(st0_ptr, sign0, &accumulator, &exponent);
-
-		yaccum.lsw = 0;
-		XSIG_LL(yaccum) = significand(st1_ptr);
-		mul_Xsig_Xsig(&accumulator, &yaccum);
-
-		exponent += round_Xsig(&accumulator);
-
-		exponent += exponent16(st1_ptr) + 1;
-		if (exponent < EXP_WAY_UNDER)
-			exponent = EXP_WAY_UNDER;
-
-		significand(dest) = XSIG_LL(accumulator);
-		setexponent16(dest, exponent);
-
-		tag = FPU_round(dest, 1, 0, FULL_PRECISION, sign0 ^ sign1);
-		FPU_settagi(1, tag);
-
-		if (tag == TAG_Valid)
-			set_precision_flag_up();	/* 80486 appears to always do this */
-	} else {
-		/* The magnitude of st0_ptr is far too large. */
-
-		if (sign0 != SIGN_POS) {
-			/* Trying to get the log of a negative number. */
-#ifdef PECULIAR_486		/* Stupid 80486 doesn't worry about log(negative). */
-			changesign(st1_ptr);
-#else
-			if (arith_invalid(1) < 0)
-				return 1;
-#endif /* PECULIAR_486 */
-		}
-
-		/* 80486 appears to do this */
-		if (sign0 == SIGN_NEG)
-			set_precision_flag_down();
-		else
-			set_precision_flag_up();
-	}
-
-	if (exponent(dest) <= EXP_UNDER)
-		EXCEPTION(EX_Underflow);
-
-	return 0;
-
-}
-
-#undef HIPOWER
-#define	HIPOWER	10
-static const unsigned long long logterms[HIPOWER] = {
-	0x2a8eca5705fc2ef0LL,
-	0xf6384ee1d01febceLL,
-	0x093bb62877cdf642LL,
-	0x006985d8a9ec439bLL,
-	0x0005212c4f55a9c8LL,
-	0x00004326a16927f0LL,
-	0x0000038d1d80a0e7LL,
-	0x0000003141cc80c6LL,
-	0x00000002b1668c9fLL,
-	0x000000002c7a46aaLL
-};
-
-static const unsigned long leadterm = 0xb8000000;
-
-/*--- log2_kernel() ---------------------------------------------------------+
- |   Base 2 logarithm by a polynomial approximation.                         |
- |   log2(x+1)                                                               |
- +---------------------------------------------------------------------------*/
-static void log2_kernel(FPU_REG const *arg, u_char argsign, Xsig *accum_result,
-			long int *expon)
-{
-	long int exponent, adj;
-	unsigned long long Xsq;
-	Xsig accumulator, Numer, Denom, argSignif, arg_signif;
-
-	exponent = exponent16(arg);
-	Numer.lsw = Denom.lsw = 0;
-	XSIG_LL(Numer) = XSIG_LL(Denom) = significand(arg);
-	if (argsign == SIGN_POS) {
-		shr_Xsig(&Denom, 2 - (1 + exponent));
-		Denom.msw |= 0x80000000;
-		div_Xsig(&Numer, &Denom, &argSignif);
-	} else {
-		shr_Xsig(&Denom, 1 - (1 + exponent));
-		negate_Xsig(&Denom);
-		if (Denom.msw & 0x80000000) {
-			div_Xsig(&Numer, &Denom, &argSignif);
-			exponent++;
-		} else {
-			/* Denom must be 1.0 */
-			argSignif.lsw = Numer.lsw;
-			argSignif.midw = Numer.midw;
-			argSignif.msw = Numer.msw;
-		}
-	}
-
-#ifndef PECULIAR_486
-	/* Should check here that  |local_arg|  is within the valid range */
-	if (exponent >= -2) {
-		if ((exponent > -2) || (argSignif.msw > (unsigned)0xafb0ccc0)) {
-			/* The argument is too large */
-		}
-	}
-#endif /* PECULIAR_486 */
-
-	arg_signif.lsw = argSignif.lsw;
-	XSIG_LL(arg_signif) = XSIG_LL(argSignif);
-	adj = norm_Xsig(&argSignif);
-	accumulator.lsw = argSignif.lsw;
-	XSIG_LL(accumulator) = XSIG_LL(argSignif);
-	mul_Xsig_Xsig(&accumulator, &accumulator);
-	shr_Xsig(&accumulator, 2 * (-1 - (1 + exponent + adj)));
-	Xsq = XSIG_LL(accumulator);
-	if (accumulator.lsw & 0x80000000)
-		Xsq++;
-
-	accumulator.msw = accumulator.midw = accumulator.lsw = 0;
-	/* Do the basic fixed point polynomial evaluation */
-	polynomial_Xsig(&accumulator, &Xsq, logterms, HIPOWER - 1);
-
-	mul_Xsig_Xsig(&accumulator, &argSignif);
-	shr_Xsig(&accumulator, 6 - adj);
-
-	mul32_Xsig(&arg_signif, leadterm);
-	add_two_Xsig(&accumulator, &arg_signif, &exponent);
-
-	*expon = exponent + 1;
-	accum_result->lsw = accumulator.lsw;
-	accum_result->midw = accumulator.midw;
-	accum_result->msw = accumulator.msw;
-
-}
diff -rupN a/arch/x86/math-emu/polynom_Xsig.S b/arch/x86/math-emu/polynom_Xsig.S
--- a/arch/x86/math-emu/polynom_Xsig.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/polynom_Xsig.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,137 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  polynomial_Xsig.S                                                        |
- |                                                                           |
- | Fixed point arithmetic polynomial evaluation.                             |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1995                                         |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@jacobi.maths.monash.edu.au |
- |                                                                           |
- | Call from C as:                                                           |
- |   void polynomial_Xsig(Xsig *accum, unsigned long long x,                 |
- |                        unsigned long long terms[], int n)                 |
- |                                                                           |
- | Computes:                                                                 |
- | terms[0] + (terms[1] + (terms[2] + ... + (terms[n-1]*x)*x)*x)*x) ... )*x  |
- | and adds the result to the 12 byte Xsig.                                  |
- | The terms[] are each 8 bytes, but all computation is performed to 12 byte |
- | precision.                                                                |
- |                                                                           |
- | This function must be used carefully: most overflow of intermediate       |
- | results is controlled, but overflow of the result is not.                 |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-	.file	"polynomial_Xsig.S"
-
-#include "fpu_emu.h"
-
-
-#define	TERM_SIZE	$8
-#define	SUM_MS		-20(%ebp)	/* sum ms long */
-#define SUM_MIDDLE	-24(%ebp)	/* sum middle long */
-#define	SUM_LS		-28(%ebp)	/* sum ls long */
-#define	ACCUM_MS	-4(%ebp)	/* accum ms long */
-#define	ACCUM_MIDDLE	-8(%ebp)	/* accum middle long */
-#define	ACCUM_LS	-12(%ebp)	/* accum ls long */
-#define OVERFLOWED      -16(%ebp)	/* addition overflow flag */
-
-.text
-SYM_FUNC_START(polynomial_Xsig)
-	pushl	%ebp
-	movl	%esp,%ebp
-	subl	$32,%esp
-	pushl	%esi
-	pushl	%edi
-	pushl	%ebx
-
-	movl	PARAM2,%esi		/* x */
-	movl	PARAM3,%edi		/* terms */
-
-	movl	TERM_SIZE,%eax
-	mull	PARAM4			/* n */
-	addl	%eax,%edi
-
-	movl	4(%edi),%edx		/* terms[n] */
-	movl	%edx,SUM_MS
-	movl	(%edi),%edx		/* terms[n] */
-	movl	%edx,SUM_MIDDLE
-	xor	%eax,%eax
-	movl	%eax,SUM_LS
-	movb	%al,OVERFLOWED
-
-	subl	TERM_SIZE,%edi
-	decl	PARAM4
-	js	L_accum_done
-
-L_accum_loop:
-	xor	%eax,%eax
-	movl	%eax,ACCUM_MS
-	movl	%eax,ACCUM_MIDDLE
-
-	movl	SUM_MIDDLE,%eax
-	mull	(%esi)			/* x ls long */
-	movl	%edx,ACCUM_LS
-
-	movl	SUM_MIDDLE,%eax
-	mull	4(%esi)			/* x ms long */
-	addl	%eax,ACCUM_LS
-	adcl	%edx,ACCUM_MIDDLE
-	adcl	$0,ACCUM_MS
-
-	movl	SUM_MS,%eax
-	mull	(%esi)			/* x ls long */
-	addl	%eax,ACCUM_LS
-	adcl	%edx,ACCUM_MIDDLE
-	adcl	$0,ACCUM_MS
-
-	movl	SUM_MS,%eax
-	mull	4(%esi)			/* x ms long */
-	addl	%eax,ACCUM_MIDDLE
-	adcl	%edx,ACCUM_MS
-
-	testb	$0xff,OVERFLOWED
-	jz	L_no_overflow
-
-	movl	(%esi),%eax
-	addl	%eax,ACCUM_MIDDLE
-	movl	4(%esi),%eax
-	adcl	%eax,ACCUM_MS		/* This could overflow too */
-
-L_no_overflow:
-
-/*
- * Now put the sum of next term and the accumulator
- * into the sum register
- */
-	movl	ACCUM_LS,%eax
-	addl	(%edi),%eax		/* term ls long */
-	movl	%eax,SUM_LS
-	movl	ACCUM_MIDDLE,%eax
-	adcl	(%edi),%eax		/* term ls long */
-	movl	%eax,SUM_MIDDLE
-	movl	ACCUM_MS,%eax
-	adcl	4(%edi),%eax		/* term ms long */
-	movl	%eax,SUM_MS
-	sbbb	%al,%al
-	movb	%al,OVERFLOWED		/* Used in the next iteration */
-
-	subl	TERM_SIZE,%edi
-	decl	PARAM4
-	jns	L_accum_loop
-
-L_accum_done:
-	movl	PARAM1,%edi		/* accum */
-	movl	SUM_LS,%eax
-	addl	%eax,(%edi)
-	movl	SUM_MIDDLE,%eax
-	adcl	%eax,4(%edi)
-	movl	SUM_MS,%eax
-	adcl	%eax,8(%edi)
-
-	popl	%ebx
-	popl	%edi
-	popl	%esi
-	leave
-	RET
-SYM_FUNC_END(polynomial_Xsig)
diff -rupN a/arch/x86/math-emu/poly_sin.c b/arch/x86/math-emu/poly_sin.c
--- a/arch/x86/math-emu/poly_sin.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/poly_sin.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,379 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  poly_sin.c                                                               |
- |                                                                           |
- |  Computation of an approximation of the sin function and the cosine       |
- |  function by a polynomial.                                                |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997,1999                                    |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@melbpc.org.au                             |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "reg_constant.h"
-#include "fpu_emu.h"
-#include "fpu_system.h"
-#include "control_w.h"
-#include "poly.h"
-
-#define	N_COEFF_P	4
-#define	N_COEFF_N	4
-
-static const unsigned long long pos_terms_l[N_COEFF_P] = {
-	0xaaaaaaaaaaaaaaabLL,
-	0x00d00d00d00cf906LL,
-	0x000006b99159a8bbLL,
-	0x000000000d7392e6LL
-};
-
-static const unsigned long long neg_terms_l[N_COEFF_N] = {
-	0x2222222222222167LL,
-	0x0002e3bc74aab624LL,
-	0x0000000b09229062LL,
-	0x00000000000c7973LL
-};
-
-#define	N_COEFF_PH	4
-#define	N_COEFF_NH	4
-static const unsigned long long pos_terms_h[N_COEFF_PH] = {
-	0x0000000000000000LL,
-	0x05b05b05b05b0406LL,
-	0x000049f93edd91a9LL,
-	0x00000000c9c9ed62LL
-};
-
-static const unsigned long long neg_terms_h[N_COEFF_NH] = {
-	0xaaaaaaaaaaaaaa98LL,
-	0x001a01a01a019064LL,
-	0x0000008f76c68a77LL,
-	0x0000000000d58f5eLL
-};
-
-/*--- poly_sine() -----------------------------------------------------------+
- |                                                                           |
- +---------------------------------------------------------------------------*/
-void poly_sine(FPU_REG *st0_ptr)
-{
-	int exponent, echange;
-	Xsig accumulator, argSqrd, argTo4;
-	unsigned long fix_up, adj;
-	unsigned long long fixed_arg;
-	FPU_REG result;
-
-	exponent = exponent(st0_ptr);
-
-	accumulator.lsw = accumulator.midw = accumulator.msw = 0;
-
-	/* Split into two ranges, for arguments below and above 1.0 */
-	/* The boundary between upper and lower is approx 0.88309101259 */
-	if ((exponent < -1)
-	    || ((exponent == -1) && (st0_ptr->sigh <= 0xe21240aa))) {
-		/* The argument is <= 0.88309101259 */
-
-		argSqrd.msw = st0_ptr->sigh;
-		argSqrd.midw = st0_ptr->sigl;
-		argSqrd.lsw = 0;
-		mul64_Xsig(&argSqrd, &significand(st0_ptr));
-		shr_Xsig(&argSqrd, 2 * (-1 - exponent));
-		argTo4.msw = argSqrd.msw;
-		argTo4.midw = argSqrd.midw;
-		argTo4.lsw = argSqrd.lsw;
-		mul_Xsig_Xsig(&argTo4, &argTo4);
-
-		polynomial_Xsig(&accumulator, &XSIG_LL(argTo4), neg_terms_l,
-				N_COEFF_N - 1);
-		mul_Xsig_Xsig(&accumulator, &argSqrd);
-		negate_Xsig(&accumulator);
-
-		polynomial_Xsig(&accumulator, &XSIG_LL(argTo4), pos_terms_l,
-				N_COEFF_P - 1);
-
-		shr_Xsig(&accumulator, 2);	/* Divide by four */
-		accumulator.msw |= 0x80000000;	/* Add 1.0 */
-
-		mul64_Xsig(&accumulator, &significand(st0_ptr));
-		mul64_Xsig(&accumulator, &significand(st0_ptr));
-		mul64_Xsig(&accumulator, &significand(st0_ptr));
-
-		/* Divide by four, FPU_REG compatible, etc */
-		exponent = 3 * exponent;
-
-		/* The minimum exponent difference is 3 */
-		shr_Xsig(&accumulator, exponent(st0_ptr) - exponent);
-
-		negate_Xsig(&accumulator);
-		XSIG_LL(accumulator) += significand(st0_ptr);
-
-		echange = round_Xsig(&accumulator);
-
-		setexponentpos(&result, exponent(st0_ptr) + echange);
-	} else {
-		/* The argument is > 0.88309101259 */
-		/* We use sin(st(0)) = cos(pi/2-st(0)) */
-
-		fixed_arg = significand(st0_ptr);
-
-		if (exponent == 0) {
-			/* The argument is >= 1.0 */
-
-			/* Put the binary point at the left. */
-			fixed_arg <<= 1;
-		}
-		/* pi/2 in hex is: 1.921fb54442d18469 898CC51701B839A2 52049C1 */
-		fixed_arg = 0x921fb54442d18469LL - fixed_arg;
-		/* There is a special case which arises due to rounding, to fix here. */
-		if (fixed_arg == 0xffffffffffffffffLL)
-			fixed_arg = 0;
-
-		XSIG_LL(argSqrd) = fixed_arg;
-		argSqrd.lsw = 0;
-		mul64_Xsig(&argSqrd, &fixed_arg);
-
-		XSIG_LL(argTo4) = XSIG_LL(argSqrd);
-		argTo4.lsw = argSqrd.lsw;
-		mul_Xsig_Xsig(&argTo4, &argTo4);
-
-		polynomial_Xsig(&accumulator, &XSIG_LL(argTo4), neg_terms_h,
-				N_COEFF_NH - 1);
-		mul_Xsig_Xsig(&accumulator, &argSqrd);
-		negate_Xsig(&accumulator);
-
-		polynomial_Xsig(&accumulator, &XSIG_LL(argTo4), pos_terms_h,
-				N_COEFF_PH - 1);
-		negate_Xsig(&accumulator);
-
-		mul64_Xsig(&accumulator, &fixed_arg);
-		mul64_Xsig(&accumulator, &fixed_arg);
-
-		shr_Xsig(&accumulator, 3);
-		negate_Xsig(&accumulator);
-
-		add_Xsig_Xsig(&accumulator, &argSqrd);
-
-		shr_Xsig(&accumulator, 1);
-
-		accumulator.lsw |= 1;	/* A zero accumulator here would cause problems */
-		negate_Xsig(&accumulator);
-
-		/* The basic computation is complete. Now fix the answer to
-		   compensate for the error due to the approximation used for
-		   pi/2
-		 */
-
-		/* This has an exponent of -65 */
-		fix_up = 0x898cc517;
-		/* The fix-up needs to be improved for larger args */
-		if (argSqrd.msw & 0xffc00000) {
-			/* Get about 32 bit precision in these: */
-			fix_up -= mul_32_32(0x898cc517, argSqrd.msw) / 6;
-		}
-		fix_up = mul_32_32(fix_up, LL_MSW(fixed_arg));
-
-		adj = accumulator.lsw;	/* temp save */
-		accumulator.lsw -= fix_up;
-		if (accumulator.lsw > adj)
-			XSIG_LL(accumulator)--;
-
-		echange = round_Xsig(&accumulator);
-
-		setexponentpos(&result, echange - 1);
-	}
-
-	significand(&result) = XSIG_LL(accumulator);
-	setsign(&result, getsign(st0_ptr));
-	FPU_copy_to_reg0(&result, TAG_Valid);
-
-#ifdef PARANOID
-	if ((exponent(&result) >= 0)
-	    && (significand(&result) > 0x8000000000000000LL)) {
-		EXCEPTION(EX_INTERNAL | 0x150);
-	}
-#endif /* PARANOID */
-
-}
-
-/*--- poly_cos() ------------------------------------------------------------+
- |                                                                           |
- +---------------------------------------------------------------------------*/
-void poly_cos(FPU_REG *st0_ptr)
-{
-	FPU_REG result;
-	long int exponent, exp2, echange;
-	Xsig accumulator, argSqrd, fix_up, argTo4;
-	unsigned long long fixed_arg;
-
-#ifdef PARANOID
-	if ((exponent(st0_ptr) > 0)
-	    || ((exponent(st0_ptr) == 0)
-		&& (significand(st0_ptr) > 0xc90fdaa22168c234LL))) {
-		EXCEPTION(EX_Invalid);
-		FPU_copy_to_reg0(&CONST_QNaN, TAG_Special);
-		return;
-	}
-#endif /* PARANOID */
-
-	exponent = exponent(st0_ptr);
-
-	accumulator.lsw = accumulator.midw = accumulator.msw = 0;
-
-	if ((exponent < -1)
-	    || ((exponent == -1) && (st0_ptr->sigh <= 0xb00d6f54))) {
-		/* arg is < 0.687705 */
-
-		argSqrd.msw = st0_ptr->sigh;
-		argSqrd.midw = st0_ptr->sigl;
-		argSqrd.lsw = 0;
-		mul64_Xsig(&argSqrd, &significand(st0_ptr));
-
-		if (exponent < -1) {
-			/* shift the argument right by the required places */
-			shr_Xsig(&argSqrd, 2 * (-1 - exponent));
-		}
-
-		argTo4.msw = argSqrd.msw;
-		argTo4.midw = argSqrd.midw;
-		argTo4.lsw = argSqrd.lsw;
-		mul_Xsig_Xsig(&argTo4, &argTo4);
-
-		polynomial_Xsig(&accumulator, &XSIG_LL(argTo4), neg_terms_h,
-				N_COEFF_NH - 1);
-		mul_Xsig_Xsig(&accumulator, &argSqrd);
-		negate_Xsig(&accumulator);
-
-		polynomial_Xsig(&accumulator, &XSIG_LL(argTo4), pos_terms_h,
-				N_COEFF_PH - 1);
-		negate_Xsig(&accumulator);
-
-		mul64_Xsig(&accumulator, &significand(st0_ptr));
-		mul64_Xsig(&accumulator, &significand(st0_ptr));
-		shr_Xsig(&accumulator, -2 * (1 + exponent));
-
-		shr_Xsig(&accumulator, 3);
-		negate_Xsig(&accumulator);
-
-		add_Xsig_Xsig(&accumulator, &argSqrd);
-
-		shr_Xsig(&accumulator, 1);
-
-		/* It doesn't matter if accumulator is all zero here, the
-		   following code will work ok */
-		negate_Xsig(&accumulator);
-
-		if (accumulator.lsw & 0x80000000)
-			XSIG_LL(accumulator)++;
-		if (accumulator.msw == 0) {
-			/* The result is 1.0 */
-			FPU_copy_to_reg0(&CONST_1, TAG_Valid);
-			return;
-		} else {
-			significand(&result) = XSIG_LL(accumulator);
-
-			/* will be a valid positive nr with expon = -1 */
-			setexponentpos(&result, -1);
-		}
-	} else {
-		fixed_arg = significand(st0_ptr);
-
-		if (exponent == 0) {
-			/* The argument is >= 1.0 */
-
-			/* Put the binary point at the left. */
-			fixed_arg <<= 1;
-		}
-		/* pi/2 in hex is: 1.921fb54442d18469 898CC51701B839A2 52049C1 */
-		fixed_arg = 0x921fb54442d18469LL - fixed_arg;
-		/* There is a special case which arises due to rounding, to fix here. */
-		if (fixed_arg == 0xffffffffffffffffLL)
-			fixed_arg = 0;
-
-		exponent = -1;
-		exp2 = -1;
-
-		/* A shift is needed here only for a narrow range of arguments,
-		   i.e. for fixed_arg approx 2^-32, but we pick up more... */
-		if (!(LL_MSW(fixed_arg) & 0xffff0000)) {
-			fixed_arg <<= 16;
-			exponent -= 16;
-			exp2 -= 16;
-		}
-
-		XSIG_LL(argSqrd) = fixed_arg;
-		argSqrd.lsw = 0;
-		mul64_Xsig(&argSqrd, &fixed_arg);
-
-		if (exponent < -1) {
-			/* shift the argument right by the required places */
-			shr_Xsig(&argSqrd, 2 * (-1 - exponent));
-		}
-
-		argTo4.msw = argSqrd.msw;
-		argTo4.midw = argSqrd.midw;
-		argTo4.lsw = argSqrd.lsw;
-		mul_Xsig_Xsig(&argTo4, &argTo4);
-
-		polynomial_Xsig(&accumulator, &XSIG_LL(argTo4), neg_terms_l,
-				N_COEFF_N - 1);
-		mul_Xsig_Xsig(&accumulator, &argSqrd);
-		negate_Xsig(&accumulator);
-
-		polynomial_Xsig(&accumulator, &XSIG_LL(argTo4), pos_terms_l,
-				N_COEFF_P - 1);
-
-		shr_Xsig(&accumulator, 2);	/* Divide by four */
-		accumulator.msw |= 0x80000000;	/* Add 1.0 */
-
-		mul64_Xsig(&accumulator, &fixed_arg);
-		mul64_Xsig(&accumulator, &fixed_arg);
-		mul64_Xsig(&accumulator, &fixed_arg);
-
-		/* Divide by four, FPU_REG compatible, etc */
-		exponent = 3 * exponent;
-
-		/* The minimum exponent difference is 3 */
-		shr_Xsig(&accumulator, exp2 - exponent);
-
-		negate_Xsig(&accumulator);
-		XSIG_LL(accumulator) += fixed_arg;
-
-		/* The basic computation is complete. Now fix the answer to
-		   compensate for the error due to the approximation used for
-		   pi/2
-		 */
-
-		/* This has an exponent of -65 */
-		XSIG_LL(fix_up) = 0x898cc51701b839a2ll;
-		fix_up.lsw = 0;
-
-		/* The fix-up needs to be improved for larger args */
-		if (argSqrd.msw & 0xffc00000) {
-			/* Get about 32 bit precision in these: */
-			fix_up.msw -= mul_32_32(0x898cc517, argSqrd.msw) / 2;
-			fix_up.msw += mul_32_32(0x898cc517, argTo4.msw) / 24;
-		}
-
-		exp2 += norm_Xsig(&accumulator);
-		shr_Xsig(&accumulator, 1);	/* Prevent overflow */
-		exp2++;
-		shr_Xsig(&fix_up, 65 + exp2);
-
-		add_Xsig_Xsig(&accumulator, &fix_up);
-
-		echange = round_Xsig(&accumulator);
-
-		setexponentpos(&result, exp2 + echange);
-		significand(&result) = XSIG_LL(accumulator);
-	}
-
-	FPU_copy_to_reg0(&result, TAG_Valid);
-
-#ifdef PARANOID
-	if ((exponent(&result) >= 0)
-	    && (significand(&result) > 0x8000000000000000LL)) {
-		EXCEPTION(EX_INTERNAL | 0x151);
-	}
-#endif /* PARANOID */
-
-}
diff -rupN a/arch/x86/math-emu/poly_tan.c b/arch/x86/math-emu/poly_tan.c
--- a/arch/x86/math-emu/poly_tan.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/poly_tan.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,213 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  poly_tan.c                                                               |
- |                                                                           |
- | Compute the tan of a FPU_REG, using a polynomial approximation.           |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997,1999                                    |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@melbpc.org.au            |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "reg_constant.h"
-#include "fpu_emu.h"
-#include "fpu_system.h"
-#include "control_w.h"
-#include "poly.h"
-
-#define	HiPOWERop	3	/* odd poly, positive terms */
-static const unsigned long long oddplterm[HiPOWERop] = {
-	0x0000000000000000LL,
-	0x0051a1cf08fca228LL,
-	0x0000000071284ff7LL
-};
-
-#define	HiPOWERon	2	/* odd poly, negative terms */
-static const unsigned long long oddnegterm[HiPOWERon] = {
-	0x1291a9a184244e80LL,
-	0x0000583245819c21LL
-};
-
-#define	HiPOWERep	2	/* even poly, positive terms */
-static const unsigned long long evenplterm[HiPOWERep] = {
-	0x0e848884b539e888LL,
-	0x00003c7f18b887daLL
-};
-
-#define	HiPOWERen	2	/* even poly, negative terms */
-static const unsigned long long evennegterm[HiPOWERen] = {
-	0xf1f0200fd51569ccLL,
-	0x003afb46105c4432LL
-};
-
-static const unsigned long long twothirds = 0xaaaaaaaaaaaaaaabLL;
-
-/*--- poly_tan() ------------------------------------------------------------+
- |                                                                           |
- +---------------------------------------------------------------------------*/
-void poly_tan(FPU_REG *st0_ptr)
-{
-	long int exponent;
-	int invert;
-	Xsig argSq, argSqSq, accumulatoro, accumulatore, accum,
-	    argSignif, fix_up;
-	unsigned long adj;
-
-	exponent = exponent(st0_ptr);
-
-#ifdef PARANOID
-	if (signnegative(st0_ptr)) {	/* Can't hack a number < 0.0 */
-		arith_invalid(0);
-		return;
-	}			/* Need a positive number */
-#endif /* PARANOID */
-
-	/* Split the problem into two domains, smaller and larger than pi/4 */
-	if ((exponent == 0)
-	    || ((exponent == -1) && (st0_ptr->sigh > 0xc90fdaa2))) {
-		/* The argument is greater than (approx) pi/4 */
-		invert = 1;
-		accum.lsw = 0;
-		XSIG_LL(accum) = significand(st0_ptr);
-
-		if (exponent == 0) {
-			/* The argument is >= 1.0 */
-			/* Put the binary point at the left. */
-			XSIG_LL(accum) <<= 1;
-		}
-		/* pi/2 in hex is: 1.921fb54442d18469 898CC51701B839A2 52049C1 */
-		XSIG_LL(accum) = 0x921fb54442d18469LL - XSIG_LL(accum);
-		/* This is a special case which arises due to rounding. */
-		if (XSIG_LL(accum) == 0xffffffffffffffffLL) {
-			FPU_settag0(TAG_Valid);
-			significand(st0_ptr) = 0x8a51e04daabda360LL;
-			setexponent16(st0_ptr,
-				      (0x41 + EXTENDED_Ebias) | SIGN_Negative);
-			return;
-		}
-
-		argSignif.lsw = accum.lsw;
-		XSIG_LL(argSignif) = XSIG_LL(accum);
-		exponent = -1 + norm_Xsig(&argSignif);
-	} else {
-		invert = 0;
-		argSignif.lsw = 0;
-		XSIG_LL(accum) = XSIG_LL(argSignif) = significand(st0_ptr);
-
-		if (exponent < -1) {
-			/* shift the argument right by the required places */
-			if (FPU_shrx(&XSIG_LL(accum), -1 - exponent) >=
-			    0x80000000U)
-				XSIG_LL(accum)++;	/* round up */
-		}
-	}
-
-	XSIG_LL(argSq) = XSIG_LL(accum);
-	argSq.lsw = accum.lsw;
-	mul_Xsig_Xsig(&argSq, &argSq);
-	XSIG_LL(argSqSq) = XSIG_LL(argSq);
-	argSqSq.lsw = argSq.lsw;
-	mul_Xsig_Xsig(&argSqSq, &argSqSq);
-
-	/* Compute the negative terms for the numerator polynomial */
-	accumulatoro.msw = accumulatoro.midw = accumulatoro.lsw = 0;
-	polynomial_Xsig(&accumulatoro, &XSIG_LL(argSqSq), oddnegterm,
-			HiPOWERon - 1);
-	mul_Xsig_Xsig(&accumulatoro, &argSq);
-	negate_Xsig(&accumulatoro);
-	/* Add the positive terms */
-	polynomial_Xsig(&accumulatoro, &XSIG_LL(argSqSq), oddplterm,
-			HiPOWERop - 1);
-
-	/* Compute the positive terms for the denominator polynomial */
-	accumulatore.msw = accumulatore.midw = accumulatore.lsw = 0;
-	polynomial_Xsig(&accumulatore, &XSIG_LL(argSqSq), evenplterm,
-			HiPOWERep - 1);
-	mul_Xsig_Xsig(&accumulatore, &argSq);
-	negate_Xsig(&accumulatore);
-	/* Add the negative terms */
-	polynomial_Xsig(&accumulatore, &XSIG_LL(argSqSq), evennegterm,
-			HiPOWERen - 1);
-	/* Multiply by arg^2 */
-	mul64_Xsig(&accumulatore, &XSIG_LL(argSignif));
-	mul64_Xsig(&accumulatore, &XSIG_LL(argSignif));
-	/* de-normalize and divide by 2 */
-	shr_Xsig(&accumulatore, -2 * (1 + exponent) + 1);
-	negate_Xsig(&accumulatore);	/* This does 1 - accumulator */
-
-	/* Now find the ratio. */
-	if (accumulatore.msw == 0) {
-		/* accumulatoro must contain 1.0 here, (actually, 0) but it
-		   really doesn't matter what value we use because it will
-		   have negligible effect in later calculations
-		 */
-		XSIG_LL(accum) = 0x8000000000000000LL;
-		accum.lsw = 0;
-	} else {
-		div_Xsig(&accumulatoro, &accumulatore, &accum);
-	}
-
-	/* Multiply by 1/3 * arg^3 */
-	mul64_Xsig(&accum, &XSIG_LL(argSignif));
-	mul64_Xsig(&accum, &XSIG_LL(argSignif));
-	mul64_Xsig(&accum, &XSIG_LL(argSignif));
-	mul64_Xsig(&accum, &twothirds);
-	shr_Xsig(&accum, -2 * (exponent + 1));
-
-	/* tan(arg) = arg + accum */
-	add_two_Xsig(&accum, &argSignif, &exponent);
-
-	if (invert) {
-		/* We now have the value of tan(pi_2 - arg) where pi_2 is an
-		   approximation for pi/2
-		 */
-		/* The next step is to fix the answer to compensate for the
-		   error due to the approximation used for pi/2
-		 */
-
-		/* This is (approx) delta, the error in our approx for pi/2
-		   (see above). It has an exponent of -65
-		 */
-		XSIG_LL(fix_up) = 0x898cc51701b839a2LL;
-		fix_up.lsw = 0;
-
-		if (exponent == 0)
-			adj = 0xffffffff;	/* We want approx 1.0 here, but
-						   this is close enough. */
-		else if (exponent > -30) {
-			adj = accum.msw >> -(exponent + 1);	/* tan */
-			adj = mul_32_32(adj, adj);	/* tan^2 */
-		} else
-			adj = 0;
-		adj = mul_32_32(0x898cc517, adj);	/* delta * tan^2 */
-
-		fix_up.msw += adj;
-		if (!(fix_up.msw & 0x80000000)) {	/* did fix_up overflow ? */
-			/* Yes, we need to add an msb */
-			shr_Xsig(&fix_up, 1);
-			fix_up.msw |= 0x80000000;
-			shr_Xsig(&fix_up, 64 + exponent);
-		} else
-			shr_Xsig(&fix_up, 65 + exponent);
-
-		add_two_Xsig(&accum, &fix_up, &exponent);
-
-		/* accum now contains tan(pi/2 - arg).
-		   Use tan(arg) = 1.0 / tan(pi/2 - arg)
-		 */
-		accumulatoro.lsw = accumulatoro.midw = 0;
-		accumulatoro.msw = 0x80000000;
-		div_Xsig(&accumulatoro, &accum, &accum);
-		exponent = -exponent - 1;
-	}
-
-	/* Transfer the result */
-	round_Xsig(&accum);
-	FPU_settag0(TAG_Valid);
-	significand(st0_ptr) = XSIG_LL(accum);
-	setexponent16(st0_ptr, exponent + EXTENDED_Ebias);	/* Result is positive. */
-
-}
diff -rupN a/arch/x86/math-emu/README b/arch/x86/math-emu/README
--- a/arch/x86/math-emu/README	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/README	1970-01-01 01:00:00.000000000 +0100
@@ -1,427 +0,0 @@
- +---------------------------------------------------------------------------+
- |  wm-FPU-emu   an FPU emulator for 80386 and 80486SX microprocessors.      |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1995,1996,1997,1999                          |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@melbpc.org.au              |
- |                                                                           |
- |    This program is free software; you can redistribute it and/or modify   |
- |    it under the terms of the GNU General Public License version 2 as      |
- |    published by the Free Software Foundation.                             |
- |                                                                           |
- |    This program is distributed in the hope that it will be useful,        |
- |    but WITHOUT ANY WARRANTY; without even the implied warranty of         |
- |    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the          |
- |    GNU General Public License for more details.                           |
- |                                                                           |
- |    You should have received a copy of the GNU General Public License      |
- |    along with this program; if not, write to the Free Software            |
- |    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.              |
- |                                                                           |
- +---------------------------------------------------------------------------+
-
-
-
-wm-FPU-emu is an FPU emulator for Linux. It is derived from wm-emu387
-which was my 80387 emulator for early versions of djgpp (gcc under
-msdos); wm-emu387 was in turn based upon emu387 which was written by
-DJ Delorie for djgpp.  The interface to the Linux kernel is based upon
-the original Linux math emulator by Linus Torvalds.
-
-My target FPU for wm-FPU-emu is that described in the Intel486
-Programmer's Reference Manual (1992 edition). Unfortunately, numerous
-facets of the functioning of the FPU are not well covered in the
-Reference Manual. The information in the manual has been supplemented
-with measurements on real 80486's. Unfortunately, it is simply not
-possible to be sure that all of the peculiarities of the 80486 have
-been discovered, so there is always likely to be obscure differences
-in the detailed behaviour of the emulator and a real 80486.
-
-wm-FPU-emu does not implement all of the behaviour of the 80486 FPU,
-but is very close.  See "Limitations" later in this file for a list of
-some differences.
-
-Please report bugs, etc to me at:
-       billm@melbpc.org.au
-or     b.metzenthen@medoto.unimelb.edu.au
-
-For more information on the emulator and on floating point topics, see
-my web pages, currently at  http://www.suburbia.net/~billm/
-
-
---Bill Metzenthen
-  December 1999
-
-
------------------------ Internals of wm-FPU-emu -----------------------
-
-Numeric algorithms:
-(1) Add, subtract, and multiply. Nothing remarkable in these.
-(2) Divide has been tuned to get reasonable performance. The algorithm
-    is not the obvious one which most people seem to use, but is designed
-    to take advantage of the characteristics of the 80386. I expect that
-    it has been invented many times before I discovered it, but I have not
-    seen it. It is based upon one of those ideas which one carries around
-    for years without ever bothering to check it out.
-(3) The sqrt function has been tuned to get good performance. It is based
-    upon Newton's classic method. Performance was improved by capitalizing
-    upon the properties of Newton's method, and the code is once again
-    structured taking account of the 80386 characteristics.
-(4) The trig, log, and exp functions are based in each case upon quasi-
-    "optimal" polynomial approximations. My definition of "optimal" was
-    based upon getting good accuracy with reasonable speed.
-(5) The argument reducing code for the trig function effectively uses
-    a value of pi which is accurate to more than 128 bits. As a consequence,
-    the reduced argument is accurate to more than 64 bits for arguments up
-    to a few pi, and accurate to more than 64 bits for most arguments,
-    even for arguments approaching 2^63. This is far superior to an
-    80486, which uses a value of pi which is accurate to 66 bits.
-
-The code of the emulator is complicated slightly by the need to
-account for a limited form of re-entrancy. Normally, the emulator will
-emulate each FPU instruction to completion without interruption.
-However, it may happen that when the emulator is accessing the user
-memory space, swapping may be needed. In this case the emulator may be
-temporarily suspended while disk i/o takes place. During this time
-another process may use the emulator, thereby perhaps changing static
-variables. The code which accesses user memory is confined to five
-files:
-    fpu_entry.c
-    reg_ld_str.c
-    load_store.c
-    get_address.c
-    errors.c
-As from version 1.12 of the emulator, no static variables are used
-(apart from those in the kernel's per-process tables). The emulator is
-therefore now fully re-entrant, rather than having just the restricted
-form of re-entrancy which is required by the Linux kernel.
-
------------------------ Limitations of wm-FPU-emu -----------------------
-
-There are a number of differences between the current wm-FPU-emu
-(version 2.01) and the 80486 FPU (apart from bugs).  The differences
-are fewer than those which applied to the 1.xx series of the emulator.
-Some of the more important differences are listed below:
-
-The Roundup flag does not have much meaning for the transcendental
-functions and its 80486 value with these functions is likely to differ
-from its emulator value.
-
-In a few rare cases the Underflow flag obtained with the emulator will
-be different from that obtained with an 80486. This occurs when the
-following conditions apply simultaneously:
-(a) the operands have a higher precision than the current setting of the
-    precision control (PC) flags.
-(b) the underflow exception is masked.
-(c) the magnitude of the exact result (before rounding) is less than 2^-16382.
-(d) the magnitude of the final result (after rounding) is exactly 2^-16382.
-(e) the magnitude of the exact result would be exactly 2^-16382 if the
-    operands were rounded to the current precision before the arithmetic
-    operation was performed.
-If all of these apply, the emulator will set the Underflow flag but a real
-80486 will not.
-
-NOTE: Certain formats of Extended Real are UNSUPPORTED. They are
-unsupported by the 80486. They are the Pseudo-NaNs, Pseudoinfinities,
-and Unnormals. None of these will be generated by an 80486 or by the
-emulator. Do not use them. The emulator treats them differently in
-detail from the way an 80486 does.
-
-Self modifying code can cause the emulator to fail. An example of such
-code is:
-          movl %esp,[%ebx]
-	  fld1
-The FPU instruction may be (usually will be) loaded into the pre-fetch
-queue of the CPU before the mov instruction is executed. If the
-destination of the 'movl' overlaps the FPU instruction then the bytes
-in the prefetch queue and memory will be inconsistent when the FPU
-instruction is executed. The emulator will be invoked but will not be
-able to find the instruction which caused the device-not-present
-exception. For this case, the emulator cannot emulate the behaviour of
-an 80486DX.
-
-Handling of the address size override prefix byte (0x67) has not been
-extensively tested yet. A major problem exists because using it in
-vm86 mode can cause a general protection fault. Address offsets
-greater than 0xffff appear to be illegal in vm86 mode but are quite
-acceptable (and work) in real mode. A small test program developed to
-check the addressing, and which runs successfully in real mode,
-crashes dosemu under Linux and also brings Windows down with a general
-protection fault message when run under the MS-DOS prompt of Windows
-3.1. (The program simply reads data from a valid address).
-
-The emulator supports 16-bit protected mode, with one difference from
-an 80486DX.  A 80486DX will allow some floating point instructions to
-write a few bytes below the lowest address of the stack.  The emulator
-will not allow this in 16-bit protected mode: no instructions are
-allowed to write outside the bounds set by the protection.
-
------------------------ Performance of wm-FPU-emu -----------------------
-
-Speed.
------
-
-The speed of floating point computation with the emulator will depend
-upon instruction mix. Relative performance is best for the instructions
-which require most computation. The simple instructions are adversely
-affected by the FPU instruction trap overhead.
-
-
-Timing: Some simple timing tests have been made on the emulator functions.
-The times include load/store instructions. All times are in microseconds
-measured on a 33MHz 386 with 64k cache. The Turbo C tests were under
-ms-dos, the next two columns are for emulators running with the djgpp
-ms-dos extender. The final column is for wm-FPU-emu in Linux 0.97,
-using libm4.0 (hard).
-
-function      Turbo C        djgpp 1.06        WM-emu387     wm-FPU-emu
-
-   +          60.5           154.8              76.5          139.4
-   -          61.1-65.5      157.3-160.8        76.2-79.5     142.9-144.7
-   *          71.0           190.8              79.6          146.6
-   /          61.2-75.0      261.4-266.9        75.3-91.6     142.2-158.1
-
- sin()        310.8          4692.0            319.0          398.5
- cos()        284.4          4855.2            308.0          388.7
- tan()        495.0          8807.1            394.9          504.7
- atan()       328.9          4866.4            601.1          419.5-491.9
-
- sqrt()       128.7          crashed           145.2          227.0
- log()        413.1-419.1    5103.4-5354.21    254.7-282.2    409.4-437.1
- exp()        479.1          6619.2            469.1          850.8
-
-
-The performance under Linux is improved by the use of look-ahead code.
-The following results show the improvement which is obtained under
-Linux due to the look-ahead code. Also given are the times for the
-original Linux emulator with the 4.1 'soft' lib.
-
- [ Linus' note: I changed look-ahead to be the default under linux, as
-   there was no reason not to use it after I had edited it to be
-   disabled during tracing ]
-
-            wm-FPU-emu w     original w
-            look-ahead       'soft' lib
-   +         106.4             190.2
-   -         108.6-111.6      192.4-216.2
-   *         113.4             193.1
-   /         108.8-124.4      700.1-706.2
-
- sin()       390.5            2642.0
- cos()       381.5            2767.4
- tan()       496.5            3153.3
- atan()      367.2-435.5     2439.4-3396.8
-
- sqrt()      195.1            4732.5
- log()       358.0-387.5     3359.2-3390.3
- exp()       619.3            4046.4
-
-
-These figures are now somewhat out-of-date. The emulator has become
-progressively slower for most functions as more of the 80486 features
-have been implemented.
-
-
------------------------ Accuracy of wm-FPU-emu -----------------------
-
-
-The accuracy of the emulator is in almost all cases equal to or better
-than that of an Intel 80486 FPU.
-
-The results of the basic arithmetic functions (+,-,*,/), and fsqrt
-match those of an 80486 FPU. They are the best possible; the error for
-these never exceeds 1/2 an lsb. The fprem and fprem1 instructions
-return exact results; they have no error.
-
-
-The following table compares the emulator accuracy for the sqrt(),
-trig and log functions against the Turbo C "emulator". For this table,
-each function was tested at about 400 points. Ideal worst-case results
-would be 64 bits. The reduced Turbo C accuracy of cos() and tan() for
-arguments greater than pi/4 can be thought of as being related to the
-precision of the argument x; e.g. an argument of pi/2-(1e-10) which is
-accurate to 64 bits can result in a relative accuracy in cos() of
-about 64 + log2(cos(x)) = 31 bits.
-
-
-Function      Tested x range            Worst result                Turbo C
-                                        (relative bits)
-
-sqrt(x)       1 .. 2                    64.1                         63.2
-atan(x)       1e-10 .. 200              64.2                         62.8
-cos(x)        0 .. pi/2-(1e-10)         64.4 (x <= pi/4)             62.4
-                                        64.1 (x = pi/2-(1e-10))      31.9
-sin(x)        1e-10 .. pi/2             64.0                         62.8
-tan(x)        1e-10 .. pi/2-(1e-10)     64.0 (x <= pi/4)             62.1
-                                        64.1 (x = pi/2-(1e-10))      31.9
-exp(x)        0 .. 1                    63.1 **                      62.9
-log(x)        1+1e-6 .. 2               63.8 **                      62.1
-
-** The accuracy for exp() and log() is low because the FPU (emulator)
-does not compute them directly; two operations are required.
-
-
-The emulator passes the "paranoia" tests (compiled with gcc 2.3.3 or
-later) for 'float' variables (24 bit precision numbers) when precision
-control is set to 24, 53 or 64 bits, and for 'double' variables (53
-bit precision numbers) when precision control is set to 53 bits (a
-properly performing FPU cannot pass the 'paranoia' tests for 'double'
-variables when precision control is set to 64 bits).
-
-The code for reducing the argument for the trig functions (fsin, fcos,
-fptan and fsincos) has been improved and now effectively uses a value
-for pi which is accurate to more than 128 bits precision. As a
-consequence, the accuracy of these functions for large arguments has
-been dramatically improved (and is now very much better than an 80486
-FPU). There is also now no degradation of accuracy for fcos and fptan
-for operands close to pi/2. Measured results are (note that the
-definition of accuracy has changed slightly from that used for the
-above table):
-
-Function      Tested x range          Worst result
-                                     (absolute bits)
-
-cos(x)        0 .. 9.22e+18              62.0
-sin(x)        1e-16 .. 9.22e+18          62.1
-tan(x)        1e-16 .. 9.22e+18          61.8
-
-It is possible with some effort to find very large arguments which
-give much degraded precision. For example, the integer number
-           8227740058411162616.0
-is within about 10e-7 of a multiple of pi. To find the tan (for
-example) of this number to 64 bits precision it would be necessary to
-have a value of pi which had about 150 bits precision. The FPU
-emulator computes the result to about 42.6 bits precision (the correct
-result is about -9.739715e-8). On the other hand, an 80486 FPU returns
-0.01059, which in relative terms is hopelessly inaccurate.
-
-For arguments close to critical angles (which occur at multiples of
-pi/2) the emulator is more accurate than an 80486 FPU. For very large
-arguments, the emulator is far more accurate.
-
-
-Prior to version 1.20 of the emulator, the accuracy of the results for
-the transcendental functions (in their principal range) was not as
-good as the results from an 80486 FPU. From version 1.20, the accuracy
-has been considerably improved and these functions now give measured
-worst-case results which are better than the worst-case results given
-by an 80486 FPU.
-
-The following table gives the measured results for the emulator. The
-number of randomly selected arguments in each case is about half a
-million.  The group of three columns gives the frequency of the given
-accuracy in number of times per million, thus the second of these
-columns shows that an accuracy of between 63.80 and 63.89 bits was
-found at a rate of 133 times per one million measurements for fsin.
-The results show that the fsin, fcos and fptan instructions return
-results which are in error (i.e. less accurate than the best possible
-result (which is 64 bits)) for about one per cent of all arguments
-between -pi/2 and +pi/2.  The other instructions have a lower
-frequency of results which are in error.  The last two columns give
-the worst accuracy which was found (in bits) and the approximate value
-of the argument which produced it.
-
-                                frequency (per M)
-                               -------------------   ---------------
-instr   arg range    # tests   63.7   63.8    63.9   worst   at arg
-                               bits   bits    bits    bits
------  ------------  -------   ----   ----   -----   -----  --------
-fsin     (0,pi/2)     547756      0    133   10673   63.89  0.451317
-fcos     (0,pi/2)     547563      0    126   10532   63.85  0.700801
-fptan    (0,pi/2)     536274     11    267   10059   63.74  0.784876
-fpatan  4 quadrants   517087      0      8    1855   63.88  0.435121 (4q)
-fyl2x     (0,20)      541861      0      0    1323   63.94  1.40923  (x)
-fyl2xp1 (-.293,.414)  520256      0      0    5678   63.93  0.408542 (x)
-f2xm1     (-1,1)      538847      4    481    6488   63.79  0.167709
-
-
-Tests performed on an 80486 FPU showed results of lower accuracy. The
-following table gives the results which were obtained with an AMD
-486DX2/66 (other tests indicate that an Intel 486DX produces
-identical results).  The tests were basically the same as those used
-to measure the emulator (the values, being random, were in general not
-the same).  The total number of tests for each instruction are given
-at the end of the table, in case each about 100k tests were performed.
-Another line of figures at the end of the table shows that most of the
-instructions return results which are in error for more than 10
-percent of the arguments tested.
-
-The numbers in the body of the table give the approx number of times a
-result of the given accuracy in bits (given in the left-most column)
-was obtained per one million arguments. For three of the instructions,
-two columns of results are given: * The second column for f2xm1 gives
-the number cases where the results of the first column were for a
-positive argument, this shows that this instruction gives better
-results for positive arguments than it does for negative.  * In the
-cases of fcos and fptan, the first column gives the results when all
-cases where arguments greater than 1.5 were removed from the results
-given in the second column. Unlike the emulator, an 80486 FPU returns
-results of relatively poor accuracy for these instructions when the
-argument approaches pi/2. The table does not show those cases when the
-accuracy of the results were less than 62 bits, which occurs quite
-often for fsin and fptan when the argument approaches pi/2. This poor
-accuracy is discussed above in relation to the Turbo C "emulator", and
-the accuracy of the value of pi.
-
-
-bits   f2xm1  f2xm1 fpatan   fcos   fcos  fyl2x fyl2xp1  fsin  fptan  fptan
-62.0       0      0      0      0    437      0      0      0      0    925
-62.1       0      0     10      0    894      0      0      0      0   1023
-62.2      14      0      0      0   1033      0      0      0      0    945
-62.3      57      0      0      0   1202      0      0      0      0   1023
-62.4     385      0      0     10   1292      0     23      0      0   1178
-62.5    1140      0      0    119   1649      0     39      0      0   1149
-62.6    2037      0      0    189   1620      0     16      0      0   1169
-62.7    5086     14      0    646   2315     10    101     35     39   1402
-62.8    8818     86      0    984   3050     59    287    131    224   2036
-62.9   11340   1355      0   2126   4153     79    605    357    321   1948
-63.0   15557   4750      0   3319   5376    246   1281    862    808   2688
-63.1   20016   8288      0   4620   6628    511   2569   1723   1510   3302
-63.2   24945  11127     10   6588   8098   1120   4470   2968   2990   4724
-63.3   25686  12382     69   8774  10682   1906   6775   4482   5474   7236
-63.4   29219  14722     79  11109  12311   3094   9414   7259   8912  10587
-63.5   30458  14936    393  13802  15014   5874  12666   9609  13762  15262
-63.6   32439  16448   1277  17945  19028  10226  15537  14657  19158  20346
-63.7   35031  16805   4067  23003  23947  18910  20116  21333  25001  26209
-63.8   33251  15820   7673  24781  25675  24617  25354  24440  29433  30329
-63.9   33293  16833  18529  28318  29233  31267  31470  27748  29676  30601
-
-Per cent with error:
-        30.9           3.2          18.5    9.8   13.1   11.6          17.4
-Total arguments tested:
-       70194  70099 101784 100641 100641 101799 128853 114893 102675 102675
-
-
-------------------------- Contributors -------------------------------
-
-A number of people have contributed to the development of the
-emulator, often by just reporting bugs, sometimes with suggested
-fixes, and a few kind people have provided me with access in one way
-or another to an 80486 machine. Contributors include (to those people
-who I may have forgotten, please forgive me):
-
-Linus Torvalds
-Tommy.Thorn@daimi.aau.dk
-Andrew.Tridgell@anu.edu.au
-Nick Holloway, alfie@dcs.warwick.ac.uk
-Hermano Moura, moura@dcs.gla.ac.uk
-Jon Jagger, J.Jagger@scp.ac.uk
-Lennart Benschop
-Brian Gallew, geek+@CMU.EDU
-Thomas Staniszewski, ts3v+@andrew.cmu.edu
-Martin Howell, mph@plasma.apana.org.au
-M Saggaf, alsaggaf@athena.mit.edu
-Peter Barker, PETER@socpsy.sci.fau.edu
-tom@vlsivie.tuwien.ac.at
-Dan Russel, russed@rpi.edu
-Daniel Carosone, danielce@ee.mu.oz.au
-cae@jpmorgan.com
-Hamish Coleman, t933093@minyos.xx.rmit.oz.au
-Bruce Evans, bde@kralizec.zeta.org.au
-Timo Korvola, Timo.Korvola@hut.fi
-Rick Lyons, rick@razorback.brisnet.org.au
-Rick, jrs@world.std.com
- 
-...and numerous others who responded to my request for help with
-a real 80486.
-
diff -rupN a/arch/x86/math-emu/reg_add_sub.c b/arch/x86/math-emu/reg_add_sub.c
--- a/arch/x86/math-emu/reg_add_sub.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_add_sub.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,334 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  reg_add_sub.c                                                            |
- |                                                                           |
- | Functions to add or subtract two registers and put the result in a third. |
- |                                                                           |
- | Copyright (C) 1992,1993,1997                                              |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- |  For each function, the destination may be any FPU_REG, including one of  |
- | the source FPU_REGs.                                                      |
- |  Each function returns 0 if the answer is o.k., otherwise a non-zero      |
- | value is returned, indicating either an exception condition or an         |
- | internal error.                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "reg_constant.h"
-#include "fpu_emu.h"
-#include "control_w.h"
-#include "fpu_system.h"
-
-static
-int add_sub_specials(FPU_REG const *a, u_char taga, u_char signa,
-		     FPU_REG const *b, u_char tagb, u_char signb,
-		     FPU_REG * dest, int deststnr, int control_w);
-
-/*
-  Operates on st(0) and st(n), or on st(0) and temporary data.
-  The destination must be one of the source st(x).
-  */
-int FPU_add(FPU_REG const *b, u_char tagb, int deststnr, int control_w)
-{
-	FPU_REG *a = &st(0);
-	FPU_REG *dest = &st(deststnr);
-	u_char signb = getsign(b);
-	u_char taga = FPU_gettag0();
-	u_char signa = getsign(a);
-	u_char saved_sign = getsign(dest);
-	int diff, tag, expa, expb;
-
-	if (!(taga | tagb)) {
-		expa = exponent(a);
-		expb = exponent(b);
-
-	      valid_add:
-		/* Both registers are valid */
-		if (!(signa ^ signb)) {
-			/* signs are the same */
-			tag =
-			    FPU_u_add(a, b, dest, control_w, signa, expa, expb);
-		} else {
-			/* The signs are different, so do a subtraction */
-			diff = expa - expb;
-			if (!diff) {
-				diff = a->sigh - b->sigh;	/* This works only if the ms bits
-								   are identical. */
-				if (!diff) {
-					diff = a->sigl > b->sigl;
-					if (!diff)
-						diff = -(a->sigl < b->sigl);
-				}
-			}
-
-			if (diff > 0) {
-				tag =
-				    FPU_u_sub(a, b, dest, control_w, signa,
-					      expa, expb);
-			} else if (diff < 0) {
-				tag =
-				    FPU_u_sub(b, a, dest, control_w, signb,
-					      expb, expa);
-			} else {
-				FPU_copy_to_regi(&CONST_Z, TAG_Zero, deststnr);
-				/* sign depends upon rounding mode */
-				setsign(dest, ((control_w & CW_RC) != RC_DOWN)
-					? SIGN_POS : SIGN_NEG);
-				return TAG_Zero;
-			}
-		}
-
-		if (tag < 0) {
-			setsign(dest, saved_sign);
-			return tag;
-		}
-		FPU_settagi(deststnr, tag);
-		return tag;
-	}
-
-	if (taga == TAG_Special)
-		taga = FPU_Special(a);
-	if (tagb == TAG_Special)
-		tagb = FPU_Special(b);
-
-	if (((taga == TAG_Valid) && (tagb == TW_Denormal))
-	    || ((taga == TW_Denormal) && (tagb == TAG_Valid))
-	    || ((taga == TW_Denormal) && (tagb == TW_Denormal))) {
-		FPU_REG x, y;
-
-		if (denormal_operand() < 0)
-			return FPU_Exception;
-
-		FPU_to_exp16(a, &x);
-		FPU_to_exp16(b, &y);
-		a = &x;
-		b = &y;
-		expa = exponent16(a);
-		expb = exponent16(b);
-		goto valid_add;
-	}
-
-	if ((taga == TW_NaN) || (tagb == TW_NaN)) {
-		if (deststnr == 0)
-			return real_2op_NaN(b, tagb, deststnr, a);
-		else
-			return real_2op_NaN(a, taga, deststnr, a);
-	}
-
-	return add_sub_specials(a, taga, signa, b, tagb, signb,
-				dest, deststnr, control_w);
-}
-
-/* Subtract b from a.  (a-b) -> dest */
-int FPU_sub(int flags, int rm, int control_w)
-{
-	FPU_REG const *a, *b;
-	FPU_REG *dest;
-	u_char taga, tagb, signa, signb, saved_sign, sign;
-	int diff, tag = 0, expa, expb, deststnr;
-
-	a = &st(0);
-	taga = FPU_gettag0();
-
-	deststnr = 0;
-	if (flags & LOADED) {
-		b = (FPU_REG *) rm;
-		tagb = flags & 0x0f;
-	} else {
-		b = &st(rm);
-		tagb = FPU_gettagi(rm);
-
-		if (flags & DEST_RM)
-			deststnr = rm;
-	}
-
-	signa = getsign(a);
-	signb = getsign(b);
-
-	if (flags & REV) {
-		signa ^= SIGN_NEG;
-		signb ^= SIGN_NEG;
-	}
-
-	dest = &st(deststnr);
-	saved_sign = getsign(dest);
-
-	if (!(taga | tagb)) {
-		expa = exponent(a);
-		expb = exponent(b);
-
-	      valid_subtract:
-		/* Both registers are valid */
-
-		diff = expa - expb;
-
-		if (!diff) {
-			diff = a->sigh - b->sigh;	/* Works only if ms bits are identical */
-			if (!diff) {
-				diff = a->sigl > b->sigl;
-				if (!diff)
-					diff = -(a->sigl < b->sigl);
-			}
-		}
-
-		switch ((((int)signa) * 2 + signb) / SIGN_NEG) {
-		case 0:	/* P - P */
-		case 3:	/* N - N */
-			if (diff > 0) {
-				/* |a| > |b| */
-				tag =
-				    FPU_u_sub(a, b, dest, control_w, signa,
-					      expa, expb);
-			} else if (diff == 0) {
-				FPU_copy_to_regi(&CONST_Z, TAG_Zero, deststnr);
-
-				/* sign depends upon rounding mode */
-				setsign(dest, ((control_w & CW_RC) != RC_DOWN)
-					? SIGN_POS : SIGN_NEG);
-				return TAG_Zero;
-			} else {
-				sign = signa ^ SIGN_NEG;
-				tag =
-				    FPU_u_sub(b, a, dest, control_w, sign, expb,
-					      expa);
-			}
-			break;
-		case 1:	/* P - N */
-			tag =
-			    FPU_u_add(a, b, dest, control_w, SIGN_POS, expa,
-				      expb);
-			break;
-		case 2:	/* N - P */
-			tag =
-			    FPU_u_add(a, b, dest, control_w, SIGN_NEG, expa,
-				      expb);
-			break;
-#ifdef PARANOID
-		default:
-			EXCEPTION(EX_INTERNAL | 0x111);
-			return -1;
-#endif
-		}
-		if (tag < 0) {
-			setsign(dest, saved_sign);
-			return tag;
-		}
-		FPU_settagi(deststnr, tag);
-		return tag;
-	}
-
-	if (taga == TAG_Special)
-		taga = FPU_Special(a);
-	if (tagb == TAG_Special)
-		tagb = FPU_Special(b);
-
-	if (((taga == TAG_Valid) && (tagb == TW_Denormal))
-	    || ((taga == TW_Denormal) && (tagb == TAG_Valid))
-	    || ((taga == TW_Denormal) && (tagb == TW_Denormal))) {
-		FPU_REG x, y;
-
-		if (denormal_operand() < 0)
-			return FPU_Exception;
-
-		FPU_to_exp16(a, &x);
-		FPU_to_exp16(b, &y);
-		a = &x;
-		b = &y;
-		expa = exponent16(a);
-		expb = exponent16(b);
-
-		goto valid_subtract;
-	}
-
-	if ((taga == TW_NaN) || (tagb == TW_NaN)) {
-		FPU_REG const *d1, *d2;
-		if (flags & REV) {
-			d1 = b;
-			d2 = a;
-		} else {
-			d1 = a;
-			d2 = b;
-		}
-		if (flags & LOADED)
-			return real_2op_NaN(b, tagb, deststnr, d1);
-		if (flags & DEST_RM)
-			return real_2op_NaN(a, taga, deststnr, d2);
-		else
-			return real_2op_NaN(b, tagb, deststnr, d2);
-	}
-
-	return add_sub_specials(a, taga, signa, b, tagb, signb ^ SIGN_NEG,
-				dest, deststnr, control_w);
-}
-
-static
-int add_sub_specials(FPU_REG const *a, u_char taga, u_char signa,
-		     FPU_REG const *b, u_char tagb, u_char signb,
-		     FPU_REG * dest, int deststnr, int control_w)
-{
-	if (((taga == TW_Denormal) || (tagb == TW_Denormal))
-	    && (denormal_operand() < 0))
-		return FPU_Exception;
-
-	if (taga == TAG_Zero) {
-		if (tagb == TAG_Zero) {
-			/* Both are zero, result will be zero. */
-			u_char different_signs = signa ^ signb;
-
-			FPU_copy_to_regi(a, TAG_Zero, deststnr);
-			if (different_signs) {
-				/* Signs are different. */
-				/* Sign of answer depends upon rounding mode. */
-				setsign(dest, ((control_w & CW_RC) != RC_DOWN)
-					? SIGN_POS : SIGN_NEG);
-			} else
-				setsign(dest, signa);	/* signa may differ from the sign of a. */
-			return TAG_Zero;
-		} else {
-			reg_copy(b, dest);
-			if ((tagb == TW_Denormal) && (b->sigh & 0x80000000)) {
-				/* A pseudoDenormal, convert it. */
-				addexponent(dest, 1);
-				tagb = TAG_Valid;
-			} else if (tagb > TAG_Empty)
-				tagb = TAG_Special;
-			setsign(dest, signb);	/* signb may differ from the sign of b. */
-			FPU_settagi(deststnr, tagb);
-			return tagb;
-		}
-	} else if (tagb == TAG_Zero) {
-		reg_copy(a, dest);
-		if ((taga == TW_Denormal) && (a->sigh & 0x80000000)) {
-			/* A pseudoDenormal */
-			addexponent(dest, 1);
-			taga = TAG_Valid;
-		} else if (taga > TAG_Empty)
-			taga = TAG_Special;
-		setsign(dest, signa);	/* signa may differ from the sign of a. */
-		FPU_settagi(deststnr, taga);
-		return taga;
-	} else if (taga == TW_Infinity) {
-		if ((tagb != TW_Infinity) || (signa == signb)) {
-			FPU_copy_to_regi(a, TAG_Special, deststnr);
-			setsign(dest, signa);	/* signa may differ from the sign of a. */
-			return taga;
-		}
-		/* Infinity-Infinity is undefined. */
-		return arith_invalid(deststnr);
-	} else if (tagb == TW_Infinity) {
-		FPU_copy_to_regi(b, TAG_Special, deststnr);
-		setsign(dest, signb);	/* signb may differ from the sign of b. */
-		return tagb;
-	}
-#ifdef PARANOID
-	EXCEPTION(EX_INTERNAL | 0x101);
-#endif
-
-	return FPU_Exception;
-}
diff -rupN a/arch/x86/math-emu/reg_compare.c b/arch/x86/math-emu/reg_compare.c
--- a/arch/x86/math-emu/reg_compare.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_compare.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,479 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  reg_compare.c                                                            |
- |                                                                           |
- | Compare two floating point registers                                      |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997                                         |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | compare() is the core FPU_REG comparison function                         |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_system.h"
-#include "exception.h"
-#include "fpu_emu.h"
-#include "control_w.h"
-#include "status_w.h"
-
-static int compare(FPU_REG const *b, int tagb)
-{
-	int diff, exp0, expb;
-	u_char st0_tag;
-	FPU_REG *st0_ptr;
-	FPU_REG x, y;
-	u_char st0_sign, signb = getsign(b);
-
-	st0_ptr = &st(0);
-	st0_tag = FPU_gettag0();
-	st0_sign = getsign(st0_ptr);
-
-	if (tagb == TAG_Special)
-		tagb = FPU_Special(b);
-	if (st0_tag == TAG_Special)
-		st0_tag = FPU_Special(st0_ptr);
-
-	if (((st0_tag != TAG_Valid) && (st0_tag != TW_Denormal))
-	    || ((tagb != TAG_Valid) && (tagb != TW_Denormal))) {
-		if (st0_tag == TAG_Zero) {
-			if (tagb == TAG_Zero)
-				return COMP_A_eq_B;
-			if (tagb == TAG_Valid)
-				return ((signb ==
-					 SIGN_POS) ? COMP_A_lt_B : COMP_A_gt_B);
-			if (tagb == TW_Denormal)
-				return ((signb ==
-					 SIGN_POS) ? COMP_A_lt_B : COMP_A_gt_B)
-				    | COMP_Denormal;
-		} else if (tagb == TAG_Zero) {
-			if (st0_tag == TAG_Valid)
-				return ((st0_sign ==
-					 SIGN_POS) ? COMP_A_gt_B : COMP_A_lt_B);
-			if (st0_tag == TW_Denormal)
-				return ((st0_sign ==
-					 SIGN_POS) ? COMP_A_gt_B : COMP_A_lt_B)
-				    | COMP_Denormal;
-		}
-
-		if (st0_tag == TW_Infinity) {
-			if ((tagb == TAG_Valid) || (tagb == TAG_Zero))
-				return ((st0_sign ==
-					 SIGN_POS) ? COMP_A_gt_B : COMP_A_lt_B);
-			else if (tagb == TW_Denormal)
-				return ((st0_sign ==
-					 SIGN_POS) ? COMP_A_gt_B : COMP_A_lt_B)
-				    | COMP_Denormal;
-			else if (tagb == TW_Infinity) {
-				/* The 80486 book says that infinities can be equal! */
-				return (st0_sign == signb) ? COMP_A_eq_B :
-				    ((st0_sign ==
-				      SIGN_POS) ? COMP_A_gt_B : COMP_A_lt_B);
-			}
-			/* Fall through to the NaN code */
-		} else if (tagb == TW_Infinity) {
-			if ((st0_tag == TAG_Valid) || (st0_tag == TAG_Zero))
-				return ((signb ==
-					 SIGN_POS) ? COMP_A_lt_B : COMP_A_gt_B);
-			if (st0_tag == TW_Denormal)
-				return ((signb ==
-					 SIGN_POS) ? COMP_A_lt_B : COMP_A_gt_B)
-				    | COMP_Denormal;
-			/* Fall through to the NaN code */
-		}
-
-		/* The only possibility now should be that one of the arguments
-		   is a NaN */
-		if ((st0_tag == TW_NaN) || (tagb == TW_NaN)) {
-			int signalling = 0, unsupported = 0;
-			if (st0_tag == TW_NaN) {
-				signalling =
-				    (st0_ptr->sigh & 0xc0000000) == 0x80000000;
-				unsupported = !((exponent(st0_ptr) == EXP_OVER)
-						&& (st0_ptr->
-						    sigh & 0x80000000));
-			}
-			if (tagb == TW_NaN) {
-				signalling |=
-				    (b->sigh & 0xc0000000) == 0x80000000;
-				unsupported |= !((exponent(b) == EXP_OVER)
-						 && (b->sigh & 0x80000000));
-			}
-			if (signalling || unsupported)
-				return COMP_No_Comp | COMP_SNaN | COMP_NaN;
-			else
-				/* Neither is a signaling NaN */
-				return COMP_No_Comp | COMP_NaN;
-		}
-
-		EXCEPTION(EX_Invalid);
-	}
-
-	if (st0_sign != signb) {
-		return ((st0_sign == SIGN_POS) ? COMP_A_gt_B : COMP_A_lt_B)
-		    | (((st0_tag == TW_Denormal) || (tagb == TW_Denormal)) ?
-		       COMP_Denormal : 0);
-	}
-
-	if ((st0_tag == TW_Denormal) || (tagb == TW_Denormal)) {
-		FPU_to_exp16(st0_ptr, &x);
-		FPU_to_exp16(b, &y);
-		st0_ptr = &x;
-		b = &y;
-		exp0 = exponent16(st0_ptr);
-		expb = exponent16(b);
-	} else {
-		exp0 = exponent(st0_ptr);
-		expb = exponent(b);
-	}
-
-#ifdef PARANOID
-	if (!(st0_ptr->sigh & 0x80000000))
-		EXCEPTION(EX_Invalid);
-	if (!(b->sigh & 0x80000000))
-		EXCEPTION(EX_Invalid);
-#endif /* PARANOID */
-
-	diff = exp0 - expb;
-	if (diff == 0) {
-		diff = st0_ptr->sigh - b->sigh;	/* Works only if ms bits are
-						   identical */
-		if (diff == 0) {
-			diff = st0_ptr->sigl > b->sigl;
-			if (diff == 0)
-				diff = -(st0_ptr->sigl < b->sigl);
-		}
-	}
-
-	if (diff > 0) {
-		return ((st0_sign == SIGN_POS) ? COMP_A_gt_B : COMP_A_lt_B)
-		    | (((st0_tag == TW_Denormal) || (tagb == TW_Denormal)) ?
-		       COMP_Denormal : 0);
-	}
-	if (diff < 0) {
-		return ((st0_sign == SIGN_POS) ? COMP_A_lt_B : COMP_A_gt_B)
-		    | (((st0_tag == TW_Denormal) || (tagb == TW_Denormal)) ?
-		       COMP_Denormal : 0);
-	}
-
-	return COMP_A_eq_B
-	    | (((st0_tag == TW_Denormal) || (tagb == TW_Denormal)) ?
-	       COMP_Denormal : 0);
-
-}
-
-/* This function requires that st(0) is not empty */
-int FPU_compare_st_data(FPU_REG const *loaded_data, u_char loaded_tag)
-{
-	int f, c;
-
-	c = compare(loaded_data, loaded_tag);
-
-	if (c & COMP_NaN) {
-		EXCEPTION(EX_Invalid);
-		f = SW_C3 | SW_C2 | SW_C0;
-	} else
-		switch (c & 7) {
-		case COMP_A_lt_B:
-			f = SW_C0;
-			break;
-		case COMP_A_eq_B:
-			f = SW_C3;
-			break;
-		case COMP_A_gt_B:
-			f = 0;
-			break;
-		case COMP_No_Comp:
-			f = SW_C3 | SW_C2 | SW_C0;
-			break;
-		default:
-#ifdef PARANOID
-			EXCEPTION(EX_INTERNAL | 0x121);
-#endif /* PARANOID */
-			f = SW_C3 | SW_C2 | SW_C0;
-			break;
-		}
-	setcc(f);
-	if (c & COMP_Denormal) {
-		return denormal_operand() < 0;
-	}
-	return 0;
-}
-
-static int compare_st_st(int nr)
-{
-	int f, c;
-	FPU_REG *st_ptr;
-
-	if (!NOT_EMPTY(0) || !NOT_EMPTY(nr)) {
-		setcc(SW_C3 | SW_C2 | SW_C0);
-		/* Stack fault */
-		EXCEPTION(EX_StackUnder);
-		return !(control_word & CW_Invalid);
-	}
-
-	st_ptr = &st(nr);
-	c = compare(st_ptr, FPU_gettagi(nr));
-	if (c & COMP_NaN) {
-		setcc(SW_C3 | SW_C2 | SW_C0);
-		EXCEPTION(EX_Invalid);
-		return !(control_word & CW_Invalid);
-	} else
-		switch (c & 7) {
-		case COMP_A_lt_B:
-			f = SW_C0;
-			break;
-		case COMP_A_eq_B:
-			f = SW_C3;
-			break;
-		case COMP_A_gt_B:
-			f = 0;
-			break;
-		case COMP_No_Comp:
-			f = SW_C3 | SW_C2 | SW_C0;
-			break;
-		default:
-#ifdef PARANOID
-			EXCEPTION(EX_INTERNAL | 0x122);
-#endif /* PARANOID */
-			f = SW_C3 | SW_C2 | SW_C0;
-			break;
-		}
-	setcc(f);
-	if (c & COMP_Denormal) {
-		return denormal_operand() < 0;
-	}
-	return 0;
-}
-
-static int compare_i_st_st(int nr)
-{
-	int f, c;
-	FPU_REG *st_ptr;
-
-	if (!NOT_EMPTY(0) || !NOT_EMPTY(nr)) {
-		FPU_EFLAGS |= (X86_EFLAGS_ZF | X86_EFLAGS_PF | X86_EFLAGS_CF);
-		/* Stack fault */
-		EXCEPTION(EX_StackUnder);
-		return !(control_word & CW_Invalid);
-	}
-
-	partial_status &= ~SW_C0;
-	st_ptr = &st(nr);
-	c = compare(st_ptr, FPU_gettagi(nr));
-	if (c & COMP_NaN) {
-		FPU_EFLAGS |= (X86_EFLAGS_ZF | X86_EFLAGS_PF | X86_EFLAGS_CF);
-		EXCEPTION(EX_Invalid);
-		return !(control_word & CW_Invalid);
-	}
-
-	switch (c & 7) {
-	case COMP_A_lt_B:
-		f = X86_EFLAGS_CF;
-		break;
-	case COMP_A_eq_B:
-		f = X86_EFLAGS_ZF;
-		break;
-	case COMP_A_gt_B:
-		f = 0;
-		break;
-	case COMP_No_Comp:
-		f = X86_EFLAGS_ZF | X86_EFLAGS_PF | X86_EFLAGS_CF;
-		break;
-	default:
-#ifdef PARANOID
-		EXCEPTION(EX_INTERNAL | 0x122);
-#endif /* PARANOID */
-		f = 0;
-		break;
-	}
-	FPU_EFLAGS = (FPU_EFLAGS & ~(X86_EFLAGS_ZF | X86_EFLAGS_PF | X86_EFLAGS_CF)) | f;
-	if (c & COMP_Denormal) {
-		return denormal_operand() < 0;
-	}
-	return 0;
-}
-
-static int compare_u_st_st(int nr)
-{
-	int f = 0, c;
-	FPU_REG *st_ptr;
-
-	if (!NOT_EMPTY(0) || !NOT_EMPTY(nr)) {
-		setcc(SW_C3 | SW_C2 | SW_C0);
-		/* Stack fault */
-		EXCEPTION(EX_StackUnder);
-		return !(control_word & CW_Invalid);
-	}
-
-	st_ptr = &st(nr);
-	c = compare(st_ptr, FPU_gettagi(nr));
-	if (c & COMP_NaN) {
-		setcc(SW_C3 | SW_C2 | SW_C0);
-		if (c & COMP_SNaN) {	/* This is the only difference between
-					   un-ordered and ordinary comparisons */
-			EXCEPTION(EX_Invalid);
-			return !(control_word & CW_Invalid);
-		}
-		return 0;
-	} else
-		switch (c & 7) {
-		case COMP_A_lt_B:
-			f = SW_C0;
-			break;
-		case COMP_A_eq_B:
-			f = SW_C3;
-			break;
-		case COMP_A_gt_B:
-			f = 0;
-			break;
-		case COMP_No_Comp:
-			f = SW_C3 | SW_C2 | SW_C0;
-			break;
-#ifdef PARANOID
-		default:
-			EXCEPTION(EX_INTERNAL | 0x123);
-			f = SW_C3 | SW_C2 | SW_C0;
-			break;
-#endif /* PARANOID */
-		}
-	setcc(f);
-	if (c & COMP_Denormal) {
-		return denormal_operand() < 0;
-	}
-	return 0;
-}
-
-static int compare_ui_st_st(int nr)
-{
-	int f = 0, c;
-	FPU_REG *st_ptr;
-
-	if (!NOT_EMPTY(0) || !NOT_EMPTY(nr)) {
-		FPU_EFLAGS |= (X86_EFLAGS_ZF | X86_EFLAGS_PF | X86_EFLAGS_CF);
-		/* Stack fault */
-		EXCEPTION(EX_StackUnder);
-		return !(control_word & CW_Invalid);
-	}
-
-	partial_status &= ~SW_C0;
-	st_ptr = &st(nr);
-	c = compare(st_ptr, FPU_gettagi(nr));
-	if (c & COMP_NaN) {
-		FPU_EFLAGS |= (X86_EFLAGS_ZF | X86_EFLAGS_PF | X86_EFLAGS_CF);
-		if (c & COMP_SNaN) {	/* This is the only difference between
-					   un-ordered and ordinary comparisons */
-			EXCEPTION(EX_Invalid);
-			return !(control_word & CW_Invalid);
-		}
-		return 0;
-	}
-
-	switch (c & 7) {
-	case COMP_A_lt_B:
-		f = X86_EFLAGS_CF;
-		break;
-	case COMP_A_eq_B:
-		f = X86_EFLAGS_ZF;
-		break;
-	case COMP_A_gt_B:
-		f = 0;
-		break;
-	case COMP_No_Comp:
-		f = X86_EFLAGS_ZF | X86_EFLAGS_PF | X86_EFLAGS_CF;
-		break;
-#ifdef PARANOID
-	default:
-		EXCEPTION(EX_INTERNAL | 0x123);
-		f = 0;
-		break;
-#endif /* PARANOID */
-	}
-	FPU_EFLAGS = (FPU_EFLAGS & ~(X86_EFLAGS_ZF | X86_EFLAGS_PF | X86_EFLAGS_CF)) | f;
-	if (c & COMP_Denormal) {
-		return denormal_operand() < 0;
-	}
-	return 0;
-}
-
-/*---------------------------------------------------------------------------*/
-
-void fcom_st(void)
-{
-	/* fcom st(i) */
-	compare_st_st(FPU_rm);
-}
-
-void fcompst(void)
-{
-	/* fcomp st(i) */
-	if (!compare_st_st(FPU_rm))
-		FPU_pop();
-}
-
-void fcompp(void)
-{
-	/* fcompp */
-	if (FPU_rm != 1) {
-		FPU_illegal();
-		return;
-	}
-	if (!compare_st_st(1))
-		poppop();
-}
-
-void fucom_(void)
-{
-	/* fucom st(i) */
-	compare_u_st_st(FPU_rm);
-
-}
-
-void fucomp(void)
-{
-	/* fucomp st(i) */
-	if (!compare_u_st_st(FPU_rm))
-		FPU_pop();
-}
-
-void fucompp(void)
-{
-	/* fucompp */
-	if (FPU_rm == 1) {
-		if (!compare_u_st_st(1))
-			poppop();
-	} else
-		FPU_illegal();
-}
-
-/* P6+ compare-to-EFLAGS ops */
-
-void fcomi_(void)
-{
-	/* fcomi st(i) */
-	compare_i_st_st(FPU_rm);
-}
-
-void fcomip(void)
-{
-	/* fcomip st(i) */
-	if (!compare_i_st_st(FPU_rm))
-		FPU_pop();
-}
-
-void fucomi_(void)
-{
-	/* fucomi st(i) */
-	compare_ui_st_st(FPU_rm);
-}
-
-void fucomip(void)
-{
-	/* fucomip st(i) */
-	if (!compare_ui_st_st(FPU_rm))
-		FPU_pop();
-}
diff -rupN a/arch/x86/math-emu/reg_constant.c b/arch/x86/math-emu/reg_constant.c
--- a/arch/x86/math-emu/reg_constant.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_constant.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,123 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  reg_constant.c                                                           |
- |                                                                           |
- | All of the constant FPU_REGs                                              |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1997                                         |
- |                     W. Metzenthen, 22 Parker St, Ormond, Vic 3163,        |
- |                     Australia.  E-mail   billm@suburbia.net               |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_system.h"
-#include "fpu_emu.h"
-#include "status_w.h"
-#include "reg_constant.h"
-#include "control_w.h"
-
-#define MAKE_REG(s, e, l, h) { l, h, \
-		(u16)((EXTENDED_Ebias+(e)) | ((SIGN_##s != 0)*0x8000)) }
-
-FPU_REG const CONST_1 = MAKE_REG(POS, 0, 0x00000000, 0x80000000);
-#if 0
-FPU_REG const CONST_2 = MAKE_REG(POS, 1, 0x00000000, 0x80000000);
-FPU_REG const CONST_HALF = MAKE_REG(POS, -1, 0x00000000, 0x80000000);
-#endif /*  0  */
-static FPU_REG const CONST_L2T = MAKE_REG(POS, 1, 0xcd1b8afe, 0xd49a784b);
-static FPU_REG const CONST_L2E = MAKE_REG(POS, 0, 0x5c17f0bc, 0xb8aa3b29);
-FPU_REG const CONST_PI = MAKE_REG(POS, 1, 0x2168c235, 0xc90fdaa2);
-FPU_REG const CONST_PI2 = MAKE_REG(POS, 0, 0x2168c235, 0xc90fdaa2);
-FPU_REG const CONST_PI4 = MAKE_REG(POS, -1, 0x2168c235, 0xc90fdaa2);
-static FPU_REG const CONST_LG2 = MAKE_REG(POS, -2, 0xfbcff799, 0x9a209a84);
-static FPU_REG const CONST_LN2 = MAKE_REG(POS, -1, 0xd1cf79ac, 0xb17217f7);
-
-/* Extra bits to take pi/2 to more than 128 bits precision. */
-FPU_REG const CONST_PI2extra = MAKE_REG(NEG, -66,
-					0xfc8f8cbb, 0xece675d1);
-
-/* Only the sign (and tag) is used in internal zeroes */
-FPU_REG const CONST_Z = MAKE_REG(POS, EXP_UNDER, 0x0, 0x0);
-
-/* Only the sign and significand (and tag) are used in internal NaNs */
-/* The 80486 never generates one of these
-FPU_REG const CONST_SNAN = MAKE_REG(POS, EXP_OVER, 0x00000001, 0x80000000);
- */
-/* This is the real indefinite QNaN */
-FPU_REG const CONST_QNaN = MAKE_REG(NEG, EXP_OVER, 0x00000000, 0xC0000000);
-
-/* Only the sign (and tag) is used in internal infinities */
-FPU_REG const CONST_INF = MAKE_REG(POS, EXP_OVER, 0x00000000, 0x80000000);
-
-static void fld_const(FPU_REG const * c, int adj, u_char tag)
-{
-	FPU_REG *st_new_ptr;
-
-	if (STACK_OVERFLOW) {
-		FPU_stack_overflow();
-		return;
-	}
-	push();
-	reg_copy(c, st_new_ptr);
-	st_new_ptr->sigl += adj;	/* For all our fldxxx constants, we don't need to
-					   borrow or carry. */
-	FPU_settag0(tag);
-	clear_C1();
-}
-
-/* A fast way to find out whether x is one of RC_DOWN or RC_CHOP
-   (and not one of RC_RND or RC_UP).
-   */
-#define DOWN_OR_CHOP(x)  (x & RC_DOWN)
-
-static void fld1(int rc)
-{
-	fld_const(&CONST_1, 0, TAG_Valid);
-}
-
-static void fldl2t(int rc)
-{
-	fld_const(&CONST_L2T, (rc == RC_UP) ? 1 : 0, TAG_Valid);
-}
-
-static void fldl2e(int rc)
-{
-	fld_const(&CONST_L2E, DOWN_OR_CHOP(rc) ? -1 : 0, TAG_Valid);
-}
-
-static void fldpi(int rc)
-{
-	fld_const(&CONST_PI, DOWN_OR_CHOP(rc) ? -1 : 0, TAG_Valid);
-}
-
-static void fldlg2(int rc)
-{
-	fld_const(&CONST_LG2, DOWN_OR_CHOP(rc) ? -1 : 0, TAG_Valid);
-}
-
-static void fldln2(int rc)
-{
-	fld_const(&CONST_LN2, DOWN_OR_CHOP(rc) ? -1 : 0, TAG_Valid);
-}
-
-static void fldz(int rc)
-{
-	fld_const(&CONST_Z, 0, TAG_Zero);
-}
-
-typedef void (*FUNC_RC) (int);
-
-static void FPU_RC_illegal(int unused)
-{
-	FPU_illegal();
-}
-
-static FUNC_RC constants_table[] = {
-	fld1, fldl2t, fldl2e, fldpi, fldlg2, fldln2, fldz, FPU_RC_illegal
-};
-
-void fconst(void)
-{
-	(constants_table[FPU_rm]) (control_word & CW_RC);
-}
diff -rupN a/arch/x86/math-emu/reg_constant.h b/arch/x86/math-emu/reg_constant.h
--- a/arch/x86/math-emu/reg_constant.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_constant.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,26 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  reg_constant.h                                                           |
- |                                                                           |
- | Copyright (C) 1992    W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@vaxc.cc.monash.edu.au    |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#ifndef _REG_CONSTANT_H_
-#define _REG_CONSTANT_H_
-
-#include "fpu_emu.h"
-
-extern FPU_REG const CONST_1;
-extern FPU_REG const CONST_PI;
-extern FPU_REG const CONST_PI2;
-extern FPU_REG const CONST_PI2extra;
-extern FPU_REG const CONST_PI4;
-extern FPU_REG const CONST_Z;
-extern FPU_REG const CONST_PINF;
-extern FPU_REG const CONST_INF;
-extern FPU_REG const CONST_MINF;
-extern FPU_REG const CONST_QNaN;
-
-#endif /* _REG_CONSTANT_H_ */
diff -rupN a/arch/x86/math-emu/reg_convert.c b/arch/x86/math-emu/reg_convert.c
--- a/arch/x86/math-emu/reg_convert.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_convert.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,47 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  reg_convert.c                                                            |
- |                                                                           |
- |  Convert register representation.                                         |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1996,1997                                    |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "fpu_emu.h"
-
-int FPU_to_exp16(FPU_REG const *a, FPU_REG *x)
-{
-	int sign = getsign(a);
-
-	*(long long *)&(x->sigl) = *(const long long *)&(a->sigl);
-
-	/* Set up the exponent as a 16 bit quantity. */
-	setexponent16(x, exponent(a));
-
-	if (exponent16(x) == EXP_UNDER) {
-		/* The number is a de-normal or pseudodenormal. */
-		/* We only deal with the significand and exponent. */
-
-		if (x->sigh & 0x80000000) {
-			/* Is a pseudodenormal. */
-			/* This is non-80486 behaviour because the number
-			   loses its 'denormal' identity. */
-			addexponent(x, 1);
-		} else {
-			/* Is a denormal. */
-			addexponent(x, 1);
-			FPU_normalize_nuo(x);
-		}
-	}
-
-	if (!(x->sigh & 0x80000000)) {
-		EXCEPTION(EX_INTERNAL | 0x180);
-	}
-
-	return sign;
-}
diff -rupN a/arch/x86/math-emu/reg_divide.c b/arch/x86/math-emu/reg_divide.c
--- a/arch/x86/math-emu/reg_divide.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_divide.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,183 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  reg_divide.c                                                             |
- |                                                                           |
- | Divide one FPU_REG by another and put the result in a destination FPU_REG.|
- |                                                                           |
- | Copyright (C) 1996                                                        |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@jacobi.maths.monash.edu.au                |
- |                                                                           |
- |    Return value is the tag of the answer, or-ed with FPU_Exception if     |
- |    one was raised, or -1 on internal error.                               |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | The destination may be any FPU_REG, including one of the source FPU_REGs. |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "reg_constant.h"
-#include "fpu_emu.h"
-#include "fpu_system.h"
-
-/*
-  Divide one register by another and put the result into a third register.
-  */
-int FPU_div(int flags, int rm, int control_w)
-{
-	FPU_REG x, y;
-	FPU_REG const *a, *b, *st0_ptr, *st_ptr;
-	FPU_REG *dest;
-	u_char taga, tagb, signa, signb, sign, saved_sign;
-	int tag, deststnr;
-
-	if (flags & DEST_RM)
-		deststnr = rm;
-	else
-		deststnr = 0;
-
-	if (flags & REV) {
-		b = &st(0);
-		st0_ptr = b;
-		tagb = FPU_gettag0();
-		if (flags & LOADED) {
-			a = (FPU_REG *) rm;
-			taga = flags & 0x0f;
-		} else {
-			a = &st(rm);
-			st_ptr = a;
-			taga = FPU_gettagi(rm);
-		}
-	} else {
-		a = &st(0);
-		st0_ptr = a;
-		taga = FPU_gettag0();
-		if (flags & LOADED) {
-			b = (FPU_REG *) rm;
-			tagb = flags & 0x0f;
-		} else {
-			b = &st(rm);
-			st_ptr = b;
-			tagb = FPU_gettagi(rm);
-		}
-	}
-
-	signa = getsign(a);
-	signb = getsign(b);
-
-	sign = signa ^ signb;
-
-	dest = &st(deststnr);
-	saved_sign = getsign(dest);
-
-	if (!(taga | tagb)) {
-		/* Both regs Valid, this should be the most common case. */
-		reg_copy(a, &x);
-		reg_copy(b, &y);
-		setpositive(&x);
-		setpositive(&y);
-		tag = FPU_u_div(&x, &y, dest, control_w, sign);
-
-		if (tag < 0)
-			return tag;
-
-		FPU_settagi(deststnr, tag);
-		return tag;
-	}
-
-	if (taga == TAG_Special)
-		taga = FPU_Special(a);
-	if (tagb == TAG_Special)
-		tagb = FPU_Special(b);
-
-	if (((taga == TAG_Valid) && (tagb == TW_Denormal))
-	    || ((taga == TW_Denormal) && (tagb == TAG_Valid))
-	    || ((taga == TW_Denormal) && (tagb == TW_Denormal))) {
-		if (denormal_operand() < 0)
-			return FPU_Exception;
-
-		FPU_to_exp16(a, &x);
-		FPU_to_exp16(b, &y);
-		tag = FPU_u_div(&x, &y, dest, control_w, sign);
-		if (tag < 0)
-			return tag;
-
-		FPU_settagi(deststnr, tag);
-		return tag;
-	} else if ((taga <= TW_Denormal) && (tagb <= TW_Denormal)) {
-		if (tagb != TAG_Zero) {
-			/* Want to find Zero/Valid */
-			if (tagb == TW_Denormal) {
-				if (denormal_operand() < 0)
-					return FPU_Exception;
-			}
-
-			/* The result is zero. */
-			FPU_copy_to_regi(&CONST_Z, TAG_Zero, deststnr);
-			setsign(dest, sign);
-			return TAG_Zero;
-		}
-		/* We have an exception condition, either 0/0 or Valid/Zero. */
-		if (taga == TAG_Zero) {
-			/* 0/0 */
-			return arith_invalid(deststnr);
-		}
-		/* Valid/Zero */
-		return FPU_divide_by_zero(deststnr, sign);
-	}
-	/* Must have infinities, NaNs, etc */
-	else if ((taga == TW_NaN) || (tagb == TW_NaN)) {
-		if (flags & LOADED)
-			return real_2op_NaN((FPU_REG *) rm, flags & 0x0f, 0,
-					    st0_ptr);
-
-		if (flags & DEST_RM) {
-			int tag;
-			tag = FPU_gettag0();
-			if (tag == TAG_Special)
-				tag = FPU_Special(st0_ptr);
-			return real_2op_NaN(st0_ptr, tag, rm,
-					    (flags & REV) ? st0_ptr : &st(rm));
-		} else {
-			int tag;
-			tag = FPU_gettagi(rm);
-			if (tag == TAG_Special)
-				tag = FPU_Special(&st(rm));
-			return real_2op_NaN(&st(rm), tag, 0,
-					    (flags & REV) ? st0_ptr : &st(rm));
-		}
-	} else if (taga == TW_Infinity) {
-		if (tagb == TW_Infinity) {
-			/* infinity/infinity */
-			return arith_invalid(deststnr);
-		} else {
-			/* tagb must be Valid or Zero */
-			if ((tagb == TW_Denormal) && (denormal_operand() < 0))
-				return FPU_Exception;
-
-			/* Infinity divided by Zero or Valid does
-			   not raise and exception, but returns Infinity */
-			FPU_copy_to_regi(a, TAG_Special, deststnr);
-			setsign(dest, sign);
-			return taga;
-		}
-	} else if (tagb == TW_Infinity) {
-		if ((taga == TW_Denormal) && (denormal_operand() < 0))
-			return FPU_Exception;
-
-		/* The result is zero. */
-		FPU_copy_to_regi(&CONST_Z, TAG_Zero, deststnr);
-		setsign(dest, sign);
-		return TAG_Zero;
-	}
-#ifdef PARANOID
-	else {
-		EXCEPTION(EX_INTERNAL | 0x102);
-		return FPU_Exception;
-	}
-#endif /* PARANOID */
-
-	return 0;
-}
diff -rupN a/arch/x86/math-emu/reg_ld_str.c b/arch/x86/math-emu/reg_ld_str.c
--- a/arch/x86/math-emu/reg_ld_str.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_ld_str.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,1220 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  reg_ld_str.c                                                             |
- |                                                                           |
- | All of the functions which transfer data between user memory and FPU_REGs.|
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1996,1997                                    |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | Note:                                                                     |
- |    The file contains code which accesses user memory.                     |
- |    Emulator static data may change when user memory is accessed, due to   |
- |    other processes using the emulator while swapping is in progress.      |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_emu.h"
-
-#include <linux/uaccess.h>
-
-#include "fpu_system.h"
-#include "exception.h"
-#include "reg_constant.h"
-#include "control_w.h"
-#include "status_w.h"
-
-#define DOUBLE_Emax 1023	/* largest valid exponent */
-#define DOUBLE_Ebias 1023
-#define DOUBLE_Emin (-1022)	/* smallest valid exponent */
-
-#define SINGLE_Emax 127		/* largest valid exponent */
-#define SINGLE_Ebias 127
-#define SINGLE_Emin (-126)	/* smallest valid exponent */
-
-static u_char normalize_no_excep(FPU_REG *r, int exp, int sign)
-{
-	u_char tag;
-
-	setexponent16(r, exp);
-
-	tag = FPU_normalize_nuo(r);
-	stdexp(r);
-	if (sign)
-		setnegative(r);
-
-	return tag;
-}
-
-int FPU_tagof(FPU_REG *ptr)
-{
-	int exp;
-
-	exp = exponent16(ptr) & 0x7fff;
-	if (exp == 0) {
-		if (!(ptr->sigh | ptr->sigl)) {
-			return TAG_Zero;
-		}
-		/* The number is a de-normal or pseudodenormal. */
-		return TAG_Special;
-	}
-
-	if (exp == 0x7fff) {
-		/* Is an Infinity, a NaN, or an unsupported data type. */
-		return TAG_Special;
-	}
-
-	if (!(ptr->sigh & 0x80000000)) {
-		/* Unsupported data type. */
-		/* Valid numbers have the ms bit set to 1. */
-		/* Unnormal. */
-		return TAG_Special;
-	}
-
-	return TAG_Valid;
-}
-
-/* Get a long double from user memory */
-int FPU_load_extended(long double __user *s, int stnr)
-{
-	FPU_REG *sti_ptr = &st(stnr);
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(s, 10);
-	FPU_copy_from_user(sti_ptr, s, 10);
-	RE_ENTRANT_CHECK_ON;
-
-	return FPU_tagof(sti_ptr);
-}
-
-/* Get a double from user memory */
-int FPU_load_double(double __user *dfloat, FPU_REG *loaded_data)
-{
-	int exp, tag, negative;
-	unsigned m64, l64;
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(dfloat, 8);
-	FPU_get_user(m64, 1 + (unsigned long __user *)dfloat);
-	FPU_get_user(l64, (unsigned long __user *)dfloat);
-	RE_ENTRANT_CHECK_ON;
-
-	negative = (m64 & 0x80000000) ? SIGN_Negative : SIGN_Positive;
-	exp = ((m64 & 0x7ff00000) >> 20) - DOUBLE_Ebias + EXTENDED_Ebias;
-	m64 &= 0xfffff;
-	if (exp > DOUBLE_Emax + EXTENDED_Ebias) {
-		/* Infinity or NaN */
-		if ((m64 == 0) && (l64 == 0)) {
-			/* +- infinity */
-			loaded_data->sigh = 0x80000000;
-			loaded_data->sigl = 0x00000000;
-			exp = EXP_Infinity + EXTENDED_Ebias;
-			tag = TAG_Special;
-		} else {
-			/* Must be a signaling or quiet NaN */
-			exp = EXP_NaN + EXTENDED_Ebias;
-			loaded_data->sigh = (m64 << 11) | 0x80000000;
-			loaded_data->sigh |= l64 >> 21;
-			loaded_data->sigl = l64 << 11;
-			tag = TAG_Special;	/* The calling function must look for NaNs */
-		}
-	} else if (exp < DOUBLE_Emin + EXTENDED_Ebias) {
-		/* Zero or de-normal */
-		if ((m64 == 0) && (l64 == 0)) {
-			/* Zero */
-			reg_copy(&CONST_Z, loaded_data);
-			exp = 0;
-			tag = TAG_Zero;
-		} else {
-			/* De-normal */
-			loaded_data->sigh = m64 << 11;
-			loaded_data->sigh |= l64 >> 21;
-			loaded_data->sigl = l64 << 11;
-
-			return normalize_no_excep(loaded_data, DOUBLE_Emin,
-						  negative)
-			    | (denormal_operand() < 0 ? FPU_Exception : 0);
-		}
-	} else {
-		loaded_data->sigh = (m64 << 11) | 0x80000000;
-		loaded_data->sigh |= l64 >> 21;
-		loaded_data->sigl = l64 << 11;
-
-		tag = TAG_Valid;
-	}
-
-	setexponent16(loaded_data, exp | negative);
-
-	return tag;
-}
-
-/* Get a float from user memory */
-int FPU_load_single(float __user *single, FPU_REG *loaded_data)
-{
-	unsigned m32;
-	int exp, tag, negative;
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(single, 4);
-	FPU_get_user(m32, (unsigned long __user *)single);
-	RE_ENTRANT_CHECK_ON;
-
-	negative = (m32 & 0x80000000) ? SIGN_Negative : SIGN_Positive;
-
-	if (!(m32 & 0x7fffffff)) {
-		/* Zero */
-		reg_copy(&CONST_Z, loaded_data);
-		addexponent(loaded_data, negative);
-		return TAG_Zero;
-	}
-	exp = ((m32 & 0x7f800000) >> 23) - SINGLE_Ebias + EXTENDED_Ebias;
-	m32 = (m32 & 0x7fffff) << 8;
-	if (exp < SINGLE_Emin + EXTENDED_Ebias) {
-		/* De-normals */
-		loaded_data->sigh = m32;
-		loaded_data->sigl = 0;
-
-		return normalize_no_excep(loaded_data, SINGLE_Emin, negative)
-		    | (denormal_operand() < 0 ? FPU_Exception : 0);
-	} else if (exp > SINGLE_Emax + EXTENDED_Ebias) {
-		/* Infinity or NaN */
-		if (m32 == 0) {
-			/* +- infinity */
-			loaded_data->sigh = 0x80000000;
-			loaded_data->sigl = 0x00000000;
-			exp = EXP_Infinity + EXTENDED_Ebias;
-			tag = TAG_Special;
-		} else {
-			/* Must be a signaling or quiet NaN */
-			exp = EXP_NaN + EXTENDED_Ebias;
-			loaded_data->sigh = m32 | 0x80000000;
-			loaded_data->sigl = 0;
-			tag = TAG_Special;	/* The calling function must look for NaNs */
-		}
-	} else {
-		loaded_data->sigh = m32 | 0x80000000;
-		loaded_data->sigl = 0;
-		tag = TAG_Valid;
-	}
-
-	setexponent16(loaded_data, exp | negative);	/* Set the sign. */
-
-	return tag;
-}
-
-/* Get a long long from user memory */
-int FPU_load_int64(long long __user *_s)
-{
-	long long s;
-	int sign;
-	FPU_REG *st0_ptr = &st(0);
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(_s, 8);
-	if (copy_from_user(&s, _s, 8))
-		FPU_abort;
-	RE_ENTRANT_CHECK_ON;
-
-	if (s == 0) {
-		reg_copy(&CONST_Z, st0_ptr);
-		return TAG_Zero;
-	}
-
-	if (s > 0)
-		sign = SIGN_Positive;
-	else {
-		s = -s;
-		sign = SIGN_Negative;
-	}
-
-	significand(st0_ptr) = s;
-
-	return normalize_no_excep(st0_ptr, 63, sign);
-}
-
-/* Get a long from user memory */
-int FPU_load_int32(long __user *_s, FPU_REG *loaded_data)
-{
-	long s;
-	int negative;
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(_s, 4);
-	FPU_get_user(s, _s);
-	RE_ENTRANT_CHECK_ON;
-
-	if (s == 0) {
-		reg_copy(&CONST_Z, loaded_data);
-		return TAG_Zero;
-	}
-
-	if (s > 0)
-		negative = SIGN_Positive;
-	else {
-		s = -s;
-		negative = SIGN_Negative;
-	}
-
-	loaded_data->sigh = s;
-	loaded_data->sigl = 0;
-
-	return normalize_no_excep(loaded_data, 31, negative);
-}
-
-/* Get a short from user memory */
-int FPU_load_int16(short __user *_s, FPU_REG *loaded_data)
-{
-	int s, negative;
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(_s, 2);
-	/* Cast as short to get the sign extended. */
-	FPU_get_user(s, _s);
-	RE_ENTRANT_CHECK_ON;
-
-	if (s == 0) {
-		reg_copy(&CONST_Z, loaded_data);
-		return TAG_Zero;
-	}
-
-	if (s > 0)
-		negative = SIGN_Positive;
-	else {
-		s = -s;
-		negative = SIGN_Negative;
-	}
-
-	loaded_data->sigh = s << 16;
-	loaded_data->sigl = 0;
-
-	return normalize_no_excep(loaded_data, 15, negative);
-}
-
-/* Get a packed bcd array from user memory */
-int FPU_load_bcd(u_char __user *s)
-{
-	FPU_REG *st0_ptr = &st(0);
-	int pos;
-	u_char bcd;
-	long long l = 0;
-	int sign;
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(s, 10);
-	RE_ENTRANT_CHECK_ON;
-	for (pos = 8; pos >= 0; pos--) {
-		l *= 10;
-		RE_ENTRANT_CHECK_OFF;
-		FPU_get_user(bcd, s + pos);
-		RE_ENTRANT_CHECK_ON;
-		l += bcd >> 4;
-		l *= 10;
-		l += bcd & 0x0f;
-	}
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_get_user(sign, s + 9);
-	sign = sign & 0x80 ? SIGN_Negative : SIGN_Positive;
-	RE_ENTRANT_CHECK_ON;
-
-	if (l == 0) {
-		reg_copy(&CONST_Z, st0_ptr);
-		addexponent(st0_ptr, sign);	/* Set the sign. */
-		return TAG_Zero;
-	} else {
-		significand(st0_ptr) = l;
-		return normalize_no_excep(st0_ptr, 63, sign);
-	}
-}
-
-/*===========================================================================*/
-
-/* Put a long double into user memory */
-int FPU_store_extended(FPU_REG *st0_ptr, u_char st0_tag,
-		       long double __user * d)
-{
-	/*
-	   The only exception raised by an attempt to store to an
-	   extended format is the Invalid Stack exception, i.e.
-	   attempting to store from an empty register.
-	 */
-
-	if (st0_tag != TAG_Empty) {
-		RE_ENTRANT_CHECK_OFF;
-		FPU_access_ok(d, 10);
-
-		FPU_put_user(st0_ptr->sigl, (unsigned long __user *)d);
-		FPU_put_user(st0_ptr->sigh,
-			     (unsigned long __user *)((u_char __user *) d + 4));
-		FPU_put_user(exponent16(st0_ptr),
-			     (unsigned short __user *)((u_char __user *) d +
-						       8));
-		RE_ENTRANT_CHECK_ON;
-
-		return 1;
-	}
-
-	/* Empty register (stack underflow) */
-	EXCEPTION(EX_StackUnder);
-	if (control_word & CW_Invalid) {
-		/* The masked response */
-		/* Put out the QNaN indefinite */
-		RE_ENTRANT_CHECK_OFF;
-		FPU_access_ok(d, 10);
-		FPU_put_user(0, (unsigned long __user *)d);
-		FPU_put_user(0xc0000000, 1 + (unsigned long __user *)d);
-		FPU_put_user(0xffff, 4 + (short __user *)d);
-		RE_ENTRANT_CHECK_ON;
-		return 1;
-	} else
-		return 0;
-
-}
-
-/* Put a double into user memory */
-int FPU_store_double(FPU_REG *st0_ptr, u_char st0_tag, double __user *dfloat)
-{
-	unsigned long l[2];
-	unsigned long increment = 0;	/* avoid gcc warnings */
-	int precision_loss;
-	int exp;
-	FPU_REG tmp;
-
-	l[0] = 0;
-	l[1] = 0;
-	if (st0_tag == TAG_Valid) {
-		reg_copy(st0_ptr, &tmp);
-		exp = exponent(&tmp);
-
-		if (exp < DOUBLE_Emin) {	/* It may be a denormal */
-			addexponent(&tmp, -DOUBLE_Emin + 52);	/* largest exp to be 51 */
-denormal_arg:
-			if ((precision_loss = FPU_round_to_int(&tmp, st0_tag))) {
-#ifdef PECULIAR_486
-				/* Did it round to a non-denormal ? */
-				/* This behaviour might be regarded as peculiar, it appears
-				   that the 80486 rounds to the dest precision, then
-				   converts to decide underflow. */
-				if (!
-				    ((tmp.sigh == 0x00100000) && (tmp.sigl == 0)
-				     && (st0_ptr->sigl & 0x000007ff)))
-#endif /* PECULIAR_486 */
-				{
-					EXCEPTION(EX_Underflow);
-					/* This is a special case: see sec 16.2.5.1 of
-					   the 80486 book */
-					if (!(control_word & CW_Underflow))
-						return 0;
-				}
-				EXCEPTION(precision_loss);
-				if (!(control_word & CW_Precision))
-					return 0;
-			}
-			l[0] = tmp.sigl;
-			l[1] = tmp.sigh;
-		} else {
-			if (tmp.sigl & 0x000007ff) {
-				precision_loss = 1;
-				switch (control_word & CW_RC) {
-				case RC_RND:
-					/* Rounding can get a little messy.. */
-					increment = ((tmp.sigl & 0x7ff) > 0x400) |	/* nearest */
-					    ((tmp.sigl & 0xc00) == 0xc00);	/* odd -> even */
-					break;
-				case RC_DOWN:	/* towards -infinity */
-					increment =
-					    signpositive(&tmp) ? 0 : tmp.
-					    sigl & 0x7ff;
-					break;
-				case RC_UP:	/* towards +infinity */
-					increment =
-					    signpositive(&tmp) ? tmp.
-					    sigl & 0x7ff : 0;
-					break;
-				case RC_CHOP:
-					increment = 0;
-					break;
-				}
-
-				/* Truncate the mantissa */
-				tmp.sigl &= 0xfffff800;
-
-				if (increment) {
-					if (tmp.sigl >= 0xfffff800) {
-						/* the sigl part overflows */
-						if (tmp.sigh == 0xffffffff) {
-							/* The sigh part overflows */
-							tmp.sigh = 0x80000000;
-							exp++;
-							if (exp >= EXP_OVER)
-								goto overflow;
-						} else {
-							tmp.sigh++;
-						}
-						tmp.sigl = 0x00000000;
-					} else {
-						/* We only need to increment sigl */
-						tmp.sigl += 0x00000800;
-					}
-				}
-			} else
-				precision_loss = 0;
-
-			l[0] = (tmp.sigl >> 11) | (tmp.sigh << 21);
-			l[1] = ((tmp.sigh >> 11) & 0xfffff);
-
-			if (exp > DOUBLE_Emax) {
-			      overflow:
-				EXCEPTION(EX_Overflow);
-				if (!(control_word & CW_Overflow))
-					return 0;
-				set_precision_flag_up();
-				if (!(control_word & CW_Precision))
-					return 0;
-
-				/* This is a special case: see sec 16.2.5.1 of the 80486 book */
-				/* Overflow to infinity */
-				l[1] = 0x7ff00000;	/* Set to + INF */
-			} else {
-				if (precision_loss) {
-					if (increment)
-						set_precision_flag_up();
-					else
-						set_precision_flag_down();
-				}
-				/* Add the exponent */
-				l[1] |= (((exp + DOUBLE_Ebias) & 0x7ff) << 20);
-			}
-		}
-	} else if (st0_tag == TAG_Zero) {
-		/* Number is zero */
-	} else if (st0_tag == TAG_Special) {
-		st0_tag = FPU_Special(st0_ptr);
-		if (st0_tag == TW_Denormal) {
-			/* A denormal will always underflow. */
-#ifndef PECULIAR_486
-			/* An 80486 is supposed to be able to generate
-			   a denormal exception here, but... */
-			/* Underflow has priority. */
-			if (control_word & CW_Underflow)
-				denormal_operand();
-#endif /* PECULIAR_486 */
-			reg_copy(st0_ptr, &tmp);
-			goto denormal_arg;
-		} else if (st0_tag == TW_Infinity) {
-			l[1] = 0x7ff00000;
-		} else if (st0_tag == TW_NaN) {
-			/* Is it really a NaN ? */
-			if ((exponent(st0_ptr) == EXP_OVER)
-			    && (st0_ptr->sigh & 0x80000000)) {
-				/* See if we can get a valid NaN from the FPU_REG */
-				l[0] =
-				    (st0_ptr->sigl >> 11) | (st0_ptr->
-							     sigh << 21);
-				l[1] = ((st0_ptr->sigh >> 11) & 0xfffff);
-				if (!(st0_ptr->sigh & 0x40000000)) {
-					/* It is a signalling NaN */
-					EXCEPTION(EX_Invalid);
-					if (!(control_word & CW_Invalid))
-						return 0;
-					l[1] |= (0x40000000 >> 11);
-				}
-				l[1] |= 0x7ff00000;
-			} else {
-				/* It is an unsupported data type */
-				EXCEPTION(EX_Invalid);
-				if (!(control_word & CW_Invalid))
-					return 0;
-				l[1] = 0xfff80000;
-			}
-		}
-	} else if (st0_tag == TAG_Empty) {
-		/* Empty register (stack underflow) */
-		EXCEPTION(EX_StackUnder);
-		if (control_word & CW_Invalid) {
-			/* The masked response */
-			/* Put out the QNaN indefinite */
-			RE_ENTRANT_CHECK_OFF;
-			FPU_access_ok(dfloat, 8);
-			FPU_put_user(0, (unsigned long __user *)dfloat);
-			FPU_put_user(0xfff80000,
-				     1 + (unsigned long __user *)dfloat);
-			RE_ENTRANT_CHECK_ON;
-			return 1;
-		} else
-			return 0;
-	}
-	if (getsign(st0_ptr))
-		l[1] |= 0x80000000;
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(dfloat, 8);
-	FPU_put_user(l[0], (unsigned long __user *)dfloat);
-	FPU_put_user(l[1], 1 + (unsigned long __user *)dfloat);
-	RE_ENTRANT_CHECK_ON;
-
-	return 1;
-}
-
-/* Put a float into user memory */
-int FPU_store_single(FPU_REG *st0_ptr, u_char st0_tag, float __user *single)
-{
-	long templ = 0;
-	unsigned long increment = 0;	/* avoid gcc warnings */
-	int precision_loss;
-	int exp;
-	FPU_REG tmp;
-
-	if (st0_tag == TAG_Valid) {
-
-		reg_copy(st0_ptr, &tmp);
-		exp = exponent(&tmp);
-
-		if (exp < SINGLE_Emin) {
-			addexponent(&tmp, -SINGLE_Emin + 23);	/* largest exp to be 22 */
-
-		      denormal_arg:
-
-			if ((precision_loss = FPU_round_to_int(&tmp, st0_tag))) {
-#ifdef PECULIAR_486
-				/* Did it round to a non-denormal ? */
-				/* This behaviour might be regarded as peculiar, it appears
-				   that the 80486 rounds to the dest precision, then
-				   converts to decide underflow. */
-				if (!((tmp.sigl == 0x00800000) &&
-				      ((st0_ptr->sigh & 0x000000ff)
-				       || st0_ptr->sigl)))
-#endif /* PECULIAR_486 */
-				{
-					EXCEPTION(EX_Underflow);
-					/* This is a special case: see sec 16.2.5.1 of
-					   the 80486 book */
-					if (!(control_word & CW_Underflow))
-						return 0;
-				}
-				EXCEPTION(precision_loss);
-				if (!(control_word & CW_Precision))
-					return 0;
-			}
-			templ = tmp.sigl;
-		} else {
-			if (tmp.sigl | (tmp.sigh & 0x000000ff)) {
-				unsigned long sigh = tmp.sigh;
-				unsigned long sigl = tmp.sigl;
-
-				precision_loss = 1;
-				switch (control_word & CW_RC) {
-				case RC_RND:
-					increment = ((sigh & 0xff) > 0x80)	/* more than half */
-					    ||(((sigh & 0xff) == 0x80) && sigl)	/* more than half */
-					    ||((sigh & 0x180) == 0x180);	/* round to even */
-					break;
-				case RC_DOWN:	/* towards -infinity */
-					increment = signpositive(&tmp)
-					    ? 0 : (sigl | (sigh & 0xff));
-					break;
-				case RC_UP:	/* towards +infinity */
-					increment = signpositive(&tmp)
-					    ? (sigl | (sigh & 0xff)) : 0;
-					break;
-				case RC_CHOP:
-					increment = 0;
-					break;
-				}
-
-				/* Truncate part of the mantissa */
-				tmp.sigl = 0;
-
-				if (increment) {
-					if (sigh >= 0xffffff00) {
-						/* The sigh part overflows */
-						tmp.sigh = 0x80000000;
-						exp++;
-						if (exp >= EXP_OVER)
-							goto overflow;
-					} else {
-						tmp.sigh &= 0xffffff00;
-						tmp.sigh += 0x100;
-					}
-				} else {
-					tmp.sigh &= 0xffffff00;	/* Finish the truncation */
-				}
-			} else
-				precision_loss = 0;
-
-			templ = (tmp.sigh >> 8) & 0x007fffff;
-
-			if (exp > SINGLE_Emax) {
-			      overflow:
-				EXCEPTION(EX_Overflow);
-				if (!(control_word & CW_Overflow))
-					return 0;
-				set_precision_flag_up();
-				if (!(control_word & CW_Precision))
-					return 0;
-
-				/* This is a special case: see sec 16.2.5.1 of the 80486 book. */
-				/* Masked response is overflow to infinity. */
-				templ = 0x7f800000;
-			} else {
-				if (precision_loss) {
-					if (increment)
-						set_precision_flag_up();
-					else
-						set_precision_flag_down();
-				}
-				/* Add the exponent */
-				templ |= ((exp + SINGLE_Ebias) & 0xff) << 23;
-			}
-		}
-	} else if (st0_tag == TAG_Zero) {
-		templ = 0;
-	} else if (st0_tag == TAG_Special) {
-		st0_tag = FPU_Special(st0_ptr);
-		if (st0_tag == TW_Denormal) {
-			reg_copy(st0_ptr, &tmp);
-
-			/* A denormal will always underflow. */
-#ifndef PECULIAR_486
-			/* An 80486 is supposed to be able to generate
-			   a denormal exception here, but... */
-			/* Underflow has priority. */
-			if (control_word & CW_Underflow)
-				denormal_operand();
-#endif /* PECULIAR_486 */
-			goto denormal_arg;
-		} else if (st0_tag == TW_Infinity) {
-			templ = 0x7f800000;
-		} else if (st0_tag == TW_NaN) {
-			/* Is it really a NaN ? */
-			if ((exponent(st0_ptr) == EXP_OVER)
-			    && (st0_ptr->sigh & 0x80000000)) {
-				/* See if we can get a valid NaN from the FPU_REG */
-				templ = st0_ptr->sigh >> 8;
-				if (!(st0_ptr->sigh & 0x40000000)) {
-					/* It is a signalling NaN */
-					EXCEPTION(EX_Invalid);
-					if (!(control_word & CW_Invalid))
-						return 0;
-					templ |= (0x40000000 >> 8);
-				}
-				templ |= 0x7f800000;
-			} else {
-				/* It is an unsupported data type */
-				EXCEPTION(EX_Invalid);
-				if (!(control_word & CW_Invalid))
-					return 0;
-				templ = 0xffc00000;
-			}
-		}
-#ifdef PARANOID
-		else {
-			EXCEPTION(EX_INTERNAL | 0x164);
-			return 0;
-		}
-#endif
-	} else if (st0_tag == TAG_Empty) {
-		/* Empty register (stack underflow) */
-		EXCEPTION(EX_StackUnder);
-		if (control_word & EX_Invalid) {
-			/* The masked response */
-			/* Put out the QNaN indefinite */
-			RE_ENTRANT_CHECK_OFF;
-			FPU_access_ok(single, 4);
-			FPU_put_user(0xffc00000,
-				     (unsigned long __user *)single);
-			RE_ENTRANT_CHECK_ON;
-			return 1;
-		} else
-			return 0;
-	}
-#ifdef PARANOID
-	else {
-		EXCEPTION(EX_INTERNAL | 0x163);
-		return 0;
-	}
-#endif
-	if (getsign(st0_ptr))
-		templ |= 0x80000000;
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(single, 4);
-	FPU_put_user(templ, (unsigned long __user *)single);
-	RE_ENTRANT_CHECK_ON;
-
-	return 1;
-}
-
-/* Put a long long into user memory */
-int FPU_store_int64(FPU_REG *st0_ptr, u_char st0_tag, long long __user *d)
-{
-	FPU_REG t;
-	long long tll;
-	int precision_loss;
-
-	if (st0_tag == TAG_Empty) {
-		/* Empty register (stack underflow) */
-		EXCEPTION(EX_StackUnder);
-		goto invalid_operand;
-	} else if (st0_tag == TAG_Special) {
-		st0_tag = FPU_Special(st0_ptr);
-		if ((st0_tag == TW_Infinity) || (st0_tag == TW_NaN)) {
-			EXCEPTION(EX_Invalid);
-			goto invalid_operand;
-		}
-	}
-
-	reg_copy(st0_ptr, &t);
-	precision_loss = FPU_round_to_int(&t, st0_tag);
-	((long *)&tll)[0] = t.sigl;
-	((long *)&tll)[1] = t.sigh;
-	if ((precision_loss == 1) ||
-	    ((t.sigh & 0x80000000) &&
-	     !((t.sigh == 0x80000000) && (t.sigl == 0) && signnegative(&t)))) {
-		EXCEPTION(EX_Invalid);
-		/* This is a special case: see sec 16.2.5.1 of the 80486 book */
-	      invalid_operand:
-		if (control_word & EX_Invalid) {
-			/* Produce something like QNaN "indefinite" */
-			tll = 0x8000000000000000LL;
-		} else
-			return 0;
-	} else {
-		if (precision_loss)
-			set_precision_flag(precision_loss);
-		if (signnegative(&t))
-			tll = -tll;
-	}
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(d, 8);
-	if (copy_to_user(d, &tll, 8))
-		FPU_abort;
-	RE_ENTRANT_CHECK_ON;
-
-	return 1;
-}
-
-/* Put a long into user memory */
-int FPU_store_int32(FPU_REG *st0_ptr, u_char st0_tag, long __user *d)
-{
-	FPU_REG t;
-	int precision_loss;
-
-	if (st0_tag == TAG_Empty) {
-		/* Empty register (stack underflow) */
-		EXCEPTION(EX_StackUnder);
-		goto invalid_operand;
-	} else if (st0_tag == TAG_Special) {
-		st0_tag = FPU_Special(st0_ptr);
-		if ((st0_tag == TW_Infinity) || (st0_tag == TW_NaN)) {
-			EXCEPTION(EX_Invalid);
-			goto invalid_operand;
-		}
-	}
-
-	reg_copy(st0_ptr, &t);
-	precision_loss = FPU_round_to_int(&t, st0_tag);
-	if (t.sigh ||
-	    ((t.sigl & 0x80000000) &&
-	     !((t.sigl == 0x80000000) && signnegative(&t)))) {
-		EXCEPTION(EX_Invalid);
-		/* This is a special case: see sec 16.2.5.1 of the 80486 book */
-	      invalid_operand:
-		if (control_word & EX_Invalid) {
-			/* Produce something like QNaN "indefinite" */
-			t.sigl = 0x80000000;
-		} else
-			return 0;
-	} else {
-		if (precision_loss)
-			set_precision_flag(precision_loss);
-		if (signnegative(&t))
-			t.sigl = -(long)t.sigl;
-	}
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(d, 4);
-	FPU_put_user(t.sigl, (unsigned long __user *)d);
-	RE_ENTRANT_CHECK_ON;
-
-	return 1;
-}
-
-/* Put a short into user memory */
-int FPU_store_int16(FPU_REG *st0_ptr, u_char st0_tag, short __user *d)
-{
-	FPU_REG t;
-	int precision_loss;
-
-	if (st0_tag == TAG_Empty) {
-		/* Empty register (stack underflow) */
-		EXCEPTION(EX_StackUnder);
-		goto invalid_operand;
-	} else if (st0_tag == TAG_Special) {
-		st0_tag = FPU_Special(st0_ptr);
-		if ((st0_tag == TW_Infinity) || (st0_tag == TW_NaN)) {
-			EXCEPTION(EX_Invalid);
-			goto invalid_operand;
-		}
-	}
-
-	reg_copy(st0_ptr, &t);
-	precision_loss = FPU_round_to_int(&t, st0_tag);
-	if (t.sigh ||
-	    ((t.sigl & 0xffff8000) &&
-	     !((t.sigl == 0x8000) && signnegative(&t)))) {
-		EXCEPTION(EX_Invalid);
-		/* This is a special case: see sec 16.2.5.1 of the 80486 book */
-	      invalid_operand:
-		if (control_word & EX_Invalid) {
-			/* Produce something like QNaN "indefinite" */
-			t.sigl = 0x8000;
-		} else
-			return 0;
-	} else {
-		if (precision_loss)
-			set_precision_flag(precision_loss);
-		if (signnegative(&t))
-			t.sigl = -t.sigl;
-	}
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(d, 2);
-	FPU_put_user((short)t.sigl, d);
-	RE_ENTRANT_CHECK_ON;
-
-	return 1;
-}
-
-/* Put a packed bcd array into user memory */
-int FPU_store_bcd(FPU_REG *st0_ptr, u_char st0_tag, u_char __user *d)
-{
-	FPU_REG t;
-	unsigned long long ll;
-	u_char b;
-	int i, precision_loss;
-	u_char sign = (getsign(st0_ptr) == SIGN_NEG) ? 0x80 : 0;
-
-	if (st0_tag == TAG_Empty) {
-		/* Empty register (stack underflow) */
-		EXCEPTION(EX_StackUnder);
-		goto invalid_operand;
-	} else if (st0_tag == TAG_Special) {
-		st0_tag = FPU_Special(st0_ptr);
-		if ((st0_tag == TW_Infinity) || (st0_tag == TW_NaN)) {
-			EXCEPTION(EX_Invalid);
-			goto invalid_operand;
-		}
-	}
-
-	reg_copy(st0_ptr, &t);
-	precision_loss = FPU_round_to_int(&t, st0_tag);
-	ll = significand(&t);
-
-	/* Check for overflow, by comparing with 999999999999999999 decimal. */
-	if ((t.sigh > 0x0de0b6b3) ||
-	    ((t.sigh == 0x0de0b6b3) && (t.sigl > 0xa763ffff))) {
-		EXCEPTION(EX_Invalid);
-		/* This is a special case: see sec 16.2.5.1 of the 80486 book */
-	      invalid_operand:
-		if (control_word & CW_Invalid) {
-			/* Produce the QNaN "indefinite" */
-			RE_ENTRANT_CHECK_OFF;
-			FPU_access_ok(d, 10);
-			for (i = 0; i < 7; i++)
-				FPU_put_user(0, d + i);	/* These bytes "undefined" */
-			FPU_put_user(0xc0, d + 7);	/* This byte "undefined" */
-			FPU_put_user(0xff, d + 8);
-			FPU_put_user(0xff, d + 9);
-			RE_ENTRANT_CHECK_ON;
-			return 1;
-		} else
-			return 0;
-	} else if (precision_loss) {
-		/* Precision loss doesn't stop the data transfer */
-		set_precision_flag(precision_loss);
-	}
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(d, 10);
-	RE_ENTRANT_CHECK_ON;
-	for (i = 0; i < 9; i++) {
-		b = FPU_div_small(&ll, 10);
-		b |= (FPU_div_small(&ll, 10)) << 4;
-		RE_ENTRANT_CHECK_OFF;
-		FPU_put_user(b, d + i);
-		RE_ENTRANT_CHECK_ON;
-	}
-	RE_ENTRANT_CHECK_OFF;
-	FPU_put_user(sign, d + 9);
-	RE_ENTRANT_CHECK_ON;
-
-	return 1;
-}
-
-/*===========================================================================*/
-
-/* r gets mangled such that sig is int, sign: 
-   it is NOT normalized */
-/* The return value (in eax) is zero if the result is exact,
-   if bits are changed due to rounding, truncation, etc, then
-   a non-zero value is returned */
-/* Overflow is signaled by a non-zero return value (in eax).
-   In the case of overflow, the returned significand always has the
-   largest possible value */
-int FPU_round_to_int(FPU_REG *r, u_char tag)
-{
-	u_char very_big;
-	unsigned eax;
-
-	if (tag == TAG_Zero) {
-		/* Make sure that zero is returned */
-		significand(r) = 0;
-		return 0;	/* o.k. */
-	}
-
-	if (exponent(r) > 63) {
-		r->sigl = r->sigh = ~0;	/* The largest representable number */
-		return 1;	/* overflow */
-	}
-
-	eax = FPU_shrxs(&r->sigl, 63 - exponent(r));
-	very_big = !(~(r->sigh) | ~(r->sigl));	/* test for 0xfff...fff */
-#define	half_or_more	(eax & 0x80000000)
-#define	frac_part	(eax)
-#define more_than_half  ((eax & 0x80000001) == 0x80000001)
-	switch (control_word & CW_RC) {
-	case RC_RND:
-		if (more_than_half	/* nearest */
-		    || (half_or_more && (r->sigl & 1))) {	/* odd -> even */
-			if (very_big)
-				return 1;	/* overflow */
-			significand(r)++;
-			return PRECISION_LOST_UP;
-		}
-		break;
-	case RC_DOWN:
-		if (frac_part && getsign(r)) {
-			if (very_big)
-				return 1;	/* overflow */
-			significand(r)++;
-			return PRECISION_LOST_UP;
-		}
-		break;
-	case RC_UP:
-		if (frac_part && !getsign(r)) {
-			if (very_big)
-				return 1;	/* overflow */
-			significand(r)++;
-			return PRECISION_LOST_UP;
-		}
-		break;
-	case RC_CHOP:
-		break;
-	}
-
-	return eax ? PRECISION_LOST_DOWN : 0;
-
-}
-
-/*===========================================================================*/
-
-u_char __user *fldenv(fpu_addr_modes addr_modes, u_char __user *s)
-{
-	unsigned short tag_word = 0;
-	u_char tag;
-	int i;
-
-	if ((addr_modes.default_mode == VM86) ||
-	    ((addr_modes.default_mode == PM16)
-	     ^ (addr_modes.override.operand_size == OP_SIZE_PREFIX))) {
-		RE_ENTRANT_CHECK_OFF;
-		FPU_access_ok(s, 0x0e);
-		FPU_get_user(control_word, (unsigned short __user *)s);
-		FPU_get_user(partial_status, (unsigned short __user *)(s + 2));
-		FPU_get_user(tag_word, (unsigned short __user *)(s + 4));
-		FPU_get_user(instruction_address.offset,
-			     (unsigned short __user *)(s + 6));
-		FPU_get_user(instruction_address.selector,
-			     (unsigned short __user *)(s + 8));
-		FPU_get_user(operand_address.offset,
-			     (unsigned short __user *)(s + 0x0a));
-		FPU_get_user(operand_address.selector,
-			     (unsigned short __user *)(s + 0x0c));
-		RE_ENTRANT_CHECK_ON;
-		s += 0x0e;
-		if (addr_modes.default_mode == VM86) {
-			instruction_address.offset
-			    += (instruction_address.selector & 0xf000) << 4;
-			operand_address.offset +=
-			    (operand_address.selector & 0xf000) << 4;
-		}
-	} else {
-		RE_ENTRANT_CHECK_OFF;
-		FPU_access_ok(s, 0x1c);
-		FPU_get_user(control_word, (unsigned short __user *)s);
-		FPU_get_user(partial_status, (unsigned short __user *)(s + 4));
-		FPU_get_user(tag_word, (unsigned short __user *)(s + 8));
-		FPU_get_user(instruction_address.offset,
-			     (unsigned long __user *)(s + 0x0c));
-		FPU_get_user(instruction_address.selector,
-			     (unsigned short __user *)(s + 0x10));
-		FPU_get_user(instruction_address.opcode,
-			     (unsigned short __user *)(s + 0x12));
-		FPU_get_user(operand_address.offset,
-			     (unsigned long __user *)(s + 0x14));
-		FPU_get_user(operand_address.selector,
-			     (unsigned long __user *)(s + 0x18));
-		RE_ENTRANT_CHECK_ON;
-		s += 0x1c;
-	}
-
-#ifdef PECULIAR_486
-	control_word &= ~0xe080;
-#endif /* PECULIAR_486 */
-
-	top = (partial_status >> SW_Top_Shift) & 7;
-
-	if (partial_status & ~control_word & CW_Exceptions)
-		partial_status |= (SW_Summary | SW_Backward);
-	else
-		partial_status &= ~(SW_Summary | SW_Backward);
-
-	for (i = 0; i < 8; i++) {
-		tag = tag_word & 3;
-		tag_word >>= 2;
-
-		if (tag == TAG_Empty)
-			/* New tag is empty.  Accept it */
-			FPU_settag(i, TAG_Empty);
-		else if (FPU_gettag(i) == TAG_Empty) {
-			/* Old tag is empty and new tag is not empty.  New tag is determined
-			   by old reg contents */
-			if (exponent(&fpu_register(i)) == -EXTENDED_Ebias) {
-				if (!
-				    (fpu_register(i).sigl | fpu_register(i).
-				     sigh))
-					FPU_settag(i, TAG_Zero);
-				else
-					FPU_settag(i, TAG_Special);
-			} else if (exponent(&fpu_register(i)) ==
-				   0x7fff - EXTENDED_Ebias) {
-				FPU_settag(i, TAG_Special);
-			} else if (fpu_register(i).sigh & 0x80000000)
-				FPU_settag(i, TAG_Valid);
-			else
-				FPU_settag(i, TAG_Special);	/* An Un-normal */
-		}
-		/* Else old tag is not empty and new tag is not empty.  Old tag
-		   remains correct */
-	}
-
-	return s;
-}
-
-void FPU_frstor(fpu_addr_modes addr_modes, u_char __user *data_address)
-{
-	int i, regnr;
-	u_char __user *s = fldenv(addr_modes, data_address);
-	int offset = (top & 7) * 10, other = 80 - offset;
-
-	/* Copy all registers in stack order. */
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(s, 80);
-	FPU_copy_from_user(register_base + offset, s, other);
-	if (offset)
-		FPU_copy_from_user(register_base, s + other, offset);
-	RE_ENTRANT_CHECK_ON;
-
-	for (i = 0; i < 8; i++) {
-		regnr = (i + top) & 7;
-		if (FPU_gettag(regnr) != TAG_Empty)
-			/* The loaded data over-rides all other cases. */
-			FPU_settag(regnr, FPU_tagof(&st(i)));
-	}
-
-}
-
-u_char __user *fstenv(fpu_addr_modes addr_modes, u_char __user *d)
-{
-	if ((addr_modes.default_mode == VM86) ||
-	    ((addr_modes.default_mode == PM16)
-	     ^ (addr_modes.override.operand_size == OP_SIZE_PREFIX))) {
-		RE_ENTRANT_CHECK_OFF;
-		FPU_access_ok(d, 14);
-#ifdef PECULIAR_486
-		FPU_put_user(control_word & ~0xe080, (unsigned long __user *)d);
-#else
-		FPU_put_user(control_word, (unsigned short __user *)d);
-#endif /* PECULIAR_486 */
-		FPU_put_user(status_word(), (unsigned short __user *)(d + 2));
-		FPU_put_user(fpu_tag_word, (unsigned short __user *)(d + 4));
-		FPU_put_user(instruction_address.offset,
-			     (unsigned short __user *)(d + 6));
-		FPU_put_user(operand_address.offset,
-			     (unsigned short __user *)(d + 0x0a));
-		if (addr_modes.default_mode == VM86) {
-			FPU_put_user((instruction_address.
-				      offset & 0xf0000) >> 4,
-				     (unsigned short __user *)(d + 8));
-			FPU_put_user((operand_address.offset & 0xf0000) >> 4,
-				     (unsigned short __user *)(d + 0x0c));
-		} else {
-			FPU_put_user(instruction_address.selector,
-				     (unsigned short __user *)(d + 8));
-			FPU_put_user(operand_address.selector,
-				     (unsigned short __user *)(d + 0x0c));
-		}
-		RE_ENTRANT_CHECK_ON;
-		d += 0x0e;
-	} else {
-		RE_ENTRANT_CHECK_OFF;
-		FPU_access_ok(d, 7 * 4);
-#ifdef PECULIAR_486
-		control_word &= ~0xe080;
-		/* An 80486 sets nearly all of the reserved bits to 1. */
-		control_word |= 0xffff0040;
-		partial_status = status_word() | 0xffff0000;
-		fpu_tag_word |= 0xffff0000;
-		I387->soft.fcs &= ~0xf8000000;
-		I387->soft.fos |= 0xffff0000;
-#endif /* PECULIAR_486 */
-		if (__copy_to_user(d, &control_word, 7 * 4))
-			FPU_abort;
-		RE_ENTRANT_CHECK_ON;
-		d += 0x1c;
-	}
-
-	control_word |= CW_Exceptions;
-	partial_status &= ~(SW_Summary | SW_Backward);
-
-	return d;
-}
-
-void fsave(fpu_addr_modes addr_modes, u_char __user *data_address)
-{
-	u_char __user *d;
-	int offset = (top & 7) * 10, other = 80 - offset;
-
-	d = fstenv(addr_modes, data_address);
-
-	RE_ENTRANT_CHECK_OFF;
-	FPU_access_ok(d, 80);
-
-	/* Copy all registers in stack order. */
-	if (__copy_to_user(d, register_base + offset, other))
-		FPU_abort;
-	if (offset)
-		if (__copy_to_user(d + other, register_base, offset))
-			FPU_abort;
-	RE_ENTRANT_CHECK_ON;
-
-	finit();
-}
-
-/*===========================================================================*/
diff -rupN a/arch/x86/math-emu/reg_mul.c b/arch/x86/math-emu/reg_mul.c
--- a/arch/x86/math-emu/reg_mul.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_mul.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,116 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*---------------------------------------------------------------------------+
- |  reg_mul.c                                                                |
- |                                                                           |
- | Multiply one FPU_REG by another, put the result in a destination FPU_REG. |
- |                                                                           |
- | Copyright (C) 1992,1993,1997                                              |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- | Returns the tag of the result if no exceptions or errors occurred.        |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | The destination may be any FPU_REG, including one of the source FPU_REGs. |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_emu.h"
-#include "exception.h"
-#include "reg_constant.h"
-#include "fpu_system.h"
-
-/*
-  Multiply two registers to give a register result.
-  The sources are st(deststnr) and (b,tagb,signb).
-  The destination is st(deststnr).
-  */
-/* This routine must be called with non-empty source registers */
-int FPU_mul(FPU_REG const *b, u_char tagb, int deststnr, int control_w)
-{
-	FPU_REG *a = &st(deststnr);
-	FPU_REG *dest = a;
-	u_char taga = FPU_gettagi(deststnr);
-	u_char saved_sign = getsign(dest);
-	u_char sign = (getsign(a) ^ getsign(b));
-	int tag;
-
-	if (!(taga | tagb)) {
-		/* Both regs Valid, this should be the most common case. */
-
-		tag =
-		    FPU_u_mul(a, b, dest, control_w, sign,
-			      exponent(a) + exponent(b));
-		if (tag < 0) {
-			setsign(dest, saved_sign);
-			return tag;
-		}
-		FPU_settagi(deststnr, tag);
-		return tag;
-	}
-
-	if (taga == TAG_Special)
-		taga = FPU_Special(a);
-	if (tagb == TAG_Special)
-		tagb = FPU_Special(b);
-
-	if (((taga == TAG_Valid) && (tagb == TW_Denormal))
-	    || ((taga == TW_Denormal) && (tagb == TAG_Valid))
-	    || ((taga == TW_Denormal) && (tagb == TW_Denormal))) {
-		FPU_REG x, y;
-		if (denormal_operand() < 0)
-			return FPU_Exception;
-
-		FPU_to_exp16(a, &x);
-		FPU_to_exp16(b, &y);
-		tag = FPU_u_mul(&x, &y, dest, control_w, sign,
-				exponent16(&x) + exponent16(&y));
-		if (tag < 0) {
-			setsign(dest, saved_sign);
-			return tag;
-		}
-		FPU_settagi(deststnr, tag);
-		return tag;
-	} else if ((taga <= TW_Denormal) && (tagb <= TW_Denormal)) {
-		if (((tagb == TW_Denormal) || (taga == TW_Denormal))
-		    && (denormal_operand() < 0))
-			return FPU_Exception;
-
-		/* Must have either both arguments == zero, or
-		   one valid and the other zero.
-		   The result is therefore zero. */
-		FPU_copy_to_regi(&CONST_Z, TAG_Zero, deststnr);
-		/* The 80486 book says that the answer is +0, but a real
-		   80486 behaves this way.
-		   IEEE-754 apparently says it should be this way. */
-		setsign(dest, sign);
-		return TAG_Zero;
-	}
-	/* Must have infinities, NaNs, etc */
-	else if ((taga == TW_NaN) || (tagb == TW_NaN)) {
-		return real_2op_NaN(b, tagb, deststnr, &st(0));
-	} else if (((taga == TW_Infinity) && (tagb == TAG_Zero))
-		   || ((tagb == TW_Infinity) && (taga == TAG_Zero))) {
-		return arith_invalid(deststnr);	/* Zero*Infinity is invalid */
-	} else if (((taga == TW_Denormal) || (tagb == TW_Denormal))
-		   && (denormal_operand() < 0)) {
-		return FPU_Exception;
-	} else if (taga == TW_Infinity) {
-		FPU_copy_to_regi(a, TAG_Special, deststnr);
-		setsign(dest, sign);
-		return TAG_Special;
-	} else if (tagb == TW_Infinity) {
-		FPU_copy_to_regi(b, TAG_Special, deststnr);
-		setsign(dest, sign);
-		return TAG_Special;
-	}
-#ifdef PARANOID
-	else {
-		EXCEPTION(EX_INTERNAL | 0x102);
-		return FPU_Exception;
-	}
-#endif /* PARANOID */
-
-	return 0;
-}
diff -rupN a/arch/x86/math-emu/reg_norm.S b/arch/x86/math-emu/reg_norm.S
--- a/arch/x86/math-emu/reg_norm.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_norm.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,150 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  reg_norm.S                                                               |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1995,1997                                    |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@suburbia.net               |
- |                                                                           |
- | Normalize the value in a FPU_REG.                                         |
- |                                                                           |
- | Call from C as:                                                           |
- |    int FPU_normalize(FPU_REG *n)                                          |
- |                                                                           |
- |    int FPU_normalize_nuo(FPU_REG *n)                                      |
- |                                                                           |
- |    Return value is the tag of the answer, or-ed with FPU_Exception if     |
- |    one was raised, or -1 on internal error.                               |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_emu.h"
-
-
-.text
-SYM_FUNC_START(FPU_normalize)
-	pushl	%ebp
-	movl	%esp,%ebp
-	pushl	%ebx
-
-	movl	PARAM1,%ebx
-
-	movl	SIGH(%ebx),%edx
-	movl	SIGL(%ebx),%eax
-
-	orl	%edx,%edx	/* ms bits */
-	js	L_done		/* Already normalized */
-	jnz	L_shift_1	/* Shift left 1 - 31 bits */
-
-	orl	%eax,%eax
-	jz	L_zero		/* The contents are zero */
-
-	movl	%eax,%edx
-	xorl	%eax,%eax
-	subw	$32,EXP(%ebx)	/* This can cause an underflow */
-
-/* We need to shift left by 1 - 31 bits */
-L_shift_1:
-	bsrl	%edx,%ecx	/* get the required shift in %ecx */
-	subl	$31,%ecx
-	negl	%ecx
-	shld	%cl,%eax,%edx
-	shl	%cl,%eax
-	subw	%cx,EXP(%ebx)	/* This can cause an underflow */
-
-	movl	%edx,SIGH(%ebx)
-	movl	%eax,SIGL(%ebx)
-
-L_done:
-	cmpw	EXP_OVER,EXP(%ebx)
-	jge	L_overflow
-
-	cmpw	EXP_UNDER,EXP(%ebx)
-	jle	L_underflow
-
-L_exit_valid:
-	movl	TAG_Valid,%eax
-
-	/* Convert the exponent to 80x87 form. */
-	addw	EXTENDED_Ebias,EXP(%ebx)
-	andw	$0x7fff,EXP(%ebx)
-
-L_exit:
-	popl	%ebx
-	leave
-	RET
-
-
-L_zero:
-	movw	$0,EXP(%ebx)
-	movl	TAG_Zero,%eax
-	jmp	L_exit
-
-L_underflow:
-	/* Convert the exponent to 80x87 form. */
-	addw	EXTENDED_Ebias,EXP(%ebx)
-	push	%ebx
-	call	arith_underflow
-	pop	%ebx
-	jmp	L_exit
-
-L_overflow:
-	/* Convert the exponent to 80x87 form. */
-	addw	EXTENDED_Ebias,EXP(%ebx)
-	push	%ebx
-	call	arith_overflow
-	pop	%ebx
-	jmp	L_exit
-SYM_FUNC_END(FPU_normalize)
-
-
-
-/* Normalise without reporting underflow or overflow */
-SYM_FUNC_START(FPU_normalize_nuo)
-	pushl	%ebp
-	movl	%esp,%ebp
-	pushl	%ebx
-
-	movl	PARAM1,%ebx
-
-	movl	SIGH(%ebx),%edx
-	movl	SIGL(%ebx),%eax
-
-	orl	%edx,%edx	/* ms bits */
-	js	L_exit_nuo_valid	/* Already normalized */
-	jnz	L_nuo_shift_1	/* Shift left 1 - 31 bits */
-
-	orl	%eax,%eax
-	jz	L_exit_nuo_zero		/* The contents are zero */
-
-	movl	%eax,%edx
-	xorl	%eax,%eax
-	subw	$32,EXP(%ebx)	/* This can cause an underflow */
-
-/* We need to shift left by 1 - 31 bits */
-L_nuo_shift_1:
-	bsrl	%edx,%ecx	/* get the required shift in %ecx */
-	subl	$31,%ecx
-	negl	%ecx
-	shld	%cl,%eax,%edx
-	shl	%cl,%eax
-	subw	%cx,EXP(%ebx)	/* This can cause an underflow */
-
-	movl	%edx,SIGH(%ebx)
-	movl	%eax,SIGL(%ebx)
-
-L_exit_nuo_valid:
-	movl	TAG_Valid,%eax
-
-	popl	%ebx
-	leave
-	RET
-
-L_exit_nuo_zero:
-	movl	TAG_Zero,%eax
-	movw	EXP_UNDER,EXP(%ebx)
-
-	popl	%ebx
-	leave
-	RET
-SYM_FUNC_END(FPU_normalize_nuo)
diff -rupN a/arch/x86/math-emu/reg_round.S b/arch/x86/math-emu/reg_round.S
--- a/arch/x86/math-emu/reg_round.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_round.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,711 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-	.file "reg_round.S"
-/*---------------------------------------------------------------------------+
- |  reg_round.S                                                              |
- |                                                                           |
- | Rounding/truncation/etc for FPU basic arithmetic functions.               |
- |                                                                           |
- | Copyright (C) 1993,1995,1997                                              |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@suburbia.net               |
- |                                                                           |
- | This code has four possible entry points.                                 |
- | The following must be entered by a jmp instruction:                       |
- |   fpu_reg_round, fpu_reg_round_sqrt, and fpu_Arith_exit.                  |
- |                                                                           |
- | The FPU_round entry point is intended to be used by C code.               |
- | From C, call as:                                                          |
- |  int FPU_round(FPU_REG *arg, unsigned int extent, unsigned int control_w) |
- |                                                                           |
- |    Return value is the tag of the answer, or-ed with FPU_Exception if     |
- |    one was raised, or -1 on internal error.                               |
- |                                                                           |
- | For correct "up" and "down" rounding, the argument must have the correct  |
- | sign.                                                                     |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | Four entry points.                                                        |
- |                                                                           |
- | Needed by both the fpu_reg_round and fpu_reg_round_sqrt entry points:     |
- |  %eax:%ebx  64 bit significand                                            |
- |  %edx       32 bit extension of the significand                           |
- |  %edi       pointer to an FPU_REG for the result to be stored             |
- |  stack      calling function must have set up a C stack frame and         |
- |             pushed %esi, %edi, and %ebx                                   |
- |                                                                           |
- | Needed just for the fpu_reg_round_sqrt entry point:                       |
- |  %cx  A control word in the same format as the FPU control word.          |
- | Otherwise, PARAM4 must give such a value.                                 |
- |                                                                           |
- |                                                                           |
- | The significand and its extension are assumed to be exact in the          |
- | following sense:                                                          |
- |   If the significand by itself is the exact result then the significand   |
- |   extension (%edx) must contain 0, otherwise the significand extension    |
- |   must be non-zero.                                                       |
- |   If the significand extension is non-zero then the significand is        |
- |   smaller than the magnitude of the correct exact result by an amount     |
- |   greater than zero and less than one ls bit of the significand.          |
- |   The significand extension is only required to have three possible       |
- |   non-zero values:                                                        |
- |       less than 0x80000000  <=> the significand is less than 1/2 an ls    |
- |                                 bit smaller than the magnitude of the     |
- |                                 true exact result.                        |
- |         exactly 0x80000000  <=> the significand is exactly 1/2 an ls bit  |
- |                                 smaller than the magnitude of the true    |
- |                                 exact result.                             |
- |    greater than 0x80000000  <=> the significand is more than 1/2 an ls    |
- |                                 bit smaller than the magnitude of the     |
- |                                 true exact result.                        |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- |  The code in this module has become quite complex, but it should handle   |
- |  all of the FPU flags which are set at this stage of the basic arithmetic |
- |  computations.                                                            |
- |  There are a few rare cases where the results are not set identically to  |
- |  a real FPU. These require a bit more thought because at this stage the   |
- |  results of the code here appear to be more consistent...                 |
- |  This may be changed in a future version.                                 |
- +---------------------------------------------------------------------------*/
-
-
-#include "fpu_emu.h"
-#include "exception.h"
-#include "control_w.h"
-
-/* Flags for FPU_bits_lost */
-#define	LOST_DOWN	$1
-#define	LOST_UP		$2
-
-/* Flags for FPU_denormal */
-#define	DENORMAL	$1
-#define	UNMASKED_UNDERFLOW $2
-
-
-#ifndef NON_REENTRANT_FPU
-/*	Make the code re-entrant by putting
-	local storage on the stack: */
-#define FPU_bits_lost	(%esp)
-#define FPU_denormal	1(%esp)
-
-#else
-/*	Not re-entrant, so we can gain speed by putting
-	local storage in a static area: */
-.data
-	.align 4,0
-FPU_bits_lost:
-	.byte	0
-FPU_denormal:
-	.byte	0
-#endif /* NON_REENTRANT_FPU */
-
-
-.text
-.globl fpu_reg_round
-.globl fpu_Arith_exit
-
-/* Entry point when called from C */
-SYM_FUNC_START(FPU_round)
-	pushl	%ebp
-	movl	%esp,%ebp
-	pushl	%esi
-	pushl	%edi
-	pushl	%ebx
-
-	movl	PARAM1,%edi
-	movl	SIGH(%edi),%eax
-	movl	SIGL(%edi),%ebx
-	movl	PARAM2,%edx
-
-fpu_reg_round:			/* Normal entry point */
-	movl	PARAM4,%ecx
-
-#ifndef NON_REENTRANT_FPU
-	pushl	%ebx		/* adjust the stack pointer */
-#endif /* NON_REENTRANT_FPU */ 
-
-#ifdef PARANOID
-/* Cannot use this here yet */
-/*	orl	%eax,%eax */
-/*	jns	L_entry_bugged */
-#endif /* PARANOID */
-
-	cmpw	EXP_UNDER,EXP(%edi)
-	jle	L_Make_denorm			/* The number is a de-normal */
-
-	movb	$0,FPU_denormal			/* 0 -> not a de-normal */
-
-Denorm_done:
-	movb	$0,FPU_bits_lost		/* No bits yet lost in rounding */
-
-	movl	%ecx,%esi
-	andl	CW_PC,%ecx
-	cmpl	PR_64_BITS,%ecx
-	je	LRound_To_64
-
-	cmpl	PR_53_BITS,%ecx
-	je	LRound_To_53
-
-	cmpl	PR_24_BITS,%ecx
-	je	LRound_To_24
-
-#ifdef PECULIAR_486
-/* With the precision control bits set to 01 "(reserved)", a real 80486
-   behaves as if the precision control bits were set to 11 "64 bits" */
-	cmpl	PR_RESERVED_BITS,%ecx
-	je	LRound_To_64
-#ifdef PARANOID
-	jmp	L_bugged_denorm_486
-#endif /* PARANOID */ 
-#else
-#ifdef PARANOID
-	jmp	L_bugged_denorm	/* There is no bug, just a bad control word */
-#endif /* PARANOID */ 
-#endif /* PECULIAR_486 */
-
-
-/* Round etc to 24 bit precision */
-LRound_To_24:
-	movl	%esi,%ecx
-	andl	CW_RC,%ecx
-	cmpl	RC_RND,%ecx
-	je	LRound_nearest_24
-
-	cmpl	RC_CHOP,%ecx
-	je	LCheck_truncate_24
-
-	cmpl	RC_UP,%ecx		/* Towards +infinity */
-	je	LUp_24
-
-	cmpl	RC_DOWN,%ecx		/* Towards -infinity */
-	je	LDown_24
-
-#ifdef PARANOID
-	jmp	L_bugged_round24
-#endif /* PARANOID */ 
-
-LUp_24:
-	cmpb	SIGN_POS,PARAM5
-	jne	LCheck_truncate_24	/* If negative then  up==truncate */
-
-	jmp	LCheck_24_round_up
-
-LDown_24:
-	cmpb	SIGN_POS,PARAM5
-	je	LCheck_truncate_24	/* If positive then  down==truncate */
-
-LCheck_24_round_up:
-	movl	%eax,%ecx
-	andl	$0x000000ff,%ecx
-	orl	%ebx,%ecx
-	orl	%edx,%ecx
-	jnz	LDo_24_round_up
-	jmp	L_Re_normalise
-
-LRound_nearest_24:
-	/* Do rounding of the 24th bit if needed (nearest or even) */
-	movl	%eax,%ecx
-	andl	$0x000000ff,%ecx
-	cmpl	$0x00000080,%ecx
-	jc	LCheck_truncate_24	/* less than half, no increment needed */
-
-	jne	LGreater_Half_24	/* greater than half, increment needed */
-
-	/* Possibly half, we need to check the ls bits */
-	orl	%ebx,%ebx
-	jnz	LGreater_Half_24	/* greater than half, increment needed */
-
-	orl	%edx,%edx
-	jnz	LGreater_Half_24	/* greater than half, increment needed */
-
-	/* Exactly half, increment only if 24th bit is 1 (round to even) */
-	testl	$0x00000100,%eax
-	jz	LDo_truncate_24
-
-LGreater_Half_24:			/* Rounding: increment at the 24th bit */
-LDo_24_round_up:
-	andl	$0xffffff00,%eax	/* Truncate to 24 bits */
-	xorl	%ebx,%ebx
-	movb	LOST_UP,FPU_bits_lost
-	addl	$0x00000100,%eax
-	jmp	LCheck_Round_Overflow
-
-LCheck_truncate_24:
-	movl	%eax,%ecx
-	andl	$0x000000ff,%ecx
-	orl	%ebx,%ecx
-	orl	%edx,%ecx
-	jz	L_Re_normalise		/* No truncation needed */
-
-LDo_truncate_24:
-	andl	$0xffffff00,%eax	/* Truncate to 24 bits */
-	xorl	%ebx,%ebx
-	movb	LOST_DOWN,FPU_bits_lost
-	jmp	L_Re_normalise
-
-
-/* Round etc to 53 bit precision */
-LRound_To_53:
-	movl	%esi,%ecx
-	andl	CW_RC,%ecx
-	cmpl	RC_RND,%ecx
-	je	LRound_nearest_53
-
-	cmpl	RC_CHOP,%ecx
-	je	LCheck_truncate_53
-
-	cmpl	RC_UP,%ecx		/* Towards +infinity */
-	je	LUp_53
-
-	cmpl	RC_DOWN,%ecx		/* Towards -infinity */
-	je	LDown_53
-
-#ifdef PARANOID
-	jmp	L_bugged_round53
-#endif /* PARANOID */ 
-
-LUp_53:
-	cmpb	SIGN_POS,PARAM5
-	jne	LCheck_truncate_53	/* If negative then  up==truncate */
-
-	jmp	LCheck_53_round_up
-
-LDown_53:
-	cmpb	SIGN_POS,PARAM5
-	je	LCheck_truncate_53	/* If positive then  down==truncate */
-
-LCheck_53_round_up:
-	movl	%ebx,%ecx
-	andl	$0x000007ff,%ecx
-	orl	%edx,%ecx
-	jnz	LDo_53_round_up
-	jmp	L_Re_normalise
-
-LRound_nearest_53:
-	/* Do rounding of the 53rd bit if needed (nearest or even) */
-	movl	%ebx,%ecx
-	andl	$0x000007ff,%ecx
-	cmpl	$0x00000400,%ecx
-	jc	LCheck_truncate_53	/* less than half, no increment needed */
-
-	jnz	LGreater_Half_53	/* greater than half, increment needed */
-
-	/* Possibly half, we need to check the ls bits */
-	orl	%edx,%edx
-	jnz	LGreater_Half_53	/* greater than half, increment needed */
-
-	/* Exactly half, increment only if 53rd bit is 1 (round to even) */
-	testl	$0x00000800,%ebx
-	jz	LTruncate_53
-
-LGreater_Half_53:			/* Rounding: increment at the 53rd bit */
-LDo_53_round_up:
-	movb	LOST_UP,FPU_bits_lost
-	andl	$0xfffff800,%ebx	/* Truncate to 53 bits */
-	addl	$0x00000800,%ebx
-	adcl	$0,%eax
-	jmp	LCheck_Round_Overflow
-
-LCheck_truncate_53:
-	movl	%ebx,%ecx
-	andl	$0x000007ff,%ecx
-	orl	%edx,%ecx
-	jz	L_Re_normalise
-
-LTruncate_53:
-	movb	LOST_DOWN,FPU_bits_lost
-	andl	$0xfffff800,%ebx	/* Truncate to 53 bits */
-	jmp	L_Re_normalise
-
-
-/* Round etc to 64 bit precision */
-LRound_To_64:
-	movl	%esi,%ecx
-	andl	CW_RC,%ecx
-	cmpl	RC_RND,%ecx
-	je	LRound_nearest_64
-
-	cmpl	RC_CHOP,%ecx
-	je	LCheck_truncate_64
-
-	cmpl	RC_UP,%ecx		/* Towards +infinity */
-	je	LUp_64
-
-	cmpl	RC_DOWN,%ecx		/* Towards -infinity */
-	je	LDown_64
-
-#ifdef PARANOID
-	jmp	L_bugged_round64
-#endif /* PARANOID */ 
-
-LUp_64:
-	cmpb	SIGN_POS,PARAM5
-	jne	LCheck_truncate_64	/* If negative then  up==truncate */
-
-	orl	%edx,%edx
-	jnz	LDo_64_round_up
-	jmp	L_Re_normalise
-
-LDown_64:
-	cmpb	SIGN_POS,PARAM5
-	je	LCheck_truncate_64	/* If positive then  down==truncate */
-
-	orl	%edx,%edx
-	jnz	LDo_64_round_up
-	jmp	L_Re_normalise
-
-LRound_nearest_64:
-	cmpl	$0x80000000,%edx
-	jc	LCheck_truncate_64
-
-	jne	LDo_64_round_up
-
-	/* Now test for round-to-even */
-	testb	$1,%bl
-	jz	LCheck_truncate_64
-
-LDo_64_round_up:
-	movb	LOST_UP,FPU_bits_lost
-	addl	$1,%ebx
-	adcl	$0,%eax
-
-LCheck_Round_Overflow:
-	jnc	L_Re_normalise
-
-	/* Overflow, adjust the result (significand to 1.0) */
-	rcrl	$1,%eax
-	rcrl	$1,%ebx
-	incw	EXP(%edi)
-	jmp	L_Re_normalise
-
-LCheck_truncate_64:
-	orl	%edx,%edx
-	jz	L_Re_normalise
-
-LTruncate_64:
-	movb	LOST_DOWN,FPU_bits_lost
-
-L_Re_normalise:
-	testb	$0xff,FPU_denormal
-	jnz	Normalise_result
-
-L_Normalised:
-	movl	TAG_Valid,%edx
-
-L_deNormalised:
-	cmpb	LOST_UP,FPU_bits_lost
-	je	L_precision_lost_up
-
-	cmpb	LOST_DOWN,FPU_bits_lost
-	je	L_precision_lost_down
-
-L_no_precision_loss:
-	/* store the result */
-
-L_Store_significand:
-	movl	%eax,SIGH(%edi)
-	movl	%ebx,SIGL(%edi)
-
-	cmpw	EXP_OVER,EXP(%edi)
-	jge	L_overflow
-
-	movl	%edx,%eax
-
-	/* Convert the exponent to 80x87 form. */
-	addw	EXTENDED_Ebias,EXP(%edi)
-	andw	$0x7fff,EXP(%edi)
-
-fpu_reg_round_signed_special_exit:
-
-	cmpb	SIGN_POS,PARAM5
-	je	fpu_reg_round_special_exit
-
-	orw	$0x8000,EXP(%edi)	/* Negative sign for the result. */
-
-fpu_reg_round_special_exit:
-
-#ifndef NON_REENTRANT_FPU
-	popl	%ebx		/* adjust the stack pointer */
-#endif /* NON_REENTRANT_FPU */ 
-
-fpu_Arith_exit:
-	popl	%ebx
-	popl	%edi
-	popl	%esi
-	leave
-	RET
-
-
-/*
- * Set the FPU status flags to represent precision loss due to
- * round-up.
- */
-L_precision_lost_up:
-	push	%edx
-	push	%eax
-	call	set_precision_flag_up
-	popl	%eax
-	popl	%edx
-	jmp	L_no_precision_loss
-
-/*
- * Set the FPU status flags to represent precision loss due to
- * truncation.
- */
-L_precision_lost_down:
-	push	%edx
-	push	%eax
-	call	set_precision_flag_down
-	popl	%eax
-	popl	%edx
-	jmp	L_no_precision_loss
-
-
-/*
- * The number is a denormal (which might get rounded up to a normal)
- * Shift the number right the required number of bits, which will
- * have to be undone later...
- */
-L_Make_denorm:
-	/* The action to be taken depends upon whether the underflow
-	   exception is masked */
-	testb	CW_Underflow,%cl		/* Underflow mask. */
-	jz	Unmasked_underflow		/* Do not make a denormal. */
-
-	movb	DENORMAL,FPU_denormal
-
-	pushl	%ecx		/* Save */
-	movw	EXP_UNDER+1,%cx
-	subw	EXP(%edi),%cx
-
-	cmpw	$64,%cx	/* shrd only works for 0..31 bits */
-	jnc	Denorm_shift_more_than_63
-
-	cmpw	$32,%cx	/* shrd only works for 0..31 bits */
-	jnc	Denorm_shift_more_than_32
-
-/*
- * We got here without jumps by assuming that the most common requirement
- *   is for a small de-normalising shift.
- * Shift by [1..31] bits
- */
-	addw	%cx,EXP(%edi)
-	orl	%edx,%edx	/* extension */
-	setne	%ch		/* Save whether %edx is non-zero */
-	xorl	%edx,%edx
-	shrd	%cl,%ebx,%edx
-	shrd	%cl,%eax,%ebx
-	shr	%cl,%eax
-	orb	%ch,%dl
-	popl	%ecx
-	jmp	Denorm_done
-
-/* Shift by [32..63] bits */
-Denorm_shift_more_than_32:
-	addw	%cx,EXP(%edi)
-	subb	$32,%cl
-	orl	%edx,%edx
-	setne	%ch
-	orb	%ch,%bl
-	xorl	%edx,%edx
-	shrd	%cl,%ebx,%edx
-	shrd	%cl,%eax,%ebx
-	shr	%cl,%eax
-	orl	%edx,%edx		/* test these 32 bits */
-	setne	%cl
-	orb	%ch,%bl
-	orb	%cl,%bl
-	movl	%ebx,%edx
-	movl	%eax,%ebx
-	xorl	%eax,%eax
-	popl	%ecx
-	jmp	Denorm_done
-
-/* Shift by [64..) bits */
-Denorm_shift_more_than_63:
-	cmpw	$64,%cx
-	jne	Denorm_shift_more_than_64
-
-/* Exactly 64 bit shift */
-	addw	%cx,EXP(%edi)
-	xorl	%ecx,%ecx
-	orl	%edx,%edx
-	setne	%cl
-	orl	%ebx,%ebx
-	setne	%ch
-	orb	%ch,%cl
-	orb	%cl,%al
-	movl	%eax,%edx
-	xorl	%eax,%eax
-	xorl	%ebx,%ebx
-	popl	%ecx
-	jmp	Denorm_done
-
-Denorm_shift_more_than_64:
-	movw	EXP_UNDER+1,EXP(%edi)
-/* This is easy, %eax must be non-zero, so.. */
-	movl	$1,%edx
-	xorl	%eax,%eax
-	xorl	%ebx,%ebx
-	popl	%ecx
-	jmp	Denorm_done
-
-
-Unmasked_underflow:
-	movb	UNMASKED_UNDERFLOW,FPU_denormal
-	jmp	Denorm_done
-
-
-/* Undo the de-normalisation. */
-Normalise_result:
-	cmpb	UNMASKED_UNDERFLOW,FPU_denormal
-	je	Signal_underflow
-
-/* The number must be a denormal if we got here. */
-#ifdef PARANOID
-	/* But check it... just in case. */
-	cmpw	EXP_UNDER+1,EXP(%edi)
-	jne	L_norm_bugged
-#endif /* PARANOID */
-
-#ifdef PECULIAR_486
-	/*
-	 * This implements a special feature of 80486 behaviour.
-	 * Underflow will be signaled even if the number is
-	 * not a denormal after rounding.
-	 * This difference occurs only for masked underflow, and not
-	 * in the unmasked case.
-	 * Actual 80486 behaviour differs from this in some circumstances.
-	 */
-	orl	%eax,%eax		/* ms bits */
-	js	LPseudoDenormal		/* Will be masked underflow */
-#else
-	orl	%eax,%eax		/* ms bits */
-	js	L_Normalised		/* No longer a denormal */
-#endif /* PECULIAR_486 */ 
-
-	jnz	LDenormal_adj_exponent
-
-	orl	%ebx,%ebx
-	jz	L_underflow_to_zero	/* The contents are zero */
-
-LDenormal_adj_exponent:
-	decw	EXP(%edi)
-
-LPseudoDenormal:
-	testb	$0xff,FPU_bits_lost	/* bits lost == underflow */
-	movl	TAG_Special,%edx
-	jz	L_deNormalised
-
-	/* There must be a masked underflow */
-	push	%eax
-	pushl	EX_Underflow
-	call	EXCEPTION
-	popl	%eax
-	popl	%eax
-	movl	TAG_Special,%edx
-	jmp	L_deNormalised
-
-
-/*
- * The operations resulted in a number too small to represent.
- * Masked response.
- */
-L_underflow_to_zero:
-	push	%eax
-	call	set_precision_flag_down
-	popl	%eax
-
-	push	%eax
-	pushl	EX_Underflow
-	call	EXCEPTION
-	popl	%eax
-	popl	%eax
-
-/* Reduce the exponent to EXP_UNDER */
-	movw	EXP_UNDER,EXP(%edi)
-	movl	TAG_Zero,%edx
-	jmp	L_Store_significand
-
-
-/* The operations resulted in a number too large to represent. */
-L_overflow:
-	addw	EXTENDED_Ebias,EXP(%edi)	/* Set for unmasked response. */
-	push	%edi
-	call	arith_overflow
-	pop	%edi
-	jmp	fpu_reg_round_signed_special_exit
-
-
-Signal_underflow:
-	/* The number may have been changed to a non-denormal */
-	/* by the rounding operations. */
-	cmpw	EXP_UNDER,EXP(%edi)
-	jle	Do_unmasked_underflow
-
-	jmp	L_Normalised
-
-Do_unmasked_underflow:
-	/* Increase the exponent by the magic number */
-	addw	$(3*(1<<13)),EXP(%edi)
-	push	%eax
-	pushl	EX_Underflow
-	call	EXCEPTION
-	popl	%eax
-	popl	%eax
-	jmp	L_Normalised
-
-
-#ifdef PARANOID
-#ifdef PECULIAR_486
-L_bugged_denorm_486:
-	pushl	EX_INTERNAL|0x236
-	call	EXCEPTION
-	popl	%ebx
-	jmp	L_exception_exit
-#else
-L_bugged_denorm:
-	pushl	EX_INTERNAL|0x230
-	call	EXCEPTION
-	popl	%ebx
-	jmp	L_exception_exit
-#endif /* PECULIAR_486 */ 
-
-L_bugged_round24:
-	pushl	EX_INTERNAL|0x231
-	call	EXCEPTION
-	popl	%ebx
-	jmp	L_exception_exit
-
-L_bugged_round53:
-	pushl	EX_INTERNAL|0x232
-	call	EXCEPTION
-	popl	%ebx
-	jmp	L_exception_exit
-
-L_bugged_round64:
-	pushl	EX_INTERNAL|0x233
-	call	EXCEPTION
-	popl	%ebx
-	jmp	L_exception_exit
-
-L_norm_bugged:
-	pushl	EX_INTERNAL|0x234
-	call	EXCEPTION
-	popl	%ebx
-	jmp	L_exception_exit
-
-L_entry_bugged:
-	pushl	EX_INTERNAL|0x235
-	call	EXCEPTION
-	popl	%ebx
-L_exception_exit:
-	mov	$-1,%eax
-	jmp	fpu_reg_round_special_exit
-#endif /* PARANOID */ 
-
-SYM_FUNC_END(FPU_round)
diff -rupN a/arch/x86/math-emu/reg_u_add.S b/arch/x86/math-emu/reg_u_add.S
--- a/arch/x86/math-emu/reg_u_add.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_u_add.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,169 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-	.file	"reg_u_add.S"
-/*---------------------------------------------------------------------------+
- |  reg_u_add.S                                                              |
- |                                                                           |
- | Add two valid (TAG_Valid) FPU_REG numbers, of the same sign, and put the  |
- |   result in a destination FPU_REG.                                        |
- |                                                                           |
- | Copyright (C) 1992,1993,1995,1997                                         |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- | Call from C as:                                                           |
- |   int  FPU_u_add(FPU_REG *arg1, FPU_REG *arg2, FPU_REG *answ,             |
- |                                                int control_w)             |
- |    Return value is the tag of the answer, or-ed with FPU_Exception if     |
- |    one was raised, or -1 on internal error.                               |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*
- |    Kernel addition routine FPU_u_add(reg *arg1, reg *arg2, reg *answ).
- |    Takes two valid reg f.p. numbers (TAG_Valid), which are
- |    treated as unsigned numbers,
- |    and returns their sum as a TAG_Valid or TAG_Special f.p. number.
- |    The returned number is normalized.
- |    Basic checks are performed if PARANOID is defined.
- */
-
-#include "exception.h"
-#include "fpu_emu.h"
-#include "control_w.h"
-
-.text
-SYM_FUNC_START(FPU_u_add)
-	pushl	%ebp
-	movl	%esp,%ebp
-	pushl	%esi
-	pushl	%edi
-	pushl	%ebx
-
-	movl	PARAM1,%esi		/* source 1 */
-	movl	PARAM2,%edi		/* source 2 */
-
-	movl	PARAM6,%ecx
-	movl	%ecx,%edx
-	subl	PARAM7,%ecx			/* exp1 - exp2 */
-	jge	L_arg1_larger
-
-	/* num1 is smaller */
-	movl	SIGL(%esi),%ebx
-	movl	SIGH(%esi),%eax
-
-	movl	%edi,%esi
-	movl	PARAM7,%edx
-	negw	%cx
-	jmp	L_accum_loaded
-
-L_arg1_larger:
-	/* num1 has larger or equal exponent */
-	movl	SIGL(%edi),%ebx
-	movl	SIGH(%edi),%eax
-
-L_accum_loaded:
-	movl	PARAM3,%edi		/* destination */
-	movw	%dx,EXP(%edi)		/* Copy exponent to destination */
-
-	xorl	%edx,%edx		/* clear the extension */
-
-#ifdef PARANOID
-	testl	$0x80000000,%eax
-	je	L_bugged
-
-	testl	$0x80000000,SIGH(%esi)
-	je	L_bugged
-#endif /* PARANOID */
-
-/* The number to be shifted is in %eax:%ebx:%edx */
-	cmpw	$32,%cx		/* shrd only works for 0..31 bits */
-	jnc	L_more_than_31
-
-/* less than 32 bits */
-	shrd	%cl,%ebx,%edx
-	shrd	%cl,%eax,%ebx
-	shr	%cl,%eax
-	jmp	L_shift_done
-
-L_more_than_31:
-	cmpw	$64,%cx
-	jnc	L_more_than_63
-
-	subb	$32,%cl
-	jz	L_exactly_32
-
-	shrd	%cl,%eax,%edx
-	shr	%cl,%eax
-	orl	%ebx,%ebx
-	jz	L_more_31_no_low	/* none of the lowest bits is set */
-
-	orl	$1,%edx			/* record the fact in the extension */
-
-L_more_31_no_low:
-	movl	%eax,%ebx
-	xorl	%eax,%eax
-	jmp	L_shift_done
-
-L_exactly_32:
-	movl	%ebx,%edx
-	movl	%eax,%ebx
-	xorl	%eax,%eax
-	jmp	L_shift_done
-
-L_more_than_63:
-	cmpw	$65,%cx
-	jnc	L_more_than_64
-
-	movl	%eax,%edx
-	orl	%ebx,%ebx
-	jz	L_more_63_no_low
-
-	orl	$1,%edx
-	jmp	L_more_63_no_low
-
-L_more_than_64:
-	movl	$1,%edx		/* The shifted nr always at least one '1' */
-
-L_more_63_no_low:
-	xorl	%ebx,%ebx
-	xorl	%eax,%eax
-
-L_shift_done:
-	/* Now do the addition */
-	addl	SIGL(%esi),%ebx
-	adcl	SIGH(%esi),%eax
-	jnc	L_round_the_result
-
-	/* Overflow, adjust the result */
-	rcrl	$1,%eax
-	rcrl	$1,%ebx
-	rcrl	$1,%edx
-	jnc	L_no_bit_lost
-
-	orl	$1,%edx
-
-L_no_bit_lost:
-	incw	EXP(%edi)
-
-L_round_the_result:
-	jmp	fpu_reg_round	/* Round the result */
-
-
-
-#ifdef PARANOID
-/* If we ever get here then we have problems! */
-L_bugged:
-	pushl	EX_INTERNAL|0x201
-	call	EXCEPTION
-	pop	%ebx
-	movl	$-1,%eax
-	jmp	L_exit
-
-L_exit:
-	popl	%ebx
-	popl	%edi
-	popl	%esi
-	leave
-	RET
-#endif /* PARANOID */
-SYM_FUNC_END(FPU_u_add)
diff -rupN a/arch/x86/math-emu/reg_u_div.S b/arch/x86/math-emu/reg_u_div.S
--- a/arch/x86/math-emu/reg_u_div.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_u_div.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,474 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-	.file	"reg_u_div.S"
-/*---------------------------------------------------------------------------+
- |  reg_u_div.S                                                              |
- |                                                                           |
- | Divide one FPU_REG by another and put the result in a destination FPU_REG.|
- |                                                                           |
- | Copyright (C) 1992,1993,1995,1997                                         |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- | Call from C as:                                                           |
- |    int FPU_u_div(FPU_REG *a, FPU_REG *b, FPU_REG *dest,                   |
- |                unsigned int control_word, char *sign)                     |
- |                                                                           |
- |  Does not compute the destination exponent, but does adjust it.           |
- |                                                                           |
- |    Return value is the tag of the answer, or-ed with FPU_Exception if     |
- |    one was raised, or -1 on internal error.                               |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "fpu_emu.h"
-#include "control_w.h"
-
-
-/* #define	dSIGL(x)	(x) */
-/* #define	dSIGH(x)	4(x) */
-
-
-#ifndef NON_REENTRANT_FPU
-/*
-	Local storage on the stack:
-	Result:		FPU_accum_3:FPU_accum_2:FPU_accum_1:FPU_accum_0
-	Overflow flag:	ovfl_flag
- */
-#define FPU_accum_3	-4(%ebp)
-#define FPU_accum_2	-8(%ebp)
-#define FPU_accum_1	-12(%ebp)
-#define FPU_accum_0	-16(%ebp)
-#define FPU_result_1	-20(%ebp)
-#define FPU_result_2	-24(%ebp)
-#define FPU_ovfl_flag	-28(%ebp)
-
-#else
-.data
-/*
-	Local storage in a static area:
-	Result:		FPU_accum_3:FPU_accum_2:FPU_accum_1:FPU_accum_0
-	Overflow flag:	ovfl_flag
- */
-	.align 4,0
-FPU_accum_3:
-	.long	0
-FPU_accum_2:
-	.long	0
-FPU_accum_1:
-	.long	0
-FPU_accum_0:
-	.long	0
-FPU_result_1:
-	.long	0
-FPU_result_2:
-	.long	0
-FPU_ovfl_flag:
-	.byte	0
-#endif /* NON_REENTRANT_FPU */
-
-#define REGA	PARAM1
-#define REGB	PARAM2
-#define DEST	PARAM3
-
-.text
-SYM_FUNC_START(FPU_u_div)
-	pushl	%ebp
-	movl	%esp,%ebp
-#ifndef NON_REENTRANT_FPU
-	subl	$28,%esp
-#endif /* NON_REENTRANT_FPU */
-
-	pushl	%esi
-	pushl	%edi
-	pushl	%ebx
-
-	movl	REGA,%esi
-	movl	REGB,%ebx
-	movl	DEST,%edi
-
-	movswl	EXP(%esi),%edx
-	movswl	EXP(%ebx),%eax
-	subl	%eax,%edx
-	addl	EXP_BIAS,%edx
-
-	/* A denormal and a large number can cause an exponent underflow */
-	cmpl	EXP_WAY_UNDER,%edx
-	jg	xExp_not_underflow
-
-	/* Set to a really low value allow correct handling */
-	movl	EXP_WAY_UNDER,%edx
-
-xExp_not_underflow:
-
-	movw    %dx,EXP(%edi)
-
-#ifdef PARANOID
-/*	testl	$0x80000000, SIGH(%esi)	// Dividend */
-/*	je	L_bugged */
-	testl	$0x80000000, SIGH(%ebx)	/* Divisor */
-	je	L_bugged
-#endif /* PARANOID */ 
-
-/* Check if the divisor can be treated as having just 32 bits */
-	cmpl	$0,SIGL(%ebx)
-	jnz	L_Full_Division	/* Can't do a quick divide */
-
-/* We should be able to zip through the division here */
-	movl	SIGH(%ebx),%ecx	/* The divisor */
-	movl	SIGH(%esi),%edx	/* Dividend */
-	movl	SIGL(%esi),%eax	/* Dividend */
-
-	cmpl	%ecx,%edx
-	setaeb	FPU_ovfl_flag	/* Keep a record */
-	jb	L_no_adjust
-
-	subl	%ecx,%edx	/* Prevent the overflow */
-
-L_no_adjust:
-	/* Divide the 64 bit number by the 32 bit denominator */
-	divl	%ecx
-	movl	%eax,FPU_result_2
-
-	/* Work on the remainder of the first division */
-	xorl	%eax,%eax
-	divl	%ecx
-	movl	%eax,FPU_result_1
-
-	/* Work on the remainder of the 64 bit division */
-	xorl	%eax,%eax
-	divl	%ecx
-
-	testb	$255,FPU_ovfl_flag	/* was the num > denom ? */
-	je	L_no_overflow
-
-	/* Do the shifting here */
-	/* increase the exponent */
-	incw	EXP(%edi)
-
-	/* shift the mantissa right one bit */
-	stc			/* To set the ms bit */
-	rcrl	FPU_result_2
-	rcrl	FPU_result_1
-	rcrl	%eax
-
-L_no_overflow:
-	jmp	LRound_precision	/* Do the rounding as required */
-
-
-/*---------------------------------------------------------------------------+
- |  Divide:   Return  arg1/arg2 to arg3.                                     |
- |                                                                           |
- |  This routine does not use the exponents of arg1 and arg2, but does       |
- |  adjust the exponent of arg3.                                             |
- |                                                                           |
- |  The maximum returned value is (ignoring exponents)                       |
- |               .ffffffff ffffffff                                          |
- |               ------------------  =  1.ffffffff fffffffe                  |
- |               .80000000 00000000                                          |
- | and the minimum is                                                        |
- |               .80000000 00000000                                          |
- |               ------------------  =  .80000000 00000001   (rounded)       |
- |               .ffffffff ffffffff                                          |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-
-L_Full_Division:
-	/* Save extended dividend in local register */
-	movl	SIGL(%esi),%eax
-	movl	%eax,FPU_accum_2
-	movl	SIGH(%esi),%eax
-	movl	%eax,FPU_accum_3
-	xorl	%eax,%eax
-	movl	%eax,FPU_accum_1	/* zero the extension */
-	movl	%eax,FPU_accum_0	/* zero the extension */
-
-	movl	SIGL(%esi),%eax	/* Get the current num */
-	movl	SIGH(%esi),%edx
-
-/*----------------------------------------------------------------------*/
-/* Initialization done.
-   Do the first 32 bits. */
-
-	movb	$0,FPU_ovfl_flag
-	cmpl	SIGH(%ebx),%edx	/* Test for imminent overflow */
-	jb	LLess_than_1
-	ja	LGreater_than_1
-
-	cmpl	SIGL(%ebx),%eax
-	jb	LLess_than_1
-
-LGreater_than_1:
-/* The dividend is greater or equal, would cause overflow */
-	setaeb	FPU_ovfl_flag		/* Keep a record */
-
-	subl	SIGL(%ebx),%eax
-	sbbl	SIGH(%ebx),%edx	/* Prevent the overflow */
-	movl	%eax,FPU_accum_2
-	movl	%edx,FPU_accum_3
-
-LLess_than_1:
-/* At this point, we have a dividend < divisor, with a record of
-   adjustment in FPU_ovfl_flag */
-
-	/* We will divide by a number which is too large */
-	movl	SIGH(%ebx),%ecx
-	addl	$1,%ecx
-	jnc	LFirst_div_not_1
-
-	/* here we need to divide by 100000000h,
-	   i.e., no division at all.. */
-	mov	%edx,%eax
-	jmp	LFirst_div_done
-
-LFirst_div_not_1:
-	divl	%ecx		/* Divide the numerator by the augmented
-				   denom ms dw */
-
-LFirst_div_done:
-	movl	%eax,FPU_result_2	/* Put the result in the answer */
-
-	mull	SIGH(%ebx)	/* mul by the ms dw of the denom */
-
-	subl	%eax,FPU_accum_2	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_3
-
-	movl	FPU_result_2,%eax	/* Get the result back */
-	mull	SIGL(%ebx)	/* now mul the ls dw of the denom */
-
-	subl	%eax,FPU_accum_1	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_2
-	sbbl	$0,FPU_accum_3
-	je	LDo_2nd_32_bits		/* Must check for non-zero result here */
-
-#ifdef PARANOID
-	jb	L_bugged_1
-#endif /* PARANOID */ 
-
-	/* need to subtract another once of the denom */
-	incl	FPU_result_2	/* Correct the answer */
-
-	movl	SIGL(%ebx),%eax
-	movl	SIGH(%ebx),%edx
-	subl	%eax,FPU_accum_1	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_2
-
-#ifdef PARANOID
-	sbbl	$0,FPU_accum_3
-	jne	L_bugged_1	/* Must check for non-zero result here */
-#endif /* PARANOID */ 
-
-/*----------------------------------------------------------------------*/
-/* Half of the main problem is done, there is just a reduced numerator
-   to handle now.
-   Work with the second 32 bits, FPU_accum_0 not used from now on */
-LDo_2nd_32_bits:
-	movl	FPU_accum_2,%edx	/* get the reduced num */
-	movl	FPU_accum_1,%eax
-
-	/* need to check for possible subsequent overflow */
-	cmpl	SIGH(%ebx),%edx
-	jb	LDo_2nd_div
-	ja	LPrevent_2nd_overflow
-
-	cmpl	SIGL(%ebx),%eax
-	jb	LDo_2nd_div
-
-LPrevent_2nd_overflow:
-/* The numerator is greater or equal, would cause overflow */
-	/* prevent overflow */
-	subl	SIGL(%ebx),%eax
-	sbbl	SIGH(%ebx),%edx
-	movl	%edx,FPU_accum_2
-	movl	%eax,FPU_accum_1
-
-	incl	FPU_result_2	/* Reflect the subtraction in the answer */
-
-#ifdef PARANOID
-	je	L_bugged_2	/* Can't bump the result to 1.0 */
-#endif /* PARANOID */ 
-
-LDo_2nd_div:
-	cmpl	$0,%ecx		/* augmented denom msw */
-	jnz	LSecond_div_not_1
-
-	/* %ecx == 0, we are dividing by 1.0 */
-	mov	%edx,%eax
-	jmp	LSecond_div_done
-
-LSecond_div_not_1:
-	divl	%ecx		/* Divide the numerator by the denom ms dw */
-
-LSecond_div_done:
-	movl	%eax,FPU_result_1	/* Put the result in the answer */
-
-	mull	SIGH(%ebx)	/* mul by the ms dw of the denom */
-
-	subl	%eax,FPU_accum_1	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_2
-
-#ifdef PARANOID
-	jc	L_bugged_2
-#endif /* PARANOID */ 
-
-	movl	FPU_result_1,%eax	/* Get the result back */
-	mull	SIGL(%ebx)	/* now mul the ls dw of the denom */
-
-	subl	%eax,FPU_accum_0	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_1	/* Subtract from the num local reg */
-	sbbl	$0,FPU_accum_2
-
-#ifdef PARANOID
-	jc	L_bugged_2
-#endif /* PARANOID */ 
-
-	jz	LDo_3rd_32_bits
-
-#ifdef PARANOID
-	cmpl	$1,FPU_accum_2
-	jne	L_bugged_2
-#endif /* PARANOID */
-
-	/* need to subtract another once of the denom */
-	movl	SIGL(%ebx),%eax
-	movl	SIGH(%ebx),%edx
-	subl	%eax,FPU_accum_0	/* Subtract from the num local reg */
-	sbbl	%edx,FPU_accum_1
-	sbbl	$0,FPU_accum_2
-
-#ifdef PARANOID
-	jc	L_bugged_2
-	jne	L_bugged_2
-#endif /* PARANOID */ 
-
-	addl	$1,FPU_result_1	/* Correct the answer */
-	adcl	$0,FPU_result_2
-
-#ifdef PARANOID
-	jc	L_bugged_2	/* Must check for non-zero result here */
-#endif /* PARANOID */
-
-/*----------------------------------------------------------------------*/
-/* The division is essentially finished here, we just need to perform
-   tidying operations.
-   Deal with the 3rd 32 bits */
-LDo_3rd_32_bits:
-	movl	FPU_accum_1,%edx		/* get the reduced num */
-	movl	FPU_accum_0,%eax
-
-	/* need to check for possible subsequent overflow */
-	cmpl	SIGH(%ebx),%edx	/* denom */
-	jb	LRound_prep
-	ja	LPrevent_3rd_overflow
-
-	cmpl	SIGL(%ebx),%eax	/* denom */
-	jb	LRound_prep
-
-LPrevent_3rd_overflow:
-	/* prevent overflow */
-	subl	SIGL(%ebx),%eax
-	sbbl	SIGH(%ebx),%edx
-	movl	%edx,FPU_accum_1
-	movl	%eax,FPU_accum_0
-
-	addl	$1,FPU_result_1	/* Reflect the subtraction in the answer */
-	adcl	$0,FPU_result_2
-	jne	LRound_prep
-	jnc	LRound_prep
-
-	/* This is a tricky spot, there is an overflow of the answer */
-	movb	$255,FPU_ovfl_flag		/* Overflow -> 1.000 */
-
-LRound_prep:
-/*
- * Prepare for rounding.
- * To test for rounding, we just need to compare 2*accum with the
- * denom.
- */
-	movl	FPU_accum_0,%ecx
-	movl	FPU_accum_1,%edx
-	movl	%ecx,%eax
-	orl	%edx,%eax
-	jz	LRound_ovfl		/* The accumulator contains zero. */
-
-	/* Multiply by 2 */
-	clc
-	rcll	$1,%ecx
-	rcll	$1,%edx
-	jc	LRound_large		/* No need to compare, denom smaller */
-
-	subl	SIGL(%ebx),%ecx
-	sbbl	SIGH(%ebx),%edx
-	jnc	LRound_not_small
-
-	movl	$0x70000000,%eax	/* Denom was larger */
-	jmp	LRound_ovfl
-
-LRound_not_small:
-	jnz	LRound_large
-
-	movl	$0x80000000,%eax	/* Remainder was exactly 1/2 denom */
-	jmp	LRound_ovfl
-
-LRound_large:
-	movl	$0xff000000,%eax	/* Denom was smaller */
-
-LRound_ovfl:
-/* We are now ready to deal with rounding, but first we must get
-   the bits properly aligned */
-	testb	$255,FPU_ovfl_flag	/* was the num > denom ? */
-	je	LRound_precision
-
-	incw	EXP(%edi)
-
-	/* shift the mantissa right one bit */
-	stc			/* Will set the ms bit */
-	rcrl	FPU_result_2
-	rcrl	FPU_result_1
-	rcrl	%eax
-
-/* Round the result as required */
-LRound_precision:
-	decw	EXP(%edi)	/* binary point between 1st & 2nd bits */
-
-	movl	%eax,%edx
-	movl	FPU_result_1,%ebx
-	movl	FPU_result_2,%eax
-	jmp	fpu_reg_round
-
-
-#ifdef PARANOID
-/* The logic is wrong if we got here */
-L_bugged:
-	pushl	EX_INTERNAL|0x202
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_exit
-
-L_bugged_1:
-	pushl	EX_INTERNAL|0x203
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_exit
-
-L_bugged_2:
-	pushl	EX_INTERNAL|0x204
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_exit
-
-L_exit:
-	movl	$-1,%eax
-	popl	%ebx
-	popl	%edi
-	popl	%esi
-
-	leave
-	RET
-#endif /* PARANOID */ 
-
-SYM_FUNC_END(FPU_u_div)
diff -rupN a/arch/x86/math-emu/reg_u_mul.S b/arch/x86/math-emu/reg_u_mul.S
--- a/arch/x86/math-emu/reg_u_mul.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_u_mul.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,150 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-	.file	"reg_u_mul.S"
-/*---------------------------------------------------------------------------+
- |  reg_u_mul.S                                                              |
- |                                                                           |
- | Core multiplication routine                                               |
- |                                                                           |
- | Copyright (C) 1992,1993,1995,1997                                         |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- |   Basic multiplication routine.                                           |
- |   Does not check the resulting exponent for overflow/underflow            |
- |                                                                           |
- |   FPU_u_mul(FPU_REG *a, FPU_REG *b, FPU_REG *c, unsigned int cw);         |
- |                                                                           |
- |   Internal working is at approx 128 bits.                                 |
- |   Result is rounded to nearest 53 or 64 bits, using "nearest or even".    |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "fpu_emu.h"
-#include "control_w.h"
-
-
-
-#ifndef NON_REENTRANT_FPU
-/*  Local storage on the stack: */
-#define FPU_accum_0	-4(%ebp)	/* ms word */
-#define FPU_accum_1	-8(%ebp)
-
-#else
-/*  Local storage in a static area: */
-.data
-	.align 4,0
-FPU_accum_0:
-	.long	0
-FPU_accum_1:
-	.long	0
-#endif /* NON_REENTRANT_FPU */
-
-
-.text
-SYM_FUNC_START(FPU_u_mul)
-	pushl	%ebp
-	movl	%esp,%ebp
-#ifndef NON_REENTRANT_FPU
-	subl	$8,%esp
-#endif /* NON_REENTRANT_FPU */ 
-
-	pushl	%esi
-	pushl	%edi
-	pushl	%ebx
-
-	movl	PARAM1,%esi
-	movl	PARAM2,%edi
-
-#ifdef PARANOID
-	testl	$0x80000000,SIGH(%esi)
-	jz	L_bugged
-	testl	$0x80000000,SIGH(%edi)
-	jz	L_bugged
-#endif /* PARANOID */
-
-	xorl	%ecx,%ecx
-	xorl	%ebx,%ebx
-
-	movl	SIGL(%esi),%eax
-	mull	SIGL(%edi)
-	movl	%eax,FPU_accum_0
-	movl	%edx,FPU_accum_1
-
-	movl	SIGL(%esi),%eax
-	mull	SIGH(%edi)
-	addl	%eax,FPU_accum_1
-	adcl	%edx,%ebx
-/*	adcl	$0,%ecx		// overflow here is not possible */
-
-	movl	SIGH(%esi),%eax
-	mull	SIGL(%edi)
-	addl	%eax,FPU_accum_1
-	adcl	%edx,%ebx
-	adcl	$0,%ecx
-
-	movl	SIGH(%esi),%eax
-	mull	SIGH(%edi)
-	addl	%eax,%ebx
-	adcl	%edx,%ecx
-
-	/* Get the sum of the exponents. */
-	movl	PARAM6,%eax
-	subl	EXP_BIAS-1,%eax
-
-	/* Two denormals can cause an exponent underflow */
-	cmpl	EXP_WAY_UNDER,%eax
-	jg	Exp_not_underflow
-
-	/* Set to a really low value allow correct handling */
-	movl	EXP_WAY_UNDER,%eax
-
-Exp_not_underflow:
-
-/*  Have now finished with the sources */
-	movl	PARAM3,%edi	/* Point to the destination */
-	movw	%ax,EXP(%edi)
-
-/*  Now make sure that the result is normalized */
-	testl	$0x80000000,%ecx
-	jnz	LResult_Normalised
-
-	/* Normalize by shifting left one bit */
-	shll	$1,FPU_accum_0
-	rcll	$1,FPU_accum_1
-	rcll	$1,%ebx
-	rcll	$1,%ecx
-	decw	EXP(%edi)
-
-LResult_Normalised:
-	movl	FPU_accum_0,%eax
-	movl	FPU_accum_1,%edx
-	orl	%eax,%eax
-	jz	L_extent_zero
-
-	orl	$1,%edx
-
-L_extent_zero:
-	movl	%ecx,%eax
-	jmp	fpu_reg_round
-
-
-#ifdef PARANOID
-L_bugged:
-	pushl	EX_INTERNAL|0x205
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_exit
-
-L_exit:
-	popl	%ebx
-	popl	%edi
-	popl	%esi
-	leave
-	RET
-#endif /* PARANOID */ 
-
-SYM_FUNC_END(FPU_u_mul)
diff -rupN a/arch/x86/math-emu/reg_u_sub.S b/arch/x86/math-emu/reg_u_sub.S
--- a/arch/x86/math-emu/reg_u_sub.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/reg_u_sub.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,274 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-	.file	"reg_u_sub.S"
-/*---------------------------------------------------------------------------+
- |  reg_u_sub.S                                                              |
- |                                                                           |
- | Core floating point subtraction routine.                                  |
- |                                                                           |
- | Copyright (C) 1992,1993,1995,1997                                         |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@suburbia.net                              |
- |                                                                           |
- | Call from C as:                                                           |
- |    int FPU_u_sub(FPU_REG *arg1, FPU_REG *arg2, FPU_REG *answ,             |
- |                                                int control_w)             |
- |    Return value is the tag of the answer, or-ed with FPU_Exception if     |
- |    one was raised, or -1 on internal error.                               |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*
- |    Kernel subtraction routine FPU_u_sub(reg *arg1, reg *arg2, reg *answ).
- |    Takes two valid reg f.p. numbers (TAG_Valid), which are
- |    treated as unsigned numbers,
- |    and returns their difference as a TAG_Valid or TAG_Zero f.p.
- |    number.
- |    The first number (arg1) must be the larger.
- |    The returned number is normalized.
- |    Basic checks are performed if PARANOID is defined.
- */
-
-#include "exception.h"
-#include "fpu_emu.h"
-#include "control_w.h"
-
-.text
-SYM_FUNC_START(FPU_u_sub)
-	pushl	%ebp
-	movl	%esp,%ebp
-	pushl	%esi
-	pushl	%edi
-	pushl	%ebx
-
-	movl	PARAM1,%esi	/* source 1 */
-	movl	PARAM2,%edi	/* source 2 */
-	
-	movl	PARAM6,%ecx
-	subl	PARAM7,%ecx	/* exp1 - exp2 */
-
-#ifdef PARANOID
-	/* source 2 is always smaller than source 1 */
-	js	L_bugged_1
-
-	testl	$0x80000000,SIGH(%edi)	/* The args are assumed to be be normalized */
-	je	L_bugged_2
-
-	testl	$0x80000000,SIGH(%esi)
-	je	L_bugged_2
-#endif /* PARANOID */
-
-/*--------------------------------------+
- |	Form a register holding the     |
- |	smaller number                  |
- +--------------------------------------*/
-	movl	SIGH(%edi),%eax	/* register ms word */
-	movl	SIGL(%edi),%ebx	/* register ls word */
-
-	movl	PARAM3,%edi	/* destination */
-	movl	PARAM6,%edx
-	movw	%dx,EXP(%edi)	/* Copy exponent to destination */
-
-	xorl	%edx,%edx	/* register extension */
-
-/*--------------------------------------+
- |	Shift the temporary register	|
- |      right the required number of	|
- |	places.				|
- +--------------------------------------*/
-
-	cmpw	$32,%cx		/* shrd only works for 0..31 bits */
-	jnc	L_more_than_31
-
-/* less than 32 bits */
-	shrd	%cl,%ebx,%edx
-	shrd	%cl,%eax,%ebx
-	shr	%cl,%eax
-	jmp	L_shift_done
-
-L_more_than_31:
-	cmpw	$64,%cx
-	jnc	L_more_than_63
-
-	subb	$32,%cl
-	jz	L_exactly_32
-
-	shrd	%cl,%eax,%edx
-	shr	%cl,%eax
-	orl	%ebx,%ebx
-	jz	L_more_31_no_low	/* none of the lowest bits is set */
-
-	orl	$1,%edx			/* record the fact in the extension */
-
-L_more_31_no_low:
-	movl	%eax,%ebx
-	xorl	%eax,%eax
-	jmp	L_shift_done
-
-L_exactly_32:
-	movl	%ebx,%edx
-	movl	%eax,%ebx
-	xorl	%eax,%eax
-	jmp	L_shift_done
-
-L_more_than_63:
-	cmpw	$65,%cx
-	jnc	L_more_than_64
-
-	/* Shift right by 64 bits */
-	movl	%eax,%edx
-	orl	%ebx,%ebx
-	jz	L_more_63_no_low
-
-	orl	$1,%edx
-	jmp	L_more_63_no_low
-
-L_more_than_64:
-	jne	L_more_than_65
-
-	/* Shift right by 65 bits */
-	/* Carry is clear if we get here */
-	movl	%eax,%edx
-	rcrl	%edx
-	jnc	L_shift_65_nc
-
-	orl	$1,%edx
-	jmp	L_more_63_no_low
-
-L_shift_65_nc:
-	orl	%ebx,%ebx
-	jz	L_more_63_no_low
-
-	orl	$1,%edx
-	jmp	L_more_63_no_low
-
-L_more_than_65:
-	movl	$1,%edx		/* The shifted nr always at least one '1' */
-
-L_more_63_no_low:
-	xorl	%ebx,%ebx
-	xorl	%eax,%eax
-
-L_shift_done:
-L_subtr:
-/*------------------------------+
- |	Do the subtraction	|
- +------------------------------*/
-	xorl	%ecx,%ecx
-	subl	%edx,%ecx
-	movl	%ecx,%edx
-	movl	SIGL(%esi),%ecx
-	sbbl	%ebx,%ecx
-	movl	%ecx,%ebx
-	movl	SIGH(%esi),%ecx
-	sbbl	%eax,%ecx
-	movl	%ecx,%eax
-
-#ifdef PARANOID
-	/* We can never get a borrow */
-	jc	L_bugged
-#endif /* PARANOID */
-
-/*--------------------------------------+
- |	Normalize the result		|
- +--------------------------------------*/
-	testl	$0x80000000,%eax
-	jnz	L_round		/* no shifting needed */
-
-	orl	%eax,%eax
-	jnz	L_shift_1	/* shift left 1 - 31 bits */
-
-	orl	%ebx,%ebx
-	jnz	L_shift_32	/* shift left 32 - 63 bits */
-
-/*
- *	 A rare case, the only one which is non-zero if we got here
- *         is:           1000000 .... 0000
- *                      -0111111 .... 1111 1
- *                       -------------------- 
- *                       0000000 .... 0000 1 
- */
-
-	cmpl	$0x80000000,%edx
-	jnz	L_must_be_zero
-
-	/* Shift left 64 bits */
-	subw	$64,EXP(%edi)
-	xchg	%edx,%eax
-	jmp	fpu_reg_round
-
-L_must_be_zero:
-#ifdef PARANOID
-	orl	%edx,%edx
-	jnz	L_bugged_3
-#endif /* PARANOID */ 
-
-	/* The result is zero */
-	movw	$0,EXP(%edi)		/* exponent */
-	movl	$0,SIGL(%edi)
-	movl	$0,SIGH(%edi)
-	movl	TAG_Zero,%eax
-	jmp	L_exit
-
-L_shift_32:
-	movl	%ebx,%eax
-	movl	%edx,%ebx
-	movl	$0,%edx
-	subw	$32,EXP(%edi)	/* Can get underflow here */
-
-/* We need to shift left by 1 - 31 bits */
-L_shift_1:
-	bsrl	%eax,%ecx	/* get the required shift in %ecx */
-	subl	$31,%ecx
-	negl	%ecx
-	shld	%cl,%ebx,%eax
-	shld	%cl,%edx,%ebx
-	shl	%cl,%edx
-	subw	%cx,EXP(%edi)	/* Can get underflow here */
-
-L_round:
-	jmp	fpu_reg_round	/* Round the result */
-
-
-#ifdef PARANOID
-L_bugged_1:
-	pushl	EX_INTERNAL|0x206
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_error_exit
-
-L_bugged_2:
-	pushl	EX_INTERNAL|0x209
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_error_exit
-
-L_bugged_3:
-	pushl	EX_INTERNAL|0x210
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_error_exit
-
-L_bugged_4:
-	pushl	EX_INTERNAL|0x211
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_error_exit
-
-L_bugged:
-	pushl	EX_INTERNAL|0x212
-	call	EXCEPTION
-	pop	%ebx
-	jmp	L_error_exit
-
-L_error_exit:
-	movl	$-1,%eax
-
-#endif /* PARANOID */
-
-L_exit:
-	popl	%ebx
-	popl	%edi
-	popl	%esi
-	leave
-	RET
-SYM_FUNC_END(FPU_u_sub)
diff -rupN a/arch/x86/math-emu/round_Xsig.S b/arch/x86/math-emu/round_Xsig.S
--- a/arch/x86/math-emu/round_Xsig.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/round_Xsig.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,142 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  round_Xsig.S                                                             |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1995                                         |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@jacobi.maths.monash.edu.au |
- |                                                                           |
- | Normalize and round a 12 byte quantity.                                   |
- | Call from C as:                                                           |
- |   int round_Xsig(Xsig *n)                                                 |
- |                                                                           |
- | Normalize a 12 byte quantity.                                             |
- | Call from C as:                                                           |
- |   int norm_Xsig(Xsig *n)                                                  |
- |                                                                           |
- | Each function returns the size of the shift (nr of bits).                 |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-	.file	"round_Xsig.S"
-
-#include "fpu_emu.h"
-
-
-.text
-SYM_FUNC_START(round_Xsig)
-	pushl	%ebp
-	movl	%esp,%ebp
-	pushl	%ebx		/* Reserve some space */
-	pushl	%ebx
-	pushl	%esi
-
-	movl	PARAM1,%esi
-
-	movl	8(%esi),%edx
-	movl	4(%esi),%ebx
-	movl	(%esi),%eax
-
-	movl	$0,-4(%ebp)
-
-	orl	%edx,%edx	/* ms bits */
-	js	L_round		/* Already normalized */
-	jnz	L_shift_1	/* Shift left 1 - 31 bits */
-
-	movl	%ebx,%edx
-	movl	%eax,%ebx
-	xorl	%eax,%eax
-	movl	$-32,-4(%ebp)
-
-/* We need to shift left by 1 - 31 bits */
-L_shift_1:
-	bsrl	%edx,%ecx	/* get the required shift in %ecx */
-	subl	$31,%ecx
-	negl	%ecx
-	subl	%ecx,-4(%ebp)
-	shld	%cl,%ebx,%edx
-	shld	%cl,%eax,%ebx
-	shl	%cl,%eax
-
-L_round:
-	testl	$0x80000000,%eax
-	jz	L_exit
-
-	addl	$1,%ebx
-	adcl	$0,%edx
-	jnz	L_exit
-
-	movl	$0x80000000,%edx
-	incl	-4(%ebp)
-
-L_exit:
-	movl	%edx,8(%esi)
-	movl	%ebx,4(%esi)
-	movl	%eax,(%esi)
-
-	movl	-4(%ebp),%eax
-
-	popl	%esi
-	popl	%ebx
-	leave
-	RET
-SYM_FUNC_END(round_Xsig)
-
-
-
-SYM_FUNC_START(norm_Xsig)
-	pushl	%ebp
-	movl	%esp,%ebp
-	pushl	%ebx		/* Reserve some space */
-	pushl	%ebx
-	pushl	%esi
-
-	movl	PARAM1,%esi
-
-	movl	8(%esi),%edx
-	movl	4(%esi),%ebx
-	movl	(%esi),%eax
-
-	movl	$0,-4(%ebp)
-
-	orl	%edx,%edx	/* ms bits */
-	js	L_n_exit		/* Already normalized */
-	jnz	L_n_shift_1	/* Shift left 1 - 31 bits */
-
-	movl	%ebx,%edx
-	movl	%eax,%ebx
-	xorl	%eax,%eax
-	movl	$-32,-4(%ebp)
-
-	orl	%edx,%edx	/* ms bits */
-	js	L_n_exit	/* Normalized now */
-	jnz	L_n_shift_1	/* Shift left 1 - 31 bits */
-
-	movl	%ebx,%edx
-	movl	%eax,%ebx
-	xorl	%eax,%eax
-	addl	$-32,-4(%ebp)
-	jmp	L_n_exit	/* Might not be normalized,
-	                           but shift no more. */
-
-/* We need to shift left by 1 - 31 bits */
-L_n_shift_1:
-	bsrl	%edx,%ecx	/* get the required shift in %ecx */
-	subl	$31,%ecx
-	negl	%ecx
-	subl	%ecx,-4(%ebp)
-	shld	%cl,%ebx,%edx
-	shld	%cl,%eax,%ebx
-	shl	%cl,%eax
-
-L_n_exit:
-	movl	%edx,8(%esi)
-	movl	%ebx,4(%esi)
-	movl	%eax,(%esi)
-
-	movl	-4(%ebp),%eax
-
-	popl	%esi
-	popl	%ebx
-	leave
-	RET
-SYM_FUNC_END(norm_Xsig)
diff -rupN a/arch/x86/math-emu/shr_Xsig.S b/arch/x86/math-emu/shr_Xsig.S
--- a/arch/x86/math-emu/shr_Xsig.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/shr_Xsig.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,89 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-	.file	"shr_Xsig.S"
-/*---------------------------------------------------------------------------+
- |  shr_Xsig.S                                                               |
- |                                                                           |
- | 12 byte right shift function                                              |
- |                                                                           |
- | Copyright (C) 1992,1994,1995                                              |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@jacobi.maths.monash.edu.au |
- |                                                                           |
- | Call from C as:                                                           |
- |   void shr_Xsig(Xsig *arg, unsigned nr)                                   |
- |                                                                           |
- |   Extended shift right function.                                          |
- |   Fastest for small shifts.                                               |
- |   Shifts the 12 byte quantity pointed to by the first arg (arg)           |
- |   right by the number of bits specified by the second arg (nr).           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_emu.h"
-
-.text
-SYM_FUNC_START(shr_Xsig)
-	push	%ebp
-	movl	%esp,%ebp
-	pushl	%esi
-	movl	PARAM2,%ecx
-	movl	PARAM1,%esi
-	cmpl	$32,%ecx	/* shrd only works for 0..31 bits */
-	jnc	L_more_than_31
-
-/* less than 32 bits */
-	pushl	%ebx
-	movl	(%esi),%eax	/* lsl */
-	movl	4(%esi),%ebx	/* midl */
-	movl	8(%esi),%edx	/* msl */
-	shrd	%cl,%ebx,%eax
-	shrd	%cl,%edx,%ebx
-	shr	%cl,%edx
-	movl	%eax,(%esi)
-	movl	%ebx,4(%esi)
-	movl	%edx,8(%esi)
-	popl	%ebx
-	popl	%esi
-	leave
-	RET
-
-L_more_than_31:
-	cmpl	$64,%ecx
-	jnc	L_more_than_63
-
-	subb	$32,%cl
-	movl	4(%esi),%eax	/* midl */
-	movl	8(%esi),%edx	/* msl */
-	shrd	%cl,%edx,%eax
-	shr	%cl,%edx
-	movl	%eax,(%esi)
-	movl	%edx,4(%esi)
-	movl	$0,8(%esi)
-	popl	%esi
-	leave
-	RET
-
-L_more_than_63:
-	cmpl	$96,%ecx
-	jnc	L_more_than_95
-
-	subb	$64,%cl
-	movl	8(%esi),%eax	/* msl */
-	shr	%cl,%eax
-	xorl	%edx,%edx
-	movl	%eax,(%esi)
-	movl	%edx,4(%esi)
-	movl	%edx,8(%esi)
-	popl	%esi
-	leave
-	RET
-
-L_more_than_95:
-	xorl	%eax,%eax
-	movl	%eax,(%esi)
-	movl	%eax,4(%esi)
-	movl	%eax,8(%esi)
-	popl	%esi
-	leave
-	RET
-SYM_FUNC_END(shr_Xsig)
diff -rupN a/arch/x86/math-emu/status_w.h b/arch/x86/math-emu/status_w.h
--- a/arch/x86/math-emu/status_w.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/status_w.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,68 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*---------------------------------------------------------------------------+
- |  status_w.h                                                               |
- |                                                                           |
- | Copyright (C) 1992,1993                                                   |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail   billm@vaxc.cc.monash.edu.au    |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#ifndef _STATUS_H_
-#define _STATUS_H_
-
-#include "fpu_emu.h"		/* for definition of PECULIAR_486 */
-
-#ifdef __ASSEMBLER__
-#define	Const__(x)	$##x
-#else
-#define	Const__(x)	x
-#endif
-
-#define SW_Backward    	Const__(0x8000)	/* backward compatibility */
-#define SW_C3		Const__(0x4000)	/* condition bit 3 */
-#define SW_Top		Const__(0x3800)	/* top of stack */
-#define SW_Top_Shift 	Const__(11)	/* shift for top of stack bits */
-#define SW_C2		Const__(0x0400)	/* condition bit 2 */
-#define SW_C1		Const__(0x0200)	/* condition bit 1 */
-#define SW_C0		Const__(0x0100)	/* condition bit 0 */
-#define SW_Summary     	Const__(0x0080)	/* exception summary */
-#define SW_Stack_Fault	Const__(0x0040)	/* stack fault */
-#define SW_Precision   	Const__(0x0020)	/* loss of precision */
-#define SW_Underflow   	Const__(0x0010)	/* underflow */
-#define SW_Overflow    	Const__(0x0008)	/* overflow */
-#define SW_Zero_Div    	Const__(0x0004)	/* divide by zero */
-#define SW_Denorm_Op   	Const__(0x0002)	/* denormalized operand */
-#define SW_Invalid     	Const__(0x0001)	/* invalid operation */
-
-#define SW_Exc_Mask     Const__(0x27f)	/* Status word exception bit mask */
-
-#ifndef __ASSEMBLER__
-
-#define COMP_A_gt_B	1
-#define COMP_A_eq_B	2
-#define COMP_A_lt_B	3
-#define COMP_No_Comp	4
-#define COMP_Denormal   0x20
-#define COMP_NaN	0x40
-#define COMP_SNaN	0x80
-
-#define status_word() \
-  ((partial_status & ~SW_Top & 0xffff) | ((top << SW_Top_Shift) & SW_Top))
-static inline void setcc(int cc)
-{
-	partial_status &= ~(SW_C0 | SW_C1 | SW_C2 | SW_C3);
-	partial_status |= (cc) & (SW_C0 | SW_C1 | SW_C2 | SW_C3);
-}
-
-#ifdef PECULIAR_486
-   /* Default, this conveys no information, but an 80486 does it. */
-   /* Clear the SW_C1 bit, "other bits undefined". */
-#  define clear_C1()  { partial_status &= ~SW_C1; }
-# else
-#  define clear_C1()
-#endif /* PECULIAR_486 */
-
-#endif /* __ASSEMBLER__ */
-
-#endif /* _STATUS_H_ */
diff -rupN a/arch/x86/math-emu/version.h b/arch/x86/math-emu/version.h
--- a/arch/x86/math-emu/version.h	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/version.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,12 +0,0 @@
-/*---------------------------------------------------------------------------+
- |  version.h                                                                |
- |                                                                           |
- |                                                                           |
- | Copyright (C) 1992,1993,1994,1996,1997,1999                               |
- |                  W. Metzenthen, 22 Parker St, Ormond, Vic 3163, Australia |
- |                  E-mail   billm@melbpc.org.au                             |
- |                                                                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#define FPU_VERSION "wm-FPU-emu version 2.01"
diff -rupN a/arch/x86/math-emu/wm_shrx.S b/arch/x86/math-emu/wm_shrx.S
--- a/arch/x86/math-emu/wm_shrx.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/wm_shrx.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,207 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-	.file	"wm_shrx.S"
-/*---------------------------------------------------------------------------+
- |  wm_shrx.S                                                                |
- |                                                                           |
- | 64 bit right shift functions                                              |
- |                                                                           |
- | Copyright (C) 1992,1995                                                   |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@jacobi.maths.monash.edu.au |
- |                                                                           |
- | Call from C as:                                                           |
- |   unsigned FPU_shrx(void *arg1, unsigned arg2)                            |
- | and                                                                       |
- |   unsigned FPU_shrxs(void *arg1, unsigned arg2)                           |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-#include "fpu_emu.h"
-
-.text
-/*---------------------------------------------------------------------------+
- |   unsigned FPU_shrx(void *arg1, unsigned arg2)                            |
- |                                                                           |
- |   Extended shift right function.                                          |
- |   Fastest for small shifts.                                               |
- |   Shifts the 64 bit quantity pointed to by the first arg (arg1)           |
- |   right by the number of bits specified by the second arg (arg2).         |
- |   Forms a 96 bit quantity from the 64 bit arg and eax:                    |
- |                [  64 bit arg ][ eax ]                                     |
- |            shift right  --------->                                        |
- |   The eax register is initialized to 0 before the shifting.               |
- |   Results returned in the 64 bit arg and eax.                             |
- +---------------------------------------------------------------------------*/
-
-SYM_FUNC_START(FPU_shrx)
-	push	%ebp
-	movl	%esp,%ebp
-	pushl	%esi
-	movl	PARAM2,%ecx
-	movl	PARAM1,%esi
-	cmpl	$32,%ecx	/* shrd only works for 0..31 bits */
-	jnc	L_more_than_31
-
-/* less than 32 bits */
-	pushl	%ebx
-	movl	(%esi),%ebx	/* lsl */
-	movl	4(%esi),%edx	/* msl */
-	xorl	%eax,%eax	/* extension */
-	shrd	%cl,%ebx,%eax
-	shrd	%cl,%edx,%ebx
-	shr	%cl,%edx
-	movl	%ebx,(%esi)
-	movl	%edx,4(%esi)
-	popl	%ebx
-	popl	%esi
-	leave
-	RET
-
-L_more_than_31:
-	cmpl	$64,%ecx
-	jnc	L_more_than_63
-
-	subb	$32,%cl
-	movl	(%esi),%eax	/* lsl */
-	movl	4(%esi),%edx	/* msl */
-	shrd	%cl,%edx,%eax
-	shr	%cl,%edx
-	movl	%edx,(%esi)
-	movl	$0,4(%esi)
-	popl	%esi
-	leave
-	RET
-
-L_more_than_63:
-	cmpl	$96,%ecx
-	jnc	L_more_than_95
-
-	subb	$64,%cl
-	movl	4(%esi),%eax	/* msl */
-	shr	%cl,%eax
-	xorl	%edx,%edx
-	movl	%edx,(%esi)
-	movl	%edx,4(%esi)
-	popl	%esi
-	leave
-	RET
-
-L_more_than_95:
-	xorl	%eax,%eax
-	movl	%eax,(%esi)
-	movl	%eax,4(%esi)
-	popl	%esi
-	leave
-	RET
-SYM_FUNC_END(FPU_shrx)
-
-
-/*---------------------------------------------------------------------------+
- |   unsigned FPU_shrxs(void *arg1, unsigned arg2)                           |
- |                                                                           |
- |   Extended shift right function (optimized for small floating point       |
- |   integers).                                                              |
- |   Shifts the 64 bit quantity pointed to by the first arg (arg1)           |
- |   right by the number of bits specified by the second arg (arg2).         |
- |   Forms a 96 bit quantity from the 64 bit arg and eax:                    |
- |                [  64 bit arg ][ eax ]                                     |
- |            shift right  --------->                                        |
- |   The eax register is initialized to 0 before the shifting.               |
- |   The lower 8 bits of eax are lost and replaced by a flag which is        |
- |   set (to 0x01) if any bit, apart from the first one, is set in the       |
- |   part which has been shifted out of the arg.                             |
- |   Results returned in the 64 bit arg and eax.                             |
- +---------------------------------------------------------------------------*/
-SYM_FUNC_START(FPU_shrxs)
-	push	%ebp
-	movl	%esp,%ebp
-	pushl	%esi
-	pushl	%ebx
-	movl	PARAM2,%ecx
-	movl	PARAM1,%esi
-	cmpl	$64,%ecx	/* shrd only works for 0..31 bits */
-	jnc	Ls_more_than_63
-
-	cmpl	$32,%ecx	/* shrd only works for 0..31 bits */
-	jc	Ls_less_than_32
-
-/* We got here without jumps by assuming that the most common requirement
-   is for small integers */
-/* Shift by [32..63] bits */
-	subb	$32,%cl
-	movl	(%esi),%eax	/* lsl */
-	movl	4(%esi),%edx	/* msl */
-	xorl	%ebx,%ebx
-	shrd	%cl,%eax,%ebx
-	shrd	%cl,%edx,%eax
-	shr	%cl,%edx
-	orl	%ebx,%ebx		/* test these 32 bits */
-	setne	%bl
-	test	$0x7fffffff,%eax	/* and 31 bits here */
-	setne	%bh
-	orw	%bx,%bx			/* Any of the 63 bit set ? */
-	setne	%al
-	movl	%edx,(%esi)
-	movl	$0,4(%esi)
-	popl	%ebx
-	popl	%esi
-	leave
-	RET
-
-/* Shift by [0..31] bits */
-Ls_less_than_32:
-	movl	(%esi),%ebx	/* lsl */
-	movl	4(%esi),%edx	/* msl */
-	xorl	%eax,%eax	/* extension */
-	shrd	%cl,%ebx,%eax
-	shrd	%cl,%edx,%ebx
-	shr	%cl,%edx
-	test	$0x7fffffff,%eax	/* only need to look at eax here */
-	setne	%al
-	movl	%ebx,(%esi)
-	movl	%edx,4(%esi)
-	popl	%ebx
-	popl	%esi
-	leave
-	RET
-
-/* Shift by [64..95] bits */
-Ls_more_than_63:
-	cmpl	$96,%ecx
-	jnc	Ls_more_than_95
-
-	subb	$64,%cl
-	movl	(%esi),%ebx	/* lsl */
-	movl	4(%esi),%eax	/* msl */
-	xorl	%edx,%edx	/* extension */
-	shrd	%cl,%ebx,%edx
-	shrd	%cl,%eax,%ebx
-	shr	%cl,%eax
-	orl	%ebx,%edx
-	setne	%bl
-	test	$0x7fffffff,%eax	/* only need to look at eax here */
-	setne	%bh
-	orw	%bx,%bx
-	setne	%al
-	xorl	%edx,%edx
-	movl	%edx,(%esi)	/* set to zero */
-	movl	%edx,4(%esi)	/* set to zero */
-	popl	%ebx
-	popl	%esi
-	leave
-	RET
-
-Ls_more_than_95:
-/* Shift by [96..inf) bits */
-	xorl	%eax,%eax
-	movl	(%esi),%ebx
-	orl	4(%esi),%ebx
-	setne	%al
-	xorl	%ebx,%ebx
-	movl	%ebx,(%esi)
-	movl	%ebx,4(%esi)
-	popl	%ebx
-	popl	%esi
-	leave
-	RET
-SYM_FUNC_END(FPU_shrxs)
diff -rupN a/arch/x86/math-emu/wm_sqrt.S b/arch/x86/math-emu/wm_sqrt.S
--- a/arch/x86/math-emu/wm_sqrt.S	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/math-emu/wm_sqrt.S	1970-01-01 01:00:00.000000000 +0100
@@ -1,472 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-	.file	"wm_sqrt.S"
-/*---------------------------------------------------------------------------+
- |  wm_sqrt.S                                                                |
- |                                                                           |
- | Fixed point arithmetic square root evaluation.                            |
- |                                                                           |
- | Copyright (C) 1992,1993,1995,1997                                         |
- |                       W. Metzenthen, 22 Parker St, Ormond, Vic 3163,      |
- |                       Australia.  E-mail billm@suburbia.net               |
- |                                                                           |
- | Call from C as:                                                           |
- |    int wm_sqrt(FPU_REG *n, unsigned int control_word)                     |
- |                                                                           |
- +---------------------------------------------------------------------------*/
-
-/*---------------------------------------------------------------------------+
- |  wm_sqrt(FPU_REG *n, unsigned int control_word)                           |
- |    returns the square root of n in n.                                     |
- |                                                                           |
- |  Use Newton's method to compute the square root of a number, which must   |
- |  be in the range  [1.0 .. 4.0),  to 64 bits accuracy.                     |
- |  Does not check the sign or tag of the argument.                          |
- |  Sets the exponent, but not the sign or tag of the result.                |
- |                                                                           |
- |  The guess is kept in %esi:%edi                                           |
- +---------------------------------------------------------------------------*/
-
-#include "exception.h"
-#include "fpu_emu.h"
-
-
-#ifndef NON_REENTRANT_FPU
-/*	Local storage on the stack: */
-#define FPU_accum_3	-4(%ebp)	/* ms word */
-#define FPU_accum_2	-8(%ebp)
-#define FPU_accum_1	-12(%ebp)
-#define FPU_accum_0	-16(%ebp)
-
-/*
- * The de-normalised argument:
- *                  sq_2                  sq_1              sq_0
- *        b b b b b b b ... b b b   b b b .... b b b   b 0 0 0 ... 0
- *           ^ binary point here
- */
-#define FPU_fsqrt_arg_2	-20(%ebp)	/* ms word */
-#define FPU_fsqrt_arg_1	-24(%ebp)
-#define FPU_fsqrt_arg_0	-28(%ebp)	/* ls word, at most the ms bit is set */
-
-#else
-/*	Local storage in a static area: */
-.data
-	.align 4,0
-FPU_accum_3:
-	.long	0		/* ms word */
-FPU_accum_2:
-	.long	0
-FPU_accum_1:
-	.long	0
-FPU_accum_0:
-	.long	0
-
-/* The de-normalised argument:
-                    sq_2                  sq_1              sq_0
-          b b b b b b b ... b b b   b b b .... b b b   b 0 0 0 ... 0
-             ^ binary point here
- */
-FPU_fsqrt_arg_2:
-	.long	0		/* ms word */
-FPU_fsqrt_arg_1:
-	.long	0
-FPU_fsqrt_arg_0:
-	.long	0		/* ls word, at most the ms bit is set */
-#endif /* NON_REENTRANT_FPU */ 
-
-
-.text
-SYM_FUNC_START(wm_sqrt)
-	pushl	%ebp
-	movl	%esp,%ebp
-#ifndef NON_REENTRANT_FPU
-	subl	$28,%esp
-#endif /* NON_REENTRANT_FPU */
-	pushl	%esi
-	pushl	%edi
-	pushl	%ebx
-
-	movl	PARAM1,%esi
-
-	movl	SIGH(%esi),%eax
-	movl	SIGL(%esi),%ecx
-	xorl	%edx,%edx
-
-/* We use a rough linear estimate for the first guess.. */
-
-	cmpw	EXP_BIAS,EXP(%esi)
-	jnz	sqrt_arg_ge_2
-
-	shrl	$1,%eax			/* arg is in the range  [1.0 .. 2.0) */
-	rcrl	$1,%ecx
-	rcrl	$1,%edx
-
-sqrt_arg_ge_2:
-/* From here on, n is never accessed directly again until it is
-   replaced by the answer. */
-
-	movl	%eax,FPU_fsqrt_arg_2		/* ms word of n */
-	movl	%ecx,FPU_fsqrt_arg_1
-	movl	%edx,FPU_fsqrt_arg_0
-
-/* Make a linear first estimate */
-	shrl	$1,%eax
-	addl	$0x40000000,%eax
-	movl	$0xaaaaaaaa,%ecx
-	mull	%ecx
-	shll	%edx			/* max result was 7fff... */
-	testl	$0x80000000,%edx	/* but min was 3fff... */
-	jnz	sqrt_prelim_no_adjust
-
-	movl	$0x80000000,%edx	/* round up */
-
-sqrt_prelim_no_adjust:
-	movl	%edx,%esi	/* Our first guess */
-
-/* We have now computed (approx)   (2 + x) / 3, which forms the basis
-   for a few iterations of Newton's method */
-
-	movl	FPU_fsqrt_arg_2,%ecx	/* ms word */
-
-/*
- * From our initial estimate, three iterations are enough to get us
- * to 30 bits or so. This will then allow two iterations at better
- * precision to complete the process.
- */
-
-/* Compute  (g + n/g)/2  at each iteration (g is the guess). */
-	shrl	%ecx		/* Doing this first will prevent a divide */
-				/* overflow later. */
-
-	movl	%ecx,%edx	/* msw of the arg / 2 */
-	divl	%esi		/* current estimate */
-	shrl	%esi		/* divide by 2 */
-	addl	%eax,%esi	/* the new estimate */
-
-	movl	%ecx,%edx
-	divl	%esi
-	shrl	%esi
-	addl	%eax,%esi
-
-	movl	%ecx,%edx
-	divl	%esi
-	shrl	%esi
-	addl	%eax,%esi
-
-/*
- * Now that an estimate accurate to about 30 bits has been obtained (in %esi),
- * we improve it to 60 bits or so.
- *
- * The strategy from now on is to compute new estimates from
- *      guess := guess + (n - guess^2) / (2 * guess)
- */
-
-/* First, find the square of the guess */
-	movl	%esi,%eax
-	mull	%esi
-/* guess^2 now in %edx:%eax */
-
-	movl	FPU_fsqrt_arg_1,%ecx
-	subl	%ecx,%eax
-	movl	FPU_fsqrt_arg_2,%ecx	/* ms word of normalized n */
-	sbbl	%ecx,%edx
-	jnc	sqrt_stage_2_positive
-
-/* Subtraction gives a negative result,
-   negate the result before division. */
-	notl	%edx
-	notl	%eax
-	addl	$1,%eax
-	adcl	$0,%edx
-
-	divl	%esi
-	movl	%eax,%ecx
-
-	movl	%edx,%eax
-	divl	%esi
-	jmp	sqrt_stage_2_finish
-
-sqrt_stage_2_positive:
-	divl	%esi
-	movl	%eax,%ecx
-
-	movl	%edx,%eax
-	divl	%esi
-
-	notl	%ecx
-	notl	%eax
-	addl	$1,%eax
-	adcl	$0,%ecx
-
-sqrt_stage_2_finish:
-	sarl	$1,%ecx		/* divide by 2 */
-	rcrl	$1,%eax
-
-	/* Form the new estimate in %esi:%edi */
-	movl	%eax,%edi
-	addl	%ecx,%esi
-
-	jnz	sqrt_stage_2_done	/* result should be [1..2) */
-
-#ifdef PARANOID
-/* It should be possible to get here only if the arg is ffff....ffff */
-	cmpl	$0xffffffff,FPU_fsqrt_arg_1
-	jnz	sqrt_stage_2_error
-#endif /* PARANOID */
-
-/* The best rounded result. */
-	xorl	%eax,%eax
-	decl	%eax
-	movl	%eax,%edi
-	movl	%eax,%esi
-	movl	$0x7fffffff,%eax
-	jmp	sqrt_round_result
-
-#ifdef PARANOID
-sqrt_stage_2_error:
-	pushl	EX_INTERNAL|0x213
-	call	EXCEPTION
-#endif /* PARANOID */ 
-
-sqrt_stage_2_done:
-
-/* Now the square root has been computed to better than 60 bits. */
-
-/* Find the square of the guess. */
-	movl	%edi,%eax		/* ls word of guess */
-	mull	%edi
-	movl	%edx,FPU_accum_1
-
-	movl	%esi,%eax
-	mull	%esi
-	movl	%edx,FPU_accum_3
-	movl	%eax,FPU_accum_2
-
-	movl	%edi,%eax
-	mull	%esi
-	addl	%eax,FPU_accum_1
-	adcl	%edx,FPU_accum_2
-	adcl	$0,FPU_accum_3
-
-/*	movl	%esi,%eax */
-/*	mull	%edi */
-	addl	%eax,FPU_accum_1
-	adcl	%edx,FPU_accum_2
-	adcl	$0,FPU_accum_3
-
-/* guess^2 now in FPU_accum_3:FPU_accum_2:FPU_accum_1 */
-
-	movl	FPU_fsqrt_arg_0,%eax		/* get normalized n */
-	subl	%eax,FPU_accum_1
-	movl	FPU_fsqrt_arg_1,%eax
-	sbbl	%eax,FPU_accum_2
-	movl	FPU_fsqrt_arg_2,%eax		/* ms word of normalized n */
-	sbbl	%eax,FPU_accum_3
-	jnc	sqrt_stage_3_positive
-
-/* Subtraction gives a negative result,
-   negate the result before division */
-	notl	FPU_accum_1
-	notl	FPU_accum_2
-	notl	FPU_accum_3
-	addl	$1,FPU_accum_1
-	adcl	$0,FPU_accum_2
-
-#ifdef PARANOID
-	adcl	$0,FPU_accum_3	/* This must be zero */
-	jz	sqrt_stage_3_no_error
-
-sqrt_stage_3_error:
-	pushl	EX_INTERNAL|0x207
-	call	EXCEPTION
-
-sqrt_stage_3_no_error:
-#endif /* PARANOID */
-
-	movl	FPU_accum_2,%edx
-	movl	FPU_accum_1,%eax
-	divl	%esi
-	movl	%eax,%ecx
-
-	movl	%edx,%eax
-	divl	%esi
-
-	sarl	$1,%ecx		/* divide by 2 */
-	rcrl	$1,%eax
-
-	/* prepare to round the result */
-
-	addl	%ecx,%edi
-	adcl	$0,%esi
-
-	jmp	sqrt_stage_3_finished
-
-sqrt_stage_3_positive:
-	movl	FPU_accum_2,%edx
-	movl	FPU_accum_1,%eax
-	divl	%esi
-	movl	%eax,%ecx
-
-	movl	%edx,%eax
-	divl	%esi
-
-	sarl	$1,%ecx		/* divide by 2 */
-	rcrl	$1,%eax
-
-	/* prepare to round the result */
-
-	notl	%eax		/* Negate the correction term */
-	notl	%ecx
-	addl	$1,%eax
-	adcl	$0,%ecx		/* carry here ==> correction == 0 */
-	adcl	$0xffffffff,%esi
-
-	addl	%ecx,%edi
-	adcl	$0,%esi
-
-sqrt_stage_3_finished:
-
-/*
- * The result in %esi:%edi:%esi should be good to about 90 bits here,
- * and the rounding information here does not have sufficient accuracy
- * in a few rare cases.
- */
-	cmpl	$0xffffffe0,%eax
-	ja	sqrt_near_exact_x
-
-	cmpl	$0x00000020,%eax
-	jb	sqrt_near_exact
-
-	cmpl	$0x7fffffe0,%eax
-	jb	sqrt_round_result
-
-	cmpl	$0x80000020,%eax
-	jb	sqrt_get_more_precision
-
-sqrt_round_result:
-/* Set up for rounding operations */
-	movl	%eax,%edx
-	movl	%esi,%eax
-	movl	%edi,%ebx
-	movl	PARAM1,%edi
-	movw	EXP_BIAS,EXP(%edi)	/* Result is in  [1.0 .. 2.0) */
-	jmp	fpu_reg_round
-
-
-sqrt_near_exact_x:
-/* First, the estimate must be rounded up. */
-	addl	$1,%edi
-	adcl	$0,%esi
-
-sqrt_near_exact:
-/*
- * This is an easy case because x^1/2 is monotonic.
- * We need just find the square of our estimate, compare it
- * with the argument, and deduce whether our estimate is
- * above, below, or exact. We use the fact that the estimate
- * is known to be accurate to about 90 bits.
- */
-	movl	%edi,%eax		/* ls word of guess */
-	mull	%edi
-	movl	%edx,%ebx		/* 2nd ls word of square */
-	movl	%eax,%ecx		/* ls word of square */
-
-	movl	%edi,%eax
-	mull	%esi
-	addl	%eax,%ebx
-	addl	%eax,%ebx
-
-#ifdef PARANOID
-	cmp	$0xffffffb0,%ebx
-	jb	sqrt_near_exact_ok
-
-	cmp	$0x00000050,%ebx
-	ja	sqrt_near_exact_ok
-
-	pushl	EX_INTERNAL|0x214
-	call	EXCEPTION
-
-sqrt_near_exact_ok:
-#endif /* PARANOID */ 
-
-	or	%ebx,%ebx
-	js	sqrt_near_exact_small
-
-	jnz	sqrt_near_exact_large
-
-	or	%ebx,%edx
-	jnz	sqrt_near_exact_large
-
-/* Our estimate is exactly the right answer */
-	xorl	%eax,%eax
-	jmp	sqrt_round_result
-
-sqrt_near_exact_small:
-/* Our estimate is too small */
-	movl	$0x000000ff,%eax
-	jmp	sqrt_round_result
-	
-sqrt_near_exact_large:
-/* Our estimate is too large, we need to decrement it */
-	subl	$1,%edi
-	sbbl	$0,%esi
-	movl	$0xffffff00,%eax
-	jmp	sqrt_round_result
-
-
-sqrt_get_more_precision:
-/* This case is almost the same as the above, except we start
-   with an extra bit of precision in the estimate. */
-	stc			/* The extra bit. */
-	rcll	$1,%edi		/* Shift the estimate left one bit */
-	rcll	$1,%esi
-
-	movl	%edi,%eax		/* ls word of guess */
-	mull	%edi
-	movl	%edx,%ebx		/* 2nd ls word of square */
-	movl	%eax,%ecx		/* ls word of square */
-
-	movl	%edi,%eax
-	mull	%esi
-	addl	%eax,%ebx
-	addl	%eax,%ebx
-
-/* Put our estimate back to its original value */
-	stc			/* The ms bit. */
-	rcrl	$1,%esi		/* Shift the estimate left one bit */
-	rcrl	$1,%edi
-
-#ifdef PARANOID
-	cmp	$0xffffff60,%ebx
-	jb	sqrt_more_prec_ok
-
-	cmp	$0x000000a0,%ebx
-	ja	sqrt_more_prec_ok
-
-	pushl	EX_INTERNAL|0x215
-	call	EXCEPTION
-
-sqrt_more_prec_ok:
-#endif /* PARANOID */ 
-
-	or	%ebx,%ebx
-	js	sqrt_more_prec_small
-
-	jnz	sqrt_more_prec_large
-
-	or	%ebx,%ecx
-	jnz	sqrt_more_prec_large
-
-/* Our estimate is exactly the right answer */
-	movl	$0x80000000,%eax
-	jmp	sqrt_round_result
-
-sqrt_more_prec_small:
-/* Our estimate is too small */
-	movl	$0x800000ff,%eax
-	jmp	sqrt_round_result
-	
-sqrt_more_prec_large:
-/* Our estimate is too large */
-	movl	$0x7fffff00,%eax
-	jmp	sqrt_round_result
-SYM_FUNC_END(wm_sqrt)
diff -rupN a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c
--- a/arch/x86/mm/fault.c	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/mm/fault.c	2025-06-01 20:34:16.755109413 +0200
@@ -754,9 +754,9 @@ show_signal_msg(struct pt_regs *regs, un
 	if (!printk_ratelimit())
 		return;
 
-	printk("%s%s[%d]: segfault at %lx ip %px sp %px error %lx",
+	printk("%s%s[%d]: segfault at %lx ip %px sp %px error %lx cpu %i",
 		loglvl, tsk->comm, task_pid_nr(tsk), address,
-		(void *)regs->ip, (void *)regs->sp, error_code);
+		(void *)regs->ip, (void *)regs->sp, error_code, raw_smp_processor_id());
 
 	print_vma_addr(KERN_CONT " in ", regs->ip);
 
diff -rupN a/arch/x86/xen/Kconfig b/arch/x86/xen/Kconfig
--- a/arch/x86/xen/Kconfig	2025-06-01 18:01:58.000000000 +0200
+++ b/arch/x86/xen/Kconfig	2025-06-01 20:34:16.756109422 +0200
@@ -10,7 +10,7 @@ config XEN
 	select X86_HV_CALLBACK_VECTOR
 	depends on X86_64 || (X86_32 && X86_PAE)
 	depends on X86_64 || (X86_GENERIC || MPENTIUM4 || MATOM)
-	depends on X86_LOCAL_APIC && X86_TSC
+	depends on X86_LOCAL_APIC
 	help
 	  This is the Linux Xen port.  Enabling this will allow the
 	  kernel to boot in a paravirtualized environment under the
diff -rupN a/block/adios.c b/block/adios.c
--- a/block/adios.c	1970-01-01 01:00:00.000000000 +0100
+++ b/block/adios.c	2025-06-01 20:34:16.757109430 +0200
@@ -0,0 +1,1344 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Adaptive Deadline I/O Scheduler (ADIOS)
+ * Copyright (C) 2025 Masahito Suzuki
+ */
+#include <linux/bio.h>
+#include <linux/blkdev.h>
+#include <linux/compiler.h>
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/math.h>
+#include <linux/module.h>
+#include <linux/rbtree.h>
+#include <linux/sbitmap.h>
+#include <linux/slab.h>
+#include <linux/timekeeping.h>
+
+#include "elevator.h"
+#include "blk.h"
+#include "blk-mq.h"
+#include "blk-mq-sched.h"
+
+#define ADIOS_VERSION "1.5.8"
+
+// Define operation types supported by ADIOS
+enum adios_op_type {
+	ADIOS_READ    = 0,
+	ADIOS_WRITE   = 1,
+	ADIOS_DISCARD = 2,
+	ADIOS_OTHER   = 3,
+	ADIOS_OPTYPES = 4,
+};
+
+// Global variable to control the latency
+static u64 default_global_latency_window = 16000000ULL;
+// Ratio below which batch queues should be refilled
+static u8  default_bq_refill_below_ratio = 15;
+
+// Dynamic thresholds for shrinkage
+static u32 default_lm_shrink_at_kreqs  = 10000;
+static u32 default_lm_shrink_at_gbytes =   100;
+static u32 default_lm_shrink_resist    =     2;
+
+// Latency targets for each operation type
+static u64 default_latency_target[ADIOS_OPTYPES] = {
+	[ADIOS_READ]    =     1ULL * NSEC_PER_MSEC,
+	[ADIOS_WRITE]   =  2000ULL * NSEC_PER_MSEC,
+	[ADIOS_DISCARD] =  8000ULL * NSEC_PER_MSEC,
+	[ADIOS_OTHER]   =     0ULL * NSEC_PER_MSEC,
+};
+
+// Maximum batch size limits for each operation type
+static u32 default_batch_limit[ADIOS_OPTYPES] = {
+	[ADIOS_READ]    = 24,
+	[ADIOS_WRITE]   = 48,
+	[ADIOS_DISCARD] =  1,
+	[ADIOS_OTHER]   =  1,
+};
+
+static u32 default_dl_prio[2] = {7, 0};
+
+// Thresholds for latency model control
+#define LM_BLOCK_SIZE_THRESHOLD 4096
+#define LM_SAMPLES_THRESHOLD    1024
+#define LM_INTERVAL_THRESHOLD   1500
+#define LM_OUTLIER_PERCENTILE     99
+#define LM_LAT_BUCKET_COUNT       64
+
+// Structure to hold latency bucket data for small requests
+struct latency_bucket_small {
+	u64 sum_latency;
+	u32 count;
+};
+
+// Structure to hold latency bucket data for large requests
+struct latency_bucket_large {
+	u64 sum_latency;
+	u64 sum_block_size;
+	u32 count;
+};
+
+// Structure to hold the latency model context data
+struct latency_model {
+	spinlock_t lock;
+	u64 base;
+	u64 slope;
+	u64 small_sum_delay;
+	u64 small_count;
+	u64 large_sum_delay;
+	u64 large_sum_bsize;
+	u64 last_update_jiffies;
+
+	spinlock_t buckets_lock;
+	struct latency_bucket_small small_bucket[LM_LAT_BUCKET_COUNT];
+	struct latency_bucket_large large_bucket[LM_LAT_BUCKET_COUNT];
+
+	u32 lm_shrink_at_kreqs;
+	u32 lm_shrink_at_gbytes;
+	u8  lm_shrink_resist;
+};
+
+#define ADIOS_BQ_PAGES 2
+
+// Adios scheduler data
+struct adios_data {
+	spinlock_t pq_lock;
+	struct list_head prio_queue;
+
+	struct rb_root_cached dl_tree[2];
+	spinlock_t lock;
+	u8  dl_queued;
+	s64 dl_bias;
+	s32 dl_prio[2];
+
+	u64 global_latency_window;
+	u64 latency_target[ADIOS_OPTYPES];
+	u32 batch_limit[ADIOS_OPTYPES];
+	u32 batch_actual_max_size[ADIOS_OPTYPES];
+	u32 batch_actual_max_total;
+	u32 async_depth;
+	u8  bq_refill_below_ratio;
+
+	u8 bq_page;
+	bool more_bq_ready;
+	struct list_head batch_queue[ADIOS_BQ_PAGES][ADIOS_OPTYPES];
+	u32 batch_count[ADIOS_BQ_PAGES][ADIOS_OPTYPES];
+	spinlock_t bq_lock;
+
+	struct latency_model latency_model[ADIOS_OPTYPES];
+	struct timer_list update_timer;
+
+	atomic64_t total_pred_lat;
+
+	struct kmem_cache *rq_data_pool;
+	struct kmem_cache *dl_group_pool;
+
+	struct request_queue *queue;
+};
+
+// List of requests with the same deadline in the deadline-sorted tree
+struct dl_group {
+	struct rb_node node;
+	struct list_head rqs;
+	u64 deadline;
+} __attribute__((aligned(64)));
+
+// Structure to hold scheduler-specific data for each request
+struct adios_rq_data {
+	struct list_head *dl_group;
+	struct list_head dl_node;
+
+	struct request *rq;
+	u64 deadline;
+	u64 pred_lat;
+	u32 block_size;
+} __attribute__((aligned(64)));
+
+static const int adios_prio_to_weight[40] = {
+ /* -20 */     88761,     71755,     56483,     46273,     36291,
+ /* -15 */     29154,     23254,     18705,     14949,     11916,
+ /* -10 */      9548,      7620,      6100,      4904,      3906,
+ /*  -5 */      3121,      2501,      1991,      1586,      1277,
+ /*   0 */      1024,       820,       655,       526,       423,
+ /*   5 */       335,       272,       215,       172,       137,
+ /*  10 */       110,        87,        70,        56,        45,
+ /*  15 */        36,        29,        23,        18,        15,
+};
+
+// Count the number of entries in small buckets
+static u32 lm_count_small_entries(struct latency_model *model) {
+	u32 total_count = 0;
+	for (u8 i = 0; i < LM_LAT_BUCKET_COUNT; i++)
+		total_count += model->small_bucket[i].count;
+	return total_count;
+}
+
+// Update the small buckets in the latency model
+static bool lm_update_small_buckets(struct latency_model *model,
+		u32 total_count, bool count_all) {
+	u64 sum_latency = 0;
+	u32 sum_count = 0;
+	u32 cumulative_count = 0, threshold_count = 0;
+	u8  outlier_threshold_bucket = 0;
+	u8  outlier_percentile = LM_OUTLIER_PERCENTILE;
+	u8  reduction;
+
+	if (count_all)
+		outlier_percentile = 100;
+
+	// Calculate the threshold count for outlier detection
+	threshold_count = (total_count * outlier_percentile) / 100;
+
+	// Identify the bucket that corresponds to the outlier threshold
+	for (u8 i = 0; i < LM_LAT_BUCKET_COUNT; i++) {
+		cumulative_count += model->small_bucket[i].count;
+		if (cumulative_count >= threshold_count) {
+			outlier_threshold_bucket = i;
+			break;
+		}
+	}
+
+	// Calculate the average latency, excluding outliers
+	for (u8 i = 0; i <= outlier_threshold_bucket; i++) {
+		struct latency_bucket_small *bucket = &model->small_bucket[i];
+		if (i < outlier_threshold_bucket) {
+			sum_latency += bucket->sum_latency;
+			sum_count += bucket->count;
+		} else {
+			// The threshold bucket's contribution is proportional
+			u64 remaining_count =
+				threshold_count - (cumulative_count - bucket->count);
+			if (bucket->count > 0) {
+				sum_latency +=
+					div_u64((bucket->sum_latency * remaining_count), bucket->count);
+				sum_count += remaining_count;
+			}
+		}
+	}
+
+	// Shrink the model if it reaches at the readjustment threshold
+	if (model->small_count >= 1000ULL * model->lm_shrink_at_kreqs) {
+		reduction = model->lm_shrink_resist;
+		if (model->small_count >> reduction) {
+			model->small_sum_delay -= model->small_sum_delay >> reduction;
+			model->small_count     -= model->small_count     >> reduction;
+		}
+	}
+
+	// Accumulate the average latency into the statistics
+	model->small_sum_delay += sum_latency;
+	model->small_count += sum_count;
+
+	// Reset small bucket information
+	memset(model->small_bucket, 0,
+		sizeof(model->small_bucket[0]) * LM_LAT_BUCKET_COUNT);
+
+	return true;
+}
+
+// Count the number of entries in large buckets
+static u32 lm_count_large_entries(struct latency_model *model) {
+	u32 total_count = 0;
+	for (u8 i = 0; i < LM_LAT_BUCKET_COUNT; i++)
+		total_count += model->large_bucket[i].count;
+	return total_count;
+}
+
+// Update the large buckets in the latency model
+static bool lm_update_large_buckets(
+		struct latency_model *model,
+		u32 total_count, bool count_all) {
+	s64 sum_latency = 0;
+	u64 sum_block_size = 0, intercept;
+	u32 cumulative_count = 0, threshold_count = 0;
+	u8  outlier_threshold_bucket = 0;
+	u8  outlier_percentile = LM_OUTLIER_PERCENTILE;
+	u8  reduction;
+
+	if (count_all)
+		outlier_percentile = 100;
+
+	// Calculate the threshold count for outlier detection
+	threshold_count = (total_count * outlier_percentile) / 100;
+
+	// Identify the bucket that corresponds to the outlier threshold
+	for (u8 i = 0; i < LM_LAT_BUCKET_COUNT; i++) {
+		cumulative_count += model->large_bucket[i].count;
+		if (cumulative_count >= threshold_count) {
+			outlier_threshold_bucket = i;
+			break;
+		}
+	}
+
+	// Calculate the average latency and block size, excluding outliers
+	for (u8 i = 0; i <= outlier_threshold_bucket; i++) {
+		struct latency_bucket_large *bucket = &model->large_bucket[i];
+		if (i < outlier_threshold_bucket) {
+			sum_latency += bucket->sum_latency;
+			sum_block_size += bucket->sum_block_size;
+		} else {
+			// The threshold bucket's contribution is proportional
+			u64 remaining_count =
+				threshold_count - (cumulative_count - bucket->count);
+			if (bucket->count > 0) {
+				sum_latency +=
+					div_u64((bucket->sum_latency * remaining_count), bucket->count);
+				sum_block_size +=
+					div_u64((bucket->sum_block_size * remaining_count), bucket->count);
+			}
+		}
+	}
+
+	// Shrink the model if it reaches at the readjustment threshold
+	if (model->large_sum_bsize >= 0x40000000ULL * model->lm_shrink_at_gbytes) {
+		reduction = model->lm_shrink_resist;
+		if (model->large_sum_bsize >> reduction) {
+			model->large_sum_delay -= model->large_sum_delay >> reduction;
+			model->large_sum_bsize -= model->large_sum_bsize >> reduction;
+		}
+	}
+
+	// Accumulate the average delay into the statistics
+	intercept = model->base * threshold_count;
+	if (sum_latency > intercept)
+		sum_latency -= intercept;
+
+	model->large_sum_delay += sum_latency;
+	model->large_sum_bsize += sum_block_size;
+
+	// Reset large bucket information
+	memset(model->large_bucket, 0,
+		sizeof(model->large_bucket[0]) * LM_LAT_BUCKET_COUNT);
+
+	return true;
+}
+
+// Update the latency model parameters and statistics
+static void latency_model_update(struct latency_model *model) {
+	unsigned long flags;
+	u64 now;
+	u32 small_count, large_count;
+	bool time_elapsed;
+	bool small_processed = false, large_processed = false;
+
+	guard(spinlock_irqsave)(&model->lock);
+
+	spin_lock_irqsave(&model->buckets_lock, flags);
+
+	// Whether enough time has elapsed since the last update
+	now = jiffies;
+	time_elapsed = unlikely(!model->base) || model->last_update_jiffies +
+		msecs_to_jiffies(LM_INTERVAL_THRESHOLD) <= now;
+
+	// Count the number of entries in buckets
+	small_count = lm_count_small_entries(model);
+	large_count = lm_count_large_entries(model);
+
+	// Update small buckets
+	if (small_count && (time_elapsed ||
+			LM_SAMPLES_THRESHOLD <= small_count || !model->base))
+		small_processed = lm_update_small_buckets(
+			model, small_count, !model->base);
+	// Update large buckets
+	if (large_count && (time_elapsed ||
+			LM_SAMPLES_THRESHOLD <= large_count || !model->slope))
+		large_processed = lm_update_large_buckets(
+			model, large_count, !model->slope);
+
+	spin_unlock_irqrestore(&model->buckets_lock, flags);
+
+	// Update the base parameter if small bucket was processed
+	if (small_processed && likely(model->small_count))
+		model->base = div_u64(model->small_sum_delay, model->small_count);
+
+	// Update the slope parameter if large bucket was processed
+	if (large_processed && likely(model->large_sum_bsize))
+		model->slope = div_u64(model->large_sum_delay,
+			DIV_ROUND_UP_ULL(model->large_sum_bsize, 1024));
+
+	// Reset statistics and update last updated jiffies if time has elapsed
+	if (time_elapsed)
+		model->last_update_jiffies = now;
+}
+
+// Determine the bucket index for a given measured and predicted latency
+static u8 lm_input_bucket_index(
+		struct latency_model *model, u64 measured, u64 predicted) {
+	u8 bucket_index;
+
+	if (measured < predicted * 2)
+		bucket_index = div_u64((measured * 20), predicted);
+	else if (measured < predicted * 5)
+		bucket_index = div_u64((measured * 10), predicted) + 20;
+	else
+		bucket_index = div_u64((measured * 3), predicted) + 40;
+
+	return bucket_index;
+}
+
+// Input latency data into the latency model
+static void latency_model_input(struct latency_model *model,
+		u32 block_size, u64 latency, u64 pred_lat) {
+	unsigned long flags;
+	u8 bucket_index;
+
+	spin_lock_irqsave(&model->buckets_lock, flags);
+
+	if (block_size <= LM_BLOCK_SIZE_THRESHOLD) {
+		// Handle small requests
+		bucket_index = lm_input_bucket_index(model, latency, model->base ?: 1);
+
+		if (bucket_index >= LM_LAT_BUCKET_COUNT)
+			bucket_index = LM_LAT_BUCKET_COUNT - 1;
+
+		model->small_bucket[bucket_index].count++;
+		model->small_bucket[bucket_index].sum_latency += latency;
+
+		if (unlikely(!model->base)) {
+			spin_unlock_irqrestore(&model->buckets_lock, flags);
+			latency_model_update(model);
+			return;
+		}
+	} else {
+		// Handle large requests
+		if (!model->base || !pred_lat) {
+			spin_unlock_irqrestore(&model->buckets_lock, flags);
+			return;
+		}
+
+		bucket_index = lm_input_bucket_index(model, latency, pred_lat);
+
+		if (bucket_index >= LM_LAT_BUCKET_COUNT)
+			bucket_index = LM_LAT_BUCKET_COUNT - 1;
+
+		model->large_bucket[bucket_index].count++;
+		model->large_bucket[bucket_index].sum_latency += latency;
+		model->large_bucket[bucket_index].sum_block_size += block_size;
+	}
+
+	spin_unlock_irqrestore(&model->buckets_lock, flags);
+}
+
+// Predict the latency for a given block size using the latency model
+static u64 latency_model_predict(struct latency_model *model, u32 block_size) {
+	u64 result;
+
+	guard(spinlock_irqsave)(&model->lock);
+	// Predict latency based on the model
+	result = model->base;
+	if (block_size > LM_BLOCK_SIZE_THRESHOLD)
+		result += model->slope *
+			DIV_ROUND_UP_ULL(block_size - LM_BLOCK_SIZE_THRESHOLD, 1024);
+
+	return result;
+}
+
+// Determine the type of operation based on request flags
+static u8 adios_optype(struct request *rq) {
+	switch (rq->cmd_flags & REQ_OP_MASK) {
+	case REQ_OP_READ:
+		return ADIOS_READ;
+	case REQ_OP_WRITE:
+		return ADIOS_WRITE;
+	case REQ_OP_DISCARD:
+		return ADIOS_DISCARD;
+	default:
+		return ADIOS_OTHER;
+	}
+}
+
+static inline u8 adios_optype_not_read(struct request *rq) {
+	return (rq->cmd_flags & REQ_OP_MASK) != REQ_OP_READ;
+}
+
+// Helper function to retrieve adios_rq_data from a request
+static inline struct adios_rq_data *get_rq_data(struct request *rq) {
+	return rq->elv.priv[0];
+}
+
+// Add a request to the deadline-sorted red-black tree
+static void add_to_dl_tree(
+		struct adios_data *ad, bool dl_idx, struct request *rq) {
+	struct rb_root_cached *root = &ad->dl_tree[dl_idx];
+	struct rb_node **link = &(root->rb_root.rb_node), *parent = NULL;
+	bool leftmost = true;
+	struct adios_rq_data *rd = get_rq_data(rq);
+	struct dl_group *dlg;
+
+	rd->block_size = blk_rq_bytes(rq);
+	u8 optype = adios_optype(rq);
+	rd->pred_lat =
+		latency_model_predict(&ad->latency_model[optype], rd->block_size);
+	rd->deadline =
+		rq->start_time_ns + ad->latency_target[optype] + rd->pred_lat;
+
+	while (*link) {
+		dlg = rb_entry(*link, struct dl_group, node);
+		s64 diff = rd->deadline - dlg->deadline;
+
+		parent = *link;
+		if (diff < 0) {
+			link = &((*link)->rb_left);
+		} else if (diff > 0) {
+			link = &((*link)->rb_right);
+			leftmost = false;
+		} else { // diff == 0
+			goto found;
+		}
+	}
+
+	dlg = rb_entry_safe(parent, struct dl_group, node);
+	if (!dlg || dlg->deadline != rd->deadline) {
+		dlg = kmem_cache_zalloc(ad->dl_group_pool, GFP_ATOMIC);
+		if (!dlg)
+			return;
+		dlg->deadline = rd->deadline;
+		INIT_LIST_HEAD(&dlg->rqs);
+		rb_link_node(&dlg->node, parent, link);
+		rb_insert_color_cached(&dlg->node, root, leftmost);
+	}
+found:
+	list_add_tail(&rd->dl_node, &dlg->rqs);
+	rd->dl_group = &dlg->rqs;
+	ad->dl_queued |= 1 << dl_idx;
+}
+
+// Remove a request from the deadline-sorted red-black tree
+static void del_from_dl_tree(
+		struct adios_data *ad, bool dl_idx, struct request *rq) {
+	struct rb_root_cached *root = &ad->dl_tree[dl_idx];
+	struct adios_rq_data *rd = get_rq_data(rq);
+	struct dl_group *dlg = container_of(rd->dl_group, struct dl_group, rqs);
+
+	list_del_init(&rd->dl_node);
+	if (list_empty(&dlg->rqs)) {
+		rb_erase_cached(&dlg->node, root);
+		kmem_cache_free(ad->dl_group_pool, dlg);
+	}
+	rd->dl_group = NULL;
+
+	if (RB_EMPTY_ROOT(&ad->dl_tree[dl_idx].rb_root))
+		ad->dl_queued &= ~(1 << dl_idx);
+}
+
+// Remove a request from the scheduler
+static void remove_request(struct adios_data *ad, struct request *rq) {
+	bool dl_idx = adios_optype_not_read(rq);
+	struct request_queue *q = rq->q;
+	struct adios_rq_data *rd = get_rq_data(rq);
+
+	list_del_init(&rq->queuelist);
+
+	// We might not be on the rbtree, if we are doing an insert merge
+	if (rd->dl_group)
+		del_from_dl_tree(ad, dl_idx, rq);
+
+	elv_rqhash_del(q, rq);
+	if (q->last_merge == rq)
+		q->last_merge = NULL;
+}
+
+// Convert a queue depth to the corresponding word depth for shallow allocation
+static int to_word_depth(struct blk_mq_hw_ctx *hctx, unsigned int qdepth) {
+	struct sbitmap_queue *bt = &hctx->sched_tags->bitmap_tags;
+	const unsigned int nrr = hctx->queue->nr_requests;
+
+	return ((qdepth << bt->sb.shift) + nrr - 1) / nrr;
+}
+
+// Limit the depth of request allocation for asynchronous and write requests
+static void adios_limit_depth(blk_opf_t opf, struct blk_mq_alloc_data *data) {
+	struct adios_data *ad = data->q->elevator->elevator_data;
+
+	// Do not throttle synchronous reads
+	if (op_is_sync(opf) && !op_is_write(opf))
+		return;
+
+	data->shallow_depth = to_word_depth(data->hctx, ad->async_depth);
+}
+
+// Update async_depth when the number of requests in the queue changes
+static void adios_depth_updated(struct blk_mq_hw_ctx *hctx) {
+	struct request_queue *q = hctx->queue;
+	struct adios_data *ad = q->elevator->elevator_data;
+	struct blk_mq_tags *tags = hctx->sched_tags;
+
+	ad->async_depth = q->nr_requests;
+
+	sbitmap_queue_min_shallow_depth(&tags->bitmap_tags, 1);
+}
+
+// Handle request merging after a merge operation
+static void adios_request_merged(struct request_queue *q, struct request *req,
+				  enum elv_merge type) {
+	bool dl_idx = adios_optype_not_read(req);
+	struct adios_data *ad = q->elevator->elevator_data;
+
+	// if the merge was a front merge, we need to reposition request
+	if (type == ELEVATOR_FRONT_MERGE) {
+		del_from_dl_tree(ad, dl_idx, req);
+		add_to_dl_tree(ad, dl_idx, req);
+	}
+}
+
+// Handle merging of requests after one has been merged into another
+static void adios_merged_requests(struct request_queue *q, struct request *req,
+				   struct request *next) {
+	struct adios_data *ad = q->elevator->elevator_data;
+
+	lockdep_assert_held(&ad->lock);
+
+	// kill knowledge of next, this one is a goner
+	remove_request(ad, next);
+}
+
+// Try to merge a bio into an existing rq before associating it with an rq
+static bool adios_bio_merge(struct request_queue *q, struct bio *bio,
+		unsigned int nr_segs) {
+	unsigned long flags;
+	struct adios_data *ad = q->elevator->elevator_data;
+	struct request *free = NULL;
+	bool ret;
+
+	spin_lock_irqsave(&ad->lock, flags);
+	ret = blk_mq_sched_try_merge(q, bio, nr_segs, &free);
+	spin_unlock_irqrestore(&ad->lock, flags);
+
+	if (free)
+		blk_mq_free_request(free);
+
+	return ret;
+}
+
+// Insert a request into the scheduler
+static void insert_request(struct blk_mq_hw_ctx *hctx, struct request *rq,
+				  blk_insert_t insert_flags, struct list_head *free) {
+	unsigned long flags;
+	bool dl_idx = adios_optype_not_read(rq);
+	struct request_queue *q = hctx->queue;
+	struct adios_data *ad = q->elevator->elevator_data;
+
+	lockdep_assert_held(&ad->lock);
+
+	if (insert_flags & BLK_MQ_INSERT_AT_HEAD) {
+		spin_lock_irqsave(&ad->pq_lock, flags);
+		list_add(&rq->queuelist, &ad->prio_queue);
+		spin_unlock_irqrestore(&ad->pq_lock, flags);
+		return;
+	}
+
+	if (blk_mq_sched_try_insert_merge(q, rq, free))
+		return;
+
+	add_to_dl_tree(ad, dl_idx, rq);
+
+	if (rq_mergeable(rq)) {
+		elv_rqhash_add(q, rq);
+		if (!q->last_merge)
+			q->last_merge = rq;
+	}
+}
+
+// Insert multiple requests into the scheduler
+static void adios_insert_requests(struct blk_mq_hw_ctx *hctx,
+				   struct list_head *list,
+				   blk_insert_t insert_flags) {
+	unsigned long flags;
+	struct request_queue *q = hctx->queue;
+	struct adios_data *ad = q->elevator->elevator_data;
+	LIST_HEAD(free);
+
+	spin_lock_irqsave(&ad->lock, flags);
+	while (!list_empty(list)) {
+		struct request *rq;
+
+		rq = list_first_entry(list, struct request, queuelist);
+		list_del_init(&rq->queuelist);
+		insert_request(hctx, rq, insert_flags, &free);
+	}
+	spin_unlock_irqrestore(&ad->lock, flags);
+
+	blk_mq_free_requests(&free);
+}
+
+// Prepare a request before it is inserted into the scheduler
+static void adios_prepare_request(struct request *rq) {
+	struct adios_data *ad = rq->q->elevator->elevator_data;
+	struct adios_rq_data *rd;
+
+	rq->elv.priv[0] = NULL;
+
+	/* Allocate adios_rq_data from the memory pool */
+	rd = kmem_cache_zalloc(ad->rq_data_pool, GFP_ATOMIC);
+	if (WARN(!rd, "adios_prepare_request: "
+			"Failed to allocate memory from rq_data_pool. rd is NULL\n"))
+		return;
+
+	rd->rq = rq;
+	rq->elv.priv[0] = rd;
+}
+
+static struct adios_rq_data *get_dl_first_rd(struct adios_data *ad, bool idx) {
+	struct rb_root_cached *root = &ad->dl_tree[idx];
+	struct rb_node *first = rb_first_cached(root);
+	struct dl_group *dl_group = rb_entry(first, struct dl_group, node);
+
+	return list_first_entry(&dl_group->rqs, struct adios_rq_data, dl_node);
+}
+
+// Select the next request to dispatch from the deadline-sorted red-black tree
+static struct request *next_request(struct adios_data *ad) {
+	struct adios_rq_data *rd;
+	bool dl_idx, bias_idx, reduce_bias;
+
+	if (!ad->dl_queued)
+		return NULL;
+
+	dl_idx = ad->dl_queued >> 1;
+	rd = get_dl_first_rd(ad, dl_idx);
+
+	bias_idx = ad->dl_bias < 0;
+	reduce_bias = (bias_idx == dl_idx);
+
+	if (ad->dl_queued == 0x3) {
+		struct adios_rq_data *trd[2];
+		trd[0] = get_dl_first_rd(ad, 0);
+		trd[1] = rd;
+
+		rd = trd[bias_idx];
+
+		reduce_bias =
+			(trd[bias_idx]->deadline > trd[((u8)bias_idx + 1) % 2]->deadline);
+	}
+
+	if (reduce_bias) {
+		s64 sign = ((int)bias_idx << 1) - 1;
+		if (unlikely(!rd->pred_lat))
+			ad->dl_bias = sign;
+		else {
+			ad->dl_bias += sign * (s64)((rd->pred_lat *
+				adios_prio_to_weight[ad->dl_prio[bias_idx] + 20]) >> 10);
+		}
+	}
+
+	return rd->rq;
+}
+
+// Reset the batch queue counts for a given page
+static void reset_batch_counts(struct adios_data *ad, u8 page) {
+	memset(&ad->batch_count[page], 0, sizeof(ad->batch_count[page]));
+}
+
+// Initialize all batch queues
+static void init_batch_queues(struct adios_data *ad) {
+	for (u8 page = 0; page < ADIOS_BQ_PAGES; page++) {
+		reset_batch_counts(ad, page);
+
+		for (u8 optype = 0; optype < ADIOS_OPTYPES; optype++)
+			INIT_LIST_HEAD(&ad->batch_queue[page][optype]);
+	}
+}
+
+// Fill the batch queues with requests from the deadline-sorted red-black tree
+static bool fill_batch_queues(struct adios_data *ad, u64 current_lat) {
+	unsigned long flags;
+	u32 count = 0;
+	u32 optype_count[ADIOS_OPTYPES] = {0};
+	u8 page = (ad->bq_page + 1) % ADIOS_BQ_PAGES;
+
+	reset_batch_counts(ad, page);
+
+	spin_lock_irqsave(&ad->lock, flags);
+	while (true) {
+		struct request *rq = next_request(ad);
+		if (!rq)
+			break;
+
+		struct adios_rq_data *rd = get_rq_data(rq);
+		u8 optype = adios_optype(rq);
+		current_lat += rd->pred_lat;
+
+		// Check batch size and total predicted latency
+		if (count && (!ad->latency_model[optype].base || 
+			ad->batch_count[page][optype] >= ad->batch_limit[optype] ||
+			current_lat > ad->global_latency_window)) {
+			break;
+		}
+
+		remove_request(ad, rq);
+
+		// Add request to the corresponding batch queue
+		list_add_tail(&rq->queuelist, &ad->batch_queue[page][optype]);
+		ad->batch_count[page][optype]++;
+		atomic64_add(rd->pred_lat, &ad->total_pred_lat);
+		optype_count[optype]++;
+		count++;
+	}
+	spin_unlock_irqrestore(&ad->lock, flags);
+
+	if (count) {
+		ad->more_bq_ready = true;
+		for (u8 optype = 0; optype < ADIOS_OPTYPES; optype++) {
+			if (ad->batch_actual_max_size[optype] < optype_count[optype])
+				ad->batch_actual_max_size[optype] = optype_count[optype];
+		}
+		if (ad->batch_actual_max_total < count)
+			ad->batch_actual_max_total = count;
+	}
+	return count;
+}
+
+// Flip to the next batch queue page
+static void flip_bq_page(struct adios_data *ad) {
+	ad->more_bq_ready = false;
+	ad->bq_page = (ad->bq_page + 1) % ADIOS_BQ_PAGES;
+}
+
+// Dispatch a request from the batch queues
+static struct request *dispatch_from_bq(struct adios_data *ad) {
+	struct request *rq = NULL;
+	u64 tpl;
+
+	guard(spinlock_irqsave)(&ad->bq_lock);
+
+	tpl = atomic64_read(&ad->total_pred_lat);
+
+	if (!ad->more_bq_ready && (!tpl ||
+			tpl < div_u64(ad->global_latency_window * ad->bq_refill_below_ratio, 100) ))
+		fill_batch_queues(ad, tpl);
+
+again:
+	// Check if there are any requests in the batch queues
+	for (u8 i = 0; i < ADIOS_OPTYPES; i++) {
+		if (!list_empty(&ad->batch_queue[ad->bq_page][i])) {
+			rq = list_first_entry(&ad->batch_queue[ad->bq_page][i],
+									struct request, queuelist);
+			list_del_init(&rq->queuelist);
+			return rq;
+		}
+	}
+
+	// If there's more batch queue page available, flip to it and retry
+	if (ad->more_bq_ready) {
+		flip_bq_page(ad);
+		goto again;
+	}
+
+	return NULL;
+}
+
+// Dispatch a request from the priority queue
+static struct request *dispatch_from_pq(struct adios_data *ad) {
+	struct request *rq = NULL;
+
+	guard(spinlock_irqsave)(&ad->pq_lock);
+
+	if (!list_empty(&ad->prio_queue)) {
+		rq = list_first_entry(&ad->prio_queue, struct request, queuelist);
+		list_del_init(&rq->queuelist);
+	}
+	return rq;
+}
+
+// Dispatch a request to the hardware queue
+static struct request *adios_dispatch_request(struct blk_mq_hw_ctx *hctx) {
+	struct adios_data *ad = hctx->queue->elevator->elevator_data;
+	struct request *rq;
+
+	rq = dispatch_from_pq(ad);
+	if (rq) goto found;
+	rq = dispatch_from_bq(ad);
+	if (!rq) return NULL;
+found:
+	rq->rq_flags |= RQF_STARTED;
+	return rq;
+}
+
+// Timer callback function to periodically update latency models
+static void update_timer_callback(struct timer_list *t) {
+	struct adios_data *ad = from_timer(ad, t, update_timer);
+
+	for (u8 optype = 0; optype < ADIOS_OPTYPES; optype++)
+		latency_model_update(&ad->latency_model[optype]);
+}
+
+// Handle the completion of a request
+static void adios_completed_request(struct request *rq, u64 now) {
+	struct adios_data *ad = rq->q->elevator->elevator_data;
+	struct adios_rq_data *rd = get_rq_data(rq);
+
+	atomic64_sub(rd->pred_lat, &ad->total_pred_lat);
+
+	if (!rq->io_start_time_ns || !rd->block_size)
+		return;
+	u64 latency = now - rq->io_start_time_ns;
+	u8 optype = adios_optype(rq);
+	latency_model_input(&ad->latency_model[optype],
+		rd->block_size, latency, rd->pred_lat);
+	timer_reduce(&ad->update_timer, jiffies + msecs_to_jiffies(100));
+}
+
+// Clean up after a request is finished
+static void adios_finish_request(struct request *rq) {
+	struct adios_data *ad = rq->q->elevator->elevator_data;
+
+	if (rq->elv.priv[0]) {
+		// Free adios_rq_data back to the memory pool
+		kmem_cache_free(ad->rq_data_pool, get_rq_data(rq));
+		rq->elv.priv[0] = NULL;
+	}
+}
+
+static inline bool pq_has_work(struct adios_data *ad) {
+	guard(spinlock_irqsave)(&ad->pq_lock);
+	return !list_empty(&ad->prio_queue);
+}
+
+static inline bool bq_has_work(struct adios_data *ad) {
+	guard(spinlock_irqsave)(&ad->bq_lock);
+
+	for (u8 i = 0; i < ADIOS_OPTYPES; i++)
+		if (!list_empty(&ad->batch_queue[ad->bq_page][i]))
+			return true;
+
+	return ad->more_bq_ready;
+}
+
+static inline bool dl_tree_has_work(struct adios_data *ad) {
+	guard(spinlock_irqsave)(&ad->lock);
+	return ad->dl_queued;
+}
+
+// Check if there are any requests available for dispatch
+static bool adios_has_work(struct blk_mq_hw_ctx *hctx) {
+	struct adios_data *ad = hctx->queue->elevator->elevator_data;
+
+	return pq_has_work(ad) || bq_has_work(ad) || dl_tree_has_work(ad);
+}
+
+// Initialize the scheduler-specific data for a hardware queue
+static int adios_init_hctx(struct blk_mq_hw_ctx *hctx, unsigned int hctx_idx) {
+	adios_depth_updated(hctx);
+	return 0;
+}
+
+// Initialize the scheduler-specific data when initializing the request queue
+static int adios_init_sched(struct request_queue *q, struct elevator_type *e) {
+	struct adios_data *ad;
+	struct elevator_queue *eq;
+	int ret = -ENOMEM;
+
+	eq = elevator_alloc(q, e);
+	if (!eq)
+		return ret;
+
+	ad = kzalloc_node(sizeof(*ad), GFP_KERNEL, q->node);
+	if (!ad)
+		goto put_eq;
+
+	// Create a memory pool for adios_rq_data
+	ad->rq_data_pool = kmem_cache_create("rq_data_pool",
+						sizeof(struct adios_rq_data),
+						0, SLAB_HWCACHE_ALIGN, NULL);
+	if (!ad->rq_data_pool) {
+		pr_err("adios: Failed to create rq_data_pool\n");
+		goto free_ad;
+	}
+
+	/* Create a memory pool for dl_group */
+	ad->dl_group_pool = kmem_cache_create("dl_group_pool",
+						sizeof(struct dl_group),
+						0, SLAB_HWCACHE_ALIGN, NULL);
+	if (!ad->dl_group_pool) {
+		pr_err("adios: Failed to create dl_group_pool\n");
+		goto destroy_rq_data_pool;
+	}
+
+	eq->elevator_data = ad;
+
+	ad->global_latency_window = default_global_latency_window;
+	ad->bq_refill_below_ratio = default_bq_refill_below_ratio;
+
+	INIT_LIST_HEAD(&ad->prio_queue);
+	for (u8 i = 0; i < 2; i++)
+		ad->dl_tree[i] = RB_ROOT_CACHED;
+	ad->dl_bias = 0;
+	ad->dl_queued = 0x0;
+	for (u8 i = 0; i < 2; i++)
+		ad->dl_prio[i] = default_dl_prio[i];
+
+	for (u8 i = 0; i < ADIOS_OPTYPES; i++) {
+		struct latency_model *model = &ad->latency_model[i];
+		spin_lock_init(&model->lock);
+		spin_lock_init(&model->buckets_lock);
+		memset(model->small_bucket, 0,
+			sizeof(model->small_bucket[0]) * LM_LAT_BUCKET_COUNT);
+		memset(model->large_bucket, 0,
+			sizeof(model->large_bucket[0]) * LM_LAT_BUCKET_COUNT);
+		model->last_update_jiffies = jiffies;
+		model->lm_shrink_at_kreqs  = default_lm_shrink_at_kreqs;
+		model->lm_shrink_at_gbytes = default_lm_shrink_at_gbytes;
+		model->lm_shrink_resist    = default_lm_shrink_resist;
+
+		ad->latency_target[i] = default_latency_target[i];
+		ad->batch_limit[i] = default_batch_limit[i];
+	}
+	timer_setup(&ad->update_timer, update_timer_callback, 0);
+	init_batch_queues(ad);
+
+	spin_lock_init(&ad->lock);
+	spin_lock_init(&ad->pq_lock);
+	spin_lock_init(&ad->bq_lock);
+
+	/* We dispatch from request queue wide instead of hw queue */
+	blk_queue_flag_set(QUEUE_FLAG_SQ_SCHED, q);
+
+	ad->queue = q;
+	blk_stat_enable_accounting(q);
+
+	q->elevator = eq;
+	return 0;
+
+destroy_rq_data_pool:
+	kmem_cache_destroy(ad->rq_data_pool);
+free_ad:
+	kfree(ad);
+put_eq:
+	kobject_put(&eq->kobj);
+	return ret;
+}
+
+// Clean up and free resources when exiting the scheduler
+static void adios_exit_sched(struct elevator_queue *e) {
+	struct adios_data *ad = e->elevator_data;
+
+	timer_shutdown_sync(&ad->update_timer);
+
+	WARN_ON_ONCE(!list_empty(&ad->prio_queue));
+
+	if (ad->rq_data_pool)
+		kmem_cache_destroy(ad->rq_data_pool);
+
+	if (ad->dl_group_pool)
+		kmem_cache_destroy(ad->dl_group_pool);
+
+	blk_stat_disable_accounting(ad->queue);
+
+	kfree(ad);
+}
+
+// Define sysfs attributes for read operation latency model
+#define SYSFS_OPTYPE_DECL(name, optype)					\
+static ssize_t adios_lat_model_##name##_show(				\
+		struct elevator_queue *e, char *page) {				\
+	struct adios_data *ad = e->elevator_data;				\
+	struct latency_model *model = &ad->latency_model[optype];		\
+	ssize_t len = 0;						\
+	guard(spinlock_irqsave)(&model->lock);				\
+	len += sprintf(page,       "base : %llu ns\n", model->base);	\
+	len += sprintf(page + len, "slope: %llu ns/KiB\n", model->slope);\
+	return len;							\
+}									\
+static ssize_t adios_lat_target_##name##_store(				\
+		struct elevator_queue *e, const char *page, size_t count) {	\
+	struct adios_data *ad = e->elevator_data;				\
+	unsigned long nsec;						\
+	int ret;							\
+	ret = kstrtoul(page, 10, &nsec);					\
+	if (ret)							\
+		return ret;						\
+	ad->latency_model[optype].base = 0ULL;				\
+	ad->latency_target[optype] = nsec;				\
+	return count;							\
+}									\
+static ssize_t adios_lat_target_##name##_show(				\
+		struct elevator_queue *e, char *page) {				\
+	struct adios_data *ad = e->elevator_data;				\
+	return sprintf(page, "%llu\n", ad->latency_target[optype]);	\
+}									\
+static ssize_t adios_batch_limit_##name##_store(			\
+		struct elevator_queue *e, const char *page, size_t count) {	\
+	unsigned long max_batch;					\
+	int ret;							\
+	ret = kstrtoul(page, 10, &max_batch);				\
+	if (ret || max_batch == 0)					\
+		return -EINVAL;						\
+	struct adios_data *ad = e->elevator_data;				\
+	ad->batch_limit[optype] = max_batch;				\
+	return count;							\
+}									\
+static ssize_t adios_batch_limit_##name##_show(				\
+		struct elevator_queue *e, char *page) {				\
+	struct adios_data *ad = e->elevator_data;				\
+	return sprintf(page, "%u\n", ad->batch_limit[optype]);		\
+}
+
+SYSFS_OPTYPE_DECL(read, ADIOS_READ);
+SYSFS_OPTYPE_DECL(write, ADIOS_WRITE);
+SYSFS_OPTYPE_DECL(discard, ADIOS_DISCARD);
+
+// Show the maximum batch size actually achieved for each operation type
+static ssize_t adios_batch_actual_max_show(
+		struct elevator_queue *e, char *page) {
+	struct adios_data *ad = e->elevator_data;
+	u32 total_count, read_count, write_count, discard_count;
+
+	total_count = ad->batch_actual_max_total;
+	read_count = ad->batch_actual_max_size[ADIOS_READ];
+	write_count = ad->batch_actual_max_size[ADIOS_WRITE];
+	discard_count = ad->batch_actual_max_size[ADIOS_DISCARD];
+
+	return sprintf(page,
+		"Total  : %u\nDiscard: %u\nRead   : %u\nWrite  : %u\n",
+		total_count, discard_count, read_count, write_count);
+}
+
+// Set the global latency window
+static ssize_t adios_global_latency_window_store(
+		struct elevator_queue *e, const char *page, size_t count) {
+	struct adios_data *ad = e->elevator_data;
+	unsigned long nsec;
+	int ret;
+
+	ret = kstrtoul(page, 10, &nsec);
+	if (ret)
+		return ret;
+
+	ad->global_latency_window = nsec;
+
+	return count;
+}
+
+// Show the global latency window
+static ssize_t adios_global_latency_window_show(
+		struct elevator_queue *e, char *page) {
+	struct adios_data *ad = e->elevator_data;
+	return sprintf(page, "%llu\n", ad->global_latency_window);
+}
+
+// Show the bq_refill_below_ratio
+static ssize_t adios_bq_refill_below_ratio_show(
+		struct elevator_queue *e, char *page) {
+	struct adios_data *ad = e->elevator_data;
+	return sprintf(page, "%d\n", ad->bq_refill_below_ratio);
+}
+
+// Set the bq_refill_below_ratio
+static ssize_t adios_bq_refill_below_ratio_store(
+		struct elevator_queue *e, const char *page, size_t count) {
+	struct adios_data *ad = e->elevator_data;
+	int ratio;
+	int ret;
+
+	ret = kstrtoint(page, 10, &ratio);
+	if (ret || ratio < 0 || ratio > 100)
+		return -EINVAL;
+
+	ad->bq_refill_below_ratio = ratio;
+
+	return count;
+}
+
+// Show the read priority
+static ssize_t adios_read_priority_show(
+		struct elevator_queue *e, char *page) {
+	struct adios_data *ad = e->elevator_data;
+	return sprintf(page, "%d\n", ad->dl_prio[0]);
+}
+
+// Set the read priority
+static ssize_t adios_read_priority_store(
+		struct elevator_queue *e, const char *page, size_t count) {
+	struct adios_data *ad = e->elevator_data;
+	int prio;
+	int ret;
+
+	ret = kstrtoint(page, 10, &prio);
+	if (ret || prio < -20 || prio > 19)
+		return -EINVAL;
+
+	guard(spinlock_irqsave)(&ad->lock);
+	ad->dl_prio[0] = prio;
+	ad->dl_bias = 0;
+
+	return count;
+}
+
+// Reset batch queue statistics
+static ssize_t adios_reset_bq_stats_store(
+		struct elevator_queue *e, const char *page, size_t count) {
+	struct adios_data *ad = e->elevator_data;
+	unsigned long val;
+	int ret;
+
+	ret = kstrtoul(page, 10, &val);
+	if (ret || val != 1)
+		return -EINVAL;
+
+	for (u8 i = 0; i < ADIOS_OPTYPES; i++)
+		ad->batch_actual_max_size[i] = 0;
+
+	ad->batch_actual_max_total = 0;
+
+	return count;
+}
+
+// Reset the latency model parameters
+static ssize_t adios_reset_lat_model_store(
+		struct elevator_queue *e, const char *page, size_t count) {
+	struct adios_data *ad = e->elevator_data;
+	unsigned long val;
+	int ret;
+
+	ret = kstrtoul(page, 10, &val);
+	if (ret || val != 1)
+		return -EINVAL;
+
+	for (u8 i = 0; i < ADIOS_OPTYPES; i++) {
+		struct latency_model *model = &ad->latency_model[i];
+		unsigned long flags;
+		spin_lock_irqsave(&model->lock, flags);
+		model->base = 0ULL;
+		model->slope = 0ULL;
+		model->small_sum_delay = 0ULL;
+		model->small_count = 0ULL;
+		model->large_sum_delay = 0ULL;
+		model->large_sum_bsize = 0ULL;
+		spin_unlock_irqrestore(&model->lock, flags);
+	}
+
+	return count;
+}
+
+// Show the ADIOS version
+static ssize_t adios_version_show(struct elevator_queue *e, char *page) {
+	return sprintf(page, "%s\n", ADIOS_VERSION);
+}
+
+// Define sysfs attributes for dynamic thresholds
+#define SHRINK_THRESHOLD_ATTR_RW(name, model_field, min_value, max_value) \
+static ssize_t adios_shrink_##name##_store( \
+		struct elevator_queue *e, const char *page, size_t count) { \
+	struct adios_data *ad = e->elevator_data; \
+	unsigned long val; \
+	int ret; \
+	ret = kstrtoul(page, 10, &val); \
+	if (ret || val < min_value || val > max_value) \
+		return -EINVAL; \
+	for (u8 i = 0; i < ADIOS_OPTYPES; i++) { \
+		struct latency_model *model = &ad->latency_model[i]; \
+		unsigned long flags; \
+		spin_lock_irqsave(&model->lock, flags); \
+		model->model_field = val; \
+		spin_unlock_irqrestore(&model->lock, flags); \
+	} \
+	return count; \
+} \
+static ssize_t adios_shrink_##name##_show( \
+		struct elevator_queue *e, char *page) { \
+	struct adios_data *ad = e->elevator_data; \
+	u32 val = 0; \
+	for (u8 i = 0; i < ADIOS_OPTYPES; i++) { \
+		struct latency_model *model = &ad->latency_model[i]; \
+		unsigned long flags; \
+		spin_lock_irqsave(&model->lock, flags); \
+		val = model->model_field; \
+		spin_unlock_irqrestore(&model->lock, flags); \
+	} \
+	return sprintf(page, "%u\n", val); \
+}
+
+SHRINK_THRESHOLD_ATTR_RW(at_kreqs,  lm_shrink_at_kreqs,  1, 100000)
+SHRINK_THRESHOLD_ATTR_RW(at_gbytes, lm_shrink_at_gbytes, 1,   1000)
+SHRINK_THRESHOLD_ATTR_RW(resist,    lm_shrink_resist,    1,      3)
+
+// Define sysfs attributes
+#define AD_ATTR(name, show_func, store_func) \
+	__ATTR(name, 0644, show_func, store_func)
+#define AD_ATTR_RW(name) \
+	__ATTR(name, 0644, adios_##name##_show, adios_##name##_store)
+#define AD_ATTR_RO(name) \
+	__ATTR(name, 0644, adios_##name##_show, NULL)
+#define AD_ATTR_WO(name) \
+	__ATTR(name, 0644, NULL, adios_##name##_store)
+
+// Define sysfs attributes for ADIOS scheduler
+static struct elv_fs_entry adios_sched_attrs[] = {
+	AD_ATTR_RO(batch_actual_max),
+	AD_ATTR_RW(bq_refill_below_ratio),
+	AD_ATTR_RW(global_latency_window),
+
+	AD_ATTR_RW(batch_limit_read),
+	AD_ATTR_RW(batch_limit_write),
+	AD_ATTR_RW(batch_limit_discard),
+
+	AD_ATTR_RO(lat_model_read),
+	AD_ATTR_RO(lat_model_write),
+	AD_ATTR_RO(lat_model_discard),
+
+	AD_ATTR_RW(lat_target_read),
+	AD_ATTR_RW(lat_target_write),
+	AD_ATTR_RW(lat_target_discard),
+
+	AD_ATTR_RW(shrink_at_kreqs),
+	AD_ATTR_RW(shrink_at_gbytes),
+	AD_ATTR_RW(shrink_resist),
+
+	AD_ATTR_RW(read_priority),
+
+	AD_ATTR_WO(reset_bq_stats),
+	AD_ATTR_WO(reset_lat_model),
+	AD_ATTR(adios_version, adios_version_show, NULL),
+
+	__ATTR_NULL
+};
+
+// Define the ADIOS scheduler type
+static struct elevator_type mq_adios = {
+	.ops = {
+		.next_request		= elv_rb_latter_request,
+		.former_request		= elv_rb_former_request,
+		.limit_depth		= adios_limit_depth,
+		.depth_updated		= adios_depth_updated,
+		.request_merged		= adios_request_merged,
+		.requests_merged	= adios_merged_requests,
+		.bio_merge			= adios_bio_merge,
+		.insert_requests	= adios_insert_requests,
+		.prepare_request	= adios_prepare_request,
+		.dispatch_request	= adios_dispatch_request,
+		.completed_request	= adios_completed_request,
+		.finish_request		= adios_finish_request,
+		.has_work			= adios_has_work,
+		.init_hctx			= adios_init_hctx,
+		.init_sched			= adios_init_sched,
+		.exit_sched			= adios_exit_sched,
+	},
+	.elevator_attrs = adios_sched_attrs,
+	.elevator_name = "adios",
+	.elevator_owner = THIS_MODULE,
+};
+MODULE_ALIAS("mq-adios-iosched");
+
+#define ADIOS_PROGNAME "Adaptive Deadline I/O Scheduler"
+#define ADIOS_AUTHOR   "Masahito Suzuki"
+
+// Initialize the ADIOS scheduler module
+static int __init adios_init(void) {
+	printk(KERN_INFO "%s %s by %s\n",
+		ADIOS_PROGNAME, ADIOS_VERSION, ADIOS_AUTHOR);
+	return elv_register(&mq_adios);
+}
+
+// Exit the ADIOS scheduler module
+static void __exit adios_exit(void) {
+	elv_unregister(&mq_adios);
+}
+
+module_init(adios_init);
+module_exit(adios_exit);
+
+MODULE_AUTHOR(ADIOS_AUTHOR);
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION(ADIOS_PROGNAME);
\ No newline at end of file
diff -rupN a/block/blk-mq.c b/block/blk-mq.c
--- a/block/blk-mq.c	2025-06-01 18:01:58.000000000 +0200
+++ b/block/blk-mq.c	2025-06-01 20:34:16.760109454 +0200
@@ -29,6 +29,7 @@
 #include <linux/blk-crypto.h>
 #include <linux/part_stat.h>
 #include <linux/sched/isolation.h>
+#include <linux/cpuidle_psd.h>
 
 #include <trace/events/block.h>
 
@@ -1220,6 +1221,7 @@ static void blk_complete_reqs(struct lli
 	struct llist_node *entry = llist_reverse_order(llist_del_all(list));
 	struct request *rq, *next;
 
+	prevent_sleep_demotion();
 	llist_for_each_entry_safe(rq, next, entry, ipi_list)
 		rq->q->mq_ops->complete(rq);
 }
diff -rupN a/block/early-lookup.c b/block/early-lookup.c
--- a/block/early-lookup.c	2025-06-01 18:01:58.000000000 +0200
+++ b/block/early-lookup.c	2025-06-01 20:34:16.760109454 +0200
@@ -5,6 +5,7 @@
  */
 #include <linux/blkdev.h>
 #include <linux/ctype.h>
+#include <linux/delay.h>
 
 struct uuidcmp {
 	const char *uuid;
@@ -243,8 +244,18 @@ static int __init devt_from_devnum(const
  */
 int __init early_lookup_bdev(const char *name, dev_t *devt)
 {
-	if (strncmp(name, "PARTUUID=", 9) == 0)
-		return devt_from_partuuid(name + 9, devt);
+	if (strncmp(name, "PARTUUID=", 9) == 0) {
+		int res;
+		int  needtowait = 40<<1;
+		res = devt_from_partuuid(name + 9, devt);
+		if (!res) return res;
+		while (res && needtowait) {
+			msleep(500);
+			res = devt_from_partuuid(name + 9, devt);
+			needtowait--;
+		}
+		return res;
+	}
 	if (strncmp(name, "PARTLABEL=", 10) == 0)
 		return devt_from_partlabel(name + 10, devt);
 	if (strncmp(name, "/dev/", 5) == 0)
diff -rupN a/block/elevator.c b/block/elevator.c
--- a/block/elevator.c	2025-06-01 18:01:58.000000000 +0200
+++ b/block/elevator.c	2025-06-01 20:34:16.761109462 +0200
@@ -727,6 +727,10 @@ void elevator_set_default(struct request
 	if (q->tag_set->flags & BLK_MQ_F_NO_SCHED_BY_DEFAULT)
 		return;
 
+#ifdef CONFIG_MQ_IOSCHED_DEFAULT_ADIOS
+       elevator_find_get("adios");
+#else // !CONFIG_MQ_IOSCHED_DEFAULT_ADIOS
+
 	/*
 	 * For single queue devices, default to using mq-deadline. If we
 	 * have multiple queues or mq-deadline is not available, default
@@ -738,6 +742,7 @@ void elevator_set_default(struct request
 	if (err < 0)
 		pr_warn("\"%s\" elevator initialization, failed %d, "
 			"falling back to \"none\"\n", ctx.name, err);
+#endif
 }
 
 void elevator_set_none(struct request_queue *q)
diff -rupN a/block/Kconfig.iosched b/block/Kconfig.iosched
--- a/block/Kconfig.iosched	2025-06-01 18:01:58.000000000 +0200
+++ b/block/Kconfig.iosched	2025-06-01 20:34:16.761109462 +0200
@@ -16,6 +16,20 @@ config MQ_IOSCHED_KYBER
 	  synchronous writes, it will self-tune queue depths to achieve that
 	  goal.
 
+config MQ_IOSCHED_ADIOS
+	tristate "Adaptive Deadline I/O scheduler"
+	default m
+	help
+	  The Adaptive Deadline I/O Scheduler (ADIOS) is a multi-queue I/O
+	  scheduler with learning-based adaptive latency control.
+
+config MQ_IOSCHED_DEFAULT_ADIOS
+	bool "Enable ADIOS I/O scheduler as default MQ I/O scheduler"
+	depends on MQ_IOSCHED_ADIOS=y
+	default n
+	help
+	  Enable the ADIOS I/O scheduler as the default scheduler for MQ I/O.
+
 config IOSCHED_BFQ
 	tristate "BFQ I/O scheduler"
 	select BLK_ICQ
diff -rupN a/block/Makefile b/block/Makefile
--- a/block/Makefile	2025-06-01 18:01:58.000000000 +0200
+++ b/block/Makefile	2025-06-01 20:34:16.761109462 +0200
@@ -22,6 +22,7 @@ obj-$(CONFIG_BLK_CGROUP_IOLATENCY)	+= bl
 obj-$(CONFIG_BLK_CGROUP_IOCOST)	+= blk-iocost.o
 obj-$(CONFIG_MQ_IOSCHED_DEADLINE)	+= mq-deadline.o
 obj-$(CONFIG_MQ_IOSCHED_KYBER)	+= kyber-iosched.o
+obj-$(CONFIG_MQ_IOSCHED_ADIOS)	+= adios.o
 bfq-y				:= bfq-iosched.o bfq-wf2q.o bfq-cgroup.o
 obj-$(CONFIG_IOSCHED_BFQ)	+= bfq.o
 
@@ -36,3 +37,10 @@ obj-$(CONFIG_BLK_INLINE_ENCRYPTION)	+= b
 					   blk-crypto-sysfs.o
 obj-$(CONFIG_BLK_INLINE_ENCRYPTION_FALLBACK)	+= blk-crypto-fallback.o
 obj-$(CONFIG_BLOCK_HOLDER_DEPRECATED)	+= holder.o
+
+all:
+	make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules
+
+clean:
+	make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean
+
diff -rupN a/crypto/kdf_sp800108.c b/crypto/kdf_sp800108.c
--- a/crypto/kdf_sp800108.c	2025-06-01 18:01:58.000000000 +0200
+++ b/crypto/kdf_sp800108.c	2025-06-01 20:34:16.762109470 +0200
@@ -149,7 +149,7 @@ static int __init crypto_kdf108_init(voi
 
 static void __exit crypto_kdf108_exit(void) { }
 
-module_init(crypto_kdf108_init);
+late_initcall(crypto_kdf108_init);
 module_exit(crypto_kdf108_exit);
 
 MODULE_LICENSE("GPL v2");
diff -rupN a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txt
--- a/Documentation/admin-guide/kernel-parameters.txt	2025-06-01 18:01:58.000000000 +0200
+++ b/Documentation/admin-guide/kernel-parameters.txt	2025-06-01 20:34:16.765109494 +0200
@@ -4099,10 +4099,6 @@
 			These settings can be accessed at runtime via
 			the nmi_watchdog and hardlockup_panic sysctls.
 
-	no387		[BUGS=X86-32] Tells the kernel to use the 387 maths
-			emulation library even if a 387 maths coprocessor
-			is present.
-
 	no4lvl		[RISCV,EARLY] Disable 4-level and 5-level paging modes.
 			Forces kernel to use 3-level paging instead.
 
diff -rupN a/drivers/acpi/osl.c b/drivers/acpi/osl.c
--- a/drivers/acpi/osl.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/acpi/osl.c	2025-06-01 20:34:16.766109502 +0200
@@ -1581,7 +1581,7 @@ void acpi_os_release_lock(acpi_spinlock
 acpi_status
 acpi_os_create_cache(char *name, u16 size, u16 depth, acpi_cache_t **cache)
 {
-	*cache = kmem_cache_create(name, size, 0, 0, NULL);
+	*cache = kmem_cache_create(name, size, 0, SLAB_HWCACHE_ALIGN, NULL);
 	if (*cache == NULL)
 		return AE_ERROR;
 	else
diff -rupN a/drivers/ata/libahci.c b/drivers/ata/libahci.c
--- a/drivers/ata/libahci.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/ata/libahci.c	2025-06-01 20:34:16.767109510 +0200
@@ -34,14 +34,14 @@
 #include "libata.h"
 
 static int ahci_skip_host_reset;
-int ahci_ignore_sss;
+int ahci_ignore_sss=1;
 EXPORT_SYMBOL_GPL(ahci_ignore_sss);
 
 module_param_named(skip_host_reset, ahci_skip_host_reset, int, 0444);
 MODULE_PARM_DESC(skip_host_reset, "skip global host reset (0=don't skip, 1=skip)");
 
 module_param_named(ignore_sss, ahci_ignore_sss, int, 0444);
-MODULE_PARM_DESC(ignore_sss, "Ignore staggered spinup flag (0=don't ignore, 1=ignore)");
+MODULE_PARM_DESC(ignore_sss, "Ignore staggered spinup flag (0=don't ignore, 1=ignore [default])");
 
 static int ahci_set_lpm(struct ata_link *link, enum ata_lpm_policy policy,
 			unsigned hints);
diff -rupN a/drivers/base/firmware_loader/main.c b/drivers/base/firmware_loader/main.c
--- a/drivers/base/firmware_loader/main.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/base/firmware_loader/main.c	2025-06-01 20:34:16.768109518 +0200
@@ -471,6 +471,8 @@ static int fw_decompress_xz(struct devic
 static char fw_path_para[256];
 static const char * const fw_path[] = {
 	fw_path_para,
+	"/etc/firmware/" UTS_RELEASE,
+	"/etc/firmware",
 	"/lib/firmware/updates/" UTS_RELEASE,
 	"/lib/firmware/updates",
 	"/lib/firmware/" UTS_RELEASE,
diff -rupN a/drivers/bluetooth/btusb.c b/drivers/bluetooth/btusb.c
--- a/drivers/bluetooth/btusb.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/bluetooth/btusb.c	2025-06-01 20:34:16.770109534 +0200
@@ -705,6 +705,8 @@ static const struct usb_device_id quirks
 						     BTUSB_WIDEBAND_SPEECH },
 	{ USB_DEVICE(0x0489, 0xe139), .driver_info = BTUSB_MEDIATEK |
 						     BTUSB_WIDEBAND_SPEECH },
+	{ USB_DEVICE(0x0489, 0xe14e), .driver_info = BTUSB_MEDIATEK |
+						     BTUSB_WIDEBAND_SPEECH },
 	{ USB_DEVICE(0x0489, 0xe14f), .driver_info = BTUSB_MEDIATEK |
 						     BTUSB_WIDEBAND_SPEECH },
 	{ USB_DEVICE(0x0489, 0xe150), .driver_info = BTUSB_MEDIATEK |
diff -rupN a/drivers/clocksource/acpi_pm.c b/drivers/clocksource/acpi_pm.c
--- a/drivers/clocksource/acpi_pm.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/clocksource/acpi_pm.c	2025-06-01 20:34:16.771109543 +0200
@@ -208,13 +208,16 @@ static int verify_pmtmr_rate(void)
 static int __init init_acpi_pm_clocksource(void)
 {
 	u64 value1, value2;
-	unsigned int i, j = 0;
+	unsigned int i, j = 0, checks = 1;
 
 	if (!pmtmr_ioport)
 		return -ENODEV;
 
+	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD)
+		checks = ACPI_PM_MONOTONICITY_CHECKS;
+
 	/* "verify" this timing source: */
-	for (j = 0; j < ACPI_PM_MONOTONICITY_CHECKS; j++) {
+	for (j = 0; j < checks; j++) {
 		udelay(100 * j);
 		value1 = clocksource_acpi_pm.read(&clocksource_acpi_pm);
 		for (i = 0; i < ACPI_PM_READ_CHECKS; i++) {
diff -rupN a/drivers/cpufreq/elanfreq.c b/drivers/cpufreq/elanfreq.c
--- a/drivers/cpufreq/elanfreq.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/cpufreq/elanfreq.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,226 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- *	elanfreq:	cpufreq driver for the AMD ELAN family
- *
- *	(c) Copyright 2002 Robert Schwebel <r.schwebel@pengutronix.de>
- *
- *	Parts of this code are (c) Sven Geggus <sven@geggus.net>
- *
- *      All Rights Reserved.
- *
- *	2002-02-13: - initial revision for 2.4.18-pre9 by Robert Schwebel
- */
-
-#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/init.h>
-
-#include <linux/delay.h>
-#include <linux/cpufreq.h>
-
-#include <asm/cpu_device_id.h>
-#include <linux/timex.h>
-#include <linux/io.h>
-
-#define REG_CSCIR 0x22		/* Chip Setup and Control Index Register    */
-#define REG_CSCDR 0x23		/* Chip Setup and Control Data  Register    */
-
-/* Module parameter */
-static int max_freq;
-
-struct s_elan_multiplier {
-	int clock;		/* frequency in kHz                         */
-	int val40h;		/* PMU Force Mode register                  */
-	int val80h;		/* CPU Clock Speed Register                 */
-};
-
-/*
- * It is important that the frequencies
- * are listed in ascending order here!
- */
-static struct s_elan_multiplier elan_multiplier[] = {
-	{1000,	0x02,	0x18},
-	{2000,	0x02,	0x10},
-	{4000,	0x02,	0x08},
-	{8000,	0x00,	0x00},
-	{16000,	0x00,	0x02},
-	{33000,	0x00,	0x04},
-	{66000,	0x01,	0x04},
-	{99000,	0x01,	0x05}
-};
-
-static struct cpufreq_frequency_table elanfreq_table[] = {
-	{0, 0,	1000},
-	{0, 1,	2000},
-	{0, 2,	4000},
-	{0, 3,	8000},
-	{0, 4,	16000},
-	{0, 5,	33000},
-	{0, 6,	66000},
-	{0, 7,	99000},
-	{0, 0,	CPUFREQ_TABLE_END},
-};
-
-
-/**
- *	elanfreq_get_cpu_frequency: determine current cpu speed
- *
- *	Finds out at which frequency the CPU of the Elan SOC runs
- *	at the moment. Frequencies from 1 to 33 MHz are generated
- *	the normal way, 66 and 99 MHz are called "Hyperspeed Mode"
- *	and have the rest of the chip running with 33 MHz.
- */
-
-static unsigned int elanfreq_get_cpu_frequency(unsigned int cpu)
-{
-	u8 clockspeed_reg;    /* Clock Speed Register */
-
-	local_irq_disable();
-	outb_p(0x80, REG_CSCIR);
-	clockspeed_reg = inb_p(REG_CSCDR);
-	local_irq_enable();
-
-	if ((clockspeed_reg & 0xE0) == 0xE0)
-		return 0;
-
-	/* Are we in CPU clock multiplied mode (66/99 MHz)? */
-	if ((clockspeed_reg & 0xE0) == 0xC0) {
-		if ((clockspeed_reg & 0x01) == 0)
-			return 66000;
-		else
-			return 99000;
-	}
-
-	/* 33 MHz is not 32 MHz... */
-	if ((clockspeed_reg & 0xE0) == 0xA0)
-		return 33000;
-
-	return (1<<((clockspeed_reg & 0xE0) >> 5)) * 1000;
-}
-
-
-static int elanfreq_target(struct cpufreq_policy *policy,
-			    unsigned int state)
-{
-	/*
-	 * Access to the Elan's internal registers is indexed via
-	 * 0x22: Chip Setup & Control Register Index Register (CSCI)
-	 * 0x23: Chip Setup & Control Register Data  Register (CSCD)
-	 *
-	 */
-
-	/*
-	 * 0x40 is the Power Management Unit's Force Mode Register.
-	 * Bit 6 enables Hyperspeed Mode (66/100 MHz core frequency)
-	 */
-
-	local_irq_disable();
-	outb_p(0x40, REG_CSCIR);		/* Disable hyperspeed mode */
-	outb_p(0x00, REG_CSCDR);
-	local_irq_enable();		/* wait till internal pipelines and */
-	udelay(1000);			/* buffers have cleaned up          */
-
-	local_irq_disable();
-
-	/* now, set the CPU clock speed register (0x80) */
-	outb_p(0x80, REG_CSCIR);
-	outb_p(elan_multiplier[state].val80h, REG_CSCDR);
-
-	/* now, the hyperspeed bit in PMU Force Mode Register (0x40) */
-	outb_p(0x40, REG_CSCIR);
-	outb_p(elan_multiplier[state].val40h, REG_CSCDR);
-	udelay(10000);
-	local_irq_enable();
-
-	return 0;
-}
-/*
- *	Module init and exit code
- */
-
-static int elanfreq_cpu_init(struct cpufreq_policy *policy)
-{
-	struct cpuinfo_x86 *c = &cpu_data(0);
-	struct cpufreq_frequency_table *pos;
-
-	/* capability check */
-	if ((c->x86_vendor != X86_VENDOR_AMD) ||
-	    (c->x86 != 4) || (c->x86_model != 10))
-		return -ENODEV;
-
-	/* max freq */
-	if (!max_freq)
-		max_freq = elanfreq_get_cpu_frequency(0);
-
-	/* table init */
-	cpufreq_for_each_entry(pos, elanfreq_table)
-		if (pos->frequency > max_freq)
-			pos->frequency = CPUFREQ_ENTRY_INVALID;
-
-	policy->freq_table = elanfreq_table;
-	return 0;
-}
-
-
-#ifndef MODULE
-/**
- * elanfreq_setup - elanfreq command line parameter parsing
- *
- * elanfreq command line parameter.  Use:
- *  elanfreq=66000
- * to set the maximum CPU frequency to 66 MHz. Note that in
- * case you do not give this boot parameter, the maximum
- * frequency will fall back to _current_ CPU frequency which
- * might be lower. If you build this as a module, use the
- * max_freq module parameter instead.
- */
-static int __init elanfreq_setup(char *str)
-{
-	max_freq = simple_strtoul(str, &str, 0);
-	pr_warn("You're using the deprecated elanfreq command line option. Use elanfreq.max_freq instead, please!\n");
-	return 1;
-}
-__setup("elanfreq=", elanfreq_setup);
-#endif
-
-
-static struct cpufreq_driver elanfreq_driver = {
-	.get		= elanfreq_get_cpu_frequency,
-	.flags		= CPUFREQ_NO_AUTO_DYNAMIC_SWITCHING,
-	.verify		= cpufreq_generic_frequency_table_verify,
-	.target_index	= elanfreq_target,
-	.init		= elanfreq_cpu_init,
-	.name		= "elanfreq",
-};
-
-static const struct x86_cpu_id elan_id[] = {
-	X86_MATCH_VENDOR_FAM_MODEL(AMD, 4, 10, NULL),
-	{}
-};
-MODULE_DEVICE_TABLE(x86cpu, elan_id);
-
-static int __init elanfreq_init(void)
-{
-	if (!x86_match_cpu(elan_id))
-		return -ENODEV;
-	return cpufreq_register_driver(&elanfreq_driver);
-}
-
-
-static void __exit elanfreq_exit(void)
-{
-	cpufreq_unregister_driver(&elanfreq_driver);
-}
-
-
-module_param(max_freq, int, 0444);
-
-MODULE_LICENSE("GPL");
-MODULE_AUTHOR("Robert Schwebel <r.schwebel@pengutronix.de>, "
-		"Sven Geggus <sven@geggus.net>");
-MODULE_DESCRIPTION("cpufreq driver for AMD's Elan CPUs");
-
-module_init(elanfreq_init);
-module_exit(elanfreq_exit);
diff -rupN a/drivers/cpufreq/intel_pstate.c b/drivers/cpufreq/intel_pstate.c
--- a/drivers/cpufreq/intel_pstate.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/cpufreq/intel_pstate.c	2025-06-01 20:34:16.772109550 +0200
@@ -382,6 +382,13 @@ static void intel_pstate_set_itmt_prio(i
 	 * update them at any time after it has been called.
 	 */
 	sched_set_itmt_core_prio(cppc_perf.highest_perf, cpu);
+	/*
+	 * On some systems with overclocking enabled, CPPC.highest_perf is hardcoded to 0xff.
+	 * In this case we can't use CPPC.highest_perf to enable ITMT.
+	 * In this case we can look at MSR_HWP_CAPABILITIES bits [8:0] to decide.
+	 */
+	if (cppc_perf.highest_perf == 0xff)
+		cppc_perf.highest_perf = HWP_HIGHEST_PERF(READ_ONCE(all_cpu_data[cpu]->hwp_cap_cached));
 
 	if (max_highest_perf <= min_highest_perf) {
 		if (cppc_perf.highest_perf > max_highest_perf)
diff -rupN a/drivers/cpufreq/Kconfig.x86 b/drivers/cpufreq/Kconfig.x86
--- a/drivers/cpufreq/Kconfig.x86	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/cpufreq/Kconfig.x86	2025-06-01 20:34:16.773109559 +0200
@@ -112,32 +112,6 @@ config X86_ACPI_CPUFREQ_CPB
 	  By enabling this option the acpi_cpufreq driver provides the old
 	  entry in addition to the new boost ones, for compatibility reasons.
 
-config ELAN_CPUFREQ
-	tristate "AMD Elan SC400 and SC410"
-	depends on MELAN
-	help
-	  This adds the CPUFreq driver for AMD Elan SC400 and SC410
-	  processors.
-
-	  You need to specify the processor maximum speed as boot
-	  parameter: elanfreq=maxspeed (in kHz) or as module
-	  parameter "max_freq".
-
-	  For details, take a look at <file:Documentation/cpu-freq/>.
-
-	  If in doubt, say N.
-
-config SC520_CPUFREQ
-	tristate "AMD Elan SC520"
-	depends on MELAN
-	help
-	  This adds the CPUFreq driver for AMD Elan SC520 processor.
-
-	  For details, take a look at <file:Documentation/cpu-freq/>.
-
-	  If in doubt, say N.
-
-
 config X86_POWERNOW_K6
 	tristate "AMD Mobile K6-2/K6-3 PowerNow!"
 	depends on X86_32
diff -rupN a/drivers/cpufreq/Makefile b/drivers/cpufreq/Makefile
--- a/drivers/cpufreq/Makefile	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/cpufreq/Makefile	2025-06-01 20:34:16.773109559 +0200
@@ -39,8 +39,6 @@ obj-$(CONFIG_X86_POWERNOW_K6)		+= powern
 obj-$(CONFIG_X86_POWERNOW_K7)		+= powernow-k7.o
 obj-$(CONFIG_X86_LONGHAUL)		+= longhaul.o
 obj-$(CONFIG_X86_E_POWERSAVER)		+= e_powersaver.o
-obj-$(CONFIG_ELAN_CPUFREQ)		+= elanfreq.o
-obj-$(CONFIG_SC520_CPUFREQ)		+= sc520_freq.o
 obj-$(CONFIG_X86_LONGRUN)		+= longrun.o
 obj-$(CONFIG_X86_GX_SUSPMOD)		+= gx-suspmod.o
 obj-$(CONFIG_X86_SPEEDSTEP_ICH)		+= speedstep-ich.o
diff -rupN a/drivers/cpufreq/sc520_freq.c b/drivers/cpufreq/sc520_freq.c
--- a/drivers/cpufreq/sc520_freq.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/cpufreq/sc520_freq.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,136 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- *	sc520_freq.c: cpufreq driver for the AMD Elan sc520
- *
- *	Copyright (C) 2005 Sean Young <sean@mess.org>
- *
- *	Based on elanfreq.c
- *
- *	2005-03-30: - initial revision
- */
-
-#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/init.h>
-
-#include <linux/delay.h>
-#include <linux/cpufreq.h>
-#include <linux/timex.h>
-#include <linux/io.h>
-
-#include <asm/cpu_device_id.h>
-
-#define MMCR_BASE	0xfffef000	/* The default base address */
-#define OFFS_CPUCTL	0x2   /* CPU Control Register */
-
-static __u8 __iomem *cpuctl;
-
-static struct cpufreq_frequency_table sc520_freq_table[] = {
-	{0, 0x01,	100000},
-	{0, 0x02,	133000},
-	{0, 0,	CPUFREQ_TABLE_END},
-};
-
-static unsigned int sc520_freq_get_cpu_frequency(unsigned int cpu)
-{
-	u8 clockspeed_reg = *cpuctl;
-
-	switch (clockspeed_reg & 0x03) {
-	default:
-		pr_err("error: cpuctl register has unexpected value %02x\n",
-		       clockspeed_reg);
-		fallthrough;
-	case 0x01:
-		return 100000;
-	case 0x02:
-		return 133000;
-	}
-}
-
-static int sc520_freq_target(struct cpufreq_policy *policy, unsigned int state)
-{
-
-	u8 clockspeed_reg;
-
-	local_irq_disable();
-
-	clockspeed_reg = *cpuctl & ~0x03;
-	*cpuctl = clockspeed_reg | sc520_freq_table[state].driver_data;
-
-	local_irq_enable();
-
-	return 0;
-}
-
-/*
- *	Module init and exit code
- */
-
-static int sc520_freq_cpu_init(struct cpufreq_policy *policy)
-{
-	struct cpuinfo_x86 *c = &cpu_data(0);
-
-	/* capability check */
-	if (c->x86_vendor != X86_VENDOR_AMD ||
-	    c->x86 != 4 || c->x86_model != 9)
-		return -ENODEV;
-
-	/* cpuinfo and default policy values */
-	policy->cpuinfo.transition_latency = 1000000; /* 1ms */
-	policy->freq_table = sc520_freq_table;
-
-	return 0;
-}
-
-
-static struct cpufreq_driver sc520_freq_driver = {
-	.get	= sc520_freq_get_cpu_frequency,
-	.verify	= cpufreq_generic_frequency_table_verify,
-	.target_index = sc520_freq_target,
-	.init	= sc520_freq_cpu_init,
-	.name	= "sc520_freq",
-};
-
-static const struct x86_cpu_id sc520_ids[] = {
-	X86_MATCH_VENDOR_FAM_MODEL(AMD, 4, 9, NULL),
-	{}
-};
-MODULE_DEVICE_TABLE(x86cpu, sc520_ids);
-
-static int __init sc520_freq_init(void)
-{
-	int err;
-
-	if (!x86_match_cpu(sc520_ids))
-		return -ENODEV;
-
-	cpuctl = ioremap((unsigned long)(MMCR_BASE + OFFS_CPUCTL), 1);
-	if (!cpuctl) {
-		pr_err("sc520_freq: error: failed to remap memory\n");
-		return -ENOMEM;
-	}
-
-	err = cpufreq_register_driver(&sc520_freq_driver);
-	if (err)
-		iounmap(cpuctl);
-
-	return err;
-}
-
-
-static void __exit sc520_freq_exit(void)
-{
-	cpufreq_unregister_driver(&sc520_freq_driver);
-	iounmap(cpuctl);
-}
-
-
-MODULE_LICENSE("GPL");
-MODULE_AUTHOR("Sean Young <sean@mess.org>");
-MODULE_DESCRIPTION("cpufreq driver for AMD's Elan sc520 CPU");
-
-module_init(sc520_freq_init);
-module_exit(sc520_freq_exit);
-
diff -rupN a/drivers/cpuidle/governors/menu.c b/drivers/cpuidle/governors/menu.c
--- a/drivers/cpuidle/governors/menu.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/cpuidle/governors/menu.c	2025-06-01 20:34:16.774109566 +0200
@@ -16,6 +16,7 @@
 #include <linux/tick.h>
 #include <linux/sched/stat.h>
 #include <linux/math64.h>
+#include <linux/cpuidle_psd.h>
 
 #include "gov.h"
 
@@ -224,6 +225,9 @@ static int menu_select(struct cpuidle_dr
 		data->needs_update = 0;
 	}
 
+	if (have_prevent_sleep_demotion())
+		latency_req = 0;
+
 	/* Find the shortest expected idle interval. */
 	predicted_ns = get_typical_interval(data) * NSEC_PER_USEC;
 	if (predicted_ns > RESIDENCY_THRESHOLD_NS) {
diff -rupN a/drivers/cpuidle/Kconfig b/drivers/cpuidle/Kconfig
--- a/drivers/cpuidle/Kconfig	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/cpuidle/Kconfig	2025-06-01 20:34:16.774109566 +0200
@@ -81,6 +81,16 @@ config HALTPOLL_CPUIDLE
 	 before halting in the guest (more efficient than polling in the
 	 host via halt_poll_ns for some scenarios).
 
+config CPU_IDLE_PSD
+	bool "prevent sleep demotion (PSD) for fast I/O devices"
+        default y
+        help
+         This option enables deferring of deep sleep states when a future
+         I/O based servicing event very probably going to happen in the very
+         near future, such as handling fast NVME device I/O. This reduces
+         uncessary transistions to deep idle sleep and reduces latency. This
+         provides the latency benefits of disabling deep sleep with the
+         power saving benefits of deep sleep when I/O is idle.
 endif
 
 config ARCH_NEEDS_CPU_IDLE_COUPLED
diff -rupN a/drivers/cpuidle/Makefile b/drivers/cpuidle/Makefile
--- a/drivers/cpuidle/Makefile	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/cpuidle/Makefile	2025-06-01 20:34:16.775109574 +0200
@@ -12,6 +12,7 @@ obj-$(CONFIG_DT_IDLE_STATES)		  += dt_id
 obj-$(CONFIG_DT_IDLE_GENPD)		  += dt_idle_genpd.o
 obj-$(CONFIG_ARCH_HAS_CPU_RELAX)	  += poll_state.o
 obj-$(CONFIG_HALTPOLL_CPUIDLE)		  += cpuidle-haltpoll.o
+obj-$(CONFIG_CPU_IDLE_PSD)	  	  += psd.o
 
 ##################################################################################
 # ARM SoC drivers
diff -rupN a/drivers/cpuidle/psd.c b/drivers/cpuidle/psd.c
--- a/drivers/cpuidle/psd.c	1970-01-01 01:00:00.000000000 +0100
+++ b/drivers/cpuidle/psd.c	2025-06-01 20:34:16.775109574 +0200
@@ -0,0 +1,123 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ *  Copyright (C) 2025 Intel Corporation
+ *  Author: Colin Ian King <colin.king@intel.com>
+ *
+ *  Kernel be-right-back infrastructructure
+ */
+#include <linux/kernel.h>
+#include <linux/cpu.h>
+#include <linux/device.h>
+#include <linux/percpu.h>
+#include <linux/jiffies.h>
+#include <linux/cpuidle_psd.h>
+
+/* jiffies at which the lease for the bump times out */
+static DEFINE_PER_CPU(unsigned long, psd_timeout);
+static int psd_cpu_lat_timeout_ms = PSD_DISK_MSEC;
+static int psd_cpu_lat_timeout_jiffies;
+
+/*
+ * a note about the use of the current cpu versus preemption.
+ *
+ * Most uses of psd_in_power_bump() are inside local power management code,
+ * and are pinned to that cpu already.
+ *
+ * On the "set" side, interrupt level code is obviously also fully
+ * migration-race free.
+ *
+ * All other cases are exposed to a migration-race.
+ *
+ * The goal of prevent sleep demotion is statistical rather than deterministic,
+ * e.g. on average the CPU that hits event X will go towards Y more
+ * often than not, and the impact of being wrong is a bit of extra
+ * power potentially for some short durations.
+ * Weighted against the costs in performance and complexity of dealing
+ * with the race, the race condition is acceptable.
+ *
+ * The second known race is where interrupt context might set a bump
+ * time in the middle of process context setting a different but smaller bump time,
+ * with the result that process context will win incorrectly, and the
+ * actual bump time will be less than expected, but still non-zero.
+ * Here also the cost of dealing with the race is outweight with the
+ * limited impact.
+ */
+
+int have_prevent_sleep_demotion(void)
+{
+	if (psd_cpu_lat_timeout_jiffies) {
+		int cpu = raw_smp_processor_id();
+
+		if (time_before(jiffies, per_cpu(psd_timeout, cpu)))
+			return 1;
+
+		/* deal with wrap issues by keeping the stored bump value close to current */
+		per_cpu(psd_timeout, cpu) = jiffies;
+	}
+	return 0;
+}
+
+EXPORT_SYMBOL_GPL(have_prevent_sleep_demotion);
+
+void prevent_sleep_demotion(void)
+{
+	if (psd_cpu_lat_timeout_jiffies) {
+		const unsigned long next_jiffies = jiffies + psd_cpu_lat_timeout_jiffies;
+		const int cpu = raw_smp_processor_id();
+
+		/*  need to round up an extra jiffie */
+		if (time_before(per_cpu(psd_timeout, cpu), next_jiffies))
+			per_cpu(psd_timeout, cpu) = next_jiffies;
+	}
+}
+
+EXPORT_SYMBOL_GPL(prevent_sleep_demotion);
+
+static ssize_t psd_cpu_lat_timeout_ms_show(struct device *dev,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	return sprintf(buf, "%d%s\n", psd_cpu_lat_timeout_ms,
+			psd_cpu_lat_timeout_ms == 0 ? " disabled" : "");
+}
+
+static ssize_t psd_cpu_lat_timeout_ms_store(struct device *dev,
+					  struct device_attribute *attr,
+					  const char *buf, size_t count)
+{
+	int val;
+
+	if (!count || sscanf(buf, "%d", &val) != 1)
+		return -EINVAL;
+	if (val < 0 || val > 1000)
+		return -EINVAL;
+
+	psd_cpu_lat_timeout_ms = val;
+	psd_cpu_lat_timeout_jiffies = msecs_to_jiffies(psd_cpu_lat_timeout_ms) + 1;
+	return count;
+}
+
+static DEVICE_ATTR_RW(psd_cpu_lat_timeout_ms);
+
+static __init int prevent_sleep_demotion_init(void)
+{
+	struct device *dev_root = bus_get_dev_root(&cpu_subsys);
+	unsigned int cpu;
+
+	if (!dev_root)
+		return -1;
+
+	psd_cpu_lat_timeout_jiffies = msecs_to_jiffies(psd_cpu_lat_timeout_ms) + 1;
+
+	pr_info("cpuidle-psd: using %d msec (%d jiffies) for idle bump\n",
+		psd_cpu_lat_timeout_ms, psd_cpu_lat_timeout_jiffies);
+
+	for_each_possible_cpu(cpu)
+		per_cpu(psd_timeout, cpu) = jiffies;
+
+	sysfs_add_file_to_group(&dev_root->kobj, &dev_attr_psd_cpu_lat_timeout_ms.attr, "cpuidle");
+
+	return 0;
+}
+
+late_initcall(prevent_sleep_demotion_init);
diff -rupN a/drivers/dma-buf/dma-buf.c b/drivers/dma-buf/dma-buf.c
--- a/drivers/dma-buf/dma-buf.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/dma-buf/dma-buf.c	2025-06-01 20:34:16.776109583 +0200
@@ -518,6 +518,7 @@ static long dma_buf_ioctl(struct file *f
 	struct dma_buf *dmabuf;
 	struct dma_buf_sync sync;
 	enum dma_data_direction direction;
+	struct dma_buf_rw_file kfile;
 	int ret;
 
 	dmabuf = file->private_data;
@@ -562,6 +563,13 @@ static long dma_buf_ioctl(struct file *f
 		return dma_buf_import_sync_file(dmabuf, (const void __user *)arg);
 #endif
 
+	case DMA_BUF_IOCTL_RW_FILE:
+		if (copy_from_user(&kfile, (void __user *) arg, sizeof(kfile)))
+			return -EFAULT;
+		if (!dmabuf->ops->rw_file)
+			return -EINVAL;
+		return dmabuf->ops->rw_file(dmabuf, &kfile);
+
 	default:
 		return -ENOTTY;
 	}
diff -rupN a/drivers/dma-buf/heaps/system_heap.c b/drivers/dma-buf/heaps/system_heap.c
--- a/drivers/dma-buf/heaps/system_heap.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/dma-buf/heaps/system_heap.c	2025-06-01 20:34:16.776109583 +0200
@@ -20,6 +20,8 @@
 #include <linux/scatterlist.h>
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
+#include <linux/bvec.h>
+#include <linux/uio.h>
 
 struct system_heap_buffer {
 	struct dma_heap *heap;
@@ -279,6 +281,124 @@ static void system_heap_vunmap(struct dm
 	iosys_map_clear(map);
 }
 
+static struct bio_vec *system_heap_init_bvec(struct system_heap_buffer *buffer,
+			size_t offset, size_t len, int *nr_segs)
+{
+	struct sg_table *sgt = &buffer->sg_table;
+	struct scatterlist *sg;
+	size_t length = 0;
+	unsigned int i, k = 0;
+	struct bio_vec *bvec;
+	size_t sg_left;
+	size_t sg_offset;
+	size_t sg_len;
+
+	bvec = kvcalloc(sgt->nents, sizeof(*bvec), GFP_KERNEL);
+	if (!bvec)
+		return NULL;
+
+	for_each_sg(sgt->sgl, sg, sgt->nents, i) {
+		length += sg->length;
+		if (length <= offset)
+			continue;
+
+		sg_left = length - offset;
+		sg_offset = sg->offset + sg->length - sg_left;
+		sg_len = min(sg_left, len);
+
+		bvec[k].bv_page = sg_page(sg);
+		bvec[k].bv_len = sg_len;
+		bvec[k].bv_offset = sg_offset;
+		k++;
+
+		offset += sg_len;
+		len -= sg_len;
+		if (len <= 0)
+			break;
+	}
+
+	*nr_segs = k;
+	return bvec;
+}
+
+static int system_heap_rw_file(struct system_heap_buffer *buffer, bool is_read,
+		bool direct_io, struct file *filp, loff_t file_offset,
+		size_t buf_offset, size_t len)
+{
+	struct bio_vec *bvec;
+	int nr_segs = 0;
+	struct iov_iter iter;
+	struct kiocb kiocb;
+	ssize_t ret = 0;
+
+	if (!list_empty(&buffer->attachments) || buffer->vmap_cnt)
+		return -EBUSY;
+
+	if (direct_io) {
+		if (!(filp->f_mode & FMODE_CAN_ODIRECT))
+			return -EINVAL;
+	}
+
+	bvec = system_heap_init_bvec(buffer, buf_offset, len, &nr_segs);
+	if (!bvec)
+		return -ENOMEM;
+
+	iov_iter_bvec(&iter, is_read ? ITER_DEST : ITER_SOURCE, bvec, nr_segs, len);
+	init_sync_kiocb(&kiocb, filp);
+	kiocb.ki_pos = file_offset;
+	if (direct_io)
+		kiocb.ki_flags |= IOCB_DIRECT;
+
+	while (kiocb.ki_pos < file_offset + len) {
+		if (is_read)
+			ret = vfs_iocb_iter_read(filp, &kiocb, &iter);
+		else
+			ret = vfs_iocb_iter_write(filp, &kiocb, &iter);
+		if (ret <= 0)
+			break;
+	}
+
+	kvfree(bvec);
+	return ret < 0 ? ret : 0;
+}
+
+static int system_heap_dma_buf_rw_file(struct dma_buf *dmabuf,
+			struct dma_buf_rw_file *back)
+{
+	struct system_heap_buffer *buffer = dmabuf->priv;
+	int ret = 0;
+	__u32 op = back->flags & DMA_BUF_RW_FLAGS_OP_MASK;
+	bool direct_io = back->flags & DMA_BUF_RW_FLAGS_DIRECT;
+	struct file *filp;
+
+	if (op != DMA_BUF_RW_FLAGS_READ && op != DMA_BUF_RW_FLAGS_WRITE)
+		return -EINVAL;
+	if (direct_io) {
+		if (!PAGE_ALIGNED(back->file_offset) ||
+		    !PAGE_ALIGNED(back->buf_offset) ||
+		    !PAGE_ALIGNED(back->buf_len))
+			return -EINVAL;
+	}
+	if (!back->buf_len || back->buf_len > dmabuf->size ||
+		back->buf_offset >= dmabuf->size ||
+		back->buf_offset + back->buf_len > dmabuf->size)
+		return -EINVAL;
+	if (back->file_offset + back->buf_len < back->file_offset)
+		return -EINVAL;
+
+	filp = fget(back->fd);
+	if (!filp)
+		return -EBADF;
+
+	mutex_lock(&buffer->lock);
+	ret = system_heap_rw_file(buffer, op == DMA_BUF_RW_FLAGS_READ, direct_io,
+			filp, back->file_offset, back->buf_offset, back->buf_len);
+	mutex_unlock(&buffer->lock);
+
+	fput(filp);
+	return ret;
+}
+
 static void system_heap_dma_buf_release(struct dma_buf *dmabuf)
 {
 	struct system_heap_buffer *buffer = dmabuf->priv;
@@ -306,6 +426,7 @@ static const struct dma_buf_ops system_h
 	.mmap = system_heap_mmap,
 	.vmap = system_heap_vmap,
 	.vunmap = system_heap_vunmap,
+	.rw_file = system_heap_dma_buf_rw_file,
 	.release = system_heap_dma_buf_release,
 };
 
diff -rupN a/drivers/gpu/drm/i915/display/intel_dsb.c b/drivers/gpu/drm/i915/display/intel_dsb.c
--- a/drivers/gpu/drm/i915/display/intel_dsb.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/gpu/drm/i915/display/intel_dsb.c	2025-06-01 20:34:16.777109591 +0200
@@ -808,6 +808,10 @@ struct intel_dsb *intel_dsb_prepare(stru
 	if (!display->params.enable_dsb)
 		return NULL;
 
+	/* TODO: DSB is broken in Xe KMD, so disabling it until fixed */
+	if (!IS_ENABLED(I915))
+		return NULL;
+
 	dsb = kzalloc(sizeof(*dsb), GFP_KERNEL);
 	if (!dsb)
 		goto out;
diff -rupN a/drivers/hid/hid-logitech-hidpp.c b/drivers/hid/hid-logitech-hidpp.c
--- a/drivers/hid/hid-logitech-hidpp.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/hid/hid-logitech-hidpp.c	2025-06-01 20:34:16.779109607 +0200
@@ -973,7 +973,7 @@ static int hidpp_root_get_protocol_versi
 		return -EIO;
 
 	if (ret > 0) {
-		hid_err(hidpp->hid_dev, "%s: received protocol error 0x%02x\n",
+		hid_dbg(hidpp->hid_dev, "%s: received protocol error 0x%02x\n",
 			__func__, ret);
 		return -EPROTO;
 	}
diff -rupN a/drivers/hid/hid-quirks.c b/drivers/hid/hid-quirks.c
--- a/drivers/hid/hid-quirks.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/hid/hid-quirks.c	2025-06-01 20:34:16.780109615 +0200
@@ -1063,7 +1063,7 @@ bool hid_ignore(struct hid_device *hdev)
 	}
 
 	if (hdev->type == HID_TYPE_USBMOUSE &&
-	    hid_match_id(hdev, hid_mouse_ignore_list))
+	    hdev->quirks & HID_QUIRK_IGNORE_MOUSE)
 		return true;
 
 	return !!hid_match_id(hdev, hid_ignore_list);
@@ -1267,6 +1267,9 @@ static unsigned long hid_gets_squirk(con
 	if (hid_match_id(hdev, hid_ignore_list))
 		quirks |= HID_QUIRK_IGNORE;
 
+	if (hid_match_id(hdev, hid_mouse_ignore_list))
+		quirks |= HID_QUIRK_IGNORE_MOUSE;
+
 	if (hid_match_id(hdev, hid_have_special_driver))
 		quirks |= HID_QUIRK_HAVE_SPECIAL_DRIVER;
 
diff -rupN a/drivers/idle/intel_idle.c b/drivers/idle/intel_idle.c
--- a/drivers/idle/intel_idle.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/idle/intel_idle.c	2025-06-01 20:34:16.781109623 +0200
@@ -50,6 +50,8 @@
 #include <linux/sched/smt.h>
 #include <linux/mutex.h>
 #include <linux/notifier.h>
+#include <linux/mutex.h>
+#include <linux/sysfs.h>
 #include <linux/cpu.h>
 #include <linux/moduleparam.h>
 #include <linux/sysfs.h>
@@ -594,7 +596,7 @@ static struct cpuidle_state hsw_cstates[
 		.desc = "MWAIT 0x01",
 		.flags = MWAIT2flg(0x01) | CPUIDLE_FLAG_ALWAYS_ENABLE,
 		.exit_latency = 10,
-		.target_residency = 20,
+		.target_residency = 120,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -602,7 +604,7 @@ static struct cpuidle_state hsw_cstates[
 		.desc = "MWAIT 0x10",
 		.flags = MWAIT2flg(0x10) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 33,
-		.target_residency = 100,
+		.target_residency = 900,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -610,7 +612,7 @@ static struct cpuidle_state hsw_cstates[
 		.desc = "MWAIT 0x20",
 		.flags = MWAIT2flg(0x20) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 133,
-		.target_residency = 400,
+		.target_residency = 1000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -618,7 +620,7 @@ static struct cpuidle_state hsw_cstates[
 		.desc = "MWAIT 0x32",
 		.flags = MWAIT2flg(0x32) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 166,
-		.target_residency = 500,
+		.target_residency = 1500,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -626,7 +628,7 @@ static struct cpuidle_state hsw_cstates[
 		.desc = "MWAIT 0x40",
 		.flags = MWAIT2flg(0x40) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 300,
-		.target_residency = 900,
+		.target_residency = 2000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -634,7 +636,7 @@ static struct cpuidle_state hsw_cstates[
 		.desc = "MWAIT 0x50",
 		.flags = MWAIT2flg(0x50) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 600,
-		.target_residency = 1800,
+		.target_residency = 5000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -642,7 +644,7 @@ static struct cpuidle_state hsw_cstates[
 		.desc = "MWAIT 0x60",
 		.flags = MWAIT2flg(0x60) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 2600,
-		.target_residency = 7700,
+		.target_residency = 9000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -662,7 +664,7 @@ static struct cpuidle_state bdw_cstates[
 		.desc = "MWAIT 0x01",
 		.flags = MWAIT2flg(0x01) | CPUIDLE_FLAG_ALWAYS_ENABLE,
 		.exit_latency = 10,
-		.target_residency = 20,
+		.target_residency = 120,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -670,7 +672,7 @@ static struct cpuidle_state bdw_cstates[
 		.desc = "MWAIT 0x10",
 		.flags = MWAIT2flg(0x10) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 40,
-		.target_residency = 100,
+		.target_residency = 1000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -678,7 +680,7 @@ static struct cpuidle_state bdw_cstates[
 		.desc = "MWAIT 0x20",
 		.flags = MWAIT2flg(0x20) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 133,
-		.target_residency = 400,
+		.target_residency = 1000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -686,7 +688,7 @@ static struct cpuidle_state bdw_cstates[
 		.desc = "MWAIT 0x32",
 		.flags = MWAIT2flg(0x32) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 166,
-		.target_residency = 500,
+		.target_residency = 2000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -694,7 +696,7 @@ static struct cpuidle_state bdw_cstates[
 		.desc = "MWAIT 0x40",
 		.flags = MWAIT2flg(0x40) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 300,
-		.target_residency = 900,
+		.target_residency = 4000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -702,7 +704,7 @@ static struct cpuidle_state bdw_cstates[
 		.desc = "MWAIT 0x50",
 		.flags = MWAIT2flg(0x50) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 600,
-		.target_residency = 1800,
+		.target_residency = 7000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -710,7 +712,7 @@ static struct cpuidle_state bdw_cstates[
 		.desc = "MWAIT 0x60",
 		.flags = MWAIT2flg(0x60) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 2600,
-		.target_residency = 7700,
+		.target_residency = 9000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -731,7 +733,7 @@ static struct cpuidle_state skl_cstates[
 		.desc = "MWAIT 0x01",
 		.flags = MWAIT2flg(0x01) | CPUIDLE_FLAG_ALWAYS_ENABLE,
 		.exit_latency = 10,
-		.target_residency = 20,
+		.target_residency = 120,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -739,7 +741,7 @@ static struct cpuidle_state skl_cstates[
 		.desc = "MWAIT 0x10",
 		.flags = MWAIT2flg(0x10) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 70,
-		.target_residency = 100,
+		.target_residency = 1000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -747,7 +749,7 @@ static struct cpuidle_state skl_cstates[
 		.desc = "MWAIT 0x20",
 		.flags = MWAIT2flg(0x20) | CPUIDLE_FLAG_TLB_FLUSHED | CPUIDLE_FLAG_IBRS,
 		.exit_latency = 85,
-		.target_residency = 200,
+		.target_residency = 600,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -755,7 +757,7 @@ static struct cpuidle_state skl_cstates[
 		.desc = "MWAIT 0x33",
 		.flags = MWAIT2flg(0x33) | CPUIDLE_FLAG_TLB_FLUSHED | CPUIDLE_FLAG_IBRS,
 		.exit_latency = 124,
-		.target_residency = 800,
+		.target_residency = 3000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -763,7 +765,7 @@ static struct cpuidle_state skl_cstates[
 		.desc = "MWAIT 0x40",
 		.flags = MWAIT2flg(0x40) | CPUIDLE_FLAG_TLB_FLUSHED | CPUIDLE_FLAG_IBRS,
 		.exit_latency = 200,
-		.target_residency = 800,
+		.target_residency = 3200,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -771,7 +773,7 @@ static struct cpuidle_state skl_cstates[
 		.desc = "MWAIT 0x50",
 		.flags = MWAIT2flg(0x50) | CPUIDLE_FLAG_TLB_FLUSHED | CPUIDLE_FLAG_IBRS,
 		.exit_latency = 480,
-		.target_residency = 5000,
+		.target_residency = 9000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -779,7 +781,7 @@ static struct cpuidle_state skl_cstates[
 		.desc = "MWAIT 0x60",
 		.flags = MWAIT2flg(0x60) | CPUIDLE_FLAG_TLB_FLUSHED | CPUIDLE_FLAG_IBRS,
 		.exit_latency = 890,
-		.target_residency = 5000,
+		.target_residency = 9000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -800,7 +802,7 @@ static struct cpuidle_state skx_cstates[
 		.desc = "MWAIT 0x01",
 		.flags = MWAIT2flg(0x01) | CPUIDLE_FLAG_ALWAYS_ENABLE,
 		.exit_latency = 10,
-		.target_residency = 20,
+		.target_residency = 300,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -829,7 +831,7 @@ static struct cpuidle_state icx_cstates[
 		.desc = "MWAIT 0x01",
 		.flags = MWAIT2flg(0x01) | CPUIDLE_FLAG_ALWAYS_ENABLE,
 		.exit_latency = 4,
-		.target_residency = 4,
+		.target_residency = 40,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -837,7 +839,7 @@ static struct cpuidle_state icx_cstates[
 		.desc = "MWAIT 0x20",
 		.flags = MWAIT2flg(0x20) | CPUIDLE_FLAG_TLB_FLUSHED,
 		.exit_latency = 170,
-		.target_residency = 600,
+		.target_residency = 900,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -987,7 +989,7 @@ static struct cpuidle_state gmt_cstates[
 		.desc = "MWAIT 0x01",
 		.flags = MWAIT2flg(0x01) | CPUIDLE_FLAG_ALWAYS_ENABLE,
 		.exit_latency = 2,
-		.target_residency = 4,
+		.target_residency = 40,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -1041,7 +1043,7 @@ static struct cpuidle_state spr_cstates[
 		.flags = MWAIT2flg(0x20) | CPUIDLE_FLAG_TLB_FLUSHED |
 					   CPUIDLE_FLAG_INIT_XSTATE,
 		.exit_latency = 290,
-		.target_residency = 800,
+		.target_residency = 1200,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -1072,7 +1074,7 @@ static struct cpuidle_state gnr_cstates[
 					   CPUIDLE_FLAG_INIT_XSTATE |
 					   CPUIDLE_FLAG_PARTIAL_HINT_MATCH,
 		.exit_latency = 170,
-		.target_residency = 650,
+		.target_residency = 1250,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -1082,7 +1084,7 @@ static struct cpuidle_state gnr_cstates[
 					   CPUIDLE_FLAG_INIT_XSTATE |
 					   CPUIDLE_FLAG_PARTIAL_HINT_MATCH,
 		.exit_latency = 210,
-		.target_residency = 1000,
+		.target_residency = 2000,
 		.enter = &intel_idle,
 		.enter_s2idle = intel_idle_s2idle, },
 	{
@@ -2420,6 +2422,52 @@ static void __init intel_idle_sysfs_unin
 	put_device(sysfs_root);
 }
 
+static void c1_demotion_toggle(void *info)
+{
+	unsigned long long msr_val;
+	bool enable = *(bool *)info;
+
+	rdmsrl(MSR_PKG_CST_CONFIG_CONTROL, msr_val);
+	/*
+	 * Enable/disable C1 undemotion along with C1 demotion, as this is the
+	 * most sensible configuration in general.
+	 */
+	if (enable)
+		msr_val |= NHM_C1_AUTO_DEMOTE | SNB_C1_AUTO_UNDEMOTE;
+	else
+		msr_val &= ~(NHM_C1_AUTO_DEMOTE | SNB_C1_AUTO_UNDEMOTE);
+	wrmsrl(MSR_PKG_CST_CONFIG_CONTROL, msr_val);
+}
+
+static ssize_t c1_demotion_store(struct device *dev,
+				 struct device_attribute *attr,
+				 const char *buf, size_t count)
+{
+	int err;
+	bool enable;
+
+	err = kstrtobool(buf, &enable);
+	if (err)
+		return err;
+
+	mutex_lock(&c1_demotion_mutex);
+	/* Enable/disable C1 demotion on all CPUs */
+	on_each_cpu(c1_demotion_toggle, &enable, 1);
+	mutex_unlock(&c1_demotion_mutex);
+
+	return count;
+}
+
+static ssize_t c1_demotion_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	unsigned long long msr_val;
+
+	rdmsrl(MSR_PKG_CST_CONFIG_CONTROL, msr_val);
+	return sysfs_emit(buf, "%d\n", !!(msr_val & NHM_C1_AUTO_DEMOTE));
+}
+static DEVICE_ATTR_RW(c1_demotion);
+
 static int __init intel_idle_init(void)
 {
 	const struct x86_cpu_id *id;
@@ -2487,6 +2535,10 @@ static int __init intel_idle_init(void)
 
 	retval = intel_idle_sysfs_init();
 	if (retval)
+		pr_warn("failed to initialized sysfs");
+
+	retval = intel_idle_sysfs_init();
+	if (retval)
 		pr_warn("failed to initialized sysfs");
 
 	intel_idle_cpuidle_driver_init(&intel_idle_driver);
diff -rupN a/drivers/input/serio/i8042.c b/drivers/input/serio/i8042.c
--- a/drivers/input/serio/i8042.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/input/serio/i8042.c	2025-06-01 20:34:16.782109631 +0200
@@ -621,7 +621,7 @@ static int i8042_enable_kbd_port(void)
 	if (i8042_command(&i8042_ctr, I8042_CMD_CTL_WCTR)) {
 		i8042_ctr &= ~I8042_CTR_KBDINT;
 		i8042_ctr |= I8042_CTR_KBDDIS;
-		pr_err("Failed to enable KBD port\n");
+		pr_info("Failed to enable KBD port\n");
 		return -EIO;
 	}
 
@@ -640,7 +640,7 @@ static int i8042_enable_aux_port(void)
 	if (i8042_command(&i8042_ctr, I8042_CMD_CTL_WCTR)) {
 		i8042_ctr &= ~I8042_CTR_AUXINT;
 		i8042_ctr |= I8042_CTR_AUXDIS;
-		pr_err("Failed to enable AUX port\n");
+		pr_info("Failed to enable AUX port\n");
 		return -EIO;
 	}
 
@@ -732,7 +732,7 @@ static int i8042_check_mux(void)
 	i8042_ctr &= ~I8042_CTR_AUXINT;
 
 	if (i8042_command(&i8042_ctr, I8042_CMD_CTL_WCTR)) {
-		pr_err("Failed to disable AUX port, can't use MUX\n");
+		pr_info("Failed to disable AUX port, can't use MUX\n");
 		return -EIO;
 	}
 
@@ -949,7 +949,7 @@ static int i8042_controller_selftest(voi
 	do {
 
 		if (i8042_command(&param, I8042_CMD_CTL_TEST)) {
-			pr_err("i8042 controller selftest timeout\n");
+			pr_info("i8042 controller selftest timeout\n");
 			return -ENODEV;
 		}
 
@@ -971,7 +971,7 @@ static int i8042_controller_selftest(voi
 	pr_info("giving up on controller selftest, continuing anyway...\n");
 	return 0;
 #else
-	pr_err("i8042 controller selftest failed\n");
+	pr_info("i8042 controller selftest failed\n");
 	return -EIO;
 #endif
 }
diff -rupN a/drivers/iommu/irq_remapping.c b/drivers/iommu/irq_remapping.c
--- a/drivers/iommu/irq_remapping.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/iommu/irq_remapping.c	2025-06-01 20:34:16.783109639 +0200
@@ -24,7 +24,7 @@ int no_x2apic_optout;
 
 int disable_irq_post = 0;
 
-bool enable_posted_msi __ro_after_init;
+bool enable_posted_msi __ro_after_init = true;
 
 static int disable_irq_remap;
 static struct irq_remap_ops *remap_ops;
diff -rupN a/drivers/net/dummy.c b/drivers/net/dummy.c
--- a/drivers/net/dummy.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/net/dummy.c	2025-06-01 20:34:16.783109639 +0200
@@ -44,7 +44,7 @@
 
 #define DRV_NAME	"dummy"
 
-static int numdummies = 1;
+static int numdummies = 0;
 
 /* fake multicast ability */
 static void set_multicast_list(struct net_device *dev)
diff -rupN a/drivers/pci/pci.c b/drivers/pci/pci.c
--- a/drivers/pci/pci.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/pci/pci.c	2025-06-01 20:34:16.785109655 +0200
@@ -60,7 +60,7 @@ struct pci_pme_device {
 	struct pci_dev *dev;
 };
 
-#define PME_TIMEOUT 1000 /* How long between PME checks */
+#define PME_TIMEOUT 4000 /* How long between PME checks */
 
 /*
  * Following exit from Conventional Reset, devices must be ready within 1 sec
diff -rupN a/drivers/thermal/intel/intel_powerclamp.c b/drivers/thermal/intel/intel_powerclamp.c
--- a/drivers/thermal/intel/intel_powerclamp.c	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/thermal/intel/intel_powerclamp.c	2025-06-01 20:34:16.786109663 +0200
@@ -710,6 +710,11 @@ static const struct thermal_cooling_devi
 	.set_cur_state = powerclamp_set_cur_state,
 };
 
+static const struct x86_cpu_id amd_cpu[] = {
+	{ X86_VENDOR_AMD },
+	{},
+};
+
 static const struct x86_cpu_id __initconst intel_powerclamp_ids[] = {
 	X86_MATCH_VENDOR_FEATURE(INTEL, X86_FEATURE_MWAIT, NULL),
 	{}
@@ -718,9 +723,13 @@ MODULE_DEVICE_TABLE(x86cpu, intel_powerc
 
 static int __init powerclamp_probe(void)
 {
-
 	if (!x86_match_cpu(intel_powerclamp_ids)) {
-		pr_err("CPU does not support MWAIT\n");
+		pr_info("CPU does not support MWAIT\n");
+		return -ENODEV;
+	}
+
+	if (x86_match_cpu(amd_cpu)){
+		pr_info("Intel PowerClamp does not support AMD CPUs\n");
 		return -ENODEV;
 	}
 
diff -rupN a/drivers/watchdog/Kconfig b/drivers/watchdog/Kconfig
--- a/drivers/watchdog/Kconfig	2025-06-01 18:01:58.000000000 +0200
+++ b/drivers/watchdog/Kconfig	2025-06-01 20:34:16.787109671 +0200
@@ -1536,7 +1536,7 @@ config NV_TCO
 
 config RDC321X_WDT
 	tristate "RDC R-321x SoC watchdog"
-	depends on X86_RDC321X || COMPILE_TEST
+	depends on X86_32 || COMPILE_TEST
 	depends on PCI
 	help
 	  This is the driver for the built in hardware watchdog
diff -rupN a/fs/binfmt_elf.c b/fs/binfmt_elf.c
--- a/fs/binfmt_elf.c	2025-06-01 18:01:58.000000000 +0200
+++ b/fs/binfmt_elf.c	2025-06-01 20:34:16.789109687 +0200
@@ -1286,6 +1286,8 @@ out_free_interp:
 	mm = current->mm;
 	mm->end_code = end_code;
 	mm->start_code = start_code;
+	if (start_code >= ELF_ET_DYN_BASE)
+		mm->mmap_base = start_code;
 	mm->start_data = start_data;
 	mm->end_data = end_data;
 	mm->start_stack = bprm->p;
diff -rupN a/fs/ext4/xattr.c b/fs/ext4/xattr.c
--- a/fs/ext4/xattr.c	2025-06-01 18:01:58.000000000 +0200
+++ b/fs/ext4/xattr.c	2025-06-01 20:34:16.790109696 +0200
@@ -1617,7 +1617,6 @@ out_err:
 static int ext4_xattr_set_entry(struct ext4_xattr_info *i,
 				struct ext4_xattr_search *s,
 				handle_t *handle, struct inode *inode,
-				struct inode *new_ea_inode,
 				bool is_block)
 {
 	struct ext4_xattr_entry *last, *next;
@@ -1625,6 +1624,7 @@ static int ext4_xattr_set_entry(struct e
 	size_t min_offs = s->end - s->base, name_len = strlen(i->name);
 	int in_inode = i->in_inode;
 	struct inode *old_ea_inode = NULL;
+	struct inode *new_ea_inode = NULL;
 	size_t old_size, new_size;
 	int ret;
 
@@ -1709,11 +1709,38 @@ static int ext4_xattr_set_entry(struct e
 			old_ea_inode = NULL;
 			goto out;
 		}
+	}
+	if (i->value && in_inode) {
+		WARN_ON_ONCE(!i->value_len);
 
+		new_ea_inode = ext4_xattr_inode_lookup_create(handle, inode,
+					i->value, i->value_len);
+		if (IS_ERR(new_ea_inode)) {
+			ret = PTR_ERR(new_ea_inode);
+			new_ea_inode = NULL;
+			goto out;
+		}
+	}
+
+	if (old_ea_inode) {
 		/* We are ready to release ref count on the old_ea_inode. */
 		ret = ext4_xattr_inode_dec_ref(handle, old_ea_inode);
-		if (ret)
+		if (ret) {
+			/* Release newly required ref count on new_ea_inode. */
+			if (new_ea_inode) {
+				int err;
+
+				err = ext4_xattr_inode_dec_ref(handle,
+							       new_ea_inode);
+				if (err)
+					ext4_warning_inode(new_ea_inode,
+						  "dec ref new_ea_inode err=%d",
+						  err);
+				ext4_xattr_inode_free_quota(inode, new_ea_inode,
+							    i->value_len);
+			}
 			goto out;
+		}
 
 		ext4_xattr_inode_free_quota(inode, old_ea_inode,
 					    le32_to_cpu(here->e_value_size));
@@ -1837,6 +1864,7 @@ update_hash:
 	ret = 0;
 out:
 	iput(old_ea_inode);
+	iput(new_ea_inode);
 	return ret;
 }
 
@@ -1899,20 +1927,8 @@ ext4_xattr_block_set(handle_t *handle, s
 	size_t old_ea_inode_quota = 0;
 	unsigned int ea_ino;
 
-#define header(x) ((struct ext4_xattr_header *)(x))
 
-	/* If we need EA inode, prepare it before locking the buffer */
-	if (i->value && i->in_inode) {
-		WARN_ON_ONCE(!i->value_len);
-
-		ea_inode = ext4_xattr_inode_lookup_create(handle, inode,
-					i->value, i->value_len);
-		if (IS_ERR(ea_inode)) {
-			error = PTR_ERR(ea_inode);
-			ea_inode = NULL;
-			goto cleanup;
-		}
-	}
+#define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (s->base) {
 		int offset = (char *)s->here - bs->bh->b_data;
@@ -1922,7 +1938,6 @@ ext4_xattr_block_set(handle_t *handle, s
 						      EXT4_JTR_NONE);
 		if (error)
 			goto cleanup;
-
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
@@ -1949,7 +1964,7 @@ ext4_xattr_block_set(handle_t *handle, s
 			}
 			ea_bdebug(bs->bh, "modifying in-place");
 			error = ext4_xattr_set_entry(i, s, handle, inode,
-					     ea_inode, true /* is_block */);
+						     true /* is_block */);
 			ext4_xattr_block_csum_set(inode, bs->bh);
 			unlock_buffer(bs->bh);
 			if (error == -EFSCORRUPTED)
@@ -2017,13 +2032,29 @@ clone_block:
 		s->end = s->base + sb->s_blocksize;
 	}
 
-	error = ext4_xattr_set_entry(i, s, handle, inode, ea_inode,
-				     true /* is_block */);
+	error = ext4_xattr_set_entry(i, s, handle, inode, true /* is_block */);
 	if (error == -EFSCORRUPTED)
 		goto bad_block;
 	if (error)
 		goto cleanup;
 
+	if (i->value && s->here->e_value_inum) {
+		/*
+		 * A ref count on ea_inode has been taken as part of the call to
+		 * ext4_xattr_set_entry() above. We would like to drop this
+		 * extra ref but we have to wait until the xattr block is
+		 * initialized and has its own ref count on the ea_inode.
+		 */
+		ea_ino = le32_to_cpu(s->here->e_value_inum);
+		error = ext4_xattr_inode_iget(inode, ea_ino,
+					      le32_to_cpu(s->here->e_hash),
+					      &ea_inode);
+		if (error) {
+			ea_inode = NULL;
+			goto cleanup;
+		}
+	}
+
 inserted:
 	if (!IS_LAST_ENTRY(s->first)) {
 		new_bh = ext4_xattr_block_cache_find(inode, header(s->base), &ce);
@@ -2181,16 +2212,17 @@ getblk_failed:
 
 cleanup:
 	if (ea_inode) {
-		if (error) {
-			int error2;
+		int error2;
+
+		error2 = ext4_xattr_inode_dec_ref(handle, ea_inode);
+		if (error2)
+			ext4_warning_inode(ea_inode, "dec ref error=%d",
+					   error2);
 
-			error2 = ext4_xattr_inode_dec_ref(handle, ea_inode);
-			if (error2)
-				ext4_warning_inode(ea_inode, "dec ref error=%d",
-						   error2);
+		/* If there was an error, revert the quota charge. */
+		if (error)
 			ext4_xattr_inode_free_quota(inode, ea_inode,
 						    i_size_read(ea_inode));
-		}
 		iput(ea_inode);
 	}
 	if (ce)
@@ -2245,38 +2277,14 @@ int ext4_xattr_ibody_set(handle_t *handl
 {
 	struct ext4_xattr_ibody_header *header;
 	struct ext4_xattr_search *s = &is->s;
-	struct inode *ea_inode = NULL;
 	int error;
 
 	if (!EXT4_INODE_HAS_XATTR_SPACE(inode))
 		return -ENOSPC;
 
-	/* If we need EA inode, prepare it before locking the buffer */
-	if (i->value && i->in_inode) {
-		WARN_ON_ONCE(!i->value_len);
-
-		ea_inode = ext4_xattr_inode_lookup_create(handle, inode,
-					i->value, i->value_len);
-		if (IS_ERR(ea_inode))
-			return PTR_ERR(ea_inode);
-	}
-	error = ext4_xattr_set_entry(i, s, handle, inode, ea_inode,
-				     false /* is_block */);
-	if (error) {
-		if (ea_inode) {
-			int error2;
-
-			error2 = ext4_xattr_inode_dec_ref(handle, ea_inode);
-			if (error2)
-				ext4_warning_inode(ea_inode, "dec ref error=%d",
-						   error2);
-
-			ext4_xattr_inode_free_quota(inode, ea_inode,
-						    i_size_read(ea_inode));
-			iput(ea_inode);
-		}
+	error = ext4_xattr_set_entry(i, s, handle, inode, false /* is_block */);
+	if (error)
 		return error;
-	}
 	header = IHDR(inode, ext4_raw_inode(&is->iloc));
 	if (!IS_LAST_ENTRY(s->first)) {
 		header->h_magic = cpu_to_le32(EXT4_XATTR_MAGIC);
@@ -2285,7 +2293,6 @@ int ext4_xattr_ibody_set(handle_t *handl
 		header->h_magic = cpu_to_le32(0);
 		ext4_clear_inode_state(inode, EXT4_STATE_XATTR);
 	}
-	iput(ea_inode);
 	return 0;
 }
 
diff -rupN a/fs/xattr.c b/fs/xattr.c
--- a/fs/xattr.c	2025-06-01 18:01:58.000000000 +0200
+++ b/fs/xattr.c	2025-06-01 20:34:16.791109703 +0200
@@ -139,16 +139,17 @@ xattr_permission(struct mnt_idmap *idmap
 	}
 
 	/*
-	 * In the user.* namespace, only regular files and directories can have
-	 * extended attributes. For sticky directories, only the owner and
-	 * privileged users can write attributes.
+	 * In the user.* namespace, only regular files, symbolic links, and
+	 * directories can have extended attributes. For symbolic links and
+	 * sticky directories, only the owner and privileged users can write
+	 * attributes.
 	 */
 	if (!strncmp(name, XATTR_USER_PREFIX, XATTR_USER_PREFIX_LEN)) {
-		if (!S_ISREG(inode->i_mode) && !S_ISDIR(inode->i_mode))
+		if (!S_ISREG(inode->i_mode) && !S_ISDIR(inode->i_mode) && !S_ISLNK(inode->i_mode))
 			return (mask & MAY_WRITE) ? -EPERM : -ENODATA;
-		if (S_ISDIR(inode->i_mode) && (inode->i_mode & S_ISVTX) &&
-		    (mask & MAY_WRITE) &&
-		    !inode_owner_or_capable(idmap, inode))
+		if (((S_ISDIR(inode->i_mode) && (inode->i_mode & S_ISVTX))
+		        || S_ISLNK(inode->i_mode)) && (mask & MAY_WRITE)
+		    && !inode_owner_or_capable(idmap, inode))
 			return -EPERM;
 	}
 
diff -rupN a/include/linux/cpuidle_psd.h b/include/linux/cpuidle_psd.h
--- a/include/linux/cpuidle_psd.h	1970-01-01 01:00:00.000000000 +0100
+++ b/include/linux/cpuidle_psd.h	2025-06-01 20:34:16.792109711 +0200
@@ -0,0 +1,32 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ *  Copyright (C) 2025 Intel Corporation
+ *  Author: Colin Ian King <colin.king@intel.com>
+ *
+ *  Kernel prevent sleep demotion infrastructructure
+ */
+#ifndef _LINUX_CPUIDLE_PSD_H
+#define _LINUX_CPUIDLE_PSD_H
+
+/* duration of sleep demotion for disks in msec */
+#define PSD_DISK_MSEC			(2)
+
+/* API prototypes */
+#ifdef CONFIG_CPU_IDLE_PSD
+
+extern void prevent_sleep_demotion(void);
+extern int have_prevent_sleep_demotion(void);
+
+#else
+
+static inline void prevent_sleep_demotion(void)
+{
+}
+
+static inline int have_prevent_sleep_demotion(void)
+{
+	return 0;
+}
+#endif
+
+#endif
diff -rupN a/include/linux/dma-buf.h b/include/linux/dma-buf.h
--- a/include/linux/dma-buf.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/linux/dma-buf.h	2025-06-01 20:34:16.792109711 +0200
@@ -22,6 +22,7 @@
 #include <linux/fs.h>
 #include <linux/dma-fence.h>
 #include <linux/wait.h>
+#include <uapi/linux/dma-buf.h>
 
 struct device;
 struct dma_buf;
@@ -276,6 +277,20 @@ struct dma_buf_ops {
 
 	int (*vmap)(struct dma_buf *dmabuf, struct iosys_map *map);
 	void (*vunmap)(struct dma_buf *dmabuf, struct iosys_map *map);
+
+	/**
+	 * @rw_file:
+	 *
+	 * If an Exporter needs to support Direct I/O file operations, it can
+	 * implement this optional callback. The exporter must verify that no
+	 * other objects hold the sg_table, ensure exclusive access to the
+	 * dmabuf's sg_table, and only then proceed with the I/O operation.
+	 *
+	 * Returns:
+	 *
+	 * 0 on success or a negative error code on failure.
+	 */
+	int (*rw_file)(struct dma_buf *dmabuf, struct dma_buf_rw_file *file);
 };
 
 /**
diff -rupN a/include/linux/hid.h b/include/linux/hid.h
--- a/include/linux/hid.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/linux/hid.h	2025-06-01 20:34:16.793109720 +0200
@@ -357,6 +357,7 @@ struct hid_item {
  * | @HID_QUIRK_INPUT_PER_APP:
  * | @HID_QUIRK_X_INVERT:
  * | @HID_QUIRK_Y_INVERT:
+ * | @HID_QUIRK_IGNORE_MOUSE:
  * | @HID_QUIRK_SKIP_OUTPUT_REPORTS:
  * | @HID_QUIRK_SKIP_OUTPUT_REPORT_ID:
  * | @HID_QUIRK_NO_OUTPUT_REPORTS_ON_INTR_EP:
@@ -382,6 +383,7 @@ struct hid_item {
 #define HID_QUIRK_INPUT_PER_APP			BIT(11)
 #define HID_QUIRK_X_INVERT			BIT(12)
 #define HID_QUIRK_Y_INVERT			BIT(13)
+#define HID_QUIRK_IGNORE_MOUSE			BIT(14)
 #define HID_QUIRK_SKIP_OUTPUT_REPORTS		BIT(16)
 #define HID_QUIRK_SKIP_OUTPUT_REPORT_ID		BIT(17)
 #define HID_QUIRK_NO_OUTPUT_REPORTS_ON_INTR_EP	BIT(18)
diff -rupN a/include/linux/jbd2.h b/include/linux/jbd2.h
--- a/include/linux/jbd2.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/linux/jbd2.h	2025-06-01 20:34:16.794109727 +0200
@@ -45,7 +45,7 @@
 /*
  * The default maximum commit age, in seconds.
  */
-#define JBD2_DEFAULT_MAX_COMMIT_AGE 5
+#define JBD2_DEFAULT_MAX_COMMIT_AGE 30
 
 #ifdef CONFIG_JBD2_DEBUG
 /*
diff -rupN a/include/linux/tcp.h b/include/linux/tcp.h
--- a/include/linux/tcp.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/linux/tcp.h	2025-06-01 20:34:16.794109727 +0200
@@ -248,7 +248,8 @@ struct tcp_sock {
 	void (*tcp_clean_acked)(struct sock *sk, u32 acked_seq);
 #endif
 	u32	snd_ssthresh;	/* Slow start size threshold		*/
-	u8	recvmsg_inq : 1;/* Indicate # of bytes in queue upon recvmsg */
+	u32	recvmsg_inq : 1,/* Indicate # of bytes in queue upon recvmsg */
+		fast_ack_mode:1;/* ack ASAP if >1 rcv_mss received? */
 	__cacheline_group_end(tcp_sock_read_rx);
 
 	/* TX read-write hotpath cache lines */
@@ -305,7 +306,8 @@ struct tcp_sock {
  */
 	struct tcp_options_received rx_opt;
 	u8	nonagle     : 4,/* Disable Nagle algorithm?             */
-		rate_app_limited:1;  /* rate_{delivered,interval_us} limited? */
+		rate_app_limited:1,  /* rate_{delivered,interval_us} limited? */
+		tlp_orig_data_app_limited:1; /* app-limited before TLP rtx? */
 	__cacheline_group_end(tcp_sock_write_txrx);
 
 	/* RX read-write hotpath cache lines */
diff -rupN a/include/linux/wait.h b/include/linux/wait.h
--- a/include/linux/wait.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/linux/wait.h	2025-06-01 20:34:16.821109945 +0200
@@ -163,6 +163,7 @@ static inline bool wq_has_sleeper(struct
 
 extern void add_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
 extern void add_wait_queue_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
+extern void add_wait_queue_exclusive_lifo(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
 extern void add_wait_queue_priority(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
 extern void remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
 
@@ -1195,6 +1196,7 @@ do {										\
  */
 void prepare_to_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state);
 bool prepare_to_wait_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state);
+void prepare_to_wait_exclusive_lifo(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state);
 long prepare_to_wait_event(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state);
 void finish_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
 long wait_woken(struct wait_queue_entry *wq_entry, unsigned mode, long timeout);
diff -rupN a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
--- a/include/net/inet_connection_sock.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/net/inet_connection_sock.h	2025-06-01 20:34:16.821109945 +0200
@@ -132,8 +132,8 @@ struct inet_connection_sock {
 	u32			  icsk_probes_tstamp;
 	u32			  icsk_user_timeout;
 
-	u64			  icsk_ca_priv[104 / sizeof(u64)];
-#define ICSK_CA_PRIV_SIZE	  sizeof_field(struct inet_connection_sock, icsk_ca_priv)
+#define ICSK_CA_PRIV_SIZE      (144)
+	u64			  icsk_ca_priv[ICSK_CA_PRIV_SIZE / sizeof(u64)];
 };
 
 #define ICSK_TIME_RETRANS	1	/* Retransmit timer */
diff -rupN a/include/net/sock.h b/include/net/sock.h
--- a/include/net/sock.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/net/sock.h	2025-06-01 20:34:16.827109993 +0200
@@ -1599,10 +1599,17 @@ static inline void sk_mem_charge(struct
 
 static inline void sk_mem_uncharge(struct sock *sk, int size)
 {
+	int reclaimable, reclaim_threshold;
+
+	reclaim_threshold = 64 * 1024;
 	if (!sk_has_account(sk))
 		return;
 	sk_forward_alloc_add(sk, size);
-	sk_mem_reclaim(sk);
+	reclaimable = sk->sk_forward_alloc - sk_unused_reserved_mem(sk);
+	if (reclaimable > reclaim_threshold) {
+		reclaimable -= reclaim_threshold;
+		__sk_mem_reclaim(sk, reclaimable);
+	}
 }
 
 #if IS_ENABLED(CONFIG_PROVE_LOCKING) && IS_ENABLED(CONFIG_MODULES)
@@ -2912,7 +2919,7 @@ void sk_get_meminfo(const struct sock *s
  * platforms.  This makes socket queueing behavior and performance
  * not depend upon such differences.
  */
-#define _SK_MEM_PACKETS		256
+#define _SK_MEM_PACKETS		1024
 #define _SK_MEM_OVERHEAD	SKB_TRUESIZE(256)
 #define SK_WMEM_MAX		(_SK_MEM_OVERHEAD * _SK_MEM_PACKETS)
 #define SK_RMEM_MAX		(_SK_MEM_OVERHEAD * _SK_MEM_PACKETS)
diff -rupN a/include/net/tcp.h b/include/net/tcp.h
--- a/include/net/tcp.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/net/tcp.h	2025-06-01 20:34:16.828110001 +0200
@@ -384,6 +384,9 @@ static inline void tcp_dec_quickack_mode
 #define	TCP_ECN_MODE_PENDING	(TCP_ECN_MODE_RFC3168 | TCP_ECN_MODE_ACCECN)
 #define	TCP_ECN_MODE_ANY	(TCP_ECN_MODE_RFC3168 | TCP_ECN_MODE_ACCECN)
 
+#define	TCP_ECN_LOW		16
+#define	TCP_ECN_ECT_PERMANENT	32
+
 static inline bool tcp_ecn_mode_any(const struct tcp_sock *tp)
 {
 	return tp->ecn_flags & TCP_ECN_MODE_ANY;
@@ -841,6 +844,15 @@ static inline void tcp_fast_path_check(s
 
 u32 tcp_delack_max(const struct sock *sk);
 
+static inline void tcp_set_ecn_low_from_dst(struct sock *sk,
+					    const struct dst_entry *dst)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (dst_feature(dst, RTAX_FEATURE_ECN_LOW))
+		tp->ecn_flags |= TCP_ECN_LOW;
+}
+
 /* Compute the actual rto_min value */
 static inline u32 tcp_rto_min(const struct sock *sk)
 {
@@ -946,6 +958,11 @@ static inline u32 tcp_stamp_us_delta(u64
 	return max_t(s64, t1 - t0, 0);
 }
 
+static inline u32 tcp_stamp32_us_delta(u32 t1, u32 t0)
+{
+	return max_t(s32, t1 - t0, 0);
+}
+
 /* provide the departure time in us unit */
 static inline u64 tcp_skb_timestamp_us(const struct sk_buff *skb)
 {
@@ -1044,9 +1061,14 @@ struct tcp_skb_cb {
 			/* pkts S/ACKed so far upon tx of skb, incl retrans: */
 			__u32 delivered;
 			/* start of send pipeline phase */
-			u64 first_tx_mstamp;
+			u32 first_tx_mstamp;
 			/* when we reached the "delivered" count */
-			u64 delivered_mstamp;
+			u32 delivered_mstamp;
+#define TCPCB_IN_FLIGHT_BITS 20
+#define TCPCB_IN_FLIGHT_MAX ((1U << TCPCB_IN_FLIGHT_BITS) - 1)
+			u32 in_flight:20,   /* packets in flight at transmit */
+			    unused2:12;
+			u32 lost;	/* packets lost so far upon tx of skb */
 		} tx;   /* only used for outgoing skbs */
 		union {
 			struct inet_skb_parm	h4;
@@ -1159,6 +1181,7 @@ enum tcp_ca_event {
 	CA_EVENT_LOSS,		/* loss timeout */
 	CA_EVENT_ECN_NO_CE,	/* ECT set, but not CE marked */
 	CA_EVENT_ECN_IS_CE,	/* received CE marked IP packet */
+	CA_EVENT_TLP_RECOVERY,	/* a lost segment was repaired by TLP probe */
 };
 
 /* Information about inbound ACK, passed to cong_ops->in_ack_event() */
@@ -1181,7 +1204,11 @@ enum tcp_ca_ack_event_flags {
 #define TCP_CONG_NON_RESTRICTED		BIT(0)
 /* Requires ECN/ECT set on all packets */
 #define TCP_CONG_NEEDS_ECN		BIT(1)
-#define TCP_CONG_MASK	(TCP_CONG_NON_RESTRICTED | TCP_CONG_NEEDS_ECN)
+/* Wants notification of CE events (CA_EVENT_ECN_IS_CE, CA_EVENT_ECN_NO_CE). */
+#define TCP_CONG_WANTS_CE_EVENTS	0x4
+#define TCP_CONG_MASK	(TCP_CONG_NON_RESTRICTED | \
+			 TCP_CONG_NEEDS_ECN | \
+			 TCP_CONG_WANTS_CE_EVENTS)
 
 union tcp_cc_info;
 
@@ -1201,10 +1228,13 @@ struct ack_sample {
  */
 struct rate_sample {
 	u64  prior_mstamp; /* starting timestamp for interval */
+	u32  prior_lost;	/* tp->lost at "prior_mstamp" */
 	u32  prior_delivered;	/* tp->delivered at "prior_mstamp" */
 	u32  prior_delivered_ce;/* tp->delivered_ce at "prior_mstamp" */
+	u32 tx_in_flight;	/* packets in flight at starting timestamp */
+	s32  lost;		/* number of packets lost over interval */
 	s32  delivered;		/* number of packets delivered over interval */
-	s32  delivered_ce;	/* number of packets delivered w/ CE marks*/
+	s32  delivered_ce;	/* packets delivered w/ CE mark over interval */
 	long interval_us;	/* time for tp->delivered to incr "delivered" */
 	u32 snd_interval_us;	/* snd interval for delivered packets */
 	u32 rcv_interval_us;	/* rcv interval for delivered packets */
@@ -1215,7 +1245,9 @@ struct rate_sample {
 	u32  last_end_seq;	/* end_seq of most recently ACKed packet */
 	bool is_app_limited;	/* is sample from packet with bubble in pipe? */
 	bool is_retrans;	/* is sample from retransmission? */
+	bool is_acking_tlp_retrans_seq;  /* ACKed a TLP retransmit sequence? */
 	bool is_ack_delayed;	/* is this (likely) a delayed ACK? */
+	bool is_ece;		/* did this ACK have ECN marked? */
 };
 
 struct tcp_congestion_ops {
@@ -1239,8 +1271,11 @@ struct tcp_congestion_ops {
 	/* hook for packet ack accounting (optional) */
 	void (*pkts_acked)(struct sock *sk, const struct ack_sample *sample);
 
-	/* override sysctl_tcp_min_tso_segs */
-	u32 (*min_tso_segs)(struct sock *sk);
+	/* pick target number of segments per TSO/GSO skb (optional): */
+	u32 (*tso_segs)(struct sock *sk, unsigned int mss_now);
+
+	/* react to a specific lost skb (optional) */
+	void (*skb_marked_lost)(struct sock *sk, const struct sk_buff *skb);
 
 	/* call when packets are delivered to update cwnd and pacing rate,
 	 * after all the ca_state processing. (optional)
@@ -1306,6 +1341,14 @@ static inline char *tcp_ca_get_name_by_k
 }
 #endif
 
+static inline bool tcp_ca_wants_ce_events(const struct sock *sk)
+{
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+
+	return icsk->icsk_ca_ops->flags & (TCP_CONG_NEEDS_ECN |
+					   TCP_CONG_WANTS_CE_EVENTS);
+}
+
 static inline bool tcp_ca_needs_ecn(const struct sock *sk)
 {
 	const struct inet_connection_sock *icsk = inet_csk(sk);
@@ -1325,6 +1368,7 @@ static inline void tcp_ca_event(struct s
 void tcp_set_ca_state(struct sock *sk, const u8 ca_state);
 
 /* From tcp_rate.c */
+void tcp_set_tx_in_flight(struct sock *sk, struct sk_buff *skb);
 void tcp_rate_skb_sent(struct sock *sk, struct sk_buff *skb);
 void tcp_rate_skb_delivered(struct sock *sk, struct sk_buff *skb,
 			    struct rate_sample *rs);
@@ -1337,6 +1381,21 @@ static inline bool tcp_skb_sent_after(u6
 	return t1 > t2 || (t1 == t2 && after(seq1, seq2));
 }
 
+/* If a retransmit failed due to local qdisc congestion or other local issues,
+ * then we may have called tcp_set_skb_tso_segs() to increase the number of
+ * segments in the skb without increasing the tx.in_flight. In all other cases,
+ * the tx.in_flight should be at least as big as the pcount of the sk_buff.  We
+ * do not have the state to know whether a retransmit failed due to local qdisc
+ * congestion or other local issues, so to avoid spurious warnings we consider
+ * that any skb marked lost may have suffered that fate.
+ */
+static inline bool tcp_skb_tx_in_flight_is_suspicious(u32 skb_pcount,
+						      u32 skb_sacked_flags,
+						      u32 tx_in_flight)
+{
+	return (skb_pcount > tx_in_flight) && !(skb_sacked_flags & TCPCB_LOST);
+}
+
 /* These functions determine how the current flow behaves in respect of SACK
  * handling. SACK is negotiated with the peer, and therefore it can vary
  * between different flows.
@@ -2490,7 +2549,7 @@ struct tcp_plb_state {
 	u8	consec_cong_rounds:5, /* consecutive congested rounds */
 		unused:3;
 	u32	pause_until; /* jiffies32 when PLB can resume rerouting */
-};
+} __attribute__ ((__packed__));
 
 static inline void tcp_plb_init(const struct sock *sk,
 				struct tcp_plb_state *plb)
diff -rupN a/include/uapi/linux/dma-buf.h b/include/uapi/linux/dma-buf.h
--- a/include/uapi/linux/dma-buf.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/uapi/linux/dma-buf.h	2025-06-01 20:34:16.832110033 +0200
@@ -167,6 +167,28 @@ struct dma_buf_import_sync_file {
 	__s32 fd;
 };
 
+/**
+ * struct dma_buf_rw_file - read/write file associated with a dma-buf
+ *
+ * Userspace can performs a DMA_BUF_IOCTL_BACK to save data from a dma-buf or
+ * restore data to a dma-buf.
+ */
+struct dma_buf_rw_file {
+	/** @flags: Flags indicating read/write for this dma-buf. */
+	__u32 flags;
+	/** @fd: File descriptor of the file associated with this dma-buf. */
+	__s32 fd;
+	/** @file_offset: Offset within the file where this dma-buf starts.
+	 *
+	 *  Offset and Length must be page-aligned for direct I/O.
+	 */
+	__u64 file_offset;
+	/** @buf_offset: Offset within this dma-buf where the read/write starts. */
+	__u64 buf_offset;
+	/** @buf_len: Length of this dma-buf read/write. */
+	__u64 buf_len;
+};
+
 #define DMA_BUF_BASE		'b'
 #define DMA_BUF_IOCTL_SYNC	_IOW(DMA_BUF_BASE, 0, struct dma_buf_sync)
 
@@ -179,4 +201,10 @@ struct dma_buf_import_sync_file {
 #define DMA_BUF_IOCTL_EXPORT_SYNC_FILE	_IOWR(DMA_BUF_BASE, 2, struct dma_buf_export_sync_file)
 #define DMA_BUF_IOCTL_IMPORT_SYNC_FILE	_IOW(DMA_BUF_BASE, 3, struct dma_buf_import_sync_file)
 
+#define DMA_BUF_RW_FLAGS_OP_MASK (0xFF << 0)
+#define DMA_BUF_RW_FLAGS_READ (1 << 0) /* Restore dma-buf data */
+#define DMA_BUF_RW_FLAGS_WRITE (2 << 0) /* Save dma-buf data */
+#define DMA_BUF_RW_FLAGS_DIRECT (1u << 31) /* Direct read/write file */
+#define DMA_BUF_IOCTL_RW_FILE	_IOW(DMA_BUF_BASE, 4, struct dma_buf_rw_file)
+
 #endif
diff -rupN a/include/uapi/linux/if_bonding.h b/include/uapi/linux/if_bonding.h
--- a/include/uapi/linux/if_bonding.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/uapi/linux/if_bonding.h	2025-06-01 20:34:16.832110033 +0200
@@ -82,7 +82,7 @@
 #define BOND_STATE_ACTIVE       0   /* link is active */
 #define BOND_STATE_BACKUP       1   /* link is backup */
 
-#define BOND_DEFAULT_MAX_BONDS  1   /* Default maximum number of devices to support */
+#define BOND_DEFAULT_MAX_BONDS  0   /* Default maximum number of devices to support */
 
 #define BOND_DEFAULT_TX_QUEUES 16   /* Default number of tx queues per device */
 
diff -rupN a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
--- a/include/uapi/linux/inet_diag.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/uapi/linux/inet_diag.h	2025-06-01 20:34:16.833110041 +0200
@@ -229,6 +229,29 @@ struct tcp_bbr_info {
 	__u32	bbr_min_rtt;		/* min-filtered RTT in uSec */
 	__u32	bbr_pacing_gain;	/* pacing gain shifted left 8 bits */
 	__u32	bbr_cwnd_gain;		/* cwnd gain shifted left 8 bits */
+	__u32	bbr_bw_hi_lsb;		/* lower 32 bits of bw_hi */
+	__u32	bbr_bw_hi_msb;		/* upper 32 bits of bw_hi */
+	__u32	bbr_bw_lo_lsb;		/* lower 32 bits of bw_lo */
+	__u32	bbr_bw_lo_msb;		/* upper 32 bits of bw_lo */
+	__u8	bbr_mode;		/* current bbr_mode in state machine */
+	__u8	bbr_phase;		/* current state machine phase */
+	__u8	unused1;		/* alignment padding; not used yet */
+	__u8	bbr_version;		/* BBR algorithm version */
+	__u32	bbr_inflight_lo;	/* lower short-term data volume bound */
+	__u32	bbr_inflight_hi;	/* higher long-term data volume bound */
+	__u32	bbr_extra_acked;	/* max excess packets ACKed in epoch */
+};
+
+/* TCP BBR congestion control bbr_phase as reported in netlink/ss stats. */
+enum tcp_bbr_phase {
+	BBR_PHASE_INVALID		= 0,
+	BBR_PHASE_STARTUP		= 1,
+	BBR_PHASE_DRAIN			= 2,
+	BBR_PHASE_PROBE_RTT		= 3,
+	BBR_PHASE_PROBE_BW_UP		= 4,
+	BBR_PHASE_PROBE_BW_DOWN		= 5,
+	BBR_PHASE_PROBE_BW_CRUISE	= 6,
+	BBR_PHASE_PROBE_BW_REFILL	= 7,
 };
 
 union tcp_cc_info {
diff -rupN a/include/uapi/linux/rtnetlink.h b/include/uapi/linux/rtnetlink.h
--- a/include/uapi/linux/rtnetlink.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/uapi/linux/rtnetlink.h	2025-06-01 20:34:16.833110041 +0200
@@ -517,12 +517,14 @@ enum {
 #define RTAX_FEATURE_TIMESTAMP		(1 << 2) /* unused */
 #define RTAX_FEATURE_ALLFRAG		(1 << 3) /* unused */
 #define RTAX_FEATURE_TCP_USEC_TS	(1 << 4)
+#define RTAX_FEATURE_ECN_LOW		(1 << 5)
 
 #define RTAX_FEATURE_MASK	(RTAX_FEATURE_ECN |		\
 				 RTAX_FEATURE_SACK |		\
 				 RTAX_FEATURE_TIMESTAMP |	\
 				 RTAX_FEATURE_ALLFRAG |		\
-				 RTAX_FEATURE_TCP_USEC_TS)
+				 RTAX_FEATURE_TCP_USEC_TS |	\
+				 RTAX_FEATURE_ECN_LOW)
 
 struct rta_session {
 	__u8	proto;
diff -rupN a/include/uapi/linux/tcp.h b/include/uapi/linux/tcp.h
--- a/include/uapi/linux/tcp.h	2025-06-01 18:01:58.000000000 +0200
+++ b/include/uapi/linux/tcp.h	2025-06-01 20:34:16.835110057 +0200
@@ -185,6 +185,7 @@ enum tcp_fastopen_client_fail {
 #define TCPI_OPT_SYN_DATA	32 /* SYN-ACK acked data in SYN sent or rcvd */
 #define TCPI_OPT_USEC_TS	64 /* usec timestamps */
 #define TCPI_OPT_TFO_CHILD	128 /* child from a Fast Open option on SYN */
+#define TCPI_OPT_ECN_LOW	256 /* Low-latency ECN enabled at conn init */
 
 /*
  * Sender's congestion state indicating normal or abnormal situations
diff -rupN a/init/do_mounts.c b/init/do_mounts.c
--- a/init/do_mounts.c	2025-06-01 18:01:58.000000000 +0200
+++ b/init/do_mounts.c	2025-06-01 20:34:16.835110057 +0200
@@ -476,7 +476,9 @@ void __init prepare_namespace(void)
 	 * For example, it is not atypical to wait 5 seconds here
 	 * for the touchpad of a laptop to initialize.
 	 */
+	async_synchronize_full();
 	wait_for_device_probe();
+	async_synchronize_full();
 
 	md_run_setup();
 
diff -rupN a/init/init_task.c b/init/init_task.c
--- a/init/init_task.c	2025-06-01 18:01:58.000000000 +0200
+++ b/init/init_task.c	2025-06-01 20:34:16.836110065 +0200
@@ -140,7 +140,7 @@ struct task_struct init_task __aligned(L
 	.journal_info	= NULL,
 	INIT_CPU_TIMERS(init_task)
 	.pi_lock	= __RAW_SPIN_LOCK_UNLOCKED(init_task.pi_lock),
-	.timer_slack_ns = 50000, /* 50 usec default slack */
+	.timer_slack_ns = 50, /* 50 nsec default slack */
 	.thread_pid	= &init_struct_pid,
 	.thread_node	= LIST_HEAD_INIT(init_signals.thread_head),
 #ifdef CONFIG_AUDIT
diff -rupN a/init/main.c b/init/main.c
--- a/init/main.c	2025-06-01 18:01:58.000000000 +0200
+++ b/init/main.c	2025-06-01 20:34:16.836110065 +0200
@@ -1210,10 +1210,13 @@ static __init_or_module void
 trace_initcall_finish_cb(void *data, initcall_t fn, int ret)
 {
 	ktime_t rettime, *calltime = data;
+	long long delta;
 
 	rettime = ktime_get();
-	printk(KERN_DEBUG "initcall %pS returned %d after %lld usecs\n",
-		 fn, ret, (unsigned long long)ktime_us_delta(rettime, *calltime));
+	delta = ktime_us_delta(rettime, *calltime);
+	if (ret || delta)
+		printk(KERN_DEBUG "initcall %pS returned %d after %lld usecs\n",
+			fn, ret, (unsigned long long)ktime_us_delta(rettime, *calltime));
 }
 
 static __init_or_module void
diff -rupN a/kernel/locking/rwsem.c b/kernel/locking/rwsem.c
--- a/kernel/locking/rwsem.c	2025-06-01 18:01:58.000000000 +0200
+++ b/kernel/locking/rwsem.c	2025-06-01 20:34:16.852110194 +0200
@@ -747,6 +747,7 @@ rwsem_spin_on_owner(struct rw_semaphore
 	struct task_struct *new, *owner;
 	unsigned long flags, new_flags;
 	enum owner_state state;
+	int i = 0;
 
 	lockdep_assert_preemption_disabled();
 
@@ -783,7 +784,8 @@ rwsem_spin_on_owner(struct rw_semaphore
 			break;
 		}
 
-		cpu_relax();
+		if (i++ > 1000)
+			cpu_relax();
 	}
 
 	return state;
diff -rupN a/kernel/module/signing.c b/kernel/module/signing.c
--- a/kernel/module/signing.c	2025-06-01 18:01:58.000000000 +0200
+++ b/kernel/module/signing.c	2025-06-01 20:34:16.852110194 +0200
@@ -14,6 +14,8 @@
 #include <linux/security.h>
 #include <crypto/public_key.h>
 #include <uapi/linux/module.h>
+#include <linux/efi.h>
+
 #include "internal.h"
 
 #undef MODULE_PARAM_PREFIX
@@ -21,6 +23,11 @@
 
 static bool sig_enforce = IS_ENABLED(CONFIG_MODULE_SIG_FORCE);
 module_param(sig_enforce, bool_enable_only, 0644);
+/* Allow disabling module signature requirement by adding boot param */
+static bool sig_unenforce = false;
+module_param(sig_unenforce, bool_enable_only, 0644);
+
+extern struct boot_params boot_params;
 
 /*
  * Export sig_enforce kernel cmdline parameter to allow other subsystems rely
@@ -28,6 +35,8 @@ module_param(sig_enforce, bool_enable_on
  */
 bool is_module_sig_enforced(void)
 {
+	if (sig_unenforce)
+		return false;
 	return sig_enforce;
 }
 EXPORT_SYMBOL(is_module_sig_enforced);
diff -rupN a/kernel/sched/fair.c b/kernel/sched/fair.c
--- a/kernel/sched/fair.c	2025-06-01 18:01:58.000000000 +0200
+++ b/kernel/sched/fair.c	2025-06-01 20:34:16.870110339 +0200
@@ -193,7 +193,7 @@ static inline void update_load_set(struc
  */
 static unsigned int get_update_sysctl_factor(void)
 {
-	unsigned int cpus = min_t(unsigned int, num_online_cpus(), 8);
+	unsigned int cpus = num_online_cpus();
 	unsigned int factor;
 
 	switch (sysctl_sched_tunable_scaling) {
@@ -12855,7 +12855,7 @@ static int sched_balance_newidle(struct
 
 		update_next_balance(sd, &next_balance);
 
-		if (this_rq->avg_idle < curr_cost + sd->max_newidle_lb_cost)
+		if (this_rq->avg_idle/2 < curr_cost + sd->max_newidle_lb_cost)
 			break;
 
 		if (sd->flags & SD_BALANCE_NEWIDLE) {
diff -rupN a/kernel/sched/syscalls.c b/kernel/sched/syscalls.c
--- a/kernel/sched/syscalls.c	2025-06-01 18:01:58.000000000 +0200
+++ b/kernel/sched/syscalls.c	2025-06-01 20:34:16.875110380 +0200
@@ -1350,10 +1350,22 @@ SYSCALL_DEFINE3(sched_getaffinity, pid_t
 	return ret;
 }
 
+static DEFINE_PER_CPU(unsigned long, last_yield);
+
 static void do_sched_yield(void)
 {
 	struct rq_flags rf;
 	struct rq *rq;
+	int cpu = raw_smp_processor_id();
+
+	cond_resched();
+
+	/* rate limit yielding to something sensible */
+
+	if (!time_after(jiffies, per_cpu(last_yield, cpu)))
+		return;
+
+	per_cpu(last_yield, cpu) = jiffies;
 
 	rq = this_rq_lock_irq(&rf);
 
diff -rupN a/kernel/sched/wait.c b/kernel/sched/wait.c
--- a/kernel/sched/wait.c	2025-06-01 18:01:58.000000000 +0200
+++ b/kernel/sched/wait.c	2025-06-01 20:34:16.876110387 +0200
@@ -47,6 +47,17 @@ void add_wait_queue_priority(struct wait
 }
 EXPORT_SYMBOL_GPL(add_wait_queue_priority);
 
+void add_wait_queue_exclusive_lifo(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)
+{
+	unsigned long flags;
+
+	wq_entry->flags |= WQ_FLAG_EXCLUSIVE;
+	spin_lock_irqsave(&wq_head->lock, flags);
+	__add_wait_queue(wq_head, wq_entry);
+	spin_unlock_irqrestore(&wq_head->lock, flags);
+}
+EXPORT_SYMBOL(add_wait_queue_exclusive_lifo);
+
 void remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)
 {
 	unsigned long flags;
@@ -258,6 +269,19 @@ prepare_to_wait_exclusive(struct wait_qu
 }
 EXPORT_SYMBOL(prepare_to_wait_exclusive);
 
+void prepare_to_wait_exclusive_lifo(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state)
+{
+	unsigned long flags;
+
+	wq_entry->flags |= WQ_FLAG_EXCLUSIVE;
+	spin_lock_irqsave(&wq_head->lock, flags);
+	if (list_empty(&wq_entry->entry))
+		__add_wait_queue(wq_head, wq_entry);
+	set_current_state(state);
+	spin_unlock_irqrestore(&wq_head->lock, flags);
+}
+EXPORT_SYMBOL(prepare_to_wait_exclusive_lifo);
+
 void init_wait_entry(struct wait_queue_entry *wq_entry, int flags)
 {
 	wq_entry->flags = flags;
diff -rupN a/lib/atomic64_test.c b/lib/atomic64_test.c
--- a/lib/atomic64_test.c	2025-06-01 18:01:58.000000000 +0200
+++ b/lib/atomic64_test.c	2025-06-01 20:34:16.886110468 +0200
@@ -251,15 +251,12 @@ static __init int test_atomics_init(void
 	test_atomic64();
 
 #ifdef CONFIG_X86
-	pr_info("passed for %s platform %s CX8 and %s SSE\n",
+	pr_info("passed for %s platform with CX8 and %s SSE\n",
 #ifdef CONFIG_X86_64
 		"x86-64",
-#elif defined(CONFIG_X86_CX8)
-		"i586+",
 #else
-		"i386+",
+		"i586+",
 #endif
-	       boot_cpu_has(X86_FEATURE_CX8) ? "with" : "without",
 	       boot_cpu_has(X86_FEATURE_XMM) ? "with" : "without");
 #else
 	pr_info("passed\n");
diff -rupN a/lib/raid6/algos.c b/lib/raid6/algos.c
--- a/lib/raid6/algos.c	2025-06-01 18:01:58.000000000 +0200
+++ b/lib/raid6/algos.c	2025-06-01 20:34:16.886110468 +0200
@@ -18,6 +18,8 @@
 #else
 #include <linux/module.h>
 #include <linux/gfp.h>
+#include <linux/sched/clock.h>
+
 /* In .bss so it's zeroed */
 const char raid6_empty_zero_page[PAGE_SIZE] __attribute__((aligned(256)));
 EXPORT_SYMBOL(raid6_empty_zero_page);
@@ -132,8 +134,10 @@ static inline const struct raid6_recov_c
 
 	for (best = NULL, algo = raid6_recov_algos; *algo; algo++)
 		if (!best || (*algo)->priority > best->priority)
-			if (!(*algo)->valid || (*algo)->valid())
+			if (!(*algo)->valid || (*algo)->valid()) {
 				best = *algo;
+				break;
+			}
 
 	if (best) {
 		raid6_2data_recov = best->data2;
@@ -149,12 +153,15 @@ static inline const struct raid6_recov_c
 static inline const struct raid6_calls *raid6_choose_gen(
 	void *(*const dptrs)[RAID6_TEST_DISKS], const int disks)
 {
-	unsigned long perf, bestgenperf, j0, j1;
+	unsigned long perf;
+	const unsigned long max_perf = 2500;
 	int start = (disks>>1)-1, stop = disks-3;	/* work on the second half of the disks */
 	const struct raid6_calls *const *algo;
 	const struct raid6_calls *best;
+	const u64 ns_per_mb = 1000000000 >> 20;
+	u64 n, ns, t, ns_best = ~0ULL;
 
-	for (bestgenperf = 0, best = NULL, algo = raid6_algos; *algo; algo++) {
+	for (best = NULL, algo = raid6_algos; *algo; algo++) {
 		if (!best || (*algo)->priority >= best->priority) {
 			if ((*algo)->valid && !(*algo)->valid())
 				continue;
@@ -164,26 +171,20 @@ static inline const struct raid6_calls *
 				break;
 			}
 
-			perf = 0;
-
 			preempt_disable();
-			j0 = jiffies;
-			while ((j1 = jiffies) == j0)
-				cpu_relax();
-			while (time_before(jiffies,
-					    j1 + (1<<RAID6_TIME_JIFFIES_LG2))) {
+			t = local_clock();
+			for (perf = 0; perf < max_perf; perf++) {
 				(*algo)->gen_syndrome(disks, PAGE_SIZE, *dptrs);
-				perf++;
 			}
+			ns = local_clock() - t;
 			preempt_enable();
 
-			if (perf > bestgenperf) {
-				bestgenperf = perf;
+			if (ns < ns_best) {
+				ns_best = ns;
 				best = *algo;
 			}
-			pr_info("raid6: %-8s gen() %5ld MB/s\n", (*algo)->name,
-				(perf * HZ * (disks-2)) >>
-				(20 - PAGE_SHIFT + RAID6_TIME_JIFFIES_LG2));
+			n = max_perf * PAGE_SIZE * ns_per_mb * (disks - 2);
+			pr_info("raid6: %-8s gen() %5llu MB/s (%llu ns)\n", (*algo)->name, (ns > 0) ? n / ns : 0, ns);
 		}
 	}
 
@@ -200,31 +201,23 @@ static inline const struct raid6_calls *
 		goto out;
 	}
 
-	pr_info("raid6: using algorithm %s gen() %ld MB/s\n",
-		best->name,
-		(bestgenperf * HZ * (disks - 2)) >>
-		(20 - PAGE_SHIFT + RAID6_TIME_JIFFIES_LG2));
+	n = max_perf * PAGE_SIZE * ns_per_mb * (disks - 2);
+	pr_info("raid6: using algorithm %s gen() %llu MB/s (%llu ns)\n",
+		best->name, (ns_best > 0) ? n / ns_best : 0, ns_best);
 
 	if (best->xor_syndrome) {
-		perf = 0;
-
 		preempt_disable();
-		j0 = jiffies;
-		while ((j1 = jiffies) == j0)
-			cpu_relax();
-		while (time_before(jiffies,
-				   j1 + (1 << RAID6_TIME_JIFFIES_LG2))) {
+		t = local_clock();
+		for (perf = 0; perf < max_perf; perf++) {
 			best->xor_syndrome(disks, start, stop,
 					   PAGE_SIZE, *dptrs);
-			perf++;
 		}
+		ns = local_clock() - t;
 		preempt_enable();
 
-		pr_info("raid6: .... xor() %ld MB/s, rmw enabled\n",
-			(perf * HZ * (disks - 2)) >>
-			(20 - PAGE_SHIFT + RAID6_TIME_JIFFIES_LG2 + 1));
+		n = max_perf * PAGE_SIZE * ns_per_mb * (disks - 2);
+		pr_info("raid6: .... xor() %llu MB/s, rmw enabled (%llu ns)\n", (ns > 0) ? n / ns : 0, ns);
 	}
-
 out:
 	return best;
 }
diff -rupN a/mm/page_alloc.c b/mm/page_alloc.c
--- a/mm/page_alloc.c	2025-06-01 18:01:58.000000000 +0200
+++ b/mm/page_alloc.c	2025-06-01 20:34:16.893110524 +0200
@@ -5621,11 +5621,11 @@ static int zone_batchsize(struct zone *z
 
 	/*
 	 * The number of pages to batch allocate is either ~0.1%
-	 * of the zone or 1MB, whichever is smaller. The batch
+	 * of the zone or 4MB, whichever is smaller. The batch
 	 * size is striking a balance between allocation latency
 	 * and zone lock contention.
 	 */
-	batch = min(zone_managed_pages(zone) >> 10, SZ_1M / PAGE_SIZE);
+	batch = min(zone_managed_pages(zone) >> 10, 4 * SZ_1M / PAGE_SIZE);
 	batch /= 4;		/* We effectively *= 4 below */
 	if (batch < 1)
 		batch = 1;
diff -rupN a/net/ipv4/bpf_tcp_ca.c b/net/ipv4/bpf_tcp_ca.c
--- a/net/ipv4/bpf_tcp_ca.c	2025-06-01 18:01:58.000000000 +0200
+++ b/net/ipv4/bpf_tcp_ca.c	2025-06-01 20:34:16.893110524 +0200
@@ -280,7 +280,7 @@ static void bpf_tcp_ca_pkts_acked(struct
 {
 }
 
-static u32 bpf_tcp_ca_min_tso_segs(struct sock *sk)
+static u32 bpf_tcp_ca_tso_segs(struct sock *sk, unsigned int mss_now)
 {
 	return 0;
 }
@@ -315,7 +315,7 @@ static struct tcp_congestion_ops __bpf_o
 	.cwnd_event = bpf_tcp_ca_cwnd_event,
 	.in_ack_event = bpf_tcp_ca_in_ack_event,
 	.pkts_acked = bpf_tcp_ca_pkts_acked,
-	.min_tso_segs = bpf_tcp_ca_min_tso_segs,
+	.tso_segs = bpf_tcp_ca_tso_segs,
 	.cong_control = bpf_tcp_ca_cong_control,
 	.undo_cwnd = bpf_tcp_ca_undo_cwnd,
 	.sndbuf_expand = bpf_tcp_ca_sndbuf_expand,
diff -rupN a/net/ipv4/inet_connection_sock.c b/net/ipv4/inet_connection_sock.c
--- a/net/ipv4/inet_connection_sock.c	2025-06-01 18:01:58.000000000 +0200
+++ b/net/ipv4/inet_connection_sock.c	2025-06-01 20:34:16.894110532 +0200
@@ -632,7 +632,7 @@ static int inet_csk_wait_for_connect(str
 	 * having to remove and re-insert us on the wait queue.
 	 */
 	for (;;) {
-		prepare_to_wait_exclusive(sk_sleep(sk), &wait,
+		prepare_to_wait_exclusive_lifo(sk_sleep(sk), &wait,
 					  TASK_INTERRUPTIBLE);
 		release_sock(sk);
 		if (reqsk_queue_empty(&icsk->icsk_accept_queue))
diff -rupN a/net/ipv4/Kconfig b/net/ipv4/Kconfig
--- a/net/ipv4/Kconfig	2025-06-01 18:01:58.000000000 +0200
+++ b/net/ipv4/Kconfig	2025-06-01 20:34:16.894110532 +0200
@@ -669,15 +669,18 @@ config TCP_CONG_BBR
 	default n
 	help
 
-	  BBR (Bottleneck Bandwidth and RTT) TCP congestion control aims to
-	  maximize network utilization and minimize queues. It builds an explicit
-	  model of the bottleneck delivery rate and path round-trip propagation
-	  delay. It tolerates packet loss and delay unrelated to congestion. It
-	  can operate over LAN, WAN, cellular, wifi, or cable modem links. It can
-	  coexist with flows that use loss-based congestion control, and can
-	  operate with shallow buffers, deep buffers, bufferbloat, policers, or
-	  AQM schemes that do not provide a delay signal. It requires the fq
-	  ("Fair Queue") pacing packet scheduler.
+	  BBR (Bottleneck Bandwidth and RTT) TCP congestion control is a
+	  model-based congestion control algorithm that aims to maximize
+	  network utilization, keep queues and retransmit rates low, and to be
+	  able to coexist with Reno/CUBIC in common scenarios. It builds an
+	  explicit model of the network path.  It tolerates a targeted degree
+	  of random packet loss and delay. It can operate over LAN, WAN,
+	  cellular, wifi, or cable modem links, and can use shallow-threshold
+	  ECN signals. It can coexist to some degree with flows that use
+	  loss-based congestion control, and can operate with shallow buffers,
+	  deep buffers, bufferbloat, policers, or AQM schemes that do not
+	  provide a delay signal. It requires pacing, using either TCP internal
+	  pacing or the fq ("Fair Queue") pacing packet scheduler.
 
 choice
 	prompt "Default TCP congestion control"
diff -rupN a/net/ipv4/tcp_bbr.c b/net/ipv4/tcp_bbr.c
--- a/net/ipv4/tcp_bbr.c	2025-06-01 18:01:58.000000000 +0200
+++ b/net/ipv4/tcp_bbr.c	2025-06-01 20:34:16.899110573 +0200
@@ -1,18 +1,19 @@
-/* Bottleneck Bandwidth and RTT (BBR) congestion control
+/* BBR (Bottleneck Bandwidth and RTT) congestion control
  *
- * BBR congestion control computes the sending rate based on the delivery
- * rate (throughput) estimated from ACKs. In a nutshell:
+ * BBR is a model-based congestion control algorithm that aims for low queues,
+ * low loss, and (bounded) Reno/CUBIC coexistence. To maintain a model of the
+ * network path, it uses measurements of bandwidth and RTT, as well as (if they
+ * occur) packet loss and/or shallow-threshold ECN signals. Note that although
+ * it can use ECN or loss signals explicitly, it does not require either; it
+ * can bound its in-flight data based on its estimate of the BDP.
  *
- *   On each ACK, update our model of the network path:
- *      bottleneck_bandwidth = windowed_max(delivered / elapsed, 10 round trips)
- *      min_rtt = windowed_min(rtt, 10 seconds)
- *   pacing_rate = pacing_gain * bottleneck_bandwidth
- *   cwnd = max(cwnd_gain * bottleneck_bandwidth * min_rtt, 4)
- *
- * The core algorithm does not react directly to packet losses or delays,
- * although BBR may adjust the size of next send per ACK when loss is
- * observed, or adjust the sending rate if it estimates there is a
- * traffic policer, in order to keep the drop rate reasonable.
+ * The model has both higher and lower bounds for the operating range:
+ *   lo: bw_lo, inflight_lo: conservative short-term lower bound
+ *   hi: bw_hi, inflight_hi: robust long-term upper bound
+ * The bandwidth-probing time scale is (a) extended dynamically based on
+ * estimated BDP to improve coexistence with Reno/CUBIC; (b) bounded by
+ * an interactive wall-clock time-scale to be more scalable and responsive
+ * than Reno and CUBIC.
  *
  * Here is a state transition diagram for BBR:
  *
@@ -65,6 +66,13 @@
 #include <linux/random.h>
 #include <linux/win_minmax.h>
 
+#include <trace/events/tcp.h>
+#include "tcp_dctcp.h"
+
+#define BBR_VERSION		3
+
+#define bbr_param(sk,name)	(bbr_ ## name)
+
 /* Scale factor for rate in pkt/uSec unit to avoid truncation in bandwidth
  * estimation. The rate unit ~= (1500 bytes / 1 usec / 2^24) ~= 715 bps.
  * This handles bandwidths from 0.06pps (715bps) to 256Mpps (3Tbps) in a u32.
@@ -85,36 +93,41 @@ enum bbr_mode {
 	BBR_PROBE_RTT,	/* cut inflight to min to probe min_rtt */
 };
 
+/* How does the incoming ACK stream relate to our bandwidth probing? */
+enum bbr_ack_phase {
+	BBR_ACKS_INIT,		  /* not probing; not getting probe feedback */
+	BBR_ACKS_REFILLING,	  /* sending at est. bw to fill pipe */
+	BBR_ACKS_PROBE_STARTING,  /* inflight rising to probe bw */
+	BBR_ACKS_PROBE_FEEDBACK,  /* getting feedback from bw probing */
+	BBR_ACKS_PROBE_STOPPING,  /* stopped probing; still getting feedback */
+};
+
 /* BBR congestion control block */
 struct bbr {
 	u32	min_rtt_us;	        /* min RTT in min_rtt_win_sec window */
 	u32	min_rtt_stamp;	        /* timestamp of min_rtt_us */
 	u32	probe_rtt_done_stamp;   /* end time for BBR_PROBE_RTT mode */
-	struct minmax bw;	/* Max recent delivery rate in pkts/uS << 24 */
-	u32	rtt_cnt;	    /* count of packet-timed rounds elapsed */
+	u32	probe_rtt_min_us;	/* min RTT in probe_rtt_win_ms win */
+	u32	probe_rtt_min_stamp;	/* timestamp of probe_rtt_min_us*/
 	u32     next_rtt_delivered; /* scb->tx.delivered at end of round */
 	u64	cycle_mstamp;	     /* time of this cycle phase start */
-	u32     mode:3,		     /* current bbr_mode in state machine */
+	u32     mode:2,		     /* current bbr_mode in state machine */
 		prev_ca_state:3,     /* CA state on previous ACK */
-		packet_conservation:1,  /* use packet conservation? */
 		round_start:1,	     /* start of packet-timed tx->ack round? */
+		ce_state:1,          /* If most recent data has CE bit set */
+		bw_probe_up_rounds:5,   /* cwnd-limited rounds in PROBE_UP */
+		try_fast_path:1,	/* can we take fast path? */
 		idle_restart:1,	     /* restarting after idle? */
 		probe_rtt_round_done:1,  /* a BBR_PROBE_RTT round at 4 pkts? */
-		unused:13,
-		lt_is_sampling:1,    /* taking long-term ("LT") samples now? */
-		lt_rtt_cnt:7,	     /* round trips in long-term interval */
-		lt_use_bw:1;	     /* use lt_bw as our bw estimate? */
-	u32	lt_bw;		     /* LT est delivery rate in pkts/uS << 24 */
-	u32	lt_last_delivered;   /* LT intvl start: tp->delivered */
-	u32	lt_last_stamp;	     /* LT intvl start: tp->delivered_mstamp */
-	u32	lt_last_lost;	     /* LT intvl start: tp->lost */
+		init_cwnd:7,         /* initial cwnd */
+		unused_1:10;
 	u32	pacing_gain:10,	/* current gain for setting pacing rate */
 		cwnd_gain:10,	/* current gain for setting cwnd */
 		full_bw_reached:1,   /* reached full bw in Startup? */
 		full_bw_cnt:2,	/* number of rounds without large bw gains */
-		cycle_idx:3,	/* current index in pacing_gain cycle array */
+		cycle_idx:2,	/* current index in pacing_gain cycle array */
 		has_seen_rtt:1, /* have we seen an RTT sample yet? */
-		unused_b:5;
+		unused_2:6;
 	u32	prior_cwnd;	/* prior cwnd upon entering loss recovery */
 	u32	full_bw;	/* recent bw, to estimate if pipe is full */
 
@@ -124,19 +137,67 @@ struct bbr {
 	u32	ack_epoch_acked:20,	/* packets (S)ACKed in sampling epoch */
 		extra_acked_win_rtts:5,	/* age of extra_acked, in round trips */
 		extra_acked_win_idx:1,	/* current index in extra_acked array */
-		unused_c:6;
+	/* BBR v3 state: */
+		full_bw_now:1,		/* recently reached full bw plateau? */
+		startup_ecn_rounds:2,	/* consecutive hi ECN STARTUP rounds */
+		loss_in_cycle:1,	/* packet loss in this cycle? */
+		ecn_in_cycle:1,		/* ECN in this cycle? */
+		unused_3:1;
+	u32	loss_round_delivered; /* scb->tx.delivered ending loss round */
+	u32	undo_bw_lo;	     /* bw_lo before latest losses */
+	u32	undo_inflight_lo;    /* inflight_lo before latest losses */
+	u32	undo_inflight_hi;    /* inflight_hi before latest losses */
+	u32	bw_latest;	 /* max delivered bw in last round trip */
+	u32	bw_lo;		 /* lower bound on sending bandwidth */
+	u32	bw_hi[2];	 /* max recent measured bw sample */
+	u32	inflight_latest; /* max delivered data in last round trip */
+	u32	inflight_lo;	 /* lower bound of inflight data range */
+	u32	inflight_hi;	 /* upper bound of inflight data range */
+	u32	bw_probe_up_cnt; /* packets delivered per inflight_hi incr */
+	u32	bw_probe_up_acks;  /* packets (S)ACKed since inflight_hi incr */
+	u32	probe_wait_us;	 /* PROBE_DOWN until next clock-driven probe */
+	u32	prior_rcv_nxt;	/* tp->rcv_nxt when CE state last changed */
+	u32	ecn_eligible:1,	/* sender can use ECN (RTT, handshake)? */
+		ecn_alpha:9,	/* EWMA delivered_ce/delivered; 0..256 */
+		bw_probe_samples:1,    /* rate samples reflect bw probing? */
+		prev_probe_too_high:1, /* did last PROBE_UP go too high? */
+		stopped_risky_probe:1, /* last PROBE_UP stopped due to risk? */
+		rounds_since_probe:8,  /* packet-timed rounds since probed bw */
+		loss_round_start:1,    /* loss_round_delivered round trip? */
+		loss_in_round:1,       /* loss marked in this round trip? */
+		ecn_in_round:1,	       /* ECN marked in this round trip? */
+		ack_phase:3,	       /* bbr_ack_phase: meaning of ACKs */
+		loss_events_in_round:4,/* losses in STARTUP round */
+		initialized:1;	       /* has bbr_init() been called? */
+	u32	alpha_last_delivered;	 /* tp->delivered    at alpha update */
+	u32	alpha_last_delivered_ce; /* tp->delivered_ce at alpha update */
+
+	u8	unused_4;		/* to preserve alignment */
+	struct tcp_plb_state plb;
 };
 
-#define CYCLE_LEN	8	/* number of phases in a pacing gain cycle */
+struct bbr_context {
+	u32 sample_bw;
+};
 
-/* Window length of bw filter (in rounds): */
-static const int bbr_bw_rtts = CYCLE_LEN + 2;
 /* Window length of min_rtt filter (in sec): */
 static const u32 bbr_min_rtt_win_sec = 10;
 /* Minimum time (in ms) spent at bbr_cwnd_min_target in BBR_PROBE_RTT mode: */
 static const u32 bbr_probe_rtt_mode_ms = 200;
-/* Skip TSO below the following bandwidth (bits/sec): */
-static const int bbr_min_tso_rate = 1200000;
+/* Window length of probe_rtt_min_us filter (in ms), and consequently the
+ * typical interval between PROBE_RTT mode entries. The default is 5000ms.
+ * Note that bbr_probe_rtt_win_ms must be <= bbr_min_rtt_win_sec * MSEC_PER_SEC
+ */
+static const u32 bbr_probe_rtt_win_ms = 5000;
+/* Proportion of cwnd to estimated BDP in PROBE_RTT, in units of BBR_UNIT: */
+static const u32 bbr_probe_rtt_cwnd_gain = BBR_UNIT * 1 / 2;
+
+/* Use min_rtt to help adapt TSO burst size, with smaller min_rtt resulting
+ * in bigger TSO bursts. We cut the RTT-based allowance in half
+ * for every 2^9 usec (aka 512 us) of RTT, so that the RTT-based allowance
+ * is below 1500 bytes after 6 * ~500 usec = 3ms.
+ */
+static const u32 bbr_tso_rtt_shift = 9;
 
 /* Pace at ~1% below estimated bw, on average, to reduce queue at bottleneck.
  * In order to help drive the network toward lower queues and low latency while
@@ -146,13 +207,15 @@ static const int bbr_min_tso_rate = 1200
  */
 static const int bbr_pacing_margin_percent = 1;
 
-/* We use a high_gain value of 2/ln(2) because it's the smallest pacing gain
+/* We use a startup_pacing_gain of 4*ln(2) because it's the smallest value
  * that will allow a smoothly increasing pacing rate that will double each RTT
  * and send the same number of packets per RTT that an un-paced, slow-starting
  * Reno or CUBIC flow would:
  */
-static const int bbr_high_gain  = BBR_UNIT * 2885 / 1000 + 1;
-/* The pacing gain of 1/high_gain in BBR_DRAIN is calculated to typically drain
+static const int bbr_startup_pacing_gain = BBR_UNIT * 277 / 100 + 1;
+/* The gain for deriving startup cwnd: */
+static const int bbr_startup_cwnd_gain = BBR_UNIT * 2;
+/* The pacing gain in BBR_DRAIN is calculated to typically drain
  * the queue created in BBR_STARTUP in a single round:
  */
 static const int bbr_drain_gain = BBR_UNIT * 1000 / 2885;
@@ -160,13 +223,17 @@ static const int bbr_drain_gain = BBR_UN
 static const int bbr_cwnd_gain  = BBR_UNIT * 2;
 /* The pacing_gain values for the PROBE_BW gain cycle, to discover/share bw: */
 static const int bbr_pacing_gain[] = {
-	BBR_UNIT * 5 / 4,	/* probe for more available bw */
-	BBR_UNIT * 3 / 4,	/* drain queue and/or yield bw to other flows */
-	BBR_UNIT, BBR_UNIT, BBR_UNIT,	/* cruise at 1.0*bw to utilize pipe, */
-	BBR_UNIT, BBR_UNIT, BBR_UNIT	/* without creating excess queue... */
+	BBR_UNIT * 5 / 4,	/* UP: probe for more available bw */
+	BBR_UNIT * 91 / 100,	/* DOWN: drain queue and/or yield bw */
+	BBR_UNIT,		/* CRUISE: try to use pipe w/ some headroom */
+	BBR_UNIT,		/* REFILL: refill pipe to estimated 100% */
+};
+enum bbr_pacing_gain_phase {
+	BBR_BW_PROBE_UP		= 0,  /* push up inflight to probe for bw/vol */
+	BBR_BW_PROBE_DOWN	= 1,  /* drain excess inflight from the queue */
+	BBR_BW_PROBE_CRUISE	= 2,  /* use pipe, w/ headroom in queue/pipe */
+	BBR_BW_PROBE_REFILL	= 3,  /* refill the pipe again to 100% */
 };
-/* Randomize the starting gain cycling phase over N phases: */
-static const u32 bbr_cycle_rand = 7;
 
 /* Try to keep at least this many packets in flight, if things go smoothly. For
  * smooth functioning, a sliding window protocol ACKing every other packet
@@ -174,24 +241,12 @@ static const u32 bbr_cycle_rand = 7;
  */
 static const u32 bbr_cwnd_min_target = 4;
 
-/* To estimate if BBR_STARTUP mode (i.e. high_gain) has filled pipe... */
+/* To estimate if BBR_STARTUP or BBR_BW_PROBE_UP has filled pipe... */
 /* If bw has increased significantly (1.25x), there may be more bw available: */
 static const u32 bbr_full_bw_thresh = BBR_UNIT * 5 / 4;
 /* But after 3 rounds w/o significant bw growth, estimate pipe is full: */
 static const u32 bbr_full_bw_cnt = 3;
 
-/* "long-term" ("LT") bandwidth estimator parameters... */
-/* The minimum number of rounds in an LT bw sampling interval: */
-static const u32 bbr_lt_intvl_min_rtts = 4;
-/* If lost/delivered ratio > 20%, interval is "lossy" and we may be policed: */
-static const u32 bbr_lt_loss_thresh = 50;
-/* If 2 intervals have a bw ratio <= 1/8, their bw is "consistent": */
-static const u32 bbr_lt_bw_ratio = BBR_UNIT / 8;
-/* If 2 intervals have a bw diff <= 4 Kbit/sec their bw is "consistent": */
-static const u32 bbr_lt_bw_diff = 4000 / 8;
-/* If we estimate we're policed, use lt_bw for this many round trips: */
-static const u32 bbr_lt_bw_max_rtts = 48;
-
 /* Gain factor for adding extra_acked to target cwnd: */
 static const int bbr_extra_acked_gain = BBR_UNIT;
 /* Window length of extra_acked window. */
@@ -201,8 +256,122 @@ static const u32 bbr_ack_epoch_acked_res
 /* Time period for clamping cwnd increment due to ack aggregation */
 static const u32 bbr_extra_acked_max_us = 100 * 1000;
 
+/* Flags to control BBR ECN-related behavior... */
+
+/* Ensure ACKs only ACK packets with consistent ECN CE status? */
+static const bool bbr_precise_ece_ack = true;
+
+/* Max RTT (in usec) at which to use sender-side ECN logic.
+ * Disabled when 0 (ECN allowed at any RTT).
+ */
+static const u32 bbr_ecn_max_rtt_us = 5000;
+
+/* On losses, scale down inflight and pacing rate by beta scaled by BBR_SCALE.
+ * No loss response when 0.
+ */
+static const u32 bbr_beta = BBR_UNIT * 30 / 100;
+
+/* Gain factor for ECN mark ratio samples, scaled by BBR_SCALE (1/16 = 6.25%) */
+static const u32 bbr_ecn_alpha_gain = BBR_UNIT * 1 / 16;
+
+/* The initial value for ecn_alpha; 1.0 allows a flow to respond quickly
+ * to congestion if the bottleneck is congested when the flow starts up.
+ */
+static const u32 bbr_ecn_alpha_init = BBR_UNIT;
+
+/* On ECN, cut inflight_lo to (1 - ecn_factor * ecn_alpha) scaled by BBR_SCALE.
+ * No ECN based bounding when 0.
+ */
+static const u32 bbr_ecn_factor = BBR_UNIT * 1 / 3;	 /* 1/3 = 33% */
+
+/* Estimate bw probing has gone too far if CE ratio exceeds this threshold.
+ * Scaled by BBR_SCALE. Disabled when 0.
+ */
+static const u32 bbr_ecn_thresh = BBR_UNIT * 1 / 2;  /* 1/2 = 50% */
+
+/* If non-zero, if in a cycle with no losses but some ECN marks, after ECN
+ * clears then make the first round's increment to inflight_hi the following
+ * fraction of inflight_hi.
+ */
+static const u32 bbr_ecn_reprobe_gain = BBR_UNIT * 1 / 2;
+
+/* Estimate bw probing has gone too far if loss rate exceeds this level. */
+static const u32 bbr_loss_thresh = BBR_UNIT * 2 / 100;  /* 2% loss */
+
+/* Slow down for a packet loss recovered by TLP? */
+static const bool bbr_loss_probe_recovery = true;
+
+/* Exit STARTUP if number of loss marking events in a Recovery round is >= N,
+ * and loss rate is higher than bbr_loss_thresh.
+ * Disabled if 0.
+ */
+static const u32 bbr_full_loss_cnt = 6;
+
+/* Exit STARTUP if number of round trips with ECN mark rate above ecn_thresh
+ * meets this count.
+ */
+static const u32 bbr_full_ecn_cnt = 2;
+
+/* Fraction of unutilized headroom to try to leave in path upon high loss. */
+static const u32 bbr_inflight_headroom = BBR_UNIT * 15 / 100;
+
+/* How much do we increase cwnd_gain when probing for bandwidth in
+ * BBR_BW_PROBE_UP? This specifies the increment in units of
+ * BBR_UNIT/4. The default is 1, meaning 0.25.
+ * The min value is 0 (meaning 0.0); max is 3 (meaning 0.75).
+ */
+static const u32 bbr_bw_probe_cwnd_gain = 1;
+
+/* Max number of packet-timed rounds to wait before probing for bandwidth.  If
+ * we want to tolerate 1% random loss per round, and not have this cut our
+ * inflight too much, we must probe for bw periodically on roughly this scale.
+ * If low, limits Reno/CUBIC coexistence; if high, limits loss tolerance.
+ * We aim to be fair with Reno/CUBIC up to a BDP of at least:
+ *  BDP = 25Mbps * .030sec /(1514bytes) = 61.9 packets
+ */
+static const u32 bbr_bw_probe_max_rounds = 63;
+
+/* Max amount of randomness to inject in round counting for Reno-coexistence.
+ */
+static const u32 bbr_bw_probe_rand_rounds = 2;
+
+/* Use BBR-native probe time scale starting at this many usec.
+ * We aim to be fair with Reno/CUBIC up to an inter-loss time epoch of at least:
+ *  BDP*RTT = 25Mbps * .030sec /(1514bytes) * 0.030sec = 1.9 secs
+ */
+static const u32 bbr_bw_probe_base_us = 2 * USEC_PER_SEC;  /* 2 secs */
+
+/* Use BBR-native probes spread over this many usec: */
+static const u32 bbr_bw_probe_rand_us = 1 * USEC_PER_SEC;  /* 1 secs */
+
+/* Use fast path if app-limited, no loss/ECN, and target cwnd was reached? */
+static const bool bbr_fast_path = true;
+
+/* Use fast ack mode? */
+static const bool bbr_fast_ack_mode = true;
+
+static u32 bbr_max_bw(const struct sock *sk);
+static u32 bbr_bw(const struct sock *sk);
+static void bbr_exit_probe_rtt(struct sock *sk);
+static void bbr_reset_congestion_signals(struct sock *sk);
+static void bbr_run_loss_probe_recovery(struct sock *sk);
+
 static void bbr_check_probe_rtt_done(struct sock *sk);
 
+/* This connection can use ECN if both endpoints have signaled ECN support in
+ * the handshake and the per-route settings indicated this is a
+ * shallow-threshold ECN environment, meaning both:
+ *  (a) ECN CE marks indicate low-latency/shallow-threshold congestion, and
+ *  (b) TCP endpoints provide precise ACKs that only ACK data segments
+ *      with consistent ECN CE status
+ */
+static bool bbr_can_use_ecn(const struct sock *sk)
+{
+	const struct tcp_sock *tp = tcp_sk(sk);
+
+	return (tcp_ecn_mode_any(tp)) && (tp->ecn_flags & TCP_ECN_LOW);
+}
+
 /* Do we estimate that STARTUP filled the pipe? */
 static bool bbr_full_bw_reached(const struct sock *sk)
 {
@@ -214,17 +383,17 @@ static bool bbr_full_bw_reached(const st
 /* Return the windowed max recent bandwidth sample, in pkts/uS << BW_SCALE. */
 static u32 bbr_max_bw(const struct sock *sk)
 {
-	struct bbr *bbr = inet_csk_ca(sk);
+	const struct bbr *bbr = inet_csk_ca(sk);
 
-	return minmax_get(&bbr->bw);
+	return max(bbr->bw_hi[0], bbr->bw_hi[1]);
 }
 
 /* Return the estimated bandwidth of the path, in pkts/uS << BW_SCALE. */
 static u32 bbr_bw(const struct sock *sk)
 {
-	struct bbr *bbr = inet_csk_ca(sk);
+	const struct bbr *bbr = inet_csk_ca(sk);
 
-	return bbr->lt_use_bw ? bbr->lt_bw : bbr_max_bw(sk);
+	return min(bbr_max_bw(sk), bbr->bw_lo);
 }
 
 /* Return maximum extra acked in past k-2k round trips,
@@ -241,15 +410,23 @@ static u16 bbr_extra_acked(const struct
  * The order here is chosen carefully to avoid overflow of u64. This should
  * work for input rates of up to 2.9Tbit/sec and gain of 2.89x.
  */
-static u64 bbr_rate_bytes_per_sec(struct sock *sk, u64 rate, int gain)
+static u64 bbr_rate_bytes_per_sec(struct sock *sk, u64 rate, int gain,
+				  int margin)
 {
 	unsigned int mss = tcp_sk(sk)->mss_cache;
 
 	rate *= mss;
 	rate *= gain;
 	rate >>= BBR_SCALE;
-	rate *= USEC_PER_SEC / 100 * (100 - bbr_pacing_margin_percent);
-	return rate >> BW_SCALE;
+	rate *= USEC_PER_SEC / 100 * (100 - margin);
+	rate >>= BW_SCALE;
+	rate = max(rate, 1ULL);
+	return rate;
+}
+
+static u64 bbr_bw_bytes_per_sec(struct sock *sk, u64 rate)
+{
+	return bbr_rate_bytes_per_sec(sk, rate, BBR_UNIT, 0);
 }
 
 /* Convert a BBR bw and gain factor to a pacing rate in bytes per second. */
@@ -257,12 +434,13 @@ static unsigned long bbr_bw_to_pacing_ra
 {
 	u64 rate = bw;
 
-	rate = bbr_rate_bytes_per_sec(sk, rate, gain);
+	rate = bbr_rate_bytes_per_sec(sk, rate, gain,
+				      bbr_pacing_margin_percent);
 	rate = min_t(u64, rate, READ_ONCE(sk->sk_max_pacing_rate));
 	return rate;
 }
 
-/* Initialize pacing rate to: high_gain * init_cwnd / RTT. */
+/* Initialize pacing rate to: startup_pacing_gain * init_cwnd / RTT. */
 static void bbr_init_pacing_rate_from_rtt(struct sock *sk)
 {
 	struct tcp_sock *tp = tcp_sk(sk);
@@ -279,7 +457,8 @@ static void bbr_init_pacing_rate_from_rt
 	bw = (u64)tcp_snd_cwnd(tp) * BW_UNIT;
 	do_div(bw, rtt_us);
 	WRITE_ONCE(sk->sk_pacing_rate,
-		   bbr_bw_to_pacing_rate(sk, bw, bbr_high_gain));
+		   bbr_bw_to_pacing_rate(sk, bw,
+					 bbr_param(sk, startup_pacing_gain)));
 }
 
 /* Pace using current bw estimate and a gain factor. */
@@ -295,26 +474,48 @@ static void bbr_set_pacing_rate(struct s
 		WRITE_ONCE(sk->sk_pacing_rate, rate);
 }
 
-/* override sysctl_tcp_min_tso_segs */
-__bpf_kfunc static u32 bbr_min_tso_segs(struct sock *sk)
+/* Return the number of segments BBR would like in a TSO/GSO skb, given a
+ * particular max gso size as a constraint. TODO: make this simpler and more
+ * consistent by switching bbr to just call tcp_tso_autosize().
+ */
+static u32 bbr_tso_segs_generic(struct sock *sk, unsigned int mss_now,
+				u32 gso_max_size)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 segs, r;
+	u64 bytes;
+
+	/* Budget a TSO/GSO burst size allowance based on bw (pacing_rate). */
+	bytes = READ_ONCE(sk->sk_pacing_rate) >> READ_ONCE(sk->sk_pacing_shift);
+
+	/* Budget a TSO/GSO burst size allowance based on min_rtt. For every
+	 * K = 2^tso_rtt_shift microseconds of min_rtt, halve the burst.
+	 * The min_rtt-based burst allowance is: 64 KBytes / 2^(min_rtt/K)
+	 */
+	if (bbr_param(sk, tso_rtt_shift)) {
+		r = bbr->min_rtt_us >> bbr_param(sk, tso_rtt_shift);
+		if (r < BITS_PER_TYPE(u32))   /* prevent undefined behavior */
+			bytes += GSO_LEGACY_MAX_SIZE >> r;
+	}
+
+	bytes = min_t(u32, bytes, gso_max_size - 1 - MAX_TCP_HEADER);
+	segs = max_t(u32, bytes / mss_now,
+		     sock_net(sk)->ipv4.sysctl_tcp_min_tso_segs);
+	return segs;
+}
+
+/* Custom tcp_tso_autosize() for BBR, used at transmit time to cap skb size. */
+__bpf_kfunc static u32 bbr_tso_segs(struct sock *sk, unsigned int mss_now)
 {
-	return READ_ONCE(sk->sk_pacing_rate) < (bbr_min_tso_rate >> 3) ? 1 : 2;
+	return bbr_tso_segs_generic(sk, mss_now, sk->sk_gso_max_size);
 }
 
+/* Like bbr_tso_segs(), using mss_cache, ignoring driver's sk_gso_max_size. */
 static u32 bbr_tso_segs_goal(struct sock *sk)
 {
 	struct tcp_sock *tp = tcp_sk(sk);
-	u32 segs, bytes;
 
-	/* Sort of tcp_tso_autosize() but ignoring
-	 * driver provided sk_gso_max_size.
-	 */
-	bytes = min_t(unsigned long,
-		      READ_ONCE(sk->sk_pacing_rate) >> READ_ONCE(sk->sk_pacing_shift),
-		      GSO_LEGACY_MAX_SIZE - 1 - MAX_TCP_HEADER);
-	segs = max_t(u32, bytes / tp->mss_cache, bbr_min_tso_segs(sk));
-
-	return min(segs, 0x7FU);
+	return bbr_tso_segs_generic(sk, tp->mss_cache, GSO_LEGACY_MAX_SIZE);
 }
 
 /* Save "last known good" cwnd so we can restore it after losses or PROBE_RTT */
@@ -334,7 +535,9 @@ __bpf_kfunc static void bbr_cwnd_event(s
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct bbr *bbr = inet_csk_ca(sk);
 
-	if (event == CA_EVENT_TX_START && tp->app_limited) {
+	if (event == CA_EVENT_TX_START) {
+		if (!tp->app_limited)
+			return;
 		bbr->idle_restart = 1;
 		bbr->ack_epoch_mstamp = tp->tcp_mstamp;
 		bbr->ack_epoch_acked = 0;
@@ -345,6 +548,16 @@ __bpf_kfunc static void bbr_cwnd_event(s
 			bbr_set_pacing_rate(sk, bbr_bw(sk), BBR_UNIT);
 		else if (bbr->mode == BBR_PROBE_RTT)
 			bbr_check_probe_rtt_done(sk);
+	} else if ((event == CA_EVENT_ECN_IS_CE ||
+		    event == CA_EVENT_ECN_NO_CE) &&
+		   bbr_can_use_ecn(sk) &&
+		   bbr_param(sk, precise_ece_ack)) {
+		u32 state = bbr->ce_state;
+		dctcp_ece_ack_update(sk, event, &bbr->prior_rcv_nxt, &state);
+		bbr->ce_state = state;
+	} else if (event == CA_EVENT_TLP_RECOVERY &&
+		   bbr_param(sk, loss_probe_recovery)) {
+		bbr_run_loss_probe_recovery(sk);
 	}
 }
 
@@ -367,10 +580,10 @@ static u32 bbr_bdp(struct sock *sk, u32
 	 * default. This should only happen when the connection is not using TCP
 	 * timestamps and has retransmitted all of the SYN/SYNACK/data packets
 	 * ACKed so far. In this case, an RTO can cut cwnd to 1, in which
-	 * case we need to slow-start up toward something safe: TCP_INIT_CWND.
+	 * case we need to slow-start up toward something safe: initial cwnd.
 	 */
 	if (unlikely(bbr->min_rtt_us == ~0U))	 /* no valid RTT samples yet? */
-		return TCP_INIT_CWND;  /* be safe: cap at default initial cwnd*/
+		return bbr->init_cwnd;  /* be safe: cap at initial cwnd */
 
 	w = (u64)bw * bbr->min_rtt_us;
 
@@ -387,23 +600,23 @@ static u32 bbr_bdp(struct sock *sk, u32
  *   - one skb in sending host Qdisc,
  *   - one skb in sending host TSO/GSO engine
  *   - one skb being received by receiver host LRO/GRO/delayed-ACK engine
- * Don't worry, at low rates (bbr_min_tso_rate) this won't bloat cwnd because
- * in such cases tso_segs_goal is 1. The minimum cwnd is 4 packets,
+ * Don't worry, at low rates this won't bloat cwnd because
+ * in such cases tso_segs_goal is small. The minimum cwnd is 4 packets,
  * which allows 2 outstanding 2-packet sequences, to try to keep pipe
  * full even with ACK-every-other-packet delayed ACKs.
  */
 static u32 bbr_quantization_budget(struct sock *sk, u32 cwnd)
 {
 	struct bbr *bbr = inet_csk_ca(sk);
+	u32 tso_segs_goal;
 
-	/* Allow enough full-sized skbs in flight to utilize end systems. */
-	cwnd += 3 * bbr_tso_segs_goal(sk);
-
-	/* Reduce delayed ACKs by rounding up cwnd to the next even number. */
-	cwnd = (cwnd + 1) & ~1U;
+	tso_segs_goal = 3 * bbr_tso_segs_goal(sk);
 
+	/* Allow enough full-sized skbs in flight to utilize end systems. */
+	cwnd = max_t(u32, cwnd, tso_segs_goal);
+	cwnd = max_t(u32, cwnd, bbr_param(sk, cwnd_min_target));
 	/* Ensure gain cycling gets inflight above BDP even for small BDPs. */
-	if (bbr->mode == BBR_PROBE_BW && bbr->cycle_idx == 0)
+	if (bbr->mode == BBR_PROBE_BW && bbr->cycle_idx == BBR_BW_PROBE_UP)
 		cwnd += 2;
 
 	return cwnd;
@@ -458,10 +671,10 @@ static u32 bbr_ack_aggregation_cwnd(stru
 {
 	u32 max_aggr_cwnd, aggr_cwnd = 0;
 
-	if (bbr_extra_acked_gain && bbr_full_bw_reached(sk)) {
+	if (bbr_param(sk, extra_acked_gain)) {
 		max_aggr_cwnd = ((u64)bbr_bw(sk) * bbr_extra_acked_max_us)
 				/ BW_UNIT;
-		aggr_cwnd = (bbr_extra_acked_gain * bbr_extra_acked(sk))
+		aggr_cwnd = (bbr_param(sk, extra_acked_gain) * bbr_extra_acked(sk))
 			     >> BBR_SCALE;
 		aggr_cwnd = min(aggr_cwnd, max_aggr_cwnd);
 	}
@@ -469,66 +682,27 @@ static u32 bbr_ack_aggregation_cwnd(stru
 	return aggr_cwnd;
 }
 
-/* An optimization in BBR to reduce losses: On the first round of recovery, we
- * follow the packet conservation principle: send P packets per P packets acked.
- * After that, we slow-start and send at most 2*P packets per P packets acked.
- * After recovery finishes, or upon undo, we restore the cwnd we had when
- * recovery started (capped by the target cwnd based on estimated BDP).
- *
- * TODO(ycheng/ncardwell): implement a rate-based approach.
- */
-static bool bbr_set_cwnd_to_recover_or_restore(
-	struct sock *sk, const struct rate_sample *rs, u32 acked, u32 *new_cwnd)
+/* Returns the cwnd for PROBE_RTT mode. */
+static u32 bbr_probe_rtt_cwnd(struct sock *sk)
 {
-	struct tcp_sock *tp = tcp_sk(sk);
-	struct bbr *bbr = inet_csk_ca(sk);
-	u8 prev_state = bbr->prev_ca_state, state = inet_csk(sk)->icsk_ca_state;
-	u32 cwnd = tcp_snd_cwnd(tp);
-
-	/* An ACK for P pkts should release at most 2*P packets. We do this
-	 * in two steps. First, here we deduct the number of lost packets.
-	 * Then, in bbr_set_cwnd() we slow start up toward the target cwnd.
-	 */
-	if (rs->losses > 0)
-		cwnd = max_t(s32, cwnd - rs->losses, 1);
-
-	if (state == TCP_CA_Recovery && prev_state != TCP_CA_Recovery) {
-		/* Starting 1st round of Recovery, so do packet conservation. */
-		bbr->packet_conservation = 1;
-		bbr->next_rtt_delivered = tp->delivered;  /* start round now */
-		/* Cut unused cwnd from app behavior, TSQ, or TSO deferral: */
-		cwnd = tcp_packets_in_flight(tp) + acked;
-	} else if (prev_state >= TCP_CA_Recovery && state < TCP_CA_Recovery) {
-		/* Exiting loss recovery; restore cwnd saved before recovery. */
-		cwnd = max(cwnd, bbr->prior_cwnd);
-		bbr->packet_conservation = 0;
-	}
-	bbr->prev_ca_state = state;
-
-	if (bbr->packet_conservation) {
-		*new_cwnd = max(cwnd, tcp_packets_in_flight(tp) + acked);
-		return true;	/* yes, using packet conservation */
-	}
-	*new_cwnd = cwnd;
-	return false;
+	return max_t(u32, bbr_param(sk, cwnd_min_target),
+		     bbr_bdp(sk, bbr_bw(sk), bbr_param(sk, probe_rtt_cwnd_gain)));
 }
 
 /* Slow-start up toward target cwnd (if bw estimate is growing, or packet loss
  * has drawn us down below target), or snap down to target if we're above it.
  */
 static void bbr_set_cwnd(struct sock *sk, const struct rate_sample *rs,
-			 u32 acked, u32 bw, int gain)
+			 u32 acked, u32 bw, int gain, u32 cwnd,
+			 struct bbr_context *ctx)
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct bbr *bbr = inet_csk_ca(sk);
-	u32 cwnd = tcp_snd_cwnd(tp), target_cwnd = 0;
+	u32 target_cwnd = 0;
 
 	if (!acked)
 		goto done;  /* no packet fully ACKed; just apply caps */
 
-	if (bbr_set_cwnd_to_recover_or_restore(sk, rs, acked, &cwnd))
-		goto done;
-
 	target_cwnd = bbr_bdp(sk, bw, gain);
 
 	/* Increment the cwnd to account for excess ACKed data that seems
@@ -537,74 +711,26 @@ static void bbr_set_cwnd(struct sock *sk
 	target_cwnd += bbr_ack_aggregation_cwnd(sk);
 	target_cwnd = bbr_quantization_budget(sk, target_cwnd);
 
-	/* If we're below target cwnd, slow start cwnd toward target cwnd. */
-	if (bbr_full_bw_reached(sk))  /* only cut cwnd if we filled the pipe */
-		cwnd = min(cwnd + acked, target_cwnd);
-	else if (cwnd < target_cwnd || tp->delivered < TCP_INIT_CWND)
-		cwnd = cwnd + acked;
-	cwnd = max(cwnd, bbr_cwnd_min_target);
+	/* Update cwnd and enable fast path if cwnd reaches target_cwnd. */
+	bbr->try_fast_path = 0;
+	if (bbr_full_bw_reached(sk)) { /* only cut cwnd if we filled the pipe */
+		cwnd += acked;
+		if (cwnd >= target_cwnd) {
+			cwnd = target_cwnd;
+			bbr->try_fast_path = 1;
+		}
+	} else if (cwnd < target_cwnd || cwnd  < 2 * bbr->init_cwnd) {
+		cwnd += acked;
+	} else {
+		bbr->try_fast_path = 1;
+	}
 
+	cwnd = max_t(u32, cwnd, bbr_param(sk, cwnd_min_target));
 done:
-	tcp_snd_cwnd_set(tp, min(cwnd, tp->snd_cwnd_clamp));	/* apply global cap */
+	tcp_snd_cwnd_set(tp, min(cwnd, tp->snd_cwnd_clamp));  /* global cap */
 	if (bbr->mode == BBR_PROBE_RTT)  /* drain queue, refresh min_rtt */
-		tcp_snd_cwnd_set(tp, min(tcp_snd_cwnd(tp), bbr_cwnd_min_target));
-}
-
-/* End cycle phase if it's time and/or we hit the phase's in-flight target. */
-static bool bbr_is_next_cycle_phase(struct sock *sk,
-				    const struct rate_sample *rs)
-{
-	struct tcp_sock *tp = tcp_sk(sk);
-	struct bbr *bbr = inet_csk_ca(sk);
-	bool is_full_length =
-		tcp_stamp_us_delta(tp->delivered_mstamp, bbr->cycle_mstamp) >
-		bbr->min_rtt_us;
-	u32 inflight, bw;
-
-	/* The pacing_gain of 1.0 paces at the estimated bw to try to fully
-	 * use the pipe without increasing the queue.
-	 */
-	if (bbr->pacing_gain == BBR_UNIT)
-		return is_full_length;		/* just use wall clock time */
-
-	inflight = bbr_packets_in_net_at_edt(sk, rs->prior_in_flight);
-	bw = bbr_max_bw(sk);
-
-	/* A pacing_gain > 1.0 probes for bw by trying to raise inflight to at
-	 * least pacing_gain*BDP; this may take more than min_rtt if min_rtt is
-	 * small (e.g. on a LAN). We do not persist if packets are lost, since
-	 * a path with small buffers may not hold that much.
-	 */
-	if (bbr->pacing_gain > BBR_UNIT)
-		return is_full_length &&
-			(rs->losses ||  /* perhaps pacing_gain*BDP won't fit */
-			 inflight >= bbr_inflight(sk, bw, bbr->pacing_gain));
-
-	/* A pacing_gain < 1.0 tries to drain extra queue we added if bw
-	 * probing didn't find more bw. If inflight falls to match BDP then we
-	 * estimate queue is drained; persisting would underutilize the pipe.
-	 */
-	return is_full_length ||
-		inflight <= bbr_inflight(sk, bw, BBR_UNIT);
-}
-
-static void bbr_advance_cycle_phase(struct sock *sk)
-{
-	struct tcp_sock *tp = tcp_sk(sk);
-	struct bbr *bbr = inet_csk_ca(sk);
-
-	bbr->cycle_idx = (bbr->cycle_idx + 1) & (CYCLE_LEN - 1);
-	bbr->cycle_mstamp = tp->delivered_mstamp;
-}
-
-/* Gain cycling: cycle pacing gain to converge to fair share of available bw. */
-static void bbr_update_cycle_phase(struct sock *sk,
-				   const struct rate_sample *rs)
-{
-	struct bbr *bbr = inet_csk_ca(sk);
-
-	if (bbr->mode == BBR_PROBE_BW && bbr_is_next_cycle_phase(sk, rs))
-		bbr_advance_cycle_phase(sk);
+		tcp_snd_cwnd_set(tp, min_t(u32, tcp_snd_cwnd(tp),
+					   bbr_probe_rtt_cwnd(sk)));
 }
 
 static void bbr_reset_startup_mode(struct sock *sk)
@@ -614,191 +740,49 @@ static void bbr_reset_startup_mode(struc
 	bbr->mode = BBR_STARTUP;
 }
 
-static void bbr_reset_probe_bw_mode(struct sock *sk)
-{
-	struct bbr *bbr = inet_csk_ca(sk);
-
-	bbr->mode = BBR_PROBE_BW;
-	bbr->cycle_idx = CYCLE_LEN - 1 - get_random_u32_below(bbr_cycle_rand);
-	bbr_advance_cycle_phase(sk);	/* flip to next phase of gain cycle */
-}
-
-static void bbr_reset_mode(struct sock *sk)
-{
-	if (!bbr_full_bw_reached(sk))
-		bbr_reset_startup_mode(sk);
-	else
-		bbr_reset_probe_bw_mode(sk);
-}
-
-/* Start a new long-term sampling interval. */
-static void bbr_reset_lt_bw_sampling_interval(struct sock *sk)
-{
-	struct tcp_sock *tp = tcp_sk(sk);
-	struct bbr *bbr = inet_csk_ca(sk);
-
-	bbr->lt_last_stamp = div_u64(tp->delivered_mstamp, USEC_PER_MSEC);
-	bbr->lt_last_delivered = tp->delivered;
-	bbr->lt_last_lost = tp->lost;
-	bbr->lt_rtt_cnt = 0;
-}
-
-/* Completely reset long-term bandwidth sampling. */
-static void bbr_reset_lt_bw_sampling(struct sock *sk)
-{
-	struct bbr *bbr = inet_csk_ca(sk);
-
-	bbr->lt_bw = 0;
-	bbr->lt_use_bw = 0;
-	bbr->lt_is_sampling = false;
-	bbr_reset_lt_bw_sampling_interval(sk);
-}
-
-/* Long-term bw sampling interval is done. Estimate whether we're policed. */
-static void bbr_lt_bw_interval_done(struct sock *sk, u32 bw)
-{
-	struct bbr *bbr = inet_csk_ca(sk);
-	u32 diff;
-
-	if (bbr->lt_bw) {  /* do we have bw from a previous interval? */
-		/* Is new bw close to the lt_bw from the previous interval? */
-		diff = abs(bw - bbr->lt_bw);
-		if ((diff * BBR_UNIT <= bbr_lt_bw_ratio * bbr->lt_bw) ||
-		    (bbr_rate_bytes_per_sec(sk, diff, BBR_UNIT) <=
-		     bbr_lt_bw_diff)) {
-			/* All criteria are met; estimate we're policed. */
-			bbr->lt_bw = (bw + bbr->lt_bw) >> 1;  /* avg 2 intvls */
-			bbr->lt_use_bw = 1;
-			bbr->pacing_gain = BBR_UNIT;  /* try to avoid drops */
-			bbr->lt_rtt_cnt = 0;
-			return;
-		}
-	}
-	bbr->lt_bw = bw;
-	bbr_reset_lt_bw_sampling_interval(sk);
-}
-
-/* Token-bucket traffic policers are common (see "An Internet-Wide Analysis of
- * Traffic Policing", SIGCOMM 2016). BBR detects token-bucket policers and
- * explicitly models their policed rate, to reduce unnecessary losses. We
- * estimate that we're policed if we see 2 consecutive sampling intervals with
- * consistent throughput and high packet loss. If we think we're being policed,
- * set lt_bw to the "long-term" average delivery rate from those 2 intervals.
+/* See if we have reached next round trip. Upon start of the new round,
+ * returns packets delivered since previous round start plus this ACK.
  */
-static void bbr_lt_bw_sampling(struct sock *sk, const struct rate_sample *rs)
+static u32 bbr_update_round_start(struct sock *sk,
+		const struct rate_sample *rs, struct bbr_context *ctx)
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct bbr *bbr = inet_csk_ca(sk);
-	u32 lost, delivered;
-	u64 bw;
-	u32 t;
-
-	if (bbr->lt_use_bw) {	/* already using long-term rate, lt_bw? */
-		if (bbr->mode == BBR_PROBE_BW && bbr->round_start &&
-		    ++bbr->lt_rtt_cnt >= bbr_lt_bw_max_rtts) {
-			bbr_reset_lt_bw_sampling(sk);    /* stop using lt_bw */
-			bbr_reset_probe_bw_mode(sk);  /* restart gain cycling */
-		}
-		return;
-	}
-
-	/* Wait for the first loss before sampling, to let the policer exhaust
-	 * its tokens and estimate the steady-state rate allowed by the policer.
-	 * Starting samples earlier includes bursts that over-estimate the bw.
-	 */
-	if (!bbr->lt_is_sampling) {
-		if (!rs->losses)
-			return;
-		bbr_reset_lt_bw_sampling_interval(sk);
-		bbr->lt_is_sampling = true;
-	}
-
-	/* To avoid underestimates, reset sampling if we run out of data. */
-	if (rs->is_app_limited) {
-		bbr_reset_lt_bw_sampling(sk);
-		return;
-	}
-
-	if (bbr->round_start)
-		bbr->lt_rtt_cnt++;	/* count round trips in this interval */
-	if (bbr->lt_rtt_cnt < bbr_lt_intvl_min_rtts)
-		return;		/* sampling interval needs to be longer */
-	if (bbr->lt_rtt_cnt > 4 * bbr_lt_intvl_min_rtts) {
-		bbr_reset_lt_bw_sampling(sk);  /* interval is too long */
-		return;
-	}
-
-	/* End sampling interval when a packet is lost, so we estimate the
-	 * policer tokens were exhausted. Stopping the sampling before the
-	 * tokens are exhausted under-estimates the policed rate.
-	 */
-	if (!rs->losses)
-		return;
-
-	/* Calculate packets lost and delivered in sampling interval. */
-	lost = tp->lost - bbr->lt_last_lost;
-	delivered = tp->delivered - bbr->lt_last_delivered;
-	/* Is loss rate (lost/delivered) >= lt_loss_thresh? If not, wait. */
-	if (!delivered || (lost << BBR_SCALE) < bbr_lt_loss_thresh * delivered)
-		return;
-
-	/* Find average delivery rate in this sampling interval. */
-	t = div_u64(tp->delivered_mstamp, USEC_PER_MSEC) - bbr->lt_last_stamp;
-	if ((s32)t < 1)
-		return;		/* interval is less than one ms, so wait */
-	/* Check if can multiply without overflow */
-	if (t >= ~0U / USEC_PER_MSEC) {
-		bbr_reset_lt_bw_sampling(sk);  /* interval too long; reset */
-		return;
-	}
-	t *= USEC_PER_MSEC;
-	bw = (u64)delivered * BW_UNIT;
-	do_div(bw, t);
-	bbr_lt_bw_interval_done(sk, bw);
-}
-
-/* Estimate the bandwidth based on how fast packets are delivered */
-static void bbr_update_bw(struct sock *sk, const struct rate_sample *rs)
-{
-	struct tcp_sock *tp = tcp_sk(sk);
-	struct bbr *bbr = inet_csk_ca(sk);
-	u64 bw;
+	u32 round_delivered = 0;
 
 	bbr->round_start = 0;
-	if (rs->delivered < 0 || rs->interval_us <= 0)
-		return; /* Not a valid observation */
 
 	/* See if we've reached the next RTT */
-	if (!before(rs->prior_delivered, bbr->next_rtt_delivered)) {
+	if (rs->interval_us > 0 &&
+	    !before(rs->prior_delivered, bbr->next_rtt_delivered)) {
+		round_delivered = tp->delivered - bbr->next_rtt_delivered;
 		bbr->next_rtt_delivered = tp->delivered;
-		bbr->rtt_cnt++;
 		bbr->round_start = 1;
-		bbr->packet_conservation = 0;
 	}
+	return round_delivered;
+}
 
-	bbr_lt_bw_sampling(sk, rs);
+/* Calculate the bandwidth based on how fast packets are delivered */
+static void bbr_calculate_bw_sample(struct sock *sk,
+			const struct rate_sample *rs, struct bbr_context *ctx)
+{
+	u64 bw = 0;
 
 	/* Divide delivered by the interval to find a (lower bound) bottleneck
 	 * bandwidth sample. Delivered is in packets and interval_us in uS and
 	 * ratio will be <<1 for most connections. So delivered is first scaled.
+	 * Round up to allow growth at low rates, even with integer division.
 	 */
-	bw = div64_long((u64)rs->delivered * BW_UNIT, rs->interval_us);
+	if (rs->interval_us > 0) {
+		if (WARN_ONCE(rs->delivered < 0,
+			      "negative delivered: %d interval_us: %ld\n",
+			      rs->delivered, rs->interval_us))
+			return;
 
-	/* If this sample is application-limited, it is likely to have a very
-	 * low delivered count that represents application behavior rather than
-	 * the available network rate. Such a sample could drag down estimated
-	 * bw, causing needless slow-down. Thus, to continue to send at the
-	 * last measured network rate, we filter out app-limited samples unless
-	 * they describe the path bw at least as well as our bw model.
-	 *
-	 * So the goal during app-limited phase is to proceed with the best
-	 * network rate no matter how long. We automatically leave this
-	 * phase when app writes faster than the network can deliver :)
-	 */
-	if (!rs->is_app_limited || bw >= bbr_max_bw(sk)) {
-		/* Incorporate new sample into our max bw filter. */
-		minmax_running_max(&bbr->bw, bbr_bw_rtts, bbr->rtt_cnt, bw);
+		bw = DIV_ROUND_UP_ULL((u64)rs->delivered * BW_UNIT, rs->interval_us);
 	}
+
+	ctx->sample_bw = bw;
 }
 
 /* Estimates the windowed max degree of ack aggregation.
@@ -812,7 +796,7 @@ static void bbr_update_bw(struct sock *s
  *
  * Max extra_acked is clamped by cwnd and bw * bbr_extra_acked_max_us (100 ms).
  * Max filter is an approximate sliding window of 5-10 (packet timed) round
- * trips.
+ * trips for non-startup phase, and 1-2 round trips for startup.
  */
 static void bbr_update_ack_aggregation(struct sock *sk,
 				       const struct rate_sample *rs)
@@ -820,15 +804,19 @@ static void bbr_update_ack_aggregation(s
 	u32 epoch_us, expected_acked, extra_acked;
 	struct bbr *bbr = inet_csk_ca(sk);
 	struct tcp_sock *tp = tcp_sk(sk);
+	u32 extra_acked_win_rtts_thresh = bbr_param(sk, extra_acked_win_rtts);
 
-	if (!bbr_extra_acked_gain || rs->acked_sacked <= 0 ||
+	if (!bbr_param(sk, extra_acked_gain) || rs->acked_sacked <= 0 ||
 	    rs->delivered < 0 || rs->interval_us <= 0)
 		return;
 
 	if (bbr->round_start) {
 		bbr->extra_acked_win_rtts = min(0x1F,
 						bbr->extra_acked_win_rtts + 1);
-		if (bbr->extra_acked_win_rtts >= bbr_extra_acked_win_rtts) {
+		if (!bbr_full_bw_reached(sk))
+			extra_acked_win_rtts_thresh = 1;
+		if (bbr->extra_acked_win_rtts >=
+		    extra_acked_win_rtts_thresh) {
 			bbr->extra_acked_win_rtts = 0;
 			bbr->extra_acked_win_idx = bbr->extra_acked_win_idx ?
 						   0 : 1;
@@ -862,49 +850,6 @@ static void bbr_update_ack_aggregation(s
 		bbr->extra_acked[bbr->extra_acked_win_idx] = extra_acked;
 }
 
-/* Estimate when the pipe is full, using the change in delivery rate: BBR
- * estimates that STARTUP filled the pipe if the estimated bw hasn't changed by
- * at least bbr_full_bw_thresh (25%) after bbr_full_bw_cnt (3) non-app-limited
- * rounds. Why 3 rounds: 1: rwin autotuning grows the rwin, 2: we fill the
- * higher rwin, 3: we get higher delivery rate samples. Or transient
- * cross-traffic or radio noise can go away. CUBIC Hystart shares a similar
- * design goal, but uses delay and inter-ACK spacing instead of bandwidth.
- */
-static void bbr_check_full_bw_reached(struct sock *sk,
-				      const struct rate_sample *rs)
-{
-	struct bbr *bbr = inet_csk_ca(sk);
-	u32 bw_thresh;
-
-	if (bbr_full_bw_reached(sk) || !bbr->round_start || rs->is_app_limited)
-		return;
-
-	bw_thresh = (u64)bbr->full_bw * bbr_full_bw_thresh >> BBR_SCALE;
-	if (bbr_max_bw(sk) >= bw_thresh) {
-		bbr->full_bw = bbr_max_bw(sk);
-		bbr->full_bw_cnt = 0;
-		return;
-	}
-	++bbr->full_bw_cnt;
-	bbr->full_bw_reached = bbr->full_bw_cnt >= bbr_full_bw_cnt;
-}
-
-/* If pipe is probably full, drain the queue and then enter steady-state. */
-static void bbr_check_drain(struct sock *sk, const struct rate_sample *rs)
-{
-	struct bbr *bbr = inet_csk_ca(sk);
-
-	if (bbr->mode == BBR_STARTUP && bbr_full_bw_reached(sk)) {
-		bbr->mode = BBR_DRAIN;	/* drain queue we created */
-		tcp_sk(sk)->snd_ssthresh =
-				bbr_inflight(sk, bbr_max_bw(sk), BBR_UNIT);
-	}	/* fall through to check if in-flight is already small: */
-	if (bbr->mode == BBR_DRAIN &&
-	    bbr_packets_in_net_at_edt(sk, tcp_packets_in_flight(tcp_sk(sk))) <=
-	    bbr_inflight(sk, bbr_max_bw(sk), BBR_UNIT))
-		bbr_reset_probe_bw_mode(sk);  /* we estimate queue is drained */
-}
-
 static void bbr_check_probe_rtt_done(struct sock *sk)
 {
 	struct tcp_sock *tp = tcp_sk(sk);
@@ -914,9 +859,9 @@ static void bbr_check_probe_rtt_done(str
 	      after(tcp_jiffies32, bbr->probe_rtt_done_stamp)))
 		return;
 
-	bbr->min_rtt_stamp = tcp_jiffies32;  /* wait a while until PROBE_RTT */
+	bbr->probe_rtt_min_stamp = tcp_jiffies32; /* schedule next PROBE_RTT */
 	tcp_snd_cwnd_set(tp, max(tcp_snd_cwnd(tp), bbr->prior_cwnd));
-	bbr_reset_mode(sk);
+	bbr_exit_probe_rtt(sk);
 }
 
 /* The goal of PROBE_RTT mode is to have BBR flows cooperatively and
@@ -942,23 +887,35 @@ static void bbr_update_min_rtt(struct so
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct bbr *bbr = inet_csk_ca(sk);
-	bool filter_expired;
+	bool probe_rtt_expired, min_rtt_expired;
+	u32 expire;
 
-	/* Track min RTT seen in the min_rtt_win_sec filter window: */
-	filter_expired = after(tcp_jiffies32,
-			       bbr->min_rtt_stamp + bbr_min_rtt_win_sec * HZ);
+	/* Track min RTT in probe_rtt_win_ms to time next PROBE_RTT state. */
+	expire = bbr->probe_rtt_min_stamp +
+		 msecs_to_jiffies(bbr_param(sk, probe_rtt_win_ms));
+	probe_rtt_expired = after(tcp_jiffies32, expire);
 	if (rs->rtt_us >= 0 &&
-	    (rs->rtt_us < bbr->min_rtt_us ||
-	     (filter_expired && !rs->is_ack_delayed))) {
-		bbr->min_rtt_us = rs->rtt_us;
-		bbr->min_rtt_stamp = tcp_jiffies32;
+	    (rs->rtt_us < bbr->probe_rtt_min_us ||
+	     (probe_rtt_expired && !rs->is_ack_delayed))) {
+		bbr->probe_rtt_min_us = rs->rtt_us;
+		bbr->probe_rtt_min_stamp = tcp_jiffies32;
+	}
+	/* Track min RTT seen in the min_rtt_win_sec filter window: */
+	expire = bbr->min_rtt_stamp + bbr_param(sk, min_rtt_win_sec) * HZ;
+	min_rtt_expired = after(tcp_jiffies32, expire);
+	if (bbr->probe_rtt_min_us <= bbr->min_rtt_us ||
+	    min_rtt_expired) {
+		bbr->min_rtt_us = bbr->probe_rtt_min_us;
+		bbr->min_rtt_stamp = bbr->probe_rtt_min_stamp;
 	}
 
-	if (bbr_probe_rtt_mode_ms > 0 && filter_expired &&
+	if (bbr_param(sk, probe_rtt_mode_ms) > 0 && probe_rtt_expired &&
 	    !bbr->idle_restart && bbr->mode != BBR_PROBE_RTT) {
 		bbr->mode = BBR_PROBE_RTT;  /* dip, drain queue */
 		bbr_save_cwnd(sk);  /* note cwnd so we can restore it */
 		bbr->probe_rtt_done_stamp = 0;
+		bbr->ack_phase = BBR_ACKS_PROBE_STOPPING;
+		bbr->next_rtt_delivered = tp->delivered;
 	}
 
 	if (bbr->mode == BBR_PROBE_RTT) {
@@ -967,9 +924,9 @@ static void bbr_update_min_rtt(struct so
 			(tp->delivered + tcp_packets_in_flight(tp)) ? : 1;
 		/* Maintain min packets in flight for max(200 ms, 1 round). */
 		if (!bbr->probe_rtt_done_stamp &&
-		    tcp_packets_in_flight(tp) <= bbr_cwnd_min_target) {
+		    tcp_packets_in_flight(tp) <= bbr_probe_rtt_cwnd(sk)) {
 			bbr->probe_rtt_done_stamp = tcp_jiffies32 +
-				msecs_to_jiffies(bbr_probe_rtt_mode_ms);
+				msecs_to_jiffies(bbr_param(sk, probe_rtt_mode_ms));
 			bbr->probe_rtt_round_done = 0;
 			bbr->next_rtt_delivered = tp->delivered;
 		} else if (bbr->probe_rtt_done_stamp) {
@@ -990,18 +947,20 @@ static void bbr_update_gains(struct sock
 
 	switch (bbr->mode) {
 	case BBR_STARTUP:
-		bbr->pacing_gain = bbr_high_gain;
-		bbr->cwnd_gain	 = bbr_high_gain;
+		bbr->pacing_gain = bbr_param(sk, startup_pacing_gain);
+		bbr->cwnd_gain	 = bbr_param(sk, startup_cwnd_gain);
 		break;
 	case BBR_DRAIN:
-		bbr->pacing_gain = bbr_drain_gain;	/* slow, to drain */
-		bbr->cwnd_gain	 = bbr_high_gain;	/* keep cwnd */
+		bbr->pacing_gain = bbr_param(sk, drain_gain);  /* slow, to drain */
+		bbr->cwnd_gain	 = bbr_param(sk, startup_cwnd_gain);  /* keep cwnd */
 		break;
 	case BBR_PROBE_BW:
-		bbr->pacing_gain = (bbr->lt_use_bw ?
-				    BBR_UNIT :
-				    bbr_pacing_gain[bbr->cycle_idx]);
-		bbr->cwnd_gain	 = bbr_cwnd_gain;
+		bbr->pacing_gain = bbr_pacing_gain[bbr->cycle_idx];
+		bbr->cwnd_gain	 = bbr_param(sk, cwnd_gain);
+		if (bbr_param(sk, bw_probe_cwnd_gain) &&
+		    bbr->cycle_idx == BBR_BW_PROBE_UP)
+			bbr->cwnd_gain +=
+				BBR_UNIT * bbr_param(sk, bw_probe_cwnd_gain) / 4;
 		break;
 	case BBR_PROBE_RTT:
 		bbr->pacing_gain = BBR_UNIT;
@@ -1013,27 +972,1108 @@ static void bbr_update_gains(struct sock
 	}
 }
 
-static void bbr_update_model(struct sock *sk, const struct rate_sample *rs)
+__bpf_kfunc static u32 bbr_sndbuf_expand(struct sock *sk)
+{
+	/* Provision 3 * cwnd since BBR may slow-start even during recovery. */
+	return 3;
+}
+
+/* Incorporate a new bw sample into the current window of our max filter. */
+static void bbr_take_max_bw_sample(struct sock *sk, u32 bw)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	bbr->bw_hi[1] = max(bw, bbr->bw_hi[1]);
+}
+
+/* Keep max of last 1-2 cycles. Each PROBE_BW cycle, flip filter window. */
+static void bbr_advance_max_bw_filter(struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	if (!bbr->bw_hi[1])
+		return;  /* no samples in this window; remember old window */
+	bbr->bw_hi[0] = bbr->bw_hi[1];
+	bbr->bw_hi[1] = 0;
+}
+
+/* Reset the estimator for reaching full bandwidth based on bw plateau. */
+static void bbr_reset_full_bw(struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	bbr->full_bw = 0;
+	bbr->full_bw_cnt = 0;
+	bbr->full_bw_now = 0;
+}
+
+/* How much do we want in flight? Our BDP, unless congestion cut cwnd. */
+static u32 bbr_target_inflight(struct sock *sk)
+{
+	u32 bdp = bbr_inflight(sk, bbr_bw(sk), BBR_UNIT);
+
+	return min(bdp, tcp_sk(sk)->snd_cwnd);
+}
+
+static bool bbr_is_probing_bandwidth(struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	return (bbr->mode == BBR_STARTUP) ||
+		(bbr->mode == BBR_PROBE_BW &&
+		 (bbr->cycle_idx == BBR_BW_PROBE_REFILL ||
+		  bbr->cycle_idx == BBR_BW_PROBE_UP));
+}
+
+/* Has the given amount of time elapsed since we marked the phase start? */
+static bool bbr_has_elapsed_in_phase(const struct sock *sk, u32 interval_us)
+{
+	const struct tcp_sock *tp = tcp_sk(sk);
+	const struct bbr *bbr = inet_csk_ca(sk);
+
+	return tcp_stamp_us_delta(tp->tcp_mstamp,
+				  bbr->cycle_mstamp + interval_us) > 0;
+}
+
+static void bbr_handle_queue_too_high_in_startup(struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 bdp;  /* estimated BDP in packets, with quantization budget */
+
+	bbr->full_bw_reached = 1;
+
+	bdp = bbr_inflight(sk, bbr_max_bw(sk), BBR_UNIT);
+	bbr->inflight_hi = max(bdp, bbr->inflight_latest);
+}
+
+/* Exit STARTUP upon N consecutive rounds with ECN mark rate > ecn_thresh. */
+static void bbr_check_ecn_too_high_in_startup(struct sock *sk, u32 ce_ratio)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	if (bbr_full_bw_reached(sk) || !bbr->ecn_eligible ||
+	    !bbr_param(sk, full_ecn_cnt) || !bbr_param(sk, ecn_thresh))
+		return;
+
+	if (ce_ratio >= bbr_param(sk, ecn_thresh))
+		bbr->startup_ecn_rounds++;
+	else
+		bbr->startup_ecn_rounds = 0;
+
+	if (bbr->startup_ecn_rounds >= bbr_param(sk, full_ecn_cnt)) {
+		bbr_handle_queue_too_high_in_startup(sk);
+		return;
+	}
+}
+
+/* Updates ecn_alpha and returns ce_ratio. -1 if not available. */
+static int bbr_update_ecn_alpha(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct net *net = sock_net(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+	s32 delivered, delivered_ce;
+	u64 alpha, ce_ratio;
+	u32 gain;
+	bool want_ecn_alpha;
+
+	/* See if we should use ECN sender logic for this connection. */
+	if (!bbr->ecn_eligible && bbr_can_use_ecn(sk) &&
+	    !!bbr_param(sk, ecn_factor) &&
+	    (bbr->min_rtt_us <= bbr_ecn_max_rtt_us ||
+	     !bbr_ecn_max_rtt_us))
+		bbr->ecn_eligible = 1;
+
+	/* Skip updating alpha only if not ECN-eligible and PLB is disabled. */
+	want_ecn_alpha = (bbr->ecn_eligible ||
+			  (bbr_can_use_ecn(sk) &&
+			   READ_ONCE(net->ipv4.sysctl_tcp_plb_enabled)));
+	if (!want_ecn_alpha)
+		return -1;
+
+	delivered = tp->delivered - bbr->alpha_last_delivered;
+	delivered_ce = tp->delivered_ce - bbr->alpha_last_delivered_ce;
+
+	if (delivered == 0 ||		/* avoid divide by zero */
+	    WARN_ON_ONCE(delivered < 0 || delivered_ce < 0))  /* backwards? */
+		return -1;
+
+	BUILD_BUG_ON(BBR_SCALE != TCP_PLB_SCALE);
+	ce_ratio = (u64)delivered_ce << BBR_SCALE;
+	do_div(ce_ratio, delivered);
+
+	gain = bbr_param(sk, ecn_alpha_gain);
+	alpha = ((BBR_UNIT - gain) * bbr->ecn_alpha) >> BBR_SCALE;
+	alpha += (gain * ce_ratio) >> BBR_SCALE;
+	bbr->ecn_alpha = min_t(u32, alpha, BBR_UNIT);
+
+	bbr->alpha_last_delivered = tp->delivered;
+	bbr->alpha_last_delivered_ce = tp->delivered_ce;
+
+	bbr_check_ecn_too_high_in_startup(sk, ce_ratio);
+	return (int)ce_ratio;
+}
+
+/* Protective Load Balancing (PLB). PLB rehashes outgoing data (to a new IPv6
+ * flow label) if it encounters sustained congestion in the form of ECN marks.
+ */
+static void bbr_plb(struct sock *sk, const struct rate_sample *rs, int ce_ratio)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	if (bbr->round_start && ce_ratio >= 0)
+		tcp_plb_update_state(sk, &bbr->plb, ce_ratio);
+
+	tcp_plb_check_rehash(sk, &bbr->plb);
+}
+
+/* Each round trip of BBR_BW_PROBE_UP, double volume of probing data. */
+static void bbr_raise_inflight_hi_slope(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 growth_this_round, cnt;
+
+	/* Calculate "slope": packets S/Acked per inflight_hi increment. */
+	growth_this_round = 1 << bbr->bw_probe_up_rounds;
+	bbr->bw_probe_up_rounds = min(bbr->bw_probe_up_rounds + 1, 30);
+	cnt = tcp_snd_cwnd(tp) / growth_this_round;
+	cnt = max(cnt, 1U);
+	bbr->bw_probe_up_cnt = cnt;
+}
+
+/* In BBR_BW_PROBE_UP, not seeing high loss/ECN/queue, so raise inflight_hi. */
+static void bbr_probe_inflight_hi_upward(struct sock *sk,
+					  const struct rate_sample *rs)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 delta;
+
+	if (!tp->is_cwnd_limited || tcp_snd_cwnd(tp) < bbr->inflight_hi)
+		return;  /* not fully using inflight_hi, so don't grow it */
+
+	/* For each bw_probe_up_cnt packets ACKed, increase inflight_hi by 1. */
+	bbr->bw_probe_up_acks += rs->acked_sacked;
+	if (bbr->bw_probe_up_acks >=  bbr->bw_probe_up_cnt) {
+		delta = bbr->bw_probe_up_acks / bbr->bw_probe_up_cnt;
+		bbr->bw_probe_up_acks -= delta * bbr->bw_probe_up_cnt;
+		bbr->inflight_hi += delta;
+		bbr->try_fast_path = 0;  /* Need to update cwnd */
+	}
+
+	if (bbr->round_start)
+		bbr_raise_inflight_hi_slope(sk);
+}
+
+/* Does loss/ECN rate for this sample say inflight is "too high"?
+ * This is used by both the bbr_check_loss_too_high_in_startup() function,
+ * and in PROBE_UP.
+ */
+static bool bbr_is_inflight_too_high(const struct sock *sk,
+				      const struct rate_sample *rs)
+{
+	const struct bbr *bbr = inet_csk_ca(sk);
+	u32 loss_thresh, ecn_thresh;
+
+	if (rs->lost > 0 && rs->tx_in_flight) {
+		loss_thresh = (u64)rs->tx_in_flight * bbr_param(sk, loss_thresh) >>
+				BBR_SCALE;
+		if (rs->lost > loss_thresh) {
+			return true;
+		}
+	}
+
+	if (rs->delivered_ce > 0 && rs->delivered > 0 &&
+	    bbr->ecn_eligible && !!bbr_param(sk, ecn_thresh)) {
+		ecn_thresh = (u64)rs->delivered * bbr_param(sk, ecn_thresh) >>
+				BBR_SCALE;
+		if (rs->delivered_ce > ecn_thresh) {
+			return true;
+		}
+	}
+
+	return false;
+}
+
+/* Calculate the tx_in_flight level that corresponded to excessive loss.
+ * We find "lost_prefix" segs of the skb where loss rate went too high,
+ * by solving for "lost_prefix" in the following equation:
+ *   lost                     /  inflight                     >= loss_thresh
+ *  (lost_prev + lost_prefix) / (inflight_prev + lost_prefix) >= loss_thresh
+ * Then we take that equation, convert it to fixed point, and
+ * round up to the nearest packet.
+ */
+static u32 bbr_inflight_hi_from_lost_skb(const struct sock *sk,
+					  const struct rate_sample *rs,
+					  const struct sk_buff *skb)
+{
+	const struct tcp_sock *tp = tcp_sk(sk);
+	u32 loss_thresh  = bbr_param(sk, loss_thresh);
+	u32 pcount, divisor, inflight_hi;
+	s32 inflight_prev, lost_prev;
+	u64 loss_budget, lost_prefix;
+
+	pcount = tcp_skb_pcount(skb);
+
+	/* How much data was in flight before this skb? */
+	inflight_prev = rs->tx_in_flight - pcount;
+	if (inflight_prev < 0) {
+		WARN_ONCE(tcp_skb_tx_in_flight_is_suspicious(
+				  pcount,
+				  TCP_SKB_CB(skb)->sacked,
+				  rs->tx_in_flight),
+			  "tx_in_flight: %u pcount: %u reneg: %u",
+			  rs->tx_in_flight, pcount, tcp_sk(sk)->is_sack_reneg);
+		return ~0U;
+	}
+
+	/* How much inflight data was marked lost before this skb? */
+	lost_prev = rs->lost - pcount;
+	if (WARN_ONCE(lost_prev < 0,
+		      "cwnd: %u ca: %d out: %u lost: %u pif: %u "
+		      "tx_in_flight: %u tx.lost: %u tp->lost: %u rs->lost: %d "
+		      "lost_prev: %d pcount: %d seq: %u end_seq: %u reneg: %u",
+		      tcp_snd_cwnd(tp), inet_csk(sk)->icsk_ca_state,
+		      tp->packets_out, tp->lost_out, tcp_packets_in_flight(tp),
+		      rs->tx_in_flight, TCP_SKB_CB(skb)->tx.lost, tp->lost,
+		      rs->lost, lost_prev, pcount,
+		      TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq,
+		      tp->is_sack_reneg))
+		return ~0U;
+
+	/* At what prefix of this lost skb did losss rate exceed loss_thresh? */
+	loss_budget = (u64)inflight_prev * loss_thresh + BBR_UNIT - 1;
+	loss_budget >>= BBR_SCALE;
+	if (lost_prev >= loss_budget) {
+		lost_prefix = 0;   /* previous losses crossed loss_thresh */
+	} else {
+		lost_prefix = loss_budget - lost_prev;
+		lost_prefix <<= BBR_SCALE;
+		divisor = BBR_UNIT - loss_thresh;
+		if (WARN_ON_ONCE(!divisor))  /* loss_thresh is 8 bits */
+			return ~0U;
+		do_div(lost_prefix, divisor);
+	}
+
+	inflight_hi = inflight_prev + lost_prefix;
+	return inflight_hi;
+}
+
+/* If loss/ECN rates during probing indicated we may have overfilled a
+ * buffer, return an operating point that tries to leave unutilized headroom in
+ * the path for other flows, for fairness convergence and lower RTTs and loss.
+ */
+static u32 bbr_inflight_with_headroom(const struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 headroom, headroom_fraction;
+
+	if (bbr->inflight_hi == ~0U)
+		return ~0U;
+
+	headroom_fraction = bbr_param(sk, inflight_headroom);
+	headroom = ((u64)bbr->inflight_hi * headroom_fraction) >> BBR_SCALE;
+	headroom = max(headroom, 1U);
+	return max_t(s32, bbr->inflight_hi - headroom,
+		     bbr_param(sk, cwnd_min_target));
+}
+
+/* Bound cwnd to a sensible level, based on our current probing state
+ * machine phase and model of a good inflight level (inflight_lo, inflight_hi).
+ */
+static void bbr_bound_cwnd_for_inflight_model(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 cap;
+
+	/* tcp_rcv_synsent_state_process() currently calls tcp_ack()
+	 * and thus cong_control() without first initializing us(!).
+	 */
+	if (!bbr->initialized)
+		return;
+
+	cap = ~0U;
+	if (bbr->mode == BBR_PROBE_BW &&
+	    bbr->cycle_idx != BBR_BW_PROBE_CRUISE) {
+		/* Probe to see if more packets fit in the path. */
+		cap = bbr->inflight_hi;
+	} else {
+		if (bbr->mode == BBR_PROBE_RTT ||
+		    (bbr->mode == BBR_PROBE_BW &&
+		     bbr->cycle_idx == BBR_BW_PROBE_CRUISE))
+			cap = bbr_inflight_with_headroom(sk);
+	}
+	/* Adapt to any loss/ECN since our last bw probe. */
+	cap = min(cap, bbr->inflight_lo);
+
+	cap = max_t(u32, cap, bbr_param(sk, cwnd_min_target));
+	tcp_snd_cwnd_set(tp, min(cap, tcp_snd_cwnd(tp)));
+}
+
+/* How should we multiplicatively cut bw or inflight limits based on ECN? */
+static u32 bbr_ecn_cut(struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	return BBR_UNIT -
+		((bbr->ecn_alpha * bbr_param(sk, ecn_factor)) >> BBR_SCALE);
+}
+
+/* Init lower bounds if have not inited yet. */
+static void bbr_init_lower_bounds(struct sock *sk, bool init_bw)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	if (init_bw && bbr->bw_lo == ~0U)
+		bbr->bw_lo = bbr_max_bw(sk);
+	if (bbr->inflight_lo == ~0U)
+		bbr->inflight_lo = tcp_snd_cwnd(tp);
+}
+
+/* Reduce bw and inflight to (1 - beta). */
+static void bbr_loss_lower_bounds(struct sock *sk, u32 *bw, u32 *inflight)
+{
+	struct bbr* bbr = inet_csk_ca(sk);
+	u32 loss_cut = BBR_UNIT - bbr_param(sk, beta);
+
+	*bw = max_t(u32, bbr->bw_latest,
+		    (u64)bbr->bw_lo * loss_cut >> BBR_SCALE);
+	*inflight = max_t(u32, bbr->inflight_latest,
+			  (u64)bbr->inflight_lo * loss_cut >> BBR_SCALE);
+}
+
+/* Reduce inflight to (1 - alpha*ecn_factor). */
+static void bbr_ecn_lower_bounds(struct sock *sk, u32 *inflight)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 ecn_cut = bbr_ecn_cut(sk);
+
+	*inflight = (u64)bbr->inflight_lo * ecn_cut >> BBR_SCALE;
+}
+
+/* Estimate a short-term lower bound on the capacity available now, based
+ * on measurements of the current delivery process and recent history. When we
+ * are seeing loss/ECN at times when we are not probing bw, then conservatively
+ * move toward flow balance by multiplicatively cutting our short-term
+ * estimated safe rate and volume of data (bw_lo and inflight_lo). We use a
+ * multiplicative decrease in order to converge to a lower capacity in time
+ * logarithmic in the magnitude of the decrease.
+ *
+ * However, we do not cut our short-term estimates lower than the current rate
+ * and volume of delivered data from this round trip, since from the current
+ * delivery process we can estimate the measured capacity available now.
+ *
+ * Anything faster than that approach would knowingly risk high loss, which can
+ * cause low bw for Reno/CUBIC and high loss recovery latency for
+ * request/response flows using any congestion control.
+ */
+static void bbr_adapt_lower_bounds(struct sock *sk,
+				    const struct rate_sample *rs)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 ecn_inflight_lo = ~0U;
+
+	/* We only use lower-bound estimates when not probing bw.
+	 * When probing we need to push inflight higher to probe bw.
+	 */
+	if (bbr_is_probing_bandwidth(sk))
+		return;
+
+	/* ECN response. */
+	if (bbr->ecn_in_round && !!bbr_param(sk, ecn_factor)) {
+		bbr_init_lower_bounds(sk, false);
+		bbr_ecn_lower_bounds(sk, &ecn_inflight_lo);
+	}
+
+	/* Loss response. */
+	if (bbr->loss_in_round) {
+		bbr_init_lower_bounds(sk, true);
+		bbr_loss_lower_bounds(sk, &bbr->bw_lo, &bbr->inflight_lo);
+	}
+
+	/* Adjust to the lower of the levels implied by loss/ECN. */
+	bbr->inflight_lo = min(bbr->inflight_lo, ecn_inflight_lo);
+	bbr->bw_lo = max(1U, bbr->bw_lo);
+}
+
+/* Reset any short-term lower-bound adaptation to congestion, so that we can
+ * push our inflight up.
+ */
+static void bbr_reset_lower_bounds(struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	bbr->bw_lo = ~0U;
+	bbr->inflight_lo = ~0U;
+}
+
+/* After bw probing (STARTUP/PROBE_UP), reset signals before entering a state
+ * machine phase where we adapt our lower bound based on congestion signals.
+ */
+static void bbr_reset_congestion_signals(struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	bbr->loss_in_round = 0;
+	bbr->ecn_in_round = 0;
+	bbr->loss_in_cycle = 0;
+	bbr->ecn_in_cycle = 0;
+	bbr->bw_latest = 0;
+	bbr->inflight_latest = 0;
+}
+
+static void bbr_exit_loss_recovery(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	tcp_snd_cwnd_set(tp, max(tcp_snd_cwnd(tp), bbr->prior_cwnd));
+	bbr->try_fast_path = 0; /* bound cwnd using latest model */
+}
+
+/* Update rate and volume of delivered data from latest round trip. */
+static void bbr_update_latest_delivery_signals(
+	struct sock *sk, const struct rate_sample *rs, struct bbr_context *ctx)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	bbr->loss_round_start = 0;
+	if (rs->interval_us <= 0 || !rs->acked_sacked)
+		return; /* Not a valid observation */
+
+	bbr->bw_latest       = max_t(u32, bbr->bw_latest,       ctx->sample_bw);
+	bbr->inflight_latest = max_t(u32, bbr->inflight_latest, rs->delivered);
+
+	if (!before(rs->prior_delivered, bbr->loss_round_delivered)) {
+		bbr->loss_round_delivered = tp->delivered;
+		bbr->loss_round_start = 1;  /* mark start of new round trip */
+	}
+}
+
+/* Once per round, reset filter for latest rate and volume of delivered data. */
+static void bbr_advance_latest_delivery_signals(
+	struct sock *sk, const struct rate_sample *rs, struct bbr_context *ctx)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	/* If ACK matches a TLP retransmit, persist the filter. If we detect
+	 * that a TLP retransmit plugged a tail loss, we'll want to remember
+	 * how much data the path delivered before the tail loss.
+	 */
+	if (bbr->loss_round_start && !rs->is_acking_tlp_retrans_seq) {
+		bbr->bw_latest = ctx->sample_bw;
+		bbr->inflight_latest = rs->delivered;
+	}
+}
+
+/* Update (most of) our congestion signals: track the recent rate and volume of
+ * delivered data, presence of loss, and EWMA degree of ECN marking.
+ */
+static void bbr_update_congestion_signals(
+	struct sock *sk, const struct rate_sample *rs, struct bbr_context *ctx)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+	u64 bw;
+
+	if (rs->interval_us <= 0 || !rs->acked_sacked)
+		return; /* Not a valid observation */
+	bw = ctx->sample_bw;
+
+	if (!rs->is_app_limited || bw >= bbr_max_bw(sk))
+		bbr_take_max_bw_sample(sk, bw);
+
+	bbr->loss_in_round |= (rs->losses > 0);
+
+	if (!bbr->loss_round_start)
+		return;		/* skip the per-round-trip updates */
+	/* Now do per-round-trip updates. */
+	bbr_adapt_lower_bounds(sk, rs);
+
+	bbr->loss_in_round = 0;
+	bbr->ecn_in_round  = 0;
+}
+
+/* Bandwidth probing can cause loss. To help coexistence with loss-based
+ * congestion control we spread out our probing in a Reno-conscious way. Due to
+ * the shape of the Reno sawtooth, the time required between loss epochs for an
+ * idealized Reno flow is a number of round trips that is the BDP of that
+ * flow. We count packet-timed round trips directly, since measured RTT can
+ * vary widely, and Reno is driven by packet-timed round trips.
+ */
+static bool bbr_is_reno_coexistence_probe_time(struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 rounds;
+
+	/* Random loss can shave some small percentage off of our inflight
+	 * in each round. To survive this, flows need robust periodic probes.
+	 */
+	rounds = min_t(u32, bbr_param(sk, bw_probe_max_rounds), bbr_target_inflight(sk));
+	return bbr->rounds_since_probe >= rounds;
+}
+
+/* How long do we want to wait before probing for bandwidth (and risking
+ * loss)? We randomize the wait, for better mixing and fairness convergence.
+ *
+ * We bound the Reno-coexistence inter-bw-probe time to be 62-63 round trips.
+ * This is calculated to allow fairness with a 25Mbps, 30ms Reno flow,
+ * (eg 4K video to a broadband user):
+ *   BDP = 25Mbps * .030sec /(1514bytes) = 61.9 packets
+ *
+ * We bound the BBR-native inter-bw-probe wall clock time to be:
+ *  (a) higher than 2 sec: to try to avoid causing loss for a long enough time
+ *      to allow Reno at 30ms to get 4K video bw, the inter-bw-probe time must
+ *      be at least: 25Mbps * .030sec / (1514bytes) * 0.030sec = 1.9secs
+ *  (b) lower than 3 sec: to ensure flows can start probing in a reasonable
+ *      amount of time to discover unutilized bw on human-scale interactive
+ *      time-scales (e.g. perhaps traffic from a web page download that we
+ *      were competing with is now complete).
+ */
+static void bbr_pick_probe_wait(struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	/* Decide the random round-trip bound for wait until probe: */
+	bbr->rounds_since_probe =
+		get_random_u32_below(bbr_param(sk, bw_probe_rand_rounds));
+	/* Decide the random wall clock bound for wait until probe: */
+	bbr->probe_wait_us = bbr_param(sk, bw_probe_base_us) +
+			     get_random_u32_below(bbr_param(sk, bw_probe_rand_us));
+}
+
+static void bbr_set_cycle_idx(struct sock *sk, int cycle_idx)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	bbr->cycle_idx = cycle_idx;
+	/* New phase, so need to update cwnd and pacing rate. */
+	bbr->try_fast_path = 0;
+}
+
+/* Send at estimated bw to fill the pipe, but not queue. We need this phase
+ * before PROBE_UP, because as soon as we send faster than the available bw
+ * we will start building a queue, and if the buffer is shallow we can cause
+ * loss. If we do not fill the pipe before we cause this loss, our bw_hi and
+ * inflight_hi estimates will underestimate.
+ */
+static void bbr_start_bw_probe_refill(struct sock *sk, u32 bw_probe_up_rounds)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	bbr_reset_lower_bounds(sk);
+	bbr->bw_probe_up_rounds = bw_probe_up_rounds;
+	bbr->bw_probe_up_acks = 0;
+	bbr->stopped_risky_probe = 0;
+	bbr->ack_phase = BBR_ACKS_REFILLING;
+	bbr->next_rtt_delivered = tp->delivered;
+	bbr_set_cycle_idx(sk, BBR_BW_PROBE_REFILL);
+}
+
+/* Now probe max deliverable data rate and volume. */
+static void bbr_start_bw_probe_up(struct sock *sk, struct bbr_context *ctx)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	bbr->ack_phase = BBR_ACKS_PROBE_STARTING;
+	bbr->next_rtt_delivered = tp->delivered;
+	bbr->cycle_mstamp = tp->tcp_mstamp;
+	bbr_reset_full_bw(sk);
+	bbr->full_bw = ctx->sample_bw;
+	bbr_set_cycle_idx(sk, BBR_BW_PROBE_UP);
+	bbr_raise_inflight_hi_slope(sk);
+}
+
+/* Start a new PROBE_BW probing cycle of some wall clock length. Pick a wall
+ * clock time at which to probe beyond an inflight that we think to be
+ * safe. This will knowingly risk packet loss, so we want to do this rarely, to
+ * keep packet loss rates low. Also start a round-trip counter, to probe faster
+ * if we estimate a Reno flow at our BDP would probe faster.
+ */
+static void bbr_start_bw_probe_down(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	bbr_reset_congestion_signals(sk);
+	bbr->bw_probe_up_cnt = ~0U;     /* not growing inflight_hi any more */
+	bbr_pick_probe_wait(sk);
+	bbr->cycle_mstamp = tp->tcp_mstamp;		/* start wall clock */
+	bbr->ack_phase = BBR_ACKS_PROBE_STOPPING;
+	bbr->next_rtt_delivered = tp->delivered;
+	bbr_set_cycle_idx(sk, BBR_BW_PROBE_DOWN);
+}
+
+/* Cruise: maintain what we estimate to be a neutral, conservative
+ * operating point, without attempting to probe up for bandwidth or down for
+ * RTT, and only reducing inflight in response to loss/ECN signals.
+ */
+static void bbr_start_bw_probe_cruise(struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	if (bbr->inflight_lo != ~0U)
+		bbr->inflight_lo = min(bbr->inflight_lo, bbr->inflight_hi);
+
+	bbr_set_cycle_idx(sk, BBR_BW_PROBE_CRUISE);
+}
+
+/* Loss and/or ECN rate is too high while probing.
+ * Adapt (once per bw probe) by cutting inflight_hi and then restarting cycle.
+ */
+static void bbr_handle_inflight_too_high(struct sock *sk,
+					  const struct rate_sample *rs)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+	const u32 beta = bbr_param(sk, beta);
+
+	bbr->prev_probe_too_high = 1;
+	bbr->bw_probe_samples = 0;  /* only react once per probe */
+	/* If we are app-limited then we are not robustly
+	 * probing the max volume of inflight data we think
+	 * might be safe (analogous to how app-limited bw
+	 * samples are not known to be robustly probing bw).
+	 */
+	if (!rs->is_app_limited) {
+		bbr->inflight_hi = max_t(u32, rs->tx_in_flight,
+					 (u64)bbr_target_inflight(sk) *
+					 (BBR_UNIT - beta) >> BBR_SCALE);
+	}
+	if (bbr->mode == BBR_PROBE_BW && bbr->cycle_idx == BBR_BW_PROBE_UP)
+		bbr_start_bw_probe_down(sk);
+}
+
+/* If we're seeing bw and loss samples reflecting our bw probing, adapt
+ * using the signals we see. If loss or ECN mark rate gets too high, then adapt
+ * inflight_hi downward. If we're able to push inflight higher without such
+ * signals, push higher: adapt inflight_hi upward.
+ */
+static bool bbr_adapt_upper_bounds(struct sock *sk,
+				    const struct rate_sample *rs,
+				    struct bbr_context *ctx)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	/* Track when we'll see bw/loss samples resulting from our bw probes. */
+	if (bbr->ack_phase == BBR_ACKS_PROBE_STARTING && bbr->round_start)
+		bbr->ack_phase = BBR_ACKS_PROBE_FEEDBACK;
+	if (bbr->ack_phase == BBR_ACKS_PROBE_STOPPING && bbr->round_start) {
+		/* End of samples from bw probing phase. */
+		bbr->bw_probe_samples = 0;
+		bbr->ack_phase = BBR_ACKS_INIT;
+		/* At this point in the cycle, our current bw sample is also
+		 * our best recent chance at finding the highest available bw
+		 * for this flow. So now is the best time to forget the bw
+		 * samples from the previous cycle, by advancing the window.
+		 */
+		if (bbr->mode == BBR_PROBE_BW && !rs->is_app_limited)
+			bbr_advance_max_bw_filter(sk);
+		/* If we had an inflight_hi, then probed and pushed inflight all
+		 * the way up to hit that inflight_hi without seeing any
+		 * high loss/ECN in all the resulting ACKs from that probing,
+		 * then probe up again, this time letting inflight persist at
+		 * inflight_hi for a round trip, then accelerating beyond.
+		 */
+		if (bbr->mode == BBR_PROBE_BW &&
+		    bbr->stopped_risky_probe && !bbr->prev_probe_too_high) {
+			bbr_start_bw_probe_refill(sk, 0);
+			return true;  /* yes, decided state transition */
+		}
+	}
+	if (bbr_is_inflight_too_high(sk, rs)) {
+		if (bbr->bw_probe_samples)  /*  sample is from bw probing? */
+			bbr_handle_inflight_too_high(sk, rs);
+	} else {
+		/* Loss/ECN rate is declared safe. Adjust upper bound upward. */
+
+		if (bbr->inflight_hi == ~0U)
+			return false;   /* no excess queue signals yet */
+
+		/* To be resilient to random loss, we must raise bw/inflight_hi
+		 * if we observe in any phase that a higher level is safe.
+		 */
+		if (rs->tx_in_flight > bbr->inflight_hi) {
+			bbr->inflight_hi = rs->tx_in_flight;
+		}
+
+		if (bbr->mode == BBR_PROBE_BW &&
+		    bbr->cycle_idx == BBR_BW_PROBE_UP)
+			bbr_probe_inflight_hi_upward(sk, rs);
+	}
+
+	return false;
+}
+
+/* Check if it's time to probe for bandwidth now, and if so, kick it off. */
+static bool bbr_check_time_to_probe_bw(struct sock *sk,
+					const struct rate_sample *rs)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 n;
+
+	/* If we seem to be at an operating point where we are not seeing loss
+	 * but we are seeing ECN marks, then when the ECN marks cease we reprobe
+	 * quickly (in case cross-traffic has ceased and freed up bw).
+	 */
+	if (bbr_param(sk, ecn_reprobe_gain) && bbr->ecn_eligible &&
+	    bbr->ecn_in_cycle && !bbr->loss_in_cycle &&
+	    inet_csk(sk)->icsk_ca_state == TCP_CA_Open) {
+		/* Calculate n so that when bbr_raise_inflight_hi_slope()
+		 * computes growth_this_round as 2^n it will be roughly the
+		 * desired volume of data (inflight_hi*ecn_reprobe_gain).
+		 */
+		n = ilog2((((u64)bbr->inflight_hi *
+			    bbr_param(sk, ecn_reprobe_gain)) >> BBR_SCALE));
+		bbr_start_bw_probe_refill(sk, n);
+		return true;
+	}
+
+	if (bbr_has_elapsed_in_phase(sk, bbr->probe_wait_us) ||
+	    bbr_is_reno_coexistence_probe_time(sk)) {
+		bbr_start_bw_probe_refill(sk, 0);
+		return true;
+	}
+	return false;
+}
+
+/* Is it time to transition from PROBE_DOWN to PROBE_CRUISE? */
+static bool bbr_check_time_to_cruise(struct sock *sk, u32 inflight, u32 bw)
+{
+	/* Always need to pull inflight down to leave headroom in queue. */
+	if (inflight > bbr_inflight_with_headroom(sk))
+		return false;
+
+	return inflight <= bbr_inflight(sk, bw, BBR_UNIT);
+}
+
+/* PROBE_BW state machine: cruise, refill, probe for bw, or drain? */
+static void bbr_update_cycle_phase(struct sock *sk,
+				    const struct rate_sample *rs,
+				    struct bbr_context *ctx)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+	bool is_bw_probe_done = false;
+	u32 inflight, bw;
+
+	if (!bbr_full_bw_reached(sk))
+		return;
+
+	/* In DRAIN, PROBE_BW, or PROBE_RTT, adjust upper bounds. */
+	if (bbr_adapt_upper_bounds(sk, rs, ctx))
+		return;		/* already decided state transition */
+
+	if (bbr->mode != BBR_PROBE_BW)
+		return;
+
+	inflight = bbr_packets_in_net_at_edt(sk, rs->prior_in_flight);
+	bw = bbr_max_bw(sk);
+
+	switch (bbr->cycle_idx) {
+	/* First we spend most of our time cruising with a pacing_gain of 1.0,
+	 * which paces at the estimated bw, to try to fully use the pipe
+	 * without building queue. If we encounter loss/ECN marks, we adapt
+	 * by slowing down.
+	 */
+	case BBR_BW_PROBE_CRUISE:
+		if (bbr_check_time_to_probe_bw(sk, rs))
+			return;		/* already decided state transition */
+		break;
+
+	/* After cruising, when it's time to probe, we first "refill": we send
+	 * at the estimated bw to fill the pipe, before probing higher and
+	 * knowingly risking overflowing the bottleneck buffer (causing loss).
+	 */
+	case BBR_BW_PROBE_REFILL:
+		if (bbr->round_start) {
+			/* After one full round trip of sending in REFILL, we
+			 * start to see bw samples reflecting our REFILL, which
+			 * may be putting too much data in flight.
+			 */
+			bbr->bw_probe_samples = 1;
+			bbr_start_bw_probe_up(sk, ctx);
+		}
+		break;
+
+	/* After we refill the pipe, we probe by using a pacing_gain > 1.0, to
+	 * probe for bw. If we have not seen loss/ECN, we try to raise inflight
+	 * to at least pacing_gain*BDP; note that this may take more than
+	 * min_rtt if min_rtt is small (e.g. on a LAN).
+	 *
+	 * We terminate PROBE_UP bandwidth probing upon any of the following:
+	 *
+	 * (1) We've pushed inflight up to hit the inflight_hi target set in the
+	 *     most recent previous bw probe phase. Thus we want to start
+	 *     draining the queue immediately because it's very likely the most
+	 *     recently sent packets will fill the queue and cause drops.
+	 * (2) If inflight_hi has not limited bandwidth growth recently, and
+	 *     yet delivered bandwidth has not increased much recently
+	 *     (bbr->full_bw_now).
+	 * (3) Loss filter says loss rate is "too high".
+	 * (4) ECN filter says ECN mark rate is "too high".
+	 *
+	 * (1) (2) checked here, (3) (4) checked in bbr_is_inflight_too_high()
+	 */
+	case BBR_BW_PROBE_UP:
+		if (bbr->prev_probe_too_high &&
+		    inflight >= bbr->inflight_hi) {
+			bbr->stopped_risky_probe = 1;
+			is_bw_probe_done = true;
+		} else {
+			if (tp->is_cwnd_limited &&
+			    tcp_snd_cwnd(tp) >= bbr->inflight_hi) {
+				/* inflight_hi is limiting bw growth */
+				bbr_reset_full_bw(sk);
+				bbr->full_bw = ctx->sample_bw;
+			} else if (bbr->full_bw_now) {
+				/* Plateau in estimated bw. Pipe looks full. */
+				is_bw_probe_done = true;
+			}
+		}
+		if (is_bw_probe_done) {
+			bbr->prev_probe_too_high = 0;  /* no loss/ECN (yet) */
+			bbr_start_bw_probe_down(sk);  /* restart w/ down */
+		}
+		break;
+
+	/* After probing in PROBE_UP, we have usually accumulated some data in
+	 * the bottleneck buffer (if bw probing didn't find more bw). We next
+	 * enter PROBE_DOWN to try to drain any excess data from the queue. To
+	 * do this, we use a pacing_gain < 1.0. We hold this pacing gain until
+	 * our inflight is less then that target cruising point, which is the
+	 * minimum of (a) the amount needed to leave headroom, and (b) the
+	 * estimated BDP. Once inflight falls to match the target, we estimate
+	 * the queue is drained; persisting would underutilize the pipe.
+	 */
+	case BBR_BW_PROBE_DOWN:
+		if (bbr_check_time_to_probe_bw(sk, rs))
+			return;		/* already decided state transition */
+		if (bbr_check_time_to_cruise(sk, inflight, bw))
+			bbr_start_bw_probe_cruise(sk);
+		break;
+
+	default:
+		WARN_ONCE(1, "BBR invalid cycle index %u\n", bbr->cycle_idx);
+	}
+}
+
+/* Exiting PROBE_RTT, so return to bandwidth probing in STARTUP or PROBE_BW. */
+static void bbr_exit_probe_rtt(struct sock *sk)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	bbr_reset_lower_bounds(sk);
+	if (bbr_full_bw_reached(sk)) {
+		bbr->mode = BBR_PROBE_BW;
+		/* Raising inflight after PROBE_RTT may cause loss, so reset
+		 * the PROBE_BW clock and schedule the next bandwidth probe for
+		 * a friendly and randomized future point in time.
+		 */
+		bbr_start_bw_probe_down(sk);
+		/* Since we are exiting PROBE_RTT, we know inflight is
+		 * below our estimated BDP, so it is reasonable to cruise.
+		 */
+		bbr_start_bw_probe_cruise(sk);
+	} else {
+		bbr->mode = BBR_STARTUP;
+	}
+}
+
+/* Exit STARTUP based on loss rate > 1% and loss gaps in round >= N. Wait until
+ * the end of the round in recovery to get a good estimate of how many packets
+ * have been lost, and how many we need to drain with a low pacing rate.
+ */
+static void bbr_check_loss_too_high_in_startup(struct sock *sk,
+						const struct rate_sample *rs)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	if (bbr_full_bw_reached(sk))
+		return;
+
+	/* For STARTUP exit, check the loss rate at the end of each round trip
+	 * of Recovery episodes in STARTUP. We check the loss rate at the end
+	 * of the round trip to filter out noisy/low loss and have a better
+	 * sense of inflight (extent of loss), so we can drain more accurately.
+	 */
+	if (rs->losses && bbr->loss_events_in_round < 0xf)
+		bbr->loss_events_in_round++;  /* update saturating counter */
+	if (bbr_param(sk, full_loss_cnt) && bbr->loss_round_start &&
+	    inet_csk(sk)->icsk_ca_state == TCP_CA_Recovery &&
+	    bbr->loss_events_in_round >= bbr_param(sk, full_loss_cnt) &&
+	    bbr_is_inflight_too_high(sk, rs)) {
+		bbr_handle_queue_too_high_in_startup(sk);
+		return;
+	}
+	if (bbr->loss_round_start)
+		bbr->loss_events_in_round = 0;
+}
+
+/* Estimate when the pipe is full, using the change in delivery rate: BBR
+ * estimates bw probing filled the pipe if the estimated bw hasn't changed by
+ * at least bbr_full_bw_thresh (25%) after bbr_full_bw_cnt (3) non-app-limited
+ * rounds. Why 3 rounds: 1: rwin autotuning grows the rwin, 2: we fill the
+ * higher rwin, 3: we get higher delivery rate samples. Or transient
+ * cross-traffic or radio noise can go away. CUBIC Hystart shares a similar
+ * design goal, but uses delay and inter-ACK spacing instead of bandwidth.
+ */
+static void bbr_check_full_bw_reached(struct sock *sk,
+				       const struct rate_sample *rs,
+				       struct bbr_context *ctx)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 bw_thresh, full_cnt, thresh;
+
+	if (bbr->full_bw_now || rs->is_app_limited)
+		return;
+
+	thresh = bbr_param(sk, full_bw_thresh);
+	full_cnt = bbr_param(sk, full_bw_cnt);
+	bw_thresh = (u64)bbr->full_bw * thresh >> BBR_SCALE;
+	if (ctx->sample_bw >= bw_thresh) {
+		bbr_reset_full_bw(sk);
+		bbr->full_bw = ctx->sample_bw;
+		return;
+	}
+	if (!bbr->round_start)
+		return;
+	++bbr->full_bw_cnt;
+	bbr->full_bw_now = bbr->full_bw_cnt >= full_cnt;
+	bbr->full_bw_reached |= bbr->full_bw_now;
+}
+
+/* If pipe is probably full, drain the queue and then enter steady-state. */
+static void bbr_check_drain(struct sock *sk, const struct rate_sample *rs,
+			    struct bbr_context *ctx)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	if (bbr->mode == BBR_STARTUP && bbr_full_bw_reached(sk)) {
+		bbr->mode = BBR_DRAIN;	/* drain queue we created */
+		/* Set ssthresh to export purely for monitoring, to signal
+		 * completion of initial STARTUP by setting to a non-
+		 * TCP_INFINITE_SSTHRESH value (ssthresh is not used by BBR).
+		 */
+		tcp_sk(sk)->snd_ssthresh =
+				bbr_inflight(sk, bbr_max_bw(sk), BBR_UNIT);
+		bbr_reset_congestion_signals(sk);
+	}	/* fall through to check if in-flight is already small: */
+	if (bbr->mode == BBR_DRAIN &&
+	    bbr_packets_in_net_at_edt(sk, tcp_packets_in_flight(tcp_sk(sk))) <=
+	    bbr_inflight(sk, bbr_max_bw(sk), BBR_UNIT)) {
+		bbr->mode = BBR_PROBE_BW;
+		bbr_start_bw_probe_down(sk);
+	}
+}
+
+static void bbr_update_model(struct sock *sk, const struct rate_sample *rs,
+			      struct bbr_context *ctx)
 {
-	bbr_update_bw(sk, rs);
+	bbr_update_congestion_signals(sk, rs, ctx);
 	bbr_update_ack_aggregation(sk, rs);
-	bbr_update_cycle_phase(sk, rs);
-	bbr_check_full_bw_reached(sk, rs);
-	bbr_check_drain(sk, rs);
+	bbr_check_loss_too_high_in_startup(sk, rs);
+	bbr_check_full_bw_reached(sk, rs, ctx);
+	bbr_check_drain(sk, rs, ctx);
+	bbr_update_cycle_phase(sk, rs, ctx);
 	bbr_update_min_rtt(sk, rs);
-	bbr_update_gains(sk);
 }
 
-__bpf_kfunc static void bbr_main(struct sock *sk, u32 ack, int flag, const struct rate_sample *rs)
+/* Fast path for app-limited case.
+ *
+ * On each ack, we execute bbr state machine, which primarily consists of:
+ * 1) update model based on new rate sample, and
+ * 2) update control based on updated model or state change.
+ *
+ * There are certain workload/scenarios, e.g. app-limited case, where
+ * either we can skip updating model or we can skip update of both model
+ * as well as control. This provides signifcant softirq cpu savings for
+ * processing incoming acks.
+ *
+ * In case of app-limited, if there is no congestion (loss/ecn) and
+ * if observed bw sample is less than current estimated bw, then we can
+ * skip some of the computation in bbr state processing:
+ *
+ * - if there is no rtt/mode/phase change: In this case, since all the
+ *   parameters of the network model are constant, we can skip model
+ *   as well control update.
+ *
+ * - else we can skip rest of the model update. But we still need to
+ *   update the control to account for the new rtt/mode/phase.
+ *
+ * Returns whether we can take fast path or not.
+ */
+static bool bbr_run_fast_path(struct sock *sk, bool *update_model,
+		const struct rate_sample *rs, struct bbr_context *ctx)
+{
+	struct bbr *bbr = inet_csk_ca(sk);
+	u32 prev_min_rtt_us, prev_mode;
+
+	if (bbr_param(sk, fast_path) && bbr->try_fast_path &&
+	    rs->is_app_limited && ctx->sample_bw < bbr_max_bw(sk) &&
+	    !bbr->loss_in_round && !bbr->ecn_in_round ) {
+		prev_mode = bbr->mode;
+		prev_min_rtt_us = bbr->min_rtt_us;
+		bbr_check_drain(sk, rs, ctx);
+		bbr_update_cycle_phase(sk, rs, ctx);
+		bbr_update_min_rtt(sk, rs);
+
+		if (bbr->mode == prev_mode &&
+		    bbr->min_rtt_us == prev_min_rtt_us &&
+		    bbr->try_fast_path) {
+			return true;
+		}
+
+		/* Skip model update, but control still needs to be updated */
+		*update_model = false;
+	}
+	return false;
+}
+
+__bpf_kfunc static void bbr_main(struct sock *sk, u32 ack, int flag,
+				 const struct rate_sample *rs)
 {
+	struct tcp_sock *tp = tcp_sk(sk);
 	struct bbr *bbr = inet_csk_ca(sk);
-	u32 bw;
+	struct bbr_context ctx = { 0 };
+	bool update_model = true;
+	u32 bw, round_delivered;
+	int ce_ratio = -1;
+
+	round_delivered = bbr_update_round_start(sk, rs, &ctx);
+	if (bbr->round_start) {
+		bbr->rounds_since_probe =
+			min_t(s32, bbr->rounds_since_probe + 1, 0xFF);
+		ce_ratio = bbr_update_ecn_alpha(sk);
+	}
+	bbr_plb(sk, rs, ce_ratio);
+
+	bbr->ecn_in_round  |= (bbr->ecn_eligible && rs->is_ece);
+	bbr_calculate_bw_sample(sk, rs, &ctx);
+	bbr_update_latest_delivery_signals(sk, rs, &ctx);
 
-	bbr_update_model(sk, rs);
+	if (bbr_run_fast_path(sk, &update_model, rs, &ctx))
+		goto out;
 
+	if (update_model)
+		bbr_update_model(sk, rs, &ctx);
+
+	bbr_update_gains(sk);
 	bw = bbr_bw(sk);
 	bbr_set_pacing_rate(sk, bw, bbr->pacing_gain);
-	bbr_set_cwnd(sk, rs, rs->acked_sacked, bw, bbr->cwnd_gain);
+	bbr_set_cwnd(sk, rs, rs->acked_sacked, bw, bbr->cwnd_gain,
+		     tcp_snd_cwnd(tp), &ctx);
+	bbr_bound_cwnd_for_inflight_model(sk);
+
+out:
+	bbr_advance_latest_delivery_signals(sk, rs, &ctx);
+	bbr->prev_ca_state = inet_csk(sk)->icsk_ca_state;
+	bbr->loss_in_cycle |= rs->lost > 0;
+	bbr->ecn_in_cycle  |= rs->delivered_ce > 0;
 }
 
 __bpf_kfunc static void bbr_init(struct sock *sk)
@@ -1041,20 +2081,21 @@ __bpf_kfunc static void bbr_init(struct
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct bbr *bbr = inet_csk_ca(sk);
 
-	bbr->prior_cwnd = 0;
+	bbr->initialized = 1;
+
+	bbr->init_cwnd = min(0x7FU, tcp_snd_cwnd(tp));
+	bbr->prior_cwnd = tp->prior_cwnd;
 	tp->snd_ssthresh = TCP_INFINITE_SSTHRESH;
-	bbr->rtt_cnt = 0;
 	bbr->next_rtt_delivered = tp->delivered;
 	bbr->prev_ca_state = TCP_CA_Open;
-	bbr->packet_conservation = 0;
 
 	bbr->probe_rtt_done_stamp = 0;
 	bbr->probe_rtt_round_done = 0;
+	bbr->probe_rtt_min_us = tcp_min_rtt(tp);
+	bbr->probe_rtt_min_stamp = tcp_jiffies32;
 	bbr->min_rtt_us = tcp_min_rtt(tp);
 	bbr->min_rtt_stamp = tcp_jiffies32;
 
-	minmax_reset(&bbr->bw, bbr->rtt_cnt, 0);  /* init max bw to 0 */
-
 	bbr->has_seen_rtt = 0;
 	bbr_init_pacing_rate_from_rtt(sk);
 
@@ -1065,7 +2106,7 @@ __bpf_kfunc static void bbr_init(struct
 	bbr->full_bw_cnt = 0;
 	bbr->cycle_mstamp = 0;
 	bbr->cycle_idx = 0;
-	bbr_reset_lt_bw_sampling(sk);
+
 	bbr_reset_startup_mode(sk);
 
 	bbr->ack_epoch_mstamp = tp->tcp_mstamp;
@@ -1075,82 +2116,243 @@ __bpf_kfunc static void bbr_init(struct
 	bbr->extra_acked[0] = 0;
 	bbr->extra_acked[1] = 0;
 
+	bbr->ce_state = 0;
+	bbr->prior_rcv_nxt = tp->rcv_nxt;
+	bbr->try_fast_path = 0;
+
 	cmpxchg(&sk->sk_pacing_status, SK_PACING_NONE, SK_PACING_NEEDED);
+
+	/* Start sampling ECN mark rate after first full flight is ACKed: */
+	bbr->loss_round_delivered = tp->delivered + 1;
+	bbr->loss_round_start = 0;
+	bbr->undo_bw_lo = 0;
+	bbr->undo_inflight_lo = 0;
+	bbr->undo_inflight_hi = 0;
+	bbr->loss_events_in_round = 0;
+	bbr->startup_ecn_rounds = 0;
+	bbr_reset_congestion_signals(sk);
+	bbr->bw_lo = ~0U;
+	bbr->bw_hi[0] = 0;
+	bbr->bw_hi[1] = 0;
+	bbr->inflight_lo = ~0U;
+	bbr->inflight_hi = ~0U;
+	bbr_reset_full_bw(sk);
+	bbr->bw_probe_up_cnt = ~0U;
+	bbr->bw_probe_up_acks = 0;
+	bbr->bw_probe_up_rounds = 0;
+	bbr->probe_wait_us = 0;
+	bbr->stopped_risky_probe = 0;
+	bbr->ack_phase = BBR_ACKS_INIT;
+	bbr->rounds_since_probe = 0;
+	bbr->bw_probe_samples = 0;
+	bbr->prev_probe_too_high = 0;
+	bbr->ecn_eligible = 0;
+	bbr->ecn_alpha = bbr_param(sk, ecn_alpha_init);
+	bbr->alpha_last_delivered = 0;
+	bbr->alpha_last_delivered_ce = 0;
+	bbr->plb.pause_until = 0;
+
+	tp->fast_ack_mode = bbr_fast_ack_mode ? 1 : 0;
+
+	if (bbr_can_use_ecn(sk))
+		tp->ecn_flags |= TCP_ECN_ECT_PERMANENT;
 }
 
-__bpf_kfunc static u32 bbr_sndbuf_expand(struct sock *sk)
+/* BBR marks the current round trip as a loss round. */
+static void bbr_note_loss(struct sock *sk)
 {
-	/* Provision 3 * cwnd since BBR may slow-start even during recovery. */
-	return 3;
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+
+	/* Capture "current" data over the full round trip of loss, to
+	 * have a better chance of observing the full capacity of the path.
+	 */
+	if (!bbr->loss_in_round)  /* first loss in this round trip? */
+		bbr->loss_round_delivered = tp->delivered;  /* set round trip */
+	bbr->loss_in_round = 1;
+	bbr->loss_in_cycle = 1;
 }
 
-/* In theory BBR does not need to undo the cwnd since it does not
- * always reduce cwnd on losses (see bbr_main()). Keep it for now.
- */
+/* Core TCP stack informs us that the given skb was just marked lost. */
+__bpf_kfunc static void bbr_skb_marked_lost(struct sock *sk,
+					    const struct sk_buff *skb)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+	struct tcp_skb_cb *scb = TCP_SKB_CB(skb);
+	struct rate_sample rs = {};
+
+	bbr_note_loss(sk);
+
+	if (!bbr->bw_probe_samples)
+		return;  /* not an skb sent while probing for bandwidth */
+	if (unlikely(!scb->tx.delivered_mstamp))
+		return;  /* skb was SACKed, reneged, marked lost; ignore it */
+	/* We are probing for bandwidth. Construct a rate sample that
+	 * estimates what happened in the flight leading up to this lost skb,
+	 * then see if the loss rate went too high, and if so at which packet.
+	 */
+	rs.tx_in_flight = scb->tx.in_flight;
+	rs.lost = tp->lost - scb->tx.lost;
+	rs.is_app_limited = scb->tx.is_app_limited;
+	if (bbr_is_inflight_too_high(sk, &rs)) {
+		rs.tx_in_flight = bbr_inflight_hi_from_lost_skb(sk, &rs, skb);
+		bbr_handle_inflight_too_high(sk, &rs);
+	}
+}
+
+static void bbr_run_loss_probe_recovery(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct bbr *bbr = inet_csk_ca(sk);
+	struct rate_sample rs = {0};
+
+	bbr_note_loss(sk);
+
+	if (!bbr->bw_probe_samples)
+		return;  /* not sent while probing for bandwidth */
+	/* We are probing for bandwidth. Construct a rate sample that
+	 * estimates what happened in the flight leading up to this
+	 * loss, then see if the loss rate went too high.
+	 */
+	rs.lost = 1;	/* TLP probe repaired loss of a single segment */
+	rs.tx_in_flight = bbr->inflight_latest + rs.lost;
+	rs.is_app_limited = tp->tlp_orig_data_app_limited;
+	if (bbr_is_inflight_too_high(sk, &rs))
+		bbr_handle_inflight_too_high(sk, &rs);
+}
+
+/* Revert short-term model if current loss recovery event was spurious. */
 __bpf_kfunc static u32 bbr_undo_cwnd(struct sock *sk)
 {
 	struct bbr *bbr = inet_csk_ca(sk);
 
-	bbr->full_bw = 0;   /* spurious slow-down; reset full pipe detection */
-	bbr->full_bw_cnt = 0;
-	bbr_reset_lt_bw_sampling(sk);
-	return tcp_snd_cwnd(tcp_sk(sk));
+	bbr_reset_full_bw(sk); /* spurious slow-down; reset full bw detector */
+	bbr->loss_in_round = 0;
+
+	/* Revert to cwnd and other state saved before loss episode. */
+	bbr->bw_lo = max(bbr->bw_lo, bbr->undo_bw_lo);
+	bbr->inflight_lo = max(bbr->inflight_lo, bbr->undo_inflight_lo);
+	bbr->inflight_hi = max(bbr->inflight_hi, bbr->undo_inflight_hi);
+	bbr->try_fast_path = 0;  /* take slow path to set proper cwnd, pacing */
+	return bbr->prior_cwnd;
 }
 
-/* Entering loss recovery, so save cwnd for when we exit or undo recovery. */
+/* Entering loss recovery, so save state for when we undo recovery. */
 __bpf_kfunc static u32 bbr_ssthresh(struct sock *sk)
 {
+	struct bbr *bbr = inet_csk_ca(sk);
+
 	bbr_save_cwnd(sk);
+	/* For undo, save state that adapts based on loss signal. */
+	bbr->undo_bw_lo		= bbr->bw_lo;
+	bbr->undo_inflight_lo	= bbr->inflight_lo;
+	bbr->undo_inflight_hi	= bbr->inflight_hi;
 	return tcp_sk(sk)->snd_ssthresh;
 }
 
+static enum tcp_bbr_phase bbr_get_phase(struct bbr *bbr)
+{
+	switch (bbr->mode) {
+	case BBR_STARTUP:
+		return BBR_PHASE_STARTUP;
+	case BBR_DRAIN:
+		return BBR_PHASE_DRAIN;
+	case BBR_PROBE_BW:
+		break;
+	case BBR_PROBE_RTT:
+		return BBR_PHASE_PROBE_RTT;
+	default:
+		return BBR_PHASE_INVALID;
+	}
+	switch (bbr->cycle_idx) {
+	case BBR_BW_PROBE_UP:
+		return BBR_PHASE_PROBE_BW_UP;
+	case BBR_BW_PROBE_DOWN:
+		return BBR_PHASE_PROBE_BW_DOWN;
+	case BBR_BW_PROBE_CRUISE:
+		return BBR_PHASE_PROBE_BW_CRUISE;
+	case BBR_BW_PROBE_REFILL:
+		return BBR_PHASE_PROBE_BW_REFILL;
+	default:
+		return BBR_PHASE_INVALID;
+	}
+}
+
 static size_t bbr_get_info(struct sock *sk, u32 ext, int *attr,
-			   union tcp_cc_info *info)
+			    union tcp_cc_info *info)
 {
 	if (ext & (1 << (INET_DIAG_BBRINFO - 1)) ||
 	    ext & (1 << (INET_DIAG_VEGASINFO - 1))) {
-		struct tcp_sock *tp = tcp_sk(sk);
 		struct bbr *bbr = inet_csk_ca(sk);
-		u64 bw = bbr_bw(sk);
-
-		bw = bw * tp->mss_cache * USEC_PER_SEC >> BW_SCALE;
-		memset(&info->bbr, 0, sizeof(info->bbr));
-		info->bbr.bbr_bw_lo		= (u32)bw;
-		info->bbr.bbr_bw_hi		= (u32)(bw >> 32);
-		info->bbr.bbr_min_rtt		= bbr->min_rtt_us;
-		info->bbr.bbr_pacing_gain	= bbr->pacing_gain;
-		info->bbr.bbr_cwnd_gain		= bbr->cwnd_gain;
+		u64 bw = bbr_bw_bytes_per_sec(sk, bbr_bw(sk));
+		u64 bw_hi = bbr_bw_bytes_per_sec(sk, bbr_max_bw(sk));
+		u64 bw_lo = bbr->bw_lo == ~0U ?
+			~0ULL : bbr_bw_bytes_per_sec(sk, bbr->bw_lo);
+		struct tcp_bbr_info *bbr_info = &info->bbr;
+
+		memset(bbr_info, 0, sizeof(*bbr_info));
+		bbr_info->bbr_bw_lo		= (u32)bw;
+		bbr_info->bbr_bw_hi		= (u32)(bw >> 32);
+		bbr_info->bbr_min_rtt		= bbr->min_rtt_us;
+		bbr_info->bbr_pacing_gain	= bbr->pacing_gain;
+		bbr_info->bbr_cwnd_gain		= bbr->cwnd_gain;
+		bbr_info->bbr_bw_hi_lsb		= (u32)bw_hi;
+		bbr_info->bbr_bw_hi_msb		= (u32)(bw_hi >> 32);
+		bbr_info->bbr_bw_lo_lsb		= (u32)bw_lo;
+		bbr_info->bbr_bw_lo_msb		= (u32)(bw_lo >> 32);
+		bbr_info->bbr_mode		= bbr->mode;
+		bbr_info->bbr_phase		= (__u8)bbr_get_phase(bbr);
+		bbr_info->bbr_version		= (__u8)BBR_VERSION;
+		bbr_info->bbr_inflight_lo	= bbr->inflight_lo;
+		bbr_info->bbr_inflight_hi	= bbr->inflight_hi;
+		bbr_info->bbr_extra_acked	= bbr_extra_acked(sk);
 		*attr = INET_DIAG_BBRINFO;
-		return sizeof(info->bbr);
+		return sizeof(*bbr_info);
 	}
 	return 0;
 }
 
 __bpf_kfunc static void bbr_set_state(struct sock *sk, u8 new_state)
 {
+	struct tcp_sock *tp = tcp_sk(sk);
 	struct bbr *bbr = inet_csk_ca(sk);
 
 	if (new_state == TCP_CA_Loss) {
-		struct rate_sample rs = { .losses = 1 };
 
 		bbr->prev_ca_state = TCP_CA_Loss;
-		bbr->full_bw = 0;
-		bbr->round_start = 1;	/* treat RTO like end of a round */
-		bbr_lt_bw_sampling(sk, &rs);
+		tcp_plb_update_state_upon_rto(sk, &bbr->plb);
+		/* The tcp_write_timeout() call to sk_rethink_txhash() likely
+		 * repathed this flow, so re-learn the min network RTT on the
+		 * new path:
+		 */
+		bbr_reset_full_bw(sk);
+		if (!bbr_is_probing_bandwidth(sk) && bbr->inflight_lo == ~0U) {
+			/* bbr_adapt_lower_bounds() needs cwnd before
+			 * we suffered an RTO, to update inflight_lo:
+			 */
+			bbr->inflight_lo =
+				max(tcp_snd_cwnd(tp), bbr->prior_cwnd);
+		}
+	} else if (bbr->prev_ca_state == TCP_CA_Loss &&
+		   new_state != TCP_CA_Loss) {
+		bbr_exit_loss_recovery(sk);
 	}
 }
 
+
 static struct tcp_congestion_ops tcp_bbr_cong_ops __read_mostly = {
-	.flags		= TCP_CONG_NON_RESTRICTED,
+	.flags		= TCP_CONG_NON_RESTRICTED | TCP_CONG_WANTS_CE_EVENTS,
 	.name		= "bbr",
 	.owner		= THIS_MODULE,
 	.init		= bbr_init,
 	.cong_control	= bbr_main,
 	.sndbuf_expand	= bbr_sndbuf_expand,
+	.skb_marked_lost = bbr_skb_marked_lost,
 	.undo_cwnd	= bbr_undo_cwnd,
 	.cwnd_event	= bbr_cwnd_event,
 	.ssthresh	= bbr_ssthresh,
-	.min_tso_segs	= bbr_min_tso_segs,
+	.tso_segs	= bbr_tso_segs,
 	.get_info	= bbr_get_info,
 	.set_state	= bbr_set_state,
 };
@@ -1159,10 +2361,11 @@ BTF_KFUNCS_START(tcp_bbr_check_kfunc_ids
 BTF_ID_FLAGS(func, bbr_init)
 BTF_ID_FLAGS(func, bbr_main)
 BTF_ID_FLAGS(func, bbr_sndbuf_expand)
+BTF_ID_FLAGS(func, bbr_skb_marked_lost)
 BTF_ID_FLAGS(func, bbr_undo_cwnd)
 BTF_ID_FLAGS(func, bbr_cwnd_event)
 BTF_ID_FLAGS(func, bbr_ssthresh)
-BTF_ID_FLAGS(func, bbr_min_tso_segs)
+BTF_ID_FLAGS(func, bbr_tso_segs)
 BTF_ID_FLAGS(func, bbr_set_state)
 BTF_KFUNCS_END(tcp_bbr_check_kfunc_ids)
 
@@ -1195,5 +2398,12 @@ MODULE_AUTHOR("Van Jacobson <vanj@google
 MODULE_AUTHOR("Neal Cardwell <ncardwell@google.com>");
 MODULE_AUTHOR("Yuchung Cheng <ycheng@google.com>");
 MODULE_AUTHOR("Soheil Hassas Yeganeh <soheil@google.com>");
+MODULE_AUTHOR("Priyaranjan Jha <priyarjha@google.com>");
+MODULE_AUTHOR("Yousuk Seung <ysseung@google.com>");
+MODULE_AUTHOR("Kevin Yang <yyd@google.com>");
+MODULE_AUTHOR("Arjun Roy <arjunroy@google.com>");
+MODULE_AUTHOR("David Morley <morleyd@google.com>");
+
 MODULE_LICENSE("Dual BSD/GPL");
 MODULE_DESCRIPTION("TCP BBR (Bottleneck Bandwidth and RTT)");
+MODULE_VERSION(__stringify(BBR_VERSION));
diff -rupN a/net/ipv4/tcp.c b/net/ipv4/tcp.c
--- a/net/ipv4/tcp.c	2025-06-01 18:01:58.000000000 +0200
+++ b/net/ipv4/tcp.c	2025-06-01 20:34:16.902110597 +0200
@@ -3442,6 +3442,7 @@ int tcp_disconnect(struct sock *sk, int
 	tp->rx_opt.dsack = 0;
 	tp->rx_opt.num_sacks = 0;
 	tp->rcv_ooopack = 0;
+	tp->fast_ack_mode = 0;
 
 
 	/* Clean up fastopen related fields */
@@ -4189,6 +4190,8 @@ void tcp_get_info(struct sock *sk, struc
 		info->tcpi_options |= TCPI_OPT_ECN;
 	if (tp->ecn_flags & TCP_ECN_SEEN)
 		info->tcpi_options |= TCPI_OPT_ECN_SEEN;
+	if (tp->ecn_flags & TCP_ECN_LOW)
+		info->tcpi_options |= TCPI_OPT_ECN_LOW;
 	if (tp->syn_data_acked)
 		info->tcpi_options |= TCPI_OPT_SYN_DATA;
 	if (tp->tcp_usec_ts)
@@ -5226,8 +5229,8 @@ void __init tcp_init(void)
 	tcp_init_mem();
 	/* Set per-socket limits to no more than 1/128 the pressure threshold */
 	limit = nr_free_buffer_pages() << (PAGE_SHIFT - 7);
-	max_wshare = min(4UL*1024*1024, limit);
-	max_rshare = min(32UL*1024*1024, limit);
+	max_wshare = min(16UL*1024*1024, limit);
+	max_rshare = min(16UL*1024*1024, limit);
 
 	init_net.ipv4.sysctl_tcp_wmem[0] = PAGE_SIZE;
 	init_net.ipv4.sysctl_tcp_wmem[1] = 16*1024;
diff -rupN a/net/ipv4/tcp_cong.c b/net/ipv4/tcp_cong.c
--- a/net/ipv4/tcp_cong.c	2025-06-01 18:01:58.000000000 +0200
+++ b/net/ipv4/tcp_cong.c	2025-06-01 20:34:16.902110597 +0200
@@ -237,6 +237,7 @@ void tcp_init_congestion_control(struct
 	struct inet_connection_sock *icsk = inet_csk(sk);
 
 	tcp_sk(sk)->prior_ssthresh = 0;
+	tcp_sk(sk)->fast_ack_mode = 0;
 	if (icsk->icsk_ca_ops->init)
 		icsk->icsk_ca_ops->init(sk);
 	if (tcp_ca_needs_ecn(sk))
diff -rupN a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
--- a/net/ipv4/tcp_input.c	2025-06-01 18:01:58.000000000 +0200
+++ b/net/ipv4/tcp_input.c	2025-06-01 20:34:16.906110629 +0200
@@ -381,7 +381,7 @@ static void tcp_data_ecn_check(struct so
 			tcp_enter_quickack_mode(sk, 2);
 		break;
 	case INET_ECN_CE:
-		if (tcp_ca_needs_ecn(sk))
+		if (tcp_ca_wants_ce_events(sk))
 			tcp_ca_event(sk, CA_EVENT_ECN_IS_CE);
 
 		if (!(tp->ecn_flags & TCP_ECN_DEMAND_CWR)) {
@@ -392,7 +392,7 @@ static void tcp_data_ecn_check(struct so
 		tp->ecn_flags |= TCP_ECN_SEEN;
 		break;
 	default:
-		if (tcp_ca_needs_ecn(sk))
+		if (tcp_ca_wants_ce_events(sk))
 			tcp_ca_event(sk, CA_EVENT_ECN_NO_CE);
 		tp->ecn_flags |= TCP_ECN_SEEN;
 		break;
@@ -1134,7 +1134,12 @@ static void tcp_verify_retransmit_hint(s
  */
 static void tcp_notify_skb_loss_event(struct tcp_sock *tp, const struct sk_buff *skb)
 {
+	struct sock *sk = (struct sock *)tp;
+	const struct tcp_congestion_ops *ca_ops = inet_csk(sk)->icsk_ca_ops;
+
 	tp->lost += tcp_skb_pcount(skb);
+	if (ca_ops->skb_marked_lost)
+		ca_ops->skb_marked_lost(sk, skb);
 }
 
 void tcp_mark_skb_lost(struct sock *sk, struct sk_buff *skb)
@@ -1506,6 +1511,17 @@ static bool tcp_shifted_skb(struct sock
 	WARN_ON_ONCE(tcp_skb_pcount(skb) < pcount);
 	tcp_skb_pcount_add(skb, -pcount);
 
+	/* Adjust tx.in_flight as pcount is shifted from skb to prev. */
+	if (WARN_ONCE(TCP_SKB_CB(skb)->tx.in_flight < pcount,
+		      "prev in_flight: %u skb in_flight: %u pcount: %u",
+		      TCP_SKB_CB(prev)->tx.in_flight,
+		      TCP_SKB_CB(skb)->tx.in_flight,
+		      pcount))
+		TCP_SKB_CB(skb)->tx.in_flight = 0;
+	else
+		TCP_SKB_CB(skb)->tx.in_flight -= pcount;
+	TCP_SKB_CB(prev)->tx.in_flight += pcount;
+
 	/* When we're adding to gso_segs == 1, gso_size will be zero,
 	 * in theory this shouldn't be necessary but as long as DSACK
 	 * code can come after this skb later on it's better to keep
@@ -3843,7 +3859,8 @@ static int tcp_replace_ts_recent(struct
 /* This routine deals with acks during a TLP episode and ends an episode by
  * resetting tlp_high_seq. Ref: TLP algorithm in draft-ietf-tcpm-rack
  */
-static void tcp_process_tlp_ack(struct sock *sk, u32 ack, int flag)
+static void tcp_process_tlp_ack(struct sock *sk, u32 ack, int flag,
+				struct rate_sample *rs)
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 
@@ -3860,6 +3877,7 @@ static void tcp_process_tlp_ack(struct s
 		/* ACK advances: there was a loss, so reduce cwnd. Reset
 		 * tlp_high_seq in tcp_init_cwnd_reduction()
 		 */
+		tcp_ca_event(sk, CA_EVENT_TLP_RECOVERY);
 		tcp_init_cwnd_reduction(sk);
 		tcp_set_ca_state(sk, TCP_CA_CWR);
 		tcp_end_cwnd_reduction(sk);
@@ -3870,6 +3888,11 @@ static void tcp_process_tlp_ack(struct s
 			     FLAG_NOT_DUP | FLAG_DATA_SACKED))) {
 		/* Pure dupack: original and TLP probe arrived; no loss */
 		tp->tlp_high_seq = 0;
+	} else {
+		/* This ACK matches a TLP retransmit. We cannot yet tell if
+		 * this ACK is for the original or the TLP retransmit.
+		 */
+		rs->is_acking_tlp_retrans_seq = 1;
 	}
 }
 
@@ -3989,6 +4012,7 @@ static int tcp_ack(struct sock *sk, cons
 
 	prior_fack = tcp_is_sack(tp) ? tcp_highest_sack_seq(tp) : tp->snd_una;
 	rs.prior_in_flight = tcp_packets_in_flight(tp);
+	tcp_rate_check_app_limited(sk);
 
 	/* ts_recent update must be made after we are sure that the packet
 	 * is in window.
@@ -4054,7 +4078,7 @@ static int tcp_ack(struct sock *sk, cons
 	tcp_in_ack_event(sk, flag);
 
 	if (tp->tlp_high_seq)
-		tcp_process_tlp_ack(sk, ack, flag);
+		tcp_process_tlp_ack(sk, ack, flag, &rs);
 
 	if (tcp_ack_is_dubious(sk, flag)) {
 		if (!(flag & (FLAG_SND_UNA_ADVANCED |
@@ -4078,6 +4102,7 @@ static int tcp_ack(struct sock *sk, cons
 	delivered = tcp_newly_delivered(sk, delivered, flag);
 	lost = tp->lost - lost;			/* freshly marked lost */
 	rs.is_ack_delayed = !!(flag & FLAG_ACK_MAYBE_DELAYED);
+	rs.is_ece = !!(flag & FLAG_ECE);
 	tcp_rate_gen(sk, delivered, lost, is_sack_reneg, sack_state.rate);
 	tcp_cong_control(sk, ack, delivered, flag, sack_state.rate);
 	tcp_xmit_recovery(sk, rexmit);
@@ -4098,7 +4123,7 @@ no_queue:
 	tcp_ack_probe(sk);
 
 	if (tp->tlp_high_seq)
-		tcp_process_tlp_ack(sk, ack, flag);
+		tcp_process_tlp_ack(sk, ack, flag, &rs);
 	return 1;
 
 old_ack:
@@ -5778,13 +5803,14 @@ static void __tcp_ack_snd_check(struct s
 
 	    /* More than one full frame received... */
 	if (((tp->rcv_nxt - tp->rcv_wup) > inet_csk(sk)->icsk_ack.rcv_mss &&
+	     (tp->fast_ack_mode == 1 ||
 	     /* ... and right edge of window advances far enough.
 	      * (tcp_recvmsg() will send ACK otherwise).
 	      * If application uses SO_RCVLOWAT, we want send ack now if
 	      * we have not received enough bytes to satisfy the condition.
 	      */
-	    (tp->rcv_nxt - tp->copied_seq < sk->sk_rcvlowat ||
-	     __tcp_select_window(sk) >= tp->rcv_wnd)) ||
+	      (tp->rcv_nxt - tp->copied_seq < sk->sk_rcvlowat ||
+	       __tcp_select_window(sk) >= tp->rcv_wnd))) ||
 	    /* We ACK each frame or... */
 	    tcp_in_quickack_mode(sk) ||
 	    /* Protocol state mandates a one-time immediate ACK */
diff -rupN a/net/ipv4/tcp_minisocks.c b/net/ipv4/tcp_minisocks.c
--- a/net/ipv4/tcp_minisocks.c	2025-06-01 18:01:58.000000000 +0200
+++ b/net/ipv4/tcp_minisocks.c	2025-06-01 20:34:16.906110629 +0200
@@ -475,6 +475,8 @@ void tcp_ca_openreq_child(struct sock *s
 	u32 ca_key = dst_metric(dst, RTAX_CC_ALGO);
 	bool ca_got_dst = false;
 
+	tcp_set_ecn_low_from_dst(sk, dst);
+
 	if (ca_key != TCP_CA_UNSPEC) {
 		const struct tcp_congestion_ops *ca;
 
diff -rupN a/net/ipv4/tcp_output.c b/net/ipv4/tcp_output.c
--- a/net/ipv4/tcp_output.c	2025-06-01 18:01:58.000000000 +0200
+++ b/net/ipv4/tcp_output.c	2025-06-01 20:34:16.907110637 +0200
@@ -339,10 +339,9 @@ static void tcp_ecn_send_syn(struct sock
 	bool bpf_needs_ecn = tcp_bpf_ca_needs_ecn(sk);
 	bool use_ecn = READ_ONCE(sock_net(sk)->ipv4.sysctl_tcp_ecn) == 1 ||
 		tcp_ca_needs_ecn(sk) || bpf_needs_ecn;
+	const struct dst_entry *dst = __sk_dst_get(sk);
 
 	if (!use_ecn) {
-		const struct dst_entry *dst = __sk_dst_get(sk);
-
 		if (dst && dst_feature(dst, RTAX_FEATURE_ECN))
 			use_ecn = true;
 	}
@@ -354,6 +353,9 @@ static void tcp_ecn_send_syn(struct sock
 		tcp_ecn_mode_set(tp, TCP_ECN_MODE_RFC3168);
 		if (tcp_ca_needs_ecn(sk) || bpf_needs_ecn)
 			INET_ECN_xmit(sk);
+
+		if (dst)
+			tcp_set_ecn_low_from_dst(sk, dst);
 	}
 }
 
@@ -391,7 +393,8 @@ static void tcp_ecn_send(struct sock *sk
 				th->cwr = 1;
 				skb_shinfo(skb)->gso_type |= SKB_GSO_TCP_ECN;
 			}
-		} else if (!tcp_ca_needs_ecn(sk)) {
+		} else if (!(tp->ecn_flags & TCP_ECN_ECT_PERMANENT) &&
+			!tcp_ca_needs_ecn(sk)) {
 			/* ACK or retransmitted segment: clear ECT|CE */
 			INET_ECN_dontxmit(sk);
 		}
@@ -1614,7 +1617,7 @@ int tcp_fragment(struct sock *sk, enum t
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct sk_buff *buff;
-	int old_factor;
+	int old_factor, inflight_prev;
 	long limit;
 	u16 flags;
 	int nlen;
@@ -1689,6 +1692,30 @@ int tcp_fragment(struct sock *sk, enum t
 
 		if (diff)
 			tcp_adjust_pcount(sk, skb, diff);
+
+		inflight_prev = TCP_SKB_CB(skb)->tx.in_flight - old_factor;
+		if (inflight_prev < 0) {
+			WARN_ONCE(tcp_skb_tx_in_flight_is_suspicious(
+					  old_factor,
+					  TCP_SKB_CB(skb)->sacked,
+					  TCP_SKB_CB(skb)->tx.in_flight),
+				  "inconsistent: tx.in_flight: %u "
+				  "old_factor: %d mss: %u sacked: %u "
+				  "1st pcount: %d 2nd pcount: %d "
+				  "1st len: %u 2nd len: %u ",
+				  TCP_SKB_CB(skb)->tx.in_flight, old_factor,
+				  mss_now, TCP_SKB_CB(skb)->sacked,
+				  tcp_skb_pcount(skb), tcp_skb_pcount(buff),
+				  skb->len, buff->len);
+			inflight_prev = 0;
+		}
+		/* Set 1st tx.in_flight as if 1st were sent by itself: */
+		TCP_SKB_CB(skb)->tx.in_flight = inflight_prev +
+						 tcp_skb_pcount(skb);
+		/* Set 2nd tx.in_flight with new 1st and 2nd pcounts: */
+		TCP_SKB_CB(buff)->tx.in_flight = inflight_prev +
+						 tcp_skb_pcount(skb) +
+						 tcp_skb_pcount(buff);
 	}
 
 	/* Link BUFF into the send queue. */
@@ -2045,13 +2072,12 @@ static u32 tcp_tso_autosize(const struct
 static u32 tcp_tso_segs(struct sock *sk, unsigned int mss_now)
 {
 	const struct tcp_congestion_ops *ca_ops = inet_csk(sk)->icsk_ca_ops;
-	u32 min_tso, tso_segs;
-
-	min_tso = ca_ops->min_tso_segs ?
-			ca_ops->min_tso_segs(sk) :
-			READ_ONCE(sock_net(sk)->ipv4.sysctl_tcp_min_tso_segs);
+	u32 tso_segs;
 
-	tso_segs = tcp_tso_autosize(sk, mss_now, min_tso);
+	tso_segs = ca_ops->tso_segs ?
+		ca_ops->tso_segs(sk, mss_now) :
+		tcp_tso_autosize(sk, mss_now,
+				 sock_net(sk)->ipv4.sysctl_tcp_min_tso_segs);
 	return min_t(u32, tso_segs, sk->sk_gso_max_segs);
 }
 
@@ -2776,6 +2802,7 @@ static bool tcp_write_xmit(struct sock *
 			skb_set_delivery_time(skb, tp->tcp_wstamp_ns, SKB_CLOCK_MONOTONIC);
 			list_move_tail(&skb->tcp_tsorted_anchor, &tp->tsorted_sent_queue);
 			tcp_init_tso_segs(skb, mss_now);
+			tcp_set_tx_in_flight(sk, skb);
 			goto repair; /* Skip network transmission */
 		}
 
@@ -2988,6 +3015,7 @@ void tcp_send_loss_probe(struct sock *sk
 	if (WARN_ON(!skb || !tcp_skb_pcount(skb)))
 		goto rearm_timer;
 
+	tp->tlp_orig_data_app_limited = TCP_SKB_CB(skb)->tx.is_app_limited;
 	if (__tcp_retransmit_skb(sk, skb, 1))
 		goto rearm_timer;
 
diff -rupN a/net/ipv4/tcp_rate.c b/net/ipv4/tcp_rate.c
--- a/net/ipv4/tcp_rate.c	2025-06-01 18:01:58.000000000 +0200
+++ b/net/ipv4/tcp_rate.c	2025-06-01 20:34:16.907110637 +0200
@@ -34,6 +34,24 @@
  * ready to send in the write queue.
  */
 
+void tcp_set_tx_in_flight(struct sock *sk, struct sk_buff *skb)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	u32 in_flight;
+
+	/* Check, sanitize, and record packets in flight after skb was sent. */
+	in_flight = tcp_packets_in_flight(tp) + tcp_skb_pcount(skb);
+	if (WARN_ONCE(in_flight > TCPCB_IN_FLIGHT_MAX,
+		      "insane in_flight %u cc %s mss %u "
+		      "cwnd %u pif %u %u %u %u\n",
+		      in_flight, inet_csk(sk)->icsk_ca_ops->name,
+		      tp->mss_cache, tp->snd_cwnd,
+		      tp->packets_out, tp->retrans_out,
+		      tp->sacked_out, tp->lost_out))
+		in_flight = TCPCB_IN_FLIGHT_MAX;
+	TCP_SKB_CB(skb)->tx.in_flight = in_flight;
+}
+
 /* Snapshot the current delivery information in the skb, to generate
  * a rate sample later when the skb is (s)acked in tcp_rate_skb_delivered().
  */
@@ -66,7 +84,9 @@ void tcp_rate_skb_sent(struct sock *sk,
 	TCP_SKB_CB(skb)->tx.delivered_mstamp	= tp->delivered_mstamp;
 	TCP_SKB_CB(skb)->tx.delivered		= tp->delivered;
 	TCP_SKB_CB(skb)->tx.delivered_ce	= tp->delivered_ce;
+	TCP_SKB_CB(skb)->tx.lost		= tp->lost;
 	TCP_SKB_CB(skb)->tx.is_app_limited	= tp->app_limited ? 1 : 0;
+	tcp_set_tx_in_flight(sk, skb);
 }
 
 /* When an skb is sacked or acked, we fill in the rate sample with the (prior)
@@ -91,18 +111,21 @@ void tcp_rate_skb_delivered(struct sock
 	if (!rs->prior_delivered ||
 	    tcp_skb_sent_after(tx_tstamp, tp->first_tx_mstamp,
 			       scb->end_seq, rs->last_end_seq)) {
+		rs->prior_lost	     = scb->tx.lost;
 		rs->prior_delivered_ce  = scb->tx.delivered_ce;
 		rs->prior_delivered  = scb->tx.delivered;
 		rs->prior_mstamp     = scb->tx.delivered_mstamp;
 		rs->is_app_limited   = scb->tx.is_app_limited;
 		rs->is_retrans	     = scb->sacked & TCPCB_RETRANS;
+		rs->tx_in_flight     = scb->tx.in_flight;
 		rs->last_end_seq     = scb->end_seq;
 
 		/* Record send time of most recently ACKed packet: */
 		tp->first_tx_mstamp  = tx_tstamp;
 		/* Find the duration of the "send phase" of this window: */
-		rs->interval_us = tcp_stamp_us_delta(tp->first_tx_mstamp,
-						     scb->tx.first_tx_mstamp);
+		rs->interval_us      = tcp_stamp32_us_delta(
+						tp->first_tx_mstamp,
+						scb->tx.first_tx_mstamp);
 
 	}
 	/* Mark off the skb delivered once it's sacked to avoid being
@@ -144,6 +167,7 @@ void tcp_rate_gen(struct sock *sk, u32 d
 		return;
 	}
 	rs->delivered   = tp->delivered - rs->prior_delivered;
+	rs->lost        = tp->lost - rs->prior_lost;
 
 	rs->delivered_ce = tp->delivered_ce - rs->prior_delivered_ce;
 	/* delivered_ce occupies less than 32 bits in the skb control block */
@@ -155,7 +179,7 @@ void tcp_rate_gen(struct sock *sk, u32 d
 	 * longer phase.
 	 */
 	snd_us = rs->interval_us;				/* send phase */
-	ack_us = tcp_stamp_us_delta(tp->tcp_mstamp,
+	ack_us = tcp_stamp32_us_delta(tp->tcp_mstamp,
 				    rs->prior_mstamp); /* ack phase */
 	rs->interval_us = max(snd_us, ack_us);
 
diff -rupN a/net/ipv4/tcp_timer.c b/net/ipv4/tcp_timer.c
--- a/net/ipv4/tcp_timer.c	2025-06-01 18:01:58.000000000 +0200
+++ b/net/ipv4/tcp_timer.c	2025-06-01 20:34:16.907110637 +0200
@@ -565,7 +565,7 @@ void tcp_retransmit_timer(struct sock *s
 		struct inet_sock *inet = inet_sk(sk);
 		u32 rtx_delta;
 
-		rtx_delta = tcp_time_stamp_ts(tp) - (tp->retrans_stamp ?: 
+		rtx_delta = tcp_time_stamp_ts(tp) - (tp->retrans_stamp ?:
 				tcp_skb_timestamp_ts(tp->tcp_usec_ts, skb));
 		if (tp->tcp_usec_ts)
 			rtx_delta /= USEC_PER_MSEC;
@@ -702,6 +702,8 @@ void tcp_write_timer_handler(struct sock
 			       icsk_timeout(icsk));
 		return;
 	}
+
+	tcp_rate_check_app_limited(sk);
 	tcp_mstamp_refresh(tcp_sk(sk));
 	event = icsk->icsk_pending;
 
diff -rupN a/samples/bpf/Makefile b/samples/bpf/Makefile
--- a/samples/bpf/Makefile	2025-06-01 18:01:58.000000000 +0200
+++ b/samples/bpf/Makefile	2025-06-01 20:34:16.910110661 +0200
@@ -143,7 +143,7 @@ endif
 endif
 
 ifeq ($(ARCH), x86)
-BPF_EXTRA_CFLAGS += -fcf-protection
+BPF_EXTRA_CFLAGS += -fcf-protection=none
 endif
 
 COMMON_CFLAGS += -Wall -O2
diff -rupN a/scripts/package/debian/rules b/scripts/package/debian/rules
--- a/scripts/package/debian/rules	2025-06-01 18:01:58.000000000 +0200
+++ b/scripts/package/debian/rules	2025-06-01 20:34:16.910110661 +0200
@@ -21,18 +21,14 @@ ifeq ($(origin KBUILD_VERBOSE),undefined
     endif
 endif
 
-revision = $(shell dpkg-parsechangelog -S Version | sed -n 's/.*-//p')
+revision = $(lastword $(subst -, ,$(shell dpkg-parsechangelog -S Version)))
 CROSS_COMPILE ?= $(filter-out $(DEB_BUILD_GNU_TYPE)-, $(DEB_HOST_GNU_TYPE)-)
-make-opts = ARCH=$(ARCH) KERNELRELEASE=$(KERNELRELEASE) \
-    $(addprefix KBUILD_BUILD_VERSION=,$(revision)) \
-    $(addprefix CROSS_COMPILE=,$(CROSS_COMPILE))
+make-opts = ARCH=$(ARCH) KERNELRELEASE=$(KERNELRELEASE) KBUILD_BUILD_VERSION=$(revision) $(addprefix CROSS_COMPILE=,$(CROSS_COMPILE))
 
-binary-targets := $(addprefix binary-, image image-dbg headers libc-dev)
+binary-targets := $(addprefix binary-, image headers)
 
 all-packages = $(shell dh_listpackages)
 image-package = $(filter linux-image-% user-%, $(filter-out %-dbg, $(all-packages)))
-image-dbg-package = $(filter %-dbg, $(all-packages))
-libc-dev-package = $(filter linux-libc-dev, $(all-packages))
 headers-package = $(filter linux-headers-%, $(all-packages))
 
 mk-files = $(patsubst binary-%,debian/%.files,$1)
@@ -43,10 +39,6 @@ package = $($(@:binary-%=%-package))
 # which package is being processed in the build log.
 DH_OPTIONS = -p$(package)
 
-# Note: future removal of KDEB_COMPRESS
-# dpkg-deb >= 1.21.10 supports the DPKG_DEB_COMPRESSOR_TYPE environment
-# variable, which provides the same functionality as KDEB_COMPRESS. The
-# KDEB_COMPRESS variable will be removed in the future.
 define binary
 	$(Q)dh_testdir $(DH_OPTIONS)
 	$(Q)dh_testroot $(DH_OPTIONS)
diff -rupN a/scripts/package/mkdebian b/scripts/package/mkdebian
--- a/scripts/package/mkdebian	2025-06-01 18:01:58.000000000 +0200
+++ b/scripts/package/mkdebian	2025-06-01 20:34:16.910110661 +0200
@@ -77,8 +77,6 @@ set_debarch() {
 			debarch=i386
 		fi
 		;;
-	loongarch64)
-		debarch=loong64 ;;
 	esac
 	if [ -z "$debarch" ]; then
 		debarch=$(dpkg-architecture -qDEB_HOST_ARCH)
@@ -157,12 +155,11 @@ while [ $# -gt 0 ]; do
 done
 
 # Some variables and settings used throughout the script
+version=$KERNELRELEASE
 if [ "${KDEB_PKGVERSION:+set}" ]; then
 	packageversion=$KDEB_PKGVERSION
 else
-	upstream_version=$("${srctree}/scripts/setlocalversion" --no-local "${srctree}" | sed 's/-\(rc[1-9]\)/~\1/')
-	debian_revision=$("${srctree}/scripts/build-version")
-	packageversion=${upstream_version}-${debian_revision}
+	packageversion=$(${srctree}/scripts/setlocalversion --no-local ${srctree})-$($srctree/scripts/build-version)
 fi
 sourcename=${KDEB_SOURCENAME:-linux-upstream}
 
@@ -215,53 +212,28 @@ Build-Depends-Arch: bc, bison, flex,
  python3:native, rsync
 Homepage: https://www.kernel.org/
 
-Package: $packagename-${KERNELRELEASE}
+Package: $packagename-$version
 Architecture: $debarch
-Description: Linux kernel, version ${KERNELRELEASE}
+Description: Linux kernel, version $version
  This package contains the Linux kernel, modules and corresponding other
- files, version: ${KERNELRELEASE}.
+ files, version: $version.
 EOF
 
 if [ "${SRCARCH}" != um ]; then
-cat <<EOF >> debian/control
-
-Package: linux-libc-dev
-Section: devel
-Provides: linux-kernel-headers
-Architecture: $debarch
-Description: Linux support headers for userspace development
- This package provides userspaces headers from the Linux kernel.  These headers
- are used by the installed headers for GNU glibc and other system libraries.
-Multi-Arch: same
-EOF
-
 if is_enabled CONFIG_MODULES; then
 cat <<EOF >> debian/control
 
-Package: linux-headers-${KERNELRELEASE}
+Package: linux-headers-$version
 Architecture: $debarch
 Build-Profiles: <!pkg.${sourcename}.nokernelheaders>
-Description: Linux kernel headers for ${KERNELRELEASE} on $debarch
- This package provides kernel header files for ${KERNELRELEASE} on $debarch
+Description: Linux kernel headers for $version on $debarch
+ This package provides kernel header files for $version on $debarch
  .
  This is useful for people who need to build external modules
 EOF
 fi
 fi
 
-if is_enabled CONFIG_DEBUG_INFO; then
-cat <<EOF >> debian/control
-
-Package: linux-image-${KERNELRELEASE}-dbg
-Section: debug
-Architecture: $debarch
-Build-Profiles: <!pkg.${sourcename}.nokerneldbg>
-Description: Linux kernel debugging symbols for ${KERNELRELEASE}
- This package will come in handy if you need to debug the kernel. It provides
- all the necessary debug symbols for the kernel and its modules.
-EOF
-fi
-
 cat <<EOF > debian/rules.vars
 ARCH := ${ARCH}
 KERNELRELEASE := ${KERNELRELEASE}
diff -rupN a/scripts/package/PKGBUILD b/scripts/package/PKGBUILD
--- a/scripts/package/PKGBUILD	2025-06-01 18:01:58.000000000 +0200
+++ b/scripts/package/PKGBUILD	2025-06-01 20:34:16.910110661 +0200
@@ -90,6 +90,11 @@ _package-headers() {
 		"${srctree}/scripts/package/install-extmod-build" "${builddir}"
 	fi
 
+	# required when DEBUG_INFO_BTF_MODULES is enabled
+	if [ -f tools/bpf/resolve_btfids/resolve_btfids ]; then
+		install -Dt "$builddir/tools/bpf/resolve_btfids" tools/bpf/resolve_btfids/resolve_btfids
+	fi
+
 	echo "Installing System.map and config..."
 	mkdir -p "${builddir}"
 	cp System.map "${builddir}/System.map"
diff -rupN a/drivers/block/zram/zram_drv.c b/drivers/block/zram/zram_drv.c
--- a/drivers/block/zram/zram_drv.c	2025-06-01 20:37:01.000000000 +0200
+++ b/drivers/block/zram/zram_drv.c	2025-06-02 14:55:36.320992128 +0200
@@ -60,6 +60,23 @@ static void zram_free_page(struct zram *
 static int zram_read_from_zspool(struct zram *zram, struct page *page,
 				 u32 index);
 
+#ifdef CONFIG_ZRAM_MULTI_COMP
+u8 __read_mostly sysctl_zram_recomp_immediate = 1;
+
+static const struct ctl_table zram_sysctl_table[] = {
+	{
+		.procname	= "zram_recomp_immediate",
+		.data		= &sysctl_zram_recomp_immediate,
+		.maxlen		= sizeof(u8),
+		.mode		= 0644,
+		.proc_handler	= proc_dou8vec_minmax,
+		.extra1		= SYSCTL_ZERO,
+		.extra2		= SYSCTL_THREE,
+	},
+};
+static struct ctl_table_header *zram_sysctl_table_header;
+#endif //CONFIG_ZRAM_MULTI_COMP
+
 #define slot_dep_map(zram, index) (&(zram)->table[(index)].dep_map)
 
 static void zram_slot_lock_init(struct zram *zram, u32 index)
@@ -1792,7 +1809,7 @@ static int write_same_filled_page(struct
 }
 
 static int write_incompressible_page(struct zram *zram, struct page *page,
-				     u32 index)
+				     u32 index, u8 prio)
 {
 	unsigned long handle;
 	void *src;
@@ -1821,6 +1838,7 @@ static int write_incompressible_page(str
 	zram_set_flag(zram, index, ZRAM_HUGE);
 	zram_set_handle(zram, index, handle);
 	zram_set_obj_size(zram, index, PAGE_SIZE);
+	zram_set_priority(zram, index, prio);
 	zram_slot_unlock(zram, index);
 
 	atomic64_add(PAGE_SIZE, &zram->stats.compr_data_size);
@@ -1837,9 +1855,13 @@ static int zram_write_page(struct zram *
 	unsigned long handle;
 	unsigned int comp_len;
 	void *mem;
-	struct zcomp_strm *zstrm;
+	struct zcomp_strm *zstrm = NULL;
 	unsigned long element;
 	bool same_filled;
+	u8 prio, prio_max = zram->num_active_comps;
+#ifdef CONFIG_ZRAM_MULTI_COMP
+	prio_max = min(prio_max, sysctl_zram_recomp_immediate + 1);
+#endif //CONFIG_ZRAM_MULTI_COMP
 
 	/* First, free memory allocated to this slot (if any) */
 	zram_slot_lock(zram, index);
@@ -1852,49 +1874,68 @@ static int zram_write_page(struct zram *
 	if (same_filled)
 		return write_same_filled_page(zram, element, index);
 
-	zstrm = zcomp_stream_get(zram->comps[ZRAM_PRIMARY_COMP]);
-	mem = kmap_local_page(page);
-	ret = zcomp_compress(zram->comps[ZRAM_PRIMARY_COMP], zstrm,
-			     mem, &comp_len);
-	kunmap_local(mem);
+	for (prio = ZRAM_PRIMARY_COMP; prio < prio_max; prio++) {
+		if (!zram->comps[prio])
+			continue;
+
+		zstrm = zcomp_stream_get(zram->comps[prio]);
+		mem = kmap_local_page(page);
+		ret = zcomp_compress(zram->comps[prio], zstrm,
+				     mem, &comp_len);
+		kunmap_local(mem);
+
+		if (unlikely(ret)) {
+			pr_err("Compression failed! err=%d\n", ret);
+			goto out;
+		}
+
+		if (comp_len < huge_class_size)
+			break;
 
-	if (unlikely(ret)) {
 		zcomp_stream_put(zstrm);
-		pr_err("Compression failed! err=%d\n", ret);
-		return ret;
+		zstrm = NULL;
 	}
 
-	if (comp_len >= huge_class_size) {
-		zcomp_stream_put(zstrm);
-		return write_incompressible_page(zram, page, index);
+	if (!zstrm) {
+		if (prio >= zram->num_active_comps) {
+			zram_slot_lock(zram, index);
+			zram_set_flag(zram, index, ZRAM_INCOMPRESSIBLE);
+			zram_slot_unlock(zram, index);
+		}
+
+		ret = write_incompressible_page(zram, page, index, prio - 1);
+		goto out;
 	}
 
 	handle = zs_malloc(zram->mem_pool, comp_len,
 			   GFP_NOIO | __GFP_NOWARN |
 			   __GFP_HIGHMEM | __GFP_MOVABLE, page_to_nid(page));
 	if (IS_ERR_VALUE(handle)) {
-		zcomp_stream_put(zstrm);
-		return PTR_ERR((void *)handle);
+		ret = PTR_ERR((void *)handle);
+		goto out;
 	}
 
 	if (!zram_can_store_page(zram)) {
-		zcomp_stream_put(zstrm);
 		zs_free(zram->mem_pool, handle);
-		return -ENOMEM;
+		ret = -ENOMEM;
+		goto out;
 	}
 
 	zs_obj_write(zram->mem_pool, handle, zstrm->buffer, comp_len);
-	zcomp_stream_put(zstrm);
 
 	zram_slot_lock(zram, index);
 	zram_set_handle(zram, index, handle);
 	zram_set_obj_size(zram, index, comp_len);
+	zram_set_priority(zram, index, prio);
 	zram_slot_unlock(zram, index);
 
 	/* Update stats */
 	atomic64_inc(&zram->stats.pages_stored);
 	atomic64_add(comp_len, &zram->stats.compr_data_size);
 
+out:
+	if (zstrm)
+		zcomp_stream_put(zstrm);
 	return ret;
 }
 
@@ -2899,6 +2940,15 @@ static int __init zram_init(void)
 		num_devices--;
 	}
 
+#ifdef CONFIG_ZRAM_MULTI_COMP
+#define ZRAM_IR_VERSION "1.2"
+#define ZRAM_IR_PROGNAME "ZRAM Immediate Recompression (ZRAM-IR)"
+#define ZRAM_IR_AUTHOR   "Masahito Suzuki"
+	printk(KERN_INFO "%s %s by %s\n",
+		ZRAM_IR_PROGNAME, ZRAM_IR_VERSION, ZRAM_IR_AUTHOR);
+	zram_sysctl_table_header = register_sysctl("vm", zram_sysctl_table);
+#endif //CONFIG_ZRAM_MULTI_COMP
+
 	return 0;
 
 out_error:
@@ -2908,6 +2958,10 @@ out_error:
 
 static void __exit zram_exit(void)
 {
+#ifdef CONFIG_ZRAM_MULTI_COMP
+	unregister_sysctl_table(zram_sysctl_table_header);
+#endif //CONFIG_ZRAM_MULTI_COMP
+
 	destroy_devices();
 }
 
